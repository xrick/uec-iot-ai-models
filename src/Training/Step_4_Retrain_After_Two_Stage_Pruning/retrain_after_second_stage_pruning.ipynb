{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dece0a29-4e80-4f04-8716-a3a060b6ab76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys;\n",
    "import os;\n",
    "import glob;\n",
    "import math;\n",
    "import numpy as np;\n",
    "import glob;\n",
    "import random;\n",
    "import time;\n",
    "import torch;\n",
    "import torch.optim as optim;\n",
    "import torch.nn as nn;\n",
    "\n",
    "sys.path.append(os.getcwd());\n",
    "sys.path.append(os.path.abspath('../../'));\n",
    "sys.path.append(os.path.abspath('../../../'));\n",
    "# sys.path.append(os.path.join(os.getcwd(), 'torch/resources'));\n",
    "import common.utils as U;\n",
    "import common.opts as opts;\n",
    "# import resources.models as models;\n",
    "import th.resources.calculator as calc;\n",
    "import common.tlopts as tlopts\n",
    "# import resources.train_generator as train_generator;\n",
    "import argparse\n",
    "from itertools import repeat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31578c7c-79a0-49e4-b8e8-4cf55b46bdc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import th.resources.models as models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b4f34949-d5aa-40ed-9a2c-8a136ed6167d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from SharedLibs.datestring import genDataTimeStr, getDateStr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "535bc4f7-f67b-4f43-85ea-e34f58b98dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reproducibility\n",
    "seed = 42;\n",
    "random.seed(seed);\n",
    "np.random.seed(seed);\n",
    "torch.manual_seed(seed);\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(seed);\n",
    "torch.backends.cudnn.deterministic = True;\n",
    "torch.backends.cudnn.benchmark = False;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f27081b-4cf2-4869-a6e3-536c75e8c98b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de6c6706-54fd-4d98-a7ab-1a5cfdda39e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "second_pruned_model = \"../../../trained_models/step_4_second_stage_pruning/valacc_95.34_tracc90_pruning_time_2024050216_prunratio85.0/model_second_stage_prun_ratio0.85_20240502164638.pt\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d69bad84-dd6d-4070-b92b-084d63c9ace0",
   "metadata": {},
   "source": [
    "## define the variables opt and set values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ba27122-464f-4a2d-a88a-98d73c578782",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getOpts():\n",
    "    parser = argparse.ArgumentParser(description='Transfer Learning for ACDNet');\n",
    "    parser.add_argument('--netType', default='ACDNetV2',  required=False);\n",
    "    parser.add_argument('--data', default='trainSet',  required=False);\n",
    "    parser.add_argument('--dataset', required=False, default='uec_iot', choices=['2']);\n",
    "    parser.add_argument('--BC', default=True, action='store_true', help='BC learning');\n",
    "    parser.add_argument('--strongAugment', default=True,  action='store_true', help='Add scale and gain augmentation');\n",
    "    #在ipynb中，不能使用parser.parse，要改用parser.parse_known_args()\n",
    "    opt, unknown = parser.parse_known_args();\n",
    "    return opt\n",
    "    # opt = parser.parse_args();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52beb2fa-e0f7-415f-bbad-9de7cb7515c8",
   "metadata": {},
   "source": [
    "## Define the Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "907bea9b-fa07-4a6e-8eb3-7695dda56452",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TLGenerator():\n",
    "    #Generates data for Keras\n",
    "    def __init__(self, samples=None, labels=None, options=None, classes_dict=None):\n",
    "        random.seed(42);\n",
    "        #Initialization\n",
    "        print(f\"length of samples:{len(samples)}\")\n",
    "        self.data = [(samples[i], labels[i]) for i in range (0, len(samples))];\n",
    "        self.opt = options;\n",
    "        self.batch_size = options.batchSize;\n",
    "        self.preprocess_funcs = self.preprocess_setup();\n",
    "        self.mapdict = classes_dict\n",
    "\n",
    "    def __len__(self):\n",
    "        #Denotes the number of batches per epoch\n",
    "        return int(np.floor(len(self.data) / self.batch_size));\n",
    "        #return len(self.samples);\n",
    "\n",
    "    def __getitem__(self, batchIndex):\n",
    "        #Generate one batch of data\n",
    "        batchX, batchY = self.generate_batch(batchIndex);\n",
    "        batchX = np.expand_dims(batchX, axis=1);\n",
    "        batchX = np.expand_dims(batchX, axis=3);\n",
    "        return batchX, batchY\n",
    "\n",
    "    def generate_batch(self, batchIndex):\n",
    "        #Generates data containing batch_size samples\n",
    "        sounds = [];\n",
    "        labels = [];\n",
    "        indexes = None;\n",
    "        for i in range(self.batch_size):\n",
    "            # Training phase of BC learning\n",
    "            # Select two training examples\n",
    "            while True:\n",
    "                sound1, label1 = self.data[random.randint(0, len(self.data) - 1)]\n",
    "                sound2, label2 = self.data[random.randint(0, len(self.data) - 1)]\n",
    "                if label1 != label2:\n",
    "                    break\n",
    "            sound1 = self.preprocess(sound1)\n",
    "            sound2 = self.preprocess(sound2)\n",
    "\n",
    "            # Mix two examples\n",
    "            r = np.array(random.random())\n",
    "            sound = U.mix(sound1, sound2, r, self.opt.sr).astype(np.float32)\n",
    "            # print(f\"sound length after U.mix is {len(sound)}\")\n",
    "            # print(f\"nClasses:{self.opt.nClasses}, type of mapdict:{type(self.mapdict)}, type of label1:{type(label1)}\")\n",
    "            eye = np.eye(self.opt.nClasses)\n",
    "            idx1 = self.mapdict[str(label1)]- 1\n",
    "            idx2 = self.mapdict[str(label2)] - 1\n",
    "            label = (eye[idx1] * r + eye[idx2] * (1 - r)).astype(np.float32)\n",
    "            # label = (eye[label1] * r + eye[label2] * (1 - r)).astype(np.float32)\n",
    "\n",
    "            #For stronger augmentation\n",
    "            sound = U.random_gain(6)(sound).astype(np.float32)\n",
    "            # print(f\"sound length after U.random_gain is {len(sound)}\")\n",
    "            sounds.append(sound);\n",
    "            labels.append(label);\n",
    "\n",
    "        sounds = np.asarray(sounds);\n",
    "        labels = np.asarray(labels);\n",
    "        # print(f\"batchIndex is {batchIndex}, total sounds is {len(sounds)}\")\n",
    "        # print(f\"labels in generate_batch is:\\n{labels}\")\n",
    "\n",
    "        return sounds, labels;\n",
    "\n",
    "    def preprocess_setup(self):\n",
    "        funcs = []\n",
    "        if self.opt.strongAugment:\n",
    "            funcs += [U.random_scale(1.25)]\n",
    "\n",
    "        funcs += [U.padding(self.opt.inputLength // 2),\n",
    "                  U.random_crop(self.opt.inputLength),\n",
    "                  U.normalize(32768.0)]\n",
    "        return funcs\n",
    "\n",
    "    def preprocess(self, sound):\n",
    "        for f in self.preprocess_funcs:\n",
    "            sound = f(sound)\n",
    "\n",
    "        return sound;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55b826e1-9169-4891-a0e2-735b417983fd",
   "metadata": {},
   "source": [
    "## Define Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e5238bdf-26a1-44b1-bcf9-0d9e196417de",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReTrainer:\n",
    "    def __init__(self, opt=None, classes_dict=None):\n",
    "        self.opt = opt;\n",
    "        self.testX = None;\n",
    "        self.testY = None;\n",
    "        self.bestAcc = 0.0;\n",
    "        self.bestAccEpoch = 0;\n",
    "        self.trainGen = getTrainGen(opt,classes_dict=classes_dict)#train_generator.setup(opt, split);\n",
    "        # self.opt.trainer = self;\n",
    "        # self.trainGen = getTrainGen(self.opt, self.opt.splits)#train_generator.setup(self.opt, self.opt.split);\n",
    "        # self.pretrainedmodelpath = \"./resources/pretrained_models/acdnet20_20khz_fold4.h5\"\n",
    "\n",
    "    def Train(self):\n",
    "        train_start_time = time.time();\n",
    "        state = torch.load(second_pruned_model, map_location=\"cuda:0\")\n",
    "        weights = state['weight']\n",
    "        config = state['config']\n",
    "        print(f\"config is {config}\")\n",
    "        net = models.GetACDNetModel(input_len=30225, sr=20000, nclass=self.opt.nClasses, channel_config=config)\n",
    "        net.load_state_dict(weights);\n",
    "         #show the acdnet structures\n",
    "        calc.summary(net,(1,1,30225))\n",
    "        # net = getPrunedModel(pruned_model_path=pruned_acdnet)\n",
    "        #print networks parameters' require_grade value\n",
    "        for k_, v_ in net.named_parameters():\n",
    "            print(f\"{k_}:{v_.requires_grad}\")\n",
    "        print('ACDNet model has been prepared for training');\n",
    "\n",
    "        calc.summary(net, (1,1,self.opt.inputLength));\n",
    "        # net = net.cuda();\n",
    "        # training_text = \"Re-Training\" if self.opt.retrain else \"Training from Scratch\";\n",
    "        # print(\"{} has been started. You will see update after finishing every training epoch and validation\".format(training_text));\n",
    "\n",
    "        lossFunc = torch.nn.KLDivLoss(reduction='batchmean');\n",
    "        optimizer = optim.SGD(net.parameters(), lr=self.opt.LR, weight_decay=self.opt.weightDecay, momentum=self.opt.momentum, nesterov=True);\n",
    "\n",
    "        # self.opt.nEpochs = 1957 if self.opt.split == 4 else 2000;\n",
    "        for epochIdx in range(self.opt.nEpochs):\n",
    "            epoch_start_time = time.time();\n",
    "            optimizer.param_groups[0]['lr'] = self.__get_lr(epochIdx+1);\n",
    "            cur_lr = optimizer.param_groups[0]['lr'];\n",
    "            running_loss = 0.0;\n",
    "            running_acc = 0.0;\n",
    "            n_batches = math.ceil(len(self.trainGen.data)/self.opt.batchSize);\n",
    "            for batchIdx in range(n_batches):\n",
    "                # with torch.no_grad():\n",
    "                x,y = self.trainGen.__getitem__(batchIdx)\n",
    "                x = torch.tensor(np.moveaxis(x, 3, 1)).to(self.opt.device);\n",
    "                y = torch.tensor(y).to(self.opt.device);\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad();\n",
    "\n",
    "                # forward + backward + optimize\n",
    "                # outputs = net(x);#in office and use cpu\n",
    "                x = x.type(torch.FloatTensor) #use apple m2\n",
    "                outputs = net(x)\n",
    "                # in office use cpu, need to change to cuda\n",
    "                # running_acc += (((outputs.data.argmax(dim=1) == y.argmax(dim=1))*1).float().mean()).item();\n",
    "                # at home use apple m2\n",
    "                res_y = y.argmax(dim=1)\n",
    "                res_y = res_y.type(torch.FloatTensor)\n",
    "                running_acc += ((( outputs.data.argmax(dim=1) == res_y)*1).float().mean()).item();\n",
    "                y = y.type(torch.FloatTensor)\n",
    "                \n",
    "                loss = lossFunc(outputs.log(), y);\n",
    "                loss.backward();\n",
    "                optimizer.step();\n",
    "\n",
    "                running_loss += loss.item();\n",
    "\n",
    "            tr_acc = (running_acc / n_batches)*100;\n",
    "            tr_loss = running_loss / n_batches;\n",
    "\n",
    "            #Epoch wise validation Validation\n",
    "            epoch_train_time = time.time() - epoch_start_time;\n",
    "\n",
    "            net.eval();\n",
    "            val_acc, val_loss = self.__validate(net, lossFunc);\n",
    "            #Save best model\n",
    "            self.__save_model(val_acc, epochIdx, net);\n",
    "            self.__on_epoch_end(epoch_start_time, epoch_train_time, epochIdx, cur_lr, tr_loss, tr_acc, val_loss, val_acc);\n",
    "\n",
    "            running_loss = 0;\n",
    "            running_acc = 0;\n",
    "            net.train();\n",
    "\n",
    "        total_time_taken = time.time() - train_start_time;\n",
    "        print(\"Execution finished in: {}\".format(U.to_hms(total_time_taken)));\n",
    "\n",
    "    def load_test_data(self):\n",
    "        # data = np.load(os.path.join(self.opt.data, self.opt.dataset, 'test_data_{}khz/fold{}_test4000.npz'.format(self.opt.sr//1000, self.opt.split)), allow_pickle=True);\n",
    "        data = np.load(self.opt.valData, allow_pickle=True);\n",
    "        print(f\"device is :{self.opt.device}\")\n",
    "        print(f\"len of Y:{len(data['y'])}\")\n",
    "        # self.testX = torch.tensor(np.moveaxis(data['x'], 3, 1)).to(self.opt.device);\n",
    "        dataX = np.moveaxis(data['x'], 3, 1).astype(np.float32);\n",
    "        self.testX = torch.tensor(dataX).to(self.opt.device);\n",
    "        self.testY = torch.tensor(data['y']).type(torch.float32).to(self.opt.device);\n",
    "\n",
    "    def __get_lr(self, epoch):\n",
    "        divide_epoch = np.array([self.opt.nEpochs * i for i in self.opt.schedule]);\n",
    "        decay = sum(epoch > divide_epoch);\n",
    "        if epoch <= self.opt.warmup:\n",
    "            decay = 1;\n",
    "        return self.opt.LR * np.power(0.1, decay);\n",
    "\n",
    "    def __get_batch(self, index):\n",
    "        x = self.trainX[index*self.opt.batchSize : (index+1)*self.opt.batchSize];\n",
    "        y = self.trainY[index*self.opt.batchSize : (index+1)*self.opt.batchSize];\n",
    "        return x.to(self.opt.device), y.to(self.opt.device);\n",
    "\n",
    "    def __validate(self, net, lossFunc):\n",
    "        if self.testX is None:\n",
    "            self.load_test_data();\n",
    "        net.eval();\n",
    "        with torch.no_grad():\n",
    "            y_pred = None;\n",
    "            batch_size = len(self.testX);#(self.opt.batchSize//self.opt.nCrops)*self.opt.nCrops;\n",
    "#             for idx in range(math.ceil(len(self.testX)/batch_size)):\n",
    "#             for idx in range(len(self.testX)):\n",
    "#             x = self.testX[idx*batch_size : (idx+1)*batch_size];\n",
    "            x = self.testX[:];\n",
    "            x = torch.tensor(x)\n",
    "            x = x.type(torch.FloatTensor) # use apple mp2\n",
    "            scores = net(x);\n",
    "            y_pred = scores.data if y_pred is None else torch.cat((y_pred, scores.data));\n",
    "            acc, loss = self.__compute_accuracy(y_pred, self.testY, lossFunc);\n",
    "#         with torch.no_grad():\n",
    "#             y_pred = None;\n",
    "#             batch_size = (self.opt.batchSize//self.opt.nCrops)*self.opt.nCrops;\n",
    "#             for idx in range(math.ceil(len(self.testX)/batch_size)):\n",
    "#                 x = self.testX[idx*batch_size : (idx+1)*batch_size];\n",
    "#                 scores = net(x);\n",
    "#                 y_pred = scores.data if y_pred is None else torch.cat((y_pred, scores.data));\n",
    "\n",
    "#             acc, loss = self.__compute_accuracy(y_pred, self.testY, lossFunc);\n",
    "        net.train();\n",
    "        return acc, loss;\n",
    "\n",
    "    #Calculating average prediction (10 crops) and final accuracy\n",
    "    def __compute_accuracy(self, y_pred, y_target, lossFunc):\n",
    "        print(f\"shape of y_pred:{y_pred.shape}\");\n",
    "        print(f\"shape of y_target:{y_target.shape}\");\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            #Reshape to shape theme like each sample comtains 10 samples, calculate mean and find theindices that has highest average value for each sample\n",
    "            if self.opt.nCrops == 1:\n",
    "                y_pred = y_pred.argmax(dim=1);\n",
    "                y_target = y_target.argmax(dim=1);\n",
    "            else:\n",
    "                y_pred = (y_pred.reshape(y_pred.shape[0]//self.opt.nCrops, self.opt.nCrops, y_pred.shape[1])).mean(dim=1).argmax(dim=1);\n",
    "                y_target = (y_target.reshape(y_target.shape[0]//self.opt.nCrops, self.opt.nCrops, y_target.shape[1])).mean(dim=1).argmax(dim=1);\n",
    "                print(f\"after: len of y_pred:{len(y_pred)}, len of y_target:{len(y_target)}\")\n",
    "            y_target = y_target.cpu() #use apple m2, in office use cuda\n",
    "            acc = (((y_pred==y_target)*1).float().mean()*100).item();\n",
    "            # valLossFunc = torch.nn.KLDivLoss();\n",
    "            loss = lossFunc(y_pred.float().log(), y_target.float()).item();\n",
    "            # loss = 0.0;\n",
    "        return acc, loss;\n",
    "\n",
    "    def __on_epoch_end(self, start_time, train_time, epochIdx, lr, tr_loss, tr_acc, val_loss, val_acc):\n",
    "        epoch_time = time.time() - start_time;\n",
    "        val_time = epoch_time - train_time;\n",
    "        line = 'SP-{} Epoch: {}/{} | Time: {} (Train {}  Val {}) | Train: LR {}  Loss {:.2f}  Acc {:.2f}% | Val: Loss {:.2f}  Acc(top1) {:.2f}% | HA {:.2f}@{}\\n'.format(\n",
    "            self.opt.splits, epochIdx+1, self.opt.nEpochs, U.to_hms(epoch_time), U.to_hms(train_time), U.to_hms(val_time),\n",
    "            lr, tr_loss, tr_acc, val_loss, val_acc, self.bestAcc, self.bestAccEpoch);\n",
    "        # print(line)\n",
    "        sys.stdout.write(line);\n",
    "        sys.stdout.flush();\n",
    "\n",
    "    def __save_model(self, acc, epochIdx, net):\n",
    "        if acc > self.bestAcc:\n",
    "            # dir = os.getcwd();\n",
    "            # fname = \"{}/torch/trained_models/{}_fold{}.pt\";\n",
    "            # old_model = fname.format(dir, self.opt.model_name.lower(), self.opt.split);\n",
    "            # if os.path.isfile(old_model):\n",
    "            #     os.remove(old_model);\n",
    "            self.bestAcc = acc;\n",
    "            self.bestAccEpoch = epochIdx +1;\n",
    "            save_model_name = self.opt.model_name.format(self.opt.pruningRatio*100,acc, epochIdx, genDataTimeStr());\n",
    "            save_model_fullpath = self.opt.saveDir + save_model_name;\n",
    "            print(f\"save model to {save_model_fullpath}\")\n",
    "            torch.save({'weight':net.state_dict(), 'config':net.ch_config}, save_model_fullpath);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "41565b1f-8241-432c-8413-303e4e4adb3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTrainGen(opt=None, split=None, classes_dict=None):\n",
    "    dataset = np.load(opt.trainData, allow_pickle=True);\n",
    "    train_sounds = []\n",
    "    train_labels = []\n",
    "    train_sounds = dataset['fold{}'.format(1)].item()['sounds']\n",
    "    train_labels = dataset['fold{}'.format(1)].item()['labels']\n",
    "    trainGen = TLGenerator(train_sounds, train_labels, opt, classes_dict=classes_dict);\n",
    "    trainGen.preprocess_setup();\n",
    "    return trainGen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "768ed5bd-b525-463e-b657-d6ce133eef24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' recording training settings and results\\nweight-pruning-ratio:\\nfinal acc:93.03\\nepoch:539\\nopt.batchSize = 32;\\nopt.LR = 0.05;\\nopt.weightDecay = 5e-3;\\nopt.momentum = 0.04;\\nopt.nEpochs = 1000;\\nopt.schedule = [0.15, 0.3, 0.45];\\nopt.warmup = 10;\\n------------------------------------\\n\\n------------------------------------\\n\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" recording training settings and results\n",
    "weight-pruning-ratio:\n",
    "final acc:93.03\n",
    "epoch:539\n",
    "opt.batchSize = 32;\n",
    "opt.LR = 0.05;\n",
    "opt.weightDecay = 5e-3;\n",
    "opt.momentum = 0.04;\n",
    "opt.nEpochs = 1000;\n",
    "opt.schedule = [0.15, 0.3, 0.45];\n",
    "opt.warmup = 10;\n",
    "------------------------------------\n",
    "\n",
    "------------------------------------\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3c5bbd80-1736-4c5a-b81d-244c4322f891",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nepoch:93\\nacc:\\nopt.batchSize = 64;\\nopt.LR = 0.1;\\nopt.weightDecay = 5e-3;\\nopt.momentum = 0.09;\\nopt.nEpochs = 1000;\\nopt.schedule = [0.03, 0.06, 0.09];\\nopt.warmup = 10;\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "epoch:93\n",
    "acc:\n",
    "opt.batchSize = 64;\n",
    "opt.LR = 0.1;\n",
    "opt.weightDecay = 5e-3;\n",
    "opt.momentum = 0.09;\n",
    "opt.nEpochs = 1000;\n",
    "opt.schedule = [0.03, 0.06, 0.09];\n",
    "opt.warmup = 10;\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "39c19cf2-18cf-4701-8c01-98235611d59d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    map_dict_train = {\n",
    "        '52':1, #alarm\n",
    "        '56':2, #moaning\n",
    "        '99':3, #other_sounds\n",
    "    };\n",
    "    \n",
    "    opt = getOpts();\n",
    "    opt.pruningRatio = 0.85\n",
    "    save_dir = \"../../../trained_models/step_5_retrain_after_step_4/train_after_second_pruning_prunratio{}_{}/\".format(opt.pruningRatio,getDateStr());\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.mkdir(save_dir)\n",
    "    print(f\"save dir is: {save_dir}\");\n",
    "    opt.trainData = \"../../../datasets/CurrentUse/generated_datasets/train/version4/single_fold_train_20240502114607.npz\"\n",
    "    opt.valData = \"../../../datasets/CurrentUse/generated_datasets/val/version4/final_single_val_20240502120516.npz\"\n",
    "    #Leqarning settings\n",
    "    \n",
    "    opt.batchSize = 64;\n",
    "    opt.LR = 0.1;\n",
    "    opt.weightDecay = 5e-3;\n",
    "    opt.momentum = 0.9;\n",
    "    opt.nEpochs = 1200;\n",
    "    opt.schedule = [0.3, 0.6, 0.9];\n",
    "    opt.warmup = 10;\n",
    "    \n",
    "    opt.saveDir = save_dir;\n",
    "    # opt.device=\"mps\";\n",
    "    # if torch.backends.mps.is_available():\n",
    "    #     opt.device=\"mps\"; #for apple m2 gpu\n",
    "    if torch.cuda.is_available():\n",
    "        opt.device=\"cuda:0\"; #for nVidia gpu\n",
    "    else:\n",
    "        opt.device=\"cpu\"\n",
    "    print(f\"***Use device:{opt.device}\");\n",
    "    # opt.device = torch.device(\"cuda:0\" if  else \"cpu\");\n",
    "    #Basic Net Settings\n",
    "    opt.nClasses = 3\n",
    "    opt.nFolds = 1;\n",
    "    opt.splits = [i for i in range(1, opt.nFolds + 1)];\n",
    "    opt.sr = 20000;\n",
    "    opt.inputLength = 30225;\n",
    "    #Test data\n",
    "    opt.nCrops = 2;\n",
    "    opt.model_name = \"retrained_model_after_second_pruning_ratio{}_acc{}_{}th_epoch_{}.pt\"\n",
    "    #Starting retraining process\n",
    "    trainer = ReTrainer(opt=opt, classes_dict=map_dict_train);\n",
    "    trainer.Train();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec08f2f-2bb7-489c-bba6-b88d9f5dd4db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save dir is: ../../../trained_models/step_5_retrain_after_step_4/train_after_second_pruning_prunratio0.85_2024050309/\n",
      "***Use device:cuda:0\n",
      "length of samples:651\n",
      "config is [5, 32, 10, 8, 17, 18, 27, 39, 34, 41, 72, 3]\n",
      "+----------------------------------------------------------------------------+\n",
      "+                           Pytorch Model Summary                            +\n",
      "------------------------------------------------------------------------------\n",
      "   Layer (type)       Input Shape      Output Shape    Param #      FLOPS #\n",
      "==============================================================================\n",
      "       Conv2d-1     (1, 1, 30225)     (5, 1, 15109)         45      679,905\n",
      "  BatchNorm2d-2     (5, 1, 15109)     (5, 1, 15109)         10            0\n",
      "         ReLu-3     (5, 1, 15109)     (5, 1, 15109)          0       75,545\n",
      "       Conv2d-4     (5, 1, 15109)     (32, 1, 7553)        800    6,042,400\n",
      "  BatchNorm2d-5     (32, 1, 7553)     (32, 1, 7553)         64            0\n",
      "         ReLu-6     (32, 1, 7553)     (32, 1, 7553)          0      241,696\n",
      "    MaxPool2d-7     (32, 1, 7553)      (32, 1, 151)          0      241,600\n",
      "      Permute-8      (32, 1, 151)      (1, 32, 151)          0            0\n",
      "       Conv2d-9      (1, 32, 151)     (10, 32, 151)         90      434,880\n",
      " BatchNorm2d-10     (10, 32, 151)     (10, 32, 151)         20            0\n",
      "        ReLu-11     (10, 32, 151)     (10, 32, 151)          0       48,320\n",
      "   MaxPool2d-12     (10, 32, 151)      (10, 16, 75)          0       48,000\n",
      "      Conv2d-13      (10, 16, 75)       (8, 16, 75)        720      864,000\n",
      " BatchNorm2d-14       (8, 16, 75)       (8, 16, 75)         16            0\n",
      "        ReLu-15       (8, 16, 75)       (8, 16, 75)          0        9,600\n",
      "      Conv2d-16       (8, 16, 75)      (17, 16, 75)      1,224    1,468,800\n",
      " BatchNorm2d-17      (17, 16, 75)      (17, 16, 75)         34            0\n",
      "        ReLu-18      (17, 16, 75)      (17, 16, 75)          0       20,400\n",
      "   MaxPool2d-19      (17, 16, 75)       (17, 8, 37)          0       20,128\n",
      "      Conv2d-20       (17, 8, 37)       (18, 8, 37)      2,754      815,184\n",
      " BatchNorm2d-21       (18, 8, 37)       (18, 8, 37)         36            0\n",
      "        ReLu-22       (18, 8, 37)       (18, 8, 37)          0        5,328\n",
      "      Conv2d-23       (18, 8, 37)       (27, 8, 37)      4,374    1,294,704\n",
      " BatchNorm2d-24       (27, 8, 37)       (27, 8, 37)         54            0\n",
      "        ReLu-25       (27, 8, 37)       (27, 8, 37)          0        7,992\n",
      "   MaxPool2d-26       (27, 8, 37)       (27, 4, 18)          0        7,776\n",
      "      Conv2d-27       (27, 4, 18)       (39, 4, 18)      9,477      682,344\n",
      " BatchNorm2d-28       (39, 4, 18)       (39, 4, 18)         78            0\n",
      "        ReLu-29       (39, 4, 18)       (39, 4, 18)          0        2,808\n",
      "      Conv2d-30       (39, 4, 18)       (34, 4, 18)     11,934      859,248\n",
      " BatchNorm2d-31       (34, 4, 18)       (34, 4, 18)         68            0\n",
      "        ReLu-32       (34, 4, 18)       (34, 4, 18)          0        2,448\n",
      "   MaxPool2d-33       (34, 4, 18)        (34, 2, 9)          0        2,448\n",
      "      Conv2d-34        (34, 2, 9)        (41, 2, 9)     12,546      225,828\n",
      " BatchNorm2d-35        (41, 2, 9)        (41, 2, 9)         82            0\n",
      "        ReLu-36        (41, 2, 9)        (41, 2, 9)          0          738\n",
      "      Conv2d-37        (41, 2, 9)        (72, 2, 9)     26,568      478,224\n",
      " BatchNorm2d-38        (72, 2, 9)        (72, 2, 9)        144            0\n",
      "        ReLu-39        (72, 2, 9)        (72, 2, 9)          0        1,296\n",
      "   MaxPool2d-40        (72, 2, 9)        (72, 1, 4)          0        1,152\n",
      "      Conv2d-41        (72, 1, 4)         (3, 1, 4)        216          864\n",
      " BatchNorm2d-42         (3, 1, 4)         (3, 1, 4)          6            0\n",
      "        ReLu-43         (3, 1, 4)         (3, 1, 4)          0           12\n",
      "   AvgPool2d-44         (3, 1, 4)         (3, 1, 1)          0           12\n",
      "     Flatten-45         (3, 1, 1)            (1, 3)          0            0\n",
      "      Linear-46            (1, 3)            (1, 3)         12           12\n",
      "     Softmax-47            (1, 3)            (1, 3)          0            3\n",
      "==============================================================================\n",
      "Total Params: 71,372\n",
      "Total FLOPs : 14,583,695\n",
      "------------------------------------------------------------------------------\n",
      "Input size (MB) : 0.12\n",
      "Params size (MB): 0.27\n",
      "Total size (MB) : 0.39\n",
      "------------------------------------------------------------------------------\n",
      "\n",
      "sfeb.0.weight:True\n",
      "sfeb.1.weight:True\n",
      "sfeb.1.bias:True\n",
      "sfeb.3.weight:True\n",
      "sfeb.4.weight:True\n",
      "sfeb.4.bias:True\n",
      "tfeb.0.weight:True\n",
      "tfeb.1.weight:True\n",
      "tfeb.1.bias:True\n",
      "tfeb.4.weight:True\n",
      "tfeb.5.weight:True\n",
      "tfeb.5.bias:True\n",
      "tfeb.7.weight:True\n",
      "tfeb.8.weight:True\n",
      "tfeb.8.bias:True\n",
      "tfeb.11.weight:True\n",
      "tfeb.12.weight:True\n",
      "tfeb.12.bias:True\n",
      "tfeb.14.weight:True\n",
      "tfeb.15.weight:True\n",
      "tfeb.15.bias:True\n",
      "tfeb.18.weight:True\n",
      "tfeb.19.weight:True\n",
      "tfeb.19.bias:True\n",
      "tfeb.21.weight:True\n",
      "tfeb.22.weight:True\n",
      "tfeb.22.bias:True\n",
      "tfeb.25.weight:True\n",
      "tfeb.26.weight:True\n",
      "tfeb.26.bias:True\n",
      "tfeb.28.weight:True\n",
      "tfeb.29.weight:True\n",
      "tfeb.29.bias:True\n",
      "tfeb.33.weight:True\n",
      "tfeb.34.weight:True\n",
      "tfeb.34.bias:True\n",
      "tfeb.38.weight:True\n",
      "tfeb.38.bias:True\n",
      "ACDNet model has been prepared for training\n",
      "+----------------------------------------------------------------------------+\n",
      "+                           Pytorch Model Summary                            +\n",
      "------------------------------------------------------------------------------\n",
      "   Layer (type)       Input Shape      Output Shape    Param #      FLOPS #\n",
      "==============================================================================\n",
      "       Conv2d-1     (1, 1, 30225)     (5, 1, 15109)         45      679,905\n",
      "  BatchNorm2d-2     (5, 1, 15109)     (5, 1, 15109)         10            0\n",
      "         ReLu-3     (5, 1, 15109)     (5, 1, 15109)          0       75,545\n",
      "       Conv2d-4     (5, 1, 15109)     (32, 1, 7553)        800    6,042,400\n",
      "  BatchNorm2d-5     (32, 1, 7553)     (32, 1, 7553)         64            0\n",
      "         ReLu-6     (32, 1, 7553)     (32, 1, 7553)          0      241,696\n",
      "    MaxPool2d-7     (32, 1, 7553)      (32, 1, 151)          0      241,600\n",
      "      Permute-8      (32, 1, 151)      (1, 32, 151)          0            0\n",
      "       Conv2d-9      (1, 32, 151)     (10, 32, 151)         90      434,880\n",
      " BatchNorm2d-10     (10, 32, 151)     (10, 32, 151)         20            0\n",
      "        ReLu-11     (10, 32, 151)     (10, 32, 151)          0       48,320\n",
      "   MaxPool2d-12     (10, 32, 151)      (10, 16, 75)          0       48,000\n",
      "      Conv2d-13      (10, 16, 75)       (8, 16, 75)        720      864,000\n",
      " BatchNorm2d-14       (8, 16, 75)       (8, 16, 75)         16            0\n",
      "        ReLu-15       (8, 16, 75)       (8, 16, 75)          0        9,600\n",
      "      Conv2d-16       (8, 16, 75)      (17, 16, 75)      1,224    1,468,800\n",
      " BatchNorm2d-17      (17, 16, 75)      (17, 16, 75)         34            0\n",
      "        ReLu-18      (17, 16, 75)      (17, 16, 75)          0       20,400\n",
      "   MaxPool2d-19      (17, 16, 75)       (17, 8, 37)          0       20,128\n",
      "      Conv2d-20       (17, 8, 37)       (18, 8, 37)      2,754      815,184\n",
      " BatchNorm2d-21       (18, 8, 37)       (18, 8, 37)         36            0\n",
      "        ReLu-22       (18, 8, 37)       (18, 8, 37)          0        5,328\n",
      "      Conv2d-23       (18, 8, 37)       (27, 8, 37)      4,374    1,294,704\n",
      " BatchNorm2d-24       (27, 8, 37)       (27, 8, 37)         54            0\n",
      "        ReLu-25       (27, 8, 37)       (27, 8, 37)          0        7,992\n",
      "   MaxPool2d-26       (27, 8, 37)       (27, 4, 18)          0        7,776\n",
      "      Conv2d-27       (27, 4, 18)       (39, 4, 18)      9,477      682,344\n",
      " BatchNorm2d-28       (39, 4, 18)       (39, 4, 18)         78            0\n",
      "        ReLu-29       (39, 4, 18)       (39, 4, 18)          0        2,808\n",
      "      Conv2d-30       (39, 4, 18)       (34, 4, 18)     11,934      859,248\n",
      " BatchNorm2d-31       (34, 4, 18)       (34, 4, 18)         68            0\n",
      "        ReLu-32       (34, 4, 18)       (34, 4, 18)          0        2,448\n",
      "   MaxPool2d-33       (34, 4, 18)        (34, 2, 9)          0        2,448\n",
      "      Conv2d-34        (34, 2, 9)        (41, 2, 9)     12,546      225,828\n",
      " BatchNorm2d-35        (41, 2, 9)        (41, 2, 9)         82            0\n",
      "        ReLu-36        (41, 2, 9)        (41, 2, 9)          0          738\n",
      "      Conv2d-37        (41, 2, 9)        (72, 2, 9)     26,568      478,224\n",
      " BatchNorm2d-38        (72, 2, 9)        (72, 2, 9)        144            0\n",
      "        ReLu-39        (72, 2, 9)        (72, 2, 9)          0        1,296\n",
      "   MaxPool2d-40        (72, 2, 9)        (72, 1, 4)          0        1,152\n",
      "      Conv2d-41        (72, 1, 4)         (3, 1, 4)        216          864\n",
      " BatchNorm2d-42         (3, 1, 4)         (3, 1, 4)          6            0\n",
      "        ReLu-43         (3, 1, 4)         (3, 1, 4)          0           12\n",
      "   AvgPool2d-44         (3, 1, 4)         (3, 1, 1)          0           12\n",
      "     Flatten-45         (3, 1, 1)            (1, 3)          0            0\n",
      "      Linear-46            (1, 3)            (1, 3)         12           12\n",
      "     Softmax-47            (1, 3)            (1, 3)          0            3\n",
      "==============================================================================\n",
      "Total Params: 71,372\n",
      "Total FLOPs : 14,583,695\n",
      "------------------------------------------------------------------------------\n",
      "Input size (MB) : 0.12\n",
      "Params size (MB): 0.27\n",
      "Total size (MB) : 0.39\n",
      "------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ai/miniconda3/envs/acdnetenv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device is :cuda:0\n",
      "len of Y:472\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_185424/3459676549.py:123: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of y_pred:torch.Size([472, 3])\n",
      "shape of y_target:torch.Size([472, 3])\n",
      "after: len of y_pred:236, len of y_target:236\n",
      "save model to ../../../trained_models/step_5_retrain_after_step_4/train_after_second_pruning_prunratio0.85_2024050309/retrained_model_after_second_pruning_ratio85.0_acc18.644067764282227_0th_epoch_20240503094500.pt\n",
      "SP-[1] Epoch: 1/1200 | Time: 0m07s (Train 0m06s  Val 0m01s) | Train: LR 0.010000000000000002  Loss 0.91  Acc 40.34% | Val: Loss nan  Acc(top1) 18.64% | HA 18.64@1\n",
      "shape of y_pred:torch.Size([472, 3])\n",
      "shape of y_target:torch.Size([472, 3])\n",
      "after: len of y_pred:236, len of y_target:236\n",
      "save model to ../../../trained_models/step_5_retrain_after_step_4/train_after_second_pruning_prunratio0.85_2024050309/retrained_model_after_second_pruning_ratio85.0_acc51.27118682861328_1th_epoch_20240503094507.pt\n",
      "SP-[1] Epoch: 2/1200 | Time: 0m06s (Train 0m05s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.59  Acc 35.65% | Val: Loss nan  Acc(top1) 51.27% | HA 51.27@2\n",
      "shape of y_pred:torch.Size([472, 3])\n",
      "shape of y_target:torch.Size([472, 3])\n",
      "after: len of y_pred:236, len of y_target:236\n",
      "save model to ../../../trained_models/step_5_retrain_after_step_4/train_after_second_pruning_prunratio0.85_2024050309/retrained_model_after_second_pruning_ratio85.0_acc64.83050537109375_2th_epoch_20240503094513.pt\n",
      "SP-[1] Epoch: 3/1200 | Time: 0m06s (Train 0m05s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.57  Acc 43.32% | Val: Loss nan  Acc(top1) 64.83% | HA 64.83@3\n",
      "shape of y_pred:torch.Size([472, 3])\n",
      "shape of y_target:torch.Size([472, 3])\n",
      "after: len of y_pred:236, len of y_target:236\n",
      "SP-[1] Epoch: 4/1200 | Time: 0m06s (Train 0m05s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.58  Acc 40.91% | Val: Loss nan  Acc(top1) 62.29% | HA 64.83@3\n",
      "shape of y_pred:torch.Size([472, 3])\n",
      "shape of y_target:torch.Size([472, 3])\n",
      "after: len of y_pred:236, len of y_target:236\n",
      "SP-[1] Epoch: 5/1200 | Time: 0m06s (Train 0m05s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.57  Acc 46.88% | Val: Loss nan  Acc(top1) 64.83% | HA 64.83@3\n",
      "shape of y_pred:torch.Size([472, 3])\n",
      "shape of y_target:torch.Size([472, 3])\n",
      "after: len of y_pred:236, len of y_target:236\n",
      "save model to ../../../trained_models/step_5_retrain_after_step_4/train_after_second_pruning_prunratio0.85_2024050309/retrained_model_after_second_pruning_ratio85.0_acc66.10169219970703_5th_epoch_20240503094532.pt\n",
      "SP-[1] Epoch: 6/1200 | Time: 0m06s (Train 0m05s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.57  Acc 42.05% | Val: Loss nan  Acc(top1) 66.10% | HA 66.10@6\n",
      "shape of y_pred:torch.Size([472, 3])\n",
      "shape of y_target:torch.Size([472, 3])\n",
      "after: len of y_pred:236, len of y_target:236\n",
      "save model to ../../../trained_models/step_5_retrain_after_step_4/train_after_second_pruning_prunratio0.85_2024050309/retrained_model_after_second_pruning_ratio85.0_acc67.37287902832031_6th_epoch_20240503094538.pt\n",
      "SP-[1] Epoch: 7/1200 | Time: 0m06s (Train 0m05s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.55  Acc 46.31% | Val: Loss nan  Acc(top1) 67.37% | HA 67.37@7\n",
      "shape of y_pred:torch.Size([472, 3])\n",
      "shape of y_target:torch.Size([472, 3])\n",
      "after: len of y_pred:236, len of y_target:236\n",
      "SP-[1] Epoch: 8/1200 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.54  Acc 45.31% | Val: Loss nan  Acc(top1) 66.10% | HA 67.37@7\n",
      "shape of y_pred:torch.Size([472, 3])\n",
      "shape of y_target:torch.Size([472, 3])\n",
      "after: len of y_pred:236, len of y_target:236\n",
      "SP-[1] Epoch: 9/1200 | Time: 0m06s (Train 0m05s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.53  Acc 48.86% | Val: Loss nan  Acc(top1) 67.37% | HA 67.37@7\n",
      "shape of y_pred:torch.Size([472, 3])\n",
      "shape of y_target:torch.Size([472, 3])\n",
      "after: len of y_pred:236, len of y_target:236\n",
      "save model to ../../../trained_models/step_5_retrain_after_step_4/train_after_second_pruning_prunratio0.85_2024050309/retrained_model_after_second_pruning_ratio85.0_acc70.33898162841797_9th_epoch_20240503094557.pt\n",
      "SP-[1] Epoch: 10/1200 | Time: 0m06s (Train 0m05s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.53  Acc 51.42% | Val: Loss nan  Acc(top1) 70.34% | HA 70.34@10\n",
      "shape of y_pred:torch.Size([472, 3])\n",
      "shape of y_target:torch.Size([472, 3])\n",
      "after: len of y_pred:236, len of y_target:236\n",
      "save model to ../../../trained_models/step_5_retrain_after_step_4/train_after_second_pruning_prunratio0.85_2024050309/retrained_model_after_second_pruning_ratio85.0_acc71.18643951416016_10th_epoch_20240503094603.pt\n",
      "SP-[1] Epoch: 11/1200 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.55  Acc 44.74% | Val: Loss nan  Acc(top1) 71.19% | HA 71.19@11\n",
      "shape of y_pred:torch.Size([472, 3])\n",
      "shape of y_target:torch.Size([472, 3])\n",
      "after: len of y_pred:236, len of y_target:236\n",
      "save model to ../../../trained_models/step_5_retrain_after_step_4/train_after_second_pruning_prunratio0.85_2024050309/retrained_model_after_second_pruning_ratio85.0_acc71.61016845703125_11th_epoch_20240503094614.pt\n",
      "SP-[1] Epoch: 12/1200 | Time: 0m10s (Train 0m10s  Val 0m00s) | Train: LR 0.1  Loss 0.56  Acc 44.46% | Val: Loss nan  Acc(top1) 71.61% | HA 71.61@12\n",
      "shape of y_pred:torch.Size([472, 3])\n",
      "shape of y_target:torch.Size([472, 3])\n",
      "after: len of y_pred:236, len of y_target:236\n",
      "SP-[1] Epoch: 13/1200 | Time: 0m09s (Train 0m09s  Val 0m00s) | Train: LR 0.1  Loss 0.54  Acc 46.73% | Val: Loss nan  Acc(top1) 71.19% | HA 71.61@12\n",
      "shape of y_pred:torch.Size([472, 3])\n",
      "shape of y_target:torch.Size([472, 3])\n",
      "after: len of y_pred:236, len of y_target:236\n",
      "save model to ../../../trained_models/step_5_retrain_after_step_4/train_after_second_pruning_prunratio0.85_2024050309/retrained_model_after_second_pruning_ratio85.0_acc74.15254211425781_13th_epoch_20240503094635.pt\n",
      "SP-[1] Epoch: 14/1200 | Time: 0m11s (Train 0m10s  Val 0m00s) | Train: LR 0.1  Loss 0.53  Acc 50.85% | Val: Loss nan  Acc(top1) 74.15% | HA 74.15@14\n",
      "shape of y_pred:torch.Size([472, 3])\n",
      "shape of y_target:torch.Size([472, 3])\n",
      "after: len of y_pred:236, len of y_target:236\n",
      "SP-[1] Epoch: 15/1200 | Time: 0m10s (Train 0m10s  Val 0m00s) | Train: LR 0.1  Loss 0.51  Acc 52.41% | Val: Loss nan  Acc(top1) 73.31% | HA 74.15@14\n",
      "shape of y_pred:torch.Size([472, 3])\n",
      "shape of y_target:torch.Size([472, 3])\n",
      "after: len of y_pred:236, len of y_target:236\n",
      "SP-[1] Epoch: 16/1200 | Time: 0m11s (Train 0m10s  Val 0m00s) | Train: LR 0.1  Loss 0.48  Acc 51.42% | Val: Loss nan  Acc(top1) 72.03% | HA 74.15@14\n",
      "shape of y_pred:torch.Size([472, 3])\n",
      "shape of y_target:torch.Size([472, 3])\n",
      "after: len of y_pred:236, len of y_target:236\n",
      "SP-[1] Epoch: 17/1200 | Time: 0m10s (Train 0m09s  Val 0m00s) | Train: LR 0.1  Loss 0.50  Acc 51.99% | Val: Loss nan  Acc(top1) 72.03% | HA 74.15@14\n",
      "shape of y_pred:torch.Size([472, 3])\n",
      "shape of y_target:torch.Size([472, 3])\n",
      "after: len of y_pred:236, len of y_target:236\n",
      "SP-[1] Epoch: 18/1200 | Time: 0m09s (Train 0m09s  Val 0m00s) | Train: LR 0.1  Loss 0.51  Acc 51.85% | Val: Loss nan  Acc(top1) 73.31% | HA 74.15@14\n",
      "shape of y_pred:torch.Size([472, 3])\n",
      "shape of y_target:torch.Size([472, 3])\n",
      "after: len of y_pred:236, len of y_target:236\n",
      "SP-[1] Epoch: 19/1200 | Time: 0m10s (Train 0m10s  Val 0m00s) | Train: LR 0.1  Loss 0.49  Acc 50.71% | Val: Loss nan  Acc(top1) 70.34% | HA 74.15@14\n",
      "shape of y_pred:torch.Size([472, 3])\n",
      "shape of y_target:torch.Size([472, 3])\n",
      "after: len of y_pred:236, len of y_target:236\n",
      "save model to ../../../trained_models/step_5_retrain_after_step_4/train_after_second_pruning_prunratio0.85_2024050309/retrained_model_after_second_pruning_ratio85.0_acc75.0_19th_epoch_20240503094738.pt\n",
      "SP-[1] Epoch: 20/1200 | Time: 0m10s (Train 0m10s  Val 0m00s) | Train: LR 0.1  Loss 0.48  Acc 50.99% | Val: Loss nan  Acc(top1) 75.00% | HA 75.00@20\n",
      "shape of y_pred:torch.Size([472, 3])\n",
      "shape of y_target:torch.Size([472, 3])\n",
      "after: len of y_pred:236, len of y_target:236\n",
      "SP-[1] Epoch: 21/1200 | Time: 0m11s (Train 0m10s  Val 0m00s) | Train: LR 0.1  Loss 0.50  Acc 51.28% | Val: Loss nan  Acc(top1) 73.31% | HA 75.00@20\n",
      "shape of y_pred:torch.Size([472, 3])\n",
      "shape of y_target:torch.Size([472, 3])\n",
      "after: len of y_pred:236, len of y_target:236\n",
      "SP-[1] Epoch: 22/1200 | Time: 0m11s (Train 0m10s  Val 0m00s) | Train: LR 0.1  Loss 0.48  Acc 53.98% | Val: Loss nan  Acc(top1) 73.31% | HA 75.00@20\n",
      "shape of y_pred:torch.Size([472, 3])\n",
      "shape of y_target:torch.Size([472, 3])\n",
      "after: len of y_pred:236, len of y_target:236\n",
      "SP-[1] Epoch: 23/1200 | Time: 0m10s (Train 0m10s  Val 0m00s) | Train: LR 0.1  Loss 0.49  Acc 53.41% | Val: Loss nan  Acc(top1) 41.95% | HA 75.00@20\n",
      "shape of y_pred:torch.Size([472, 3])\n",
      "shape of y_target:torch.Size([472, 3])\n",
      "after: len of y_pred:236, len of y_target:236\n",
      "SP-[1] Epoch: 24/1200 | Time: 0m11s (Train 0m11s  Val 0m00s) | Train: LR 0.1  Loss 0.49  Acc 52.98% | Val: Loss nan  Acc(top1) 64.41% | HA 75.00@20\n",
      "shape of y_pred:torch.Size([472, 3])\n",
      "shape of y_target:torch.Size([472, 3])\n",
      "after: len of y_pred:236, len of y_target:236\n",
      "SP-[1] Epoch: 25/1200 | Time: 0m09s (Train 0m09s  Val 0m00s) | Train: LR 0.1  Loss 0.50  Acc 47.44% | Val: Loss nan  Acc(top1) 67.80% | HA 75.00@20\n",
      "shape of y_pred:torch.Size([472, 3])\n",
      "shape of y_target:torch.Size([472, 3])\n",
      "after: len of y_pred:236, len of y_target:236\n",
      "SP-[1] Epoch: 26/1200 | Time: 0m11s (Train 0m10s  Val 0m00s) | Train: LR 0.1  Loss 0.49  Acc 52.27% | Val: Loss nan  Acc(top1) 74.58% | HA 75.00@20\n",
      "shape of y_pred:torch.Size([472, 3])\n",
      "shape of y_target:torch.Size([472, 3])\n",
      "after: len of y_pred:236, len of y_target:236\n",
      "SP-[1] Epoch: 27/1200 | Time: 0m10s (Train 0m09s  Val 0m00s) | Train: LR 0.1  Loss 0.50  Acc 51.99% | Val: Loss nan  Acc(top1) 74.58% | HA 75.00@20\n",
      "shape of y_pred:torch.Size([472, 3])\n",
      "shape of y_target:torch.Size([472, 3])\n",
      "after: len of y_pred:236, len of y_target:236\n",
      "SP-[1] Epoch: 28/1200 | Time: 0m10s (Train 0m10s  Val 0m00s) | Train: LR 0.1  Loss 0.51  Acc 53.41% | Val: Loss nan  Acc(top1) 70.76% | HA 75.00@20\n",
      "shape of y_pred:torch.Size([472, 3])\n",
      "shape of y_target:torch.Size([472, 3])\n",
      "after: len of y_pred:236, len of y_target:236\n",
      "SP-[1] Epoch: 29/1200 | Time: 0m11s (Train 0m10s  Val 0m00s) | Train: LR 0.1  Loss 0.50  Acc 50.71% | Val: Loss nan  Acc(top1) 72.46% | HA 75.00@20\n",
      "shape of y_pred:torch.Size([472, 3])\n",
      "shape of y_target:torch.Size([472, 3])\n",
      "after: len of y_pred:236, len of y_target:236\n",
      "save model to ../../../trained_models/step_5_retrain_after_step_4/train_after_second_pruning_prunratio0.85_2024050309/retrained_model_after_second_pruning_ratio85.0_acc76.69491577148438_29th_epoch_20240503094928.pt\n",
      "SP-[1] Epoch: 30/1200 | Time: 0m10s (Train 0m10s  Val 0m00s) | Train: LR 0.1  Loss 0.49  Acc 52.27% | Val: Loss nan  Acc(top1) 76.69% | HA 76.69@30\n",
      "shape of y_pred:torch.Size([472, 3])\n",
      "shape of y_target:torch.Size([472, 3])\n",
      "after: len of y_pred:236, len of y_target:236\n",
      "SP-[1] Epoch: 31/1200 | Time: 0m11s (Train 0m11s  Val 0m00s) | Train: LR 0.1  Loss 0.49  Acc 52.13% | Val: Loss nan  Acc(top1) 39.41% | HA 76.69@30\n",
      "shape of y_pred:torch.Size([472, 3])\n",
      "shape of y_target:torch.Size([472, 3])\n",
      "after: len of y_pred:236, len of y_target:236\n",
      "SP-[1] Epoch: 32/1200 | Time: 0m10s (Train 0m10s  Val 0m00s) | Train: LR 0.1  Loss 0.49  Acc 54.83% | Val: Loss nan  Acc(top1) 57.63% | HA 76.69@30\n",
      "shape of y_pred:torch.Size([472, 3])\n",
      "shape of y_target:torch.Size([472, 3])\n",
      "after: len of y_pred:236, len of y_target:236\n",
      "SP-[1] Epoch: 33/1200 | Time: 0m10s (Train 0m10s  Val 0m00s) | Train: LR 0.1  Loss 0.49  Acc 49.57% | Val: Loss nan  Acc(top1) 52.54% | HA 76.69@30\n",
      "shape of y_pred:torch.Size([472, 3])\n",
      "shape of y_target:torch.Size([472, 3])\n",
      "after: len of y_pred:236, len of y_target:236\n",
      "SP-[1] Epoch: 34/1200 | Time: 0m10s (Train 0m09s  Val 0m00s) | Train: LR 0.1  Loss 0.49  Acc 55.11% | Val: Loss -0.12  Acc(top1) 63.98% | HA 76.69@30\n",
      "shape of y_pred:torch.Size([472, 3])\n",
      "shape of y_target:torch.Size([472, 3])\n",
      "after: len of y_pred:236, len of y_target:236\n",
      "SP-[1] Epoch: 35/1200 | Time: 0m10s (Train 0m10s  Val 0m00s) | Train: LR 0.1  Loss 0.51  Acc 52.70% | Val: Loss nan  Acc(top1) 69.92% | HA 76.69@30\n",
      "shape of y_pred:torch.Size([472, 3])\n",
      "shape of y_target:torch.Size([472, 3])\n",
      "after: len of y_pred:236, len of y_target:236\n",
      "SP-[1] Epoch: 36/1200 | Time: 0m11s (Train 0m10s  Val 0m00s) | Train: LR 0.1  Loss 0.50  Acc 55.11% | Val: Loss nan  Acc(top1) 71.61% | HA 76.69@30\n",
      "shape of y_pred:torch.Size([472, 3])\n",
      "shape of y_target:torch.Size([472, 3])\n",
      "after: len of y_pred:236, len of y_target:236\n",
      "SP-[1] Epoch: 37/1200 | Time: 0m10s (Train 0m10s  Val 0m00s) | Train: LR 0.1  Loss 0.50  Acc 50.71% | Val: Loss nan  Acc(top1) 75.42% | HA 76.69@30\n",
      "shape of y_pred:torch.Size([472, 3])\n",
      "shape of y_target:torch.Size([472, 3])\n",
      "after: len of y_pred:236, len of y_target:236\n",
      "SP-[1] Epoch: 38/1200 | Time: 0m13s (Train 0m12s  Val 0m01s) | Train: LR 0.1  Loss 0.48  Acc 49.43% | Val: Loss nan  Acc(top1) 73.31% | HA 76.69@30\n",
      "shape of y_pred:torch.Size([472, 3])\n",
      "shape of y_target:torch.Size([472, 3])\n",
      "after: len of y_pred:236, len of y_target:236\n",
      "SP-[1] Epoch: 39/1200 | Time: 0m09s (Train 0m09s  Val 0m00s) | Train: LR 0.1  Loss 0.51  Acc 49.43% | Val: Loss -0.12  Acc(top1) 63.98% | HA 76.69@30\n",
      "shape of y_pred:torch.Size([472, 3])\n",
      "shape of y_target:torch.Size([472, 3])\n",
      "after: len of y_pred:236, len of y_target:236\n",
      "SP-[1] Epoch: 40/1200 | Time: 0m10s (Train 0m10s  Val 0m00s) | Train: LR 0.1  Loss 0.51  Acc 51.85% | Val: Loss nan  Acc(top1) 75.85% | HA 76.69@30\n",
      "shape of y_pred:torch.Size([472, 3])\n",
      "shape of y_target:torch.Size([472, 3])\n",
      "after: len of y_pred:236, len of y_target:236\n",
      "SP-[1] Epoch: 41/1200 | Time: 0m09s (Train 0m09s  Val 0m00s) | Train: LR 0.1  Loss 0.49  Acc 55.68% | Val: Loss nan  Acc(top1) 72.03% | HA 76.69@30\n",
      "shape of y_pred:torch.Size([472, 3])\n",
      "shape of y_target:torch.Size([472, 3])\n",
      "after: len of y_pred:236, len of y_target:236\n",
      "SP-[1] Epoch: 42/1200 | Time: 0m10s (Train 0m10s  Val 0m00s) | Train: LR 0.1  Loss 0.51  Acc 49.29% | Val: Loss nan  Acc(top1) 18.64% | HA 76.69@30\n",
      "shape of y_pred:torch.Size([472, 3])\n",
      "shape of y_target:torch.Size([472, 3])\n",
      "after: len of y_pred:236, len of y_target:236\n",
      "SP-[1] Epoch: 43/1200 | Time: 0m11s (Train 0m10s  Val 0m00s) | Train: LR 0.1  Loss 0.50  Acc 54.83% | Val: Loss nan  Acc(top1) 69.49% | HA 76.69@30\n",
      "shape of y_pred:torch.Size([472, 3])\n",
      "shape of y_target:torch.Size([472, 3])\n",
      "after: len of y_pred:236, len of y_target:236\n",
      "SP-[1] Epoch: 44/1200 | Time: 0m09s (Train 0m09s  Val 0m00s) | Train: LR 0.1  Loss 0.52  Acc 51.56% | Val: Loss -0.11  Acc(top1) 63.56% | HA 76.69@30\n",
      "shape of y_pred:torch.Size([472, 3])\n",
      "shape of y_target:torch.Size([472, 3])\n",
      "after: len of y_pred:236, len of y_target:236\n",
      "SP-[1] Epoch: 45/1200 | Time: 0m10s (Train 0m10s  Val 0m00s) | Train: LR 0.1  Loss 0.50  Acc 53.69% | Val: Loss nan  Acc(top1) 28.39% | HA 76.69@30\n",
      "shape of y_pred:torch.Size([472, 3])\n",
      "shape of y_target:torch.Size([472, 3])\n",
      "after: len of y_pred:236, len of y_target:236\n",
      "SP-[1] Epoch: 46/1200 | Time: 0m10s (Train 0m09s  Val 0m00s) | Train: LR 0.1  Loss 0.49  Acc 50.14% | Val: Loss nan  Acc(top1) 73.73% | HA 76.69@30\n",
      "shape of y_pred:torch.Size([472, 3])\n",
      "shape of y_target:torch.Size([472, 3])\n",
      "after: len of y_pred:236, len of y_target:236\n",
      "SP-[1] Epoch: 47/1200 | Time: 0m11s (Train 0m10s  Val 0m00s) | Train: LR 0.1  Loss 0.50  Acc 50.14% | Val: Loss nan  Acc(top1) 19.49% | HA 76.69@30\n",
      "shape of y_pred:torch.Size([472, 3])\n",
      "shape of y_target:torch.Size([472, 3])\n",
      "after: len of y_pred:236, len of y_target:236\n",
      "SP-[1] Epoch: 48/1200 | Time: 0m09s (Train 0m09s  Val 0m00s) | Train: LR 0.1  Loss 0.49  Acc 51.99% | Val: Loss nan  Acc(top1) 71.19% | HA 76.69@30\n",
      "shape of y_pred:torch.Size([472, 3])\n",
      "shape of y_target:torch.Size([472, 3])\n",
      "after: len of y_pred:236, len of y_target:236\n",
      "SP-[1] Epoch: 49/1200 | Time: 0m11s (Train 0m10s  Val 0m00s) | Train: LR 0.1  Loss 0.50  Acc 50.43% | Val: Loss nan  Acc(top1) 69.07% | HA 76.69@30\n",
      "shape of y_pred:torch.Size([472, 3])\n",
      "shape of y_target:torch.Size([472, 3])\n",
      "after: len of y_pred:236, len of y_target:236\n",
      "SP-[1] Epoch: 50/1200 | Time: 0m11s (Train 0m10s  Val 0m00s) | Train: LR 0.1  Loss 0.51  Acc 50.85% | Val: Loss nan  Acc(top1) 72.03% | HA 76.69@30\n",
      "shape of y_pred:torch.Size([472, 3])\n",
      "shape of y_target:torch.Size([472, 3])\n",
      "after: len of y_pred:236, len of y_target:236\n",
      "SP-[1] Epoch: 51/1200 | Time: 0m10s (Train 0m10s  Val 0m00s) | Train: LR 0.1  Loss 0.49  Acc 54.12% | Val: Loss nan  Acc(top1) 74.58% | HA 76.69@30\n",
      "shape of y_pred:torch.Size([472, 3])\n",
      "shape of y_target:torch.Size([472, 3])\n",
      "after: len of y_pred:236, len of y_target:236\n",
      "SP-[1] Epoch: 52/1200 | Time: 0m11s (Train 0m11s  Val 0m00s) | Train: LR 0.1  Loss 0.48  Acc 55.68% | Val: Loss nan  Acc(top1) 72.03% | HA 76.69@30\n",
      "shape of y_pred:torch.Size([472, 3])\n",
      "shape of y_target:torch.Size([472, 3])\n",
      "after: len of y_pred:236, len of y_target:236\n",
      "SP-[1] Epoch: 53/1200 | Time: 0m09s (Train 0m08s  Val 0m00s) | Train: LR 0.1  Loss 0.48  Acc 51.85% | Val: Loss nan  Acc(top1) 61.86% | HA 76.69@30\n",
      "shape of y_pred:torch.Size([472, 3])\n",
      "shape of y_target:torch.Size([472, 3])\n",
      "after: len of y_pred:236, len of y_target:236\n",
      "SP-[1] Epoch: 54/1200 | Time: 0m11s (Train 0m10s  Val 0m00s) | Train: LR 0.1  Loss 0.51  Acc 46.02% | Val: Loss -0.12  Acc(top1) 63.98% | HA 76.69@30\n",
      "shape of y_pred:torch.Size([472, 3])\n",
      "shape of y_target:torch.Size([472, 3])\n",
      "after: len of y_pred:236, len of y_target:236\n",
      "SP-[1] Epoch: 55/1200 | Time: 0m10s (Train 0m09s  Val 0m01s) | Train: LR 0.1  Loss 0.49  Acc 52.98% | Val: Loss nan  Acc(top1) 72.46% | HA 76.69@30\n",
      "shape of y_pred:torch.Size([472, 3])\n",
      "shape of y_target:torch.Size([472, 3])\n",
      "after: len of y_pred:236, len of y_target:236\n",
      "SP-[1] Epoch: 56/1200 | Time: 0m11s (Train 0m10s  Val 0m00s) | Train: LR 0.1  Loss 0.50  Acc 53.55% | Val: Loss nan  Acc(top1) 74.15% | HA 76.69@30\n",
      "shape of y_pred:torch.Size([472, 3])\n",
      "shape of y_target:torch.Size([472, 3])\n",
      "after: len of y_pred:236, len of y_target:236\n",
      "SP-[1] Epoch: 57/1200 | Time: 0m11s (Train 0m11s  Val 0m00s) | Train: LR 0.1  Loss 0.50  Acc 51.56% | Val: Loss nan  Acc(top1) 72.46% | HA 76.69@30\n",
      "shape of y_pred:torch.Size([472, 3])\n",
      "shape of y_target:torch.Size([472, 3])\n",
      "after: len of y_pred:236, len of y_target:236\n",
      "SP-[1] Epoch: 58/1200 | Time: 0m10s (Train 0m10s  Val 0m00s) | Train: LR 0.1  Loss 0.47  Acc 54.40% | Val: Loss nan  Acc(top1) 74.58% | HA 76.69@30\n",
      "shape of y_pred:torch.Size([472, 3])\n",
      "shape of y_target:torch.Size([472, 3])\n",
      "after: len of y_pred:236, len of y_target:236\n",
      "SP-[1] Epoch: 59/1200 | Time: 0m10s (Train 0m09s  Val 0m00s) | Train: LR 0.1  Loss 0.49  Acc 54.69% | Val: Loss nan  Acc(top1) 69.07% | HA 76.69@30\n",
      "shape of y_pred:torch.Size([472, 3])\n",
      "shape of y_target:torch.Size([472, 3])\n",
      "after: len of y_pred:236, len of y_target:236\n",
      "SP-[1] Epoch: 60/1200 | Time: 0m10s (Train 0m10s  Val 0m00s) | Train: LR 0.1  Loss 0.50  Acc 50.71% | Val: Loss nan  Acc(top1) 66.95% | HA 76.69@30\n",
      "shape of y_pred:torch.Size([472, 3])\n",
      "shape of y_target:torch.Size([472, 3])\n",
      "after: len of y_pred:236, len of y_target:236\n",
      "save model to ../../../trained_models/step_5_retrain_after_step_4/train_after_second_pruning_prunratio0.85_2024050309/retrained_model_after_second_pruning_ratio85.0_acc77.54237365722656_60th_epoch_20240503095505.pt\n",
      "SP-[1] Epoch: 61/1200 | Time: 0m10s (Train 0m10s  Val 0m00s) | Train: LR 0.1  Loss 0.51  Acc 52.13% | Val: Loss nan  Acc(top1) 77.54% | HA 77.54@61\n",
      "shape of y_pred:torch.Size([472, 3])\n",
      "shape of y_target:torch.Size([472, 3])\n",
      "after: len of y_pred:236, len of y_target:236\n",
      "SP-[1] Epoch: 62/1200 | Time: 0m10s (Train 0m10s  Val 0m00s) | Train: LR 0.1  Loss 0.49  Acc 54.55% | Val: Loss nan  Acc(top1) 75.00% | HA 77.54@61\n",
      "shape of y_pred:torch.Size([472, 3])\n",
      "shape of y_target:torch.Size([472, 3])\n",
      "after: len of y_pred:236, len of y_target:236\n",
      "SP-[1] Epoch: 63/1200 | Time: 0m10s (Train 0m09s  Val 0m00s) | Train: LR 0.1  Loss 0.49  Acc 48.72% | Val: Loss 0.83  Acc(top1) 21.19% | HA 77.54@61\n",
      "shape of y_pred:torch.Size([472, 3])\n",
      "shape of y_target:torch.Size([472, 3])\n",
      "after: len of y_pred:236, len of y_target:236\n",
      "SP-[1] Epoch: 64/1200 | Time: 0m10s (Train 0m09s  Val 0m00s) | Train: LR 0.1  Loss 0.49  Acc 51.56% | Val: Loss nan  Acc(top1) 72.88% | HA 77.54@61\n",
      "shape of y_pred:torch.Size([472, 3])\n",
      "shape of y_target:torch.Size([472, 3])\n",
      "after: len of y_pred:236, len of y_target:236\n",
      "SP-[1] Epoch: 65/1200 | Time: 0m11s (Train 0m11s  Val 0m00s) | Train: LR 0.1  Loss 0.51  Acc 51.70% | Val: Loss nan  Acc(top1) 55.51% | HA 77.54@61\n",
      "shape of y_pred:torch.Size([472, 3])\n",
      "shape of y_target:torch.Size([472, 3])\n",
      "after: len of y_pred:236, len of y_target:236\n",
      "SP-[1] Epoch: 66/1200 | Time: 0m11s (Train 0m10s  Val 0m00s) | Train: LR 0.1  Loss 0.49  Acc 53.98% | Val: Loss nan  Acc(top1) 51.27% | HA 77.54@61\n",
      "shape of y_pred:torch.Size([472, 3])\n",
      "shape of y_target:torch.Size([472, 3])\n",
      "after: len of y_pred:236, len of y_target:236\n",
      "SP-[1] Epoch: 67/1200 | Time: 0m10s (Train 0m10s  Val 0m00s) | Train: LR 0.1  Loss 0.49  Acc 51.42% | Val: Loss nan  Acc(top1) 74.58% | HA 77.54@61\n",
      "shape of y_pred:torch.Size([472, 3])\n",
      "shape of y_target:torch.Size([472, 3])\n",
      "after: len of y_pred:236, len of y_target:236\n",
      "SP-[1] Epoch: 68/1200 | Time: 0m11s (Train 0m10s  Val 0m00s) | Train: LR 0.1  Loss 0.49  Acc 50.71% | Val: Loss 0.57  Acc(top1) 35.17% | HA 77.54@61\n",
      "shape of y_pred:torch.Size([472, 3])\n",
      "shape of y_target:torch.Size([472, 3])\n",
      "after: len of y_pred:236, len of y_target:236\n",
      "SP-[1] Epoch: 69/1200 | Time: 0m10s (Train 0m09s  Val 0m00s) | Train: LR 0.1  Loss 0.48  Acc 50.28% | Val: Loss nan  Acc(top1) 40.68% | HA 77.54@61\n",
      "shape of y_pred:torch.Size([472, 3])\n",
      "shape of y_target:torch.Size([472, 3])\n",
      "after: len of y_pred:236, len of y_target:236\n",
      "SP-[1] Epoch: 70/1200 | Time: 0m11s (Train 0m10s  Val 0m00s) | Train: LR 0.1  Loss 0.51  Acc 48.30% | Val: Loss 0.38  Acc(top1) 42.80% | HA 77.54@61\n",
      "shape of y_pred:torch.Size([472, 3])\n",
      "shape of y_target:torch.Size([472, 3])\n",
      "after: len of y_pred:236, len of y_target:236\n",
      "SP-[1] Epoch: 71/1200 | Time: 0m10s (Train 0m09s  Val 0m00s) | Train: LR 0.1  Loss 0.52  Acc 50.00% | Val: Loss nan  Acc(top1) 67.37% | HA 77.54@61\n",
      "shape of y_pred:torch.Size([472, 3])\n",
      "shape of y_target:torch.Size([472, 3])\n",
      "after: len of y_pred:236, len of y_target:236\n",
      "SP-[1] Epoch: 72/1200 | Time: 0m11s (Train 0m10s  Val 0m00s) | Train: LR 0.1  Loss 0.49  Acc 51.42% | Val: Loss nan  Acc(top1) 74.15% | HA 77.54@61\n",
      "shape of y_pred:torch.Size([472, 3])\n",
      "shape of y_target:torch.Size([472, 3])\n",
      "after: len of y_pred:236, len of y_target:236\n",
      "SP-[1] Epoch: 73/1200 | Time: 0m09s (Train 0m09s  Val 0m00s) | Train: LR 0.1  Loss 0.51  Acc 51.28% | Val: Loss nan  Acc(top1) 69.92% | HA 77.54@61\n",
      "shape of y_pred:torch.Size([472, 3])\n",
      "shape of y_target:torch.Size([472, 3])\n",
      "after: len of y_pred:236, len of y_target:236\n",
      "SP-[1] Epoch: 74/1200 | Time: 0m10s (Train 0m09s  Val 0m00s) | Train: LR 0.1  Loss 0.51  Acc 48.30% | Val: Loss nan  Acc(top1) 60.59% | HA 77.54@61\n",
      "shape of y_pred:torch.Size([472, 3])\n",
      "shape of y_target:torch.Size([472, 3])\n",
      "after: len of y_pred:236, len of y_target:236\n",
      "SP-[1] Epoch: 75/1200 | Time: 0m11s (Train 0m10s  Val 0m00s) | Train: LR 0.1  Loss 0.48  Acc 52.70% | Val: Loss nan  Acc(top1) 72.03% | HA 77.54@61\n",
      "shape of y_pred:torch.Size([472, 3])\n",
      "shape of y_target:torch.Size([472, 3])\n",
      "after: len of y_pred:236, len of y_target:236\n",
      "SP-[1] Epoch: 76/1200 | Time: 0m11s (Train 0m10s  Val 0m00s) | Train: LR 0.1  Loss 0.50  Acc 50.57% | Val: Loss nan  Acc(top1) 44.92% | HA 77.54@61\n",
      "shape of y_pred:torch.Size([472, 3])\n",
      "shape of y_target:torch.Size([472, 3])\n",
      "after: len of y_pred:236, len of y_target:236\n",
      "SP-[1] Epoch: 77/1200 | Time: 0m11s (Train 0m11s  Val 0m00s) | Train: LR 0.1  Loss 0.49  Acc 52.13% | Val: Loss nan  Acc(top1) 71.19% | HA 77.54@61\n",
      "shape of y_pred:torch.Size([472, 3])\n",
      "shape of y_target:torch.Size([472, 3])\n",
      "after: len of y_pred:236, len of y_target:236\n",
      "SP-[1] Epoch: 78/1200 | Time: 0m11s (Train 0m10s  Val 0m00s) | Train: LR 0.1  Loss 0.48  Acc 53.98% | Val: Loss nan  Acc(top1) 70.76% | HA 77.54@61\n",
      "shape of y_pred:torch.Size([472, 3])\n",
      "shape of y_target:torch.Size([472, 3])\n",
      "after: len of y_pred:236, len of y_target:236\n",
      "SP-[1] Epoch: 79/1200 | Time: 0m11s (Train 0m10s  Val 0m00s) | Train: LR 0.1  Loss 0.51  Acc 48.58% | Val: Loss nan  Acc(top1) 72.88% | HA 77.54@61\n",
      "shape of y_pred:torch.Size([472, 3])\n",
      "shape of y_target:torch.Size([472, 3])\n",
      "after: len of y_pred:236, len of y_target:236\n",
      "SP-[1] Epoch: 80/1200 | Time: 0m10s (Train 0m10s  Val 0m00s) | Train: LR 0.1  Loss 0.51  Acc 51.70% | Val: Loss nan  Acc(top1) 63.14% | HA 77.54@61\n",
      "shape of y_pred:torch.Size([472, 3])\n",
      "shape of y_target:torch.Size([472, 3])\n",
      "after: len of y_pred:236, len of y_target:236\n",
      "SP-[1] Epoch: 81/1200 | Time: 0m11s (Train 0m11s  Val 0m00s) | Train: LR 0.1  Loss 0.50  Acc 53.98% | Val: Loss nan  Acc(top1) 76.69% | HA 77.54@61\n",
      "shape of y_pred:torch.Size([472, 3])\n",
      "shape of y_target:torch.Size([472, 3])\n",
      "after: len of y_pred:236, len of y_target:236\n",
      "SP-[1] Epoch: 82/1200 | Time: 0m11s (Train 0m11s  Val 0m00s) | Train: LR 0.1  Loss 0.50  Acc 51.42% | Val: Loss nan  Acc(top1) 18.64% | HA 77.54@61\n",
      "shape of y_pred:torch.Size([472, 3])\n",
      "shape of y_target:torch.Size([472, 3])\n",
      "after: len of y_pred:236, len of y_target:236\n",
      "SP-[1] Epoch: 83/1200 | Time: 0m09s (Train 0m09s  Val 0m00s) | Train: LR 0.1  Loss 0.51  Acc 51.56% | Val: Loss nan  Acc(top1) 69.07% | HA 77.54@61\n",
      "shape of y_pred:torch.Size([472, 3])\n",
      "shape of y_target:torch.Size([472, 3])\n",
      "after: len of y_pred:236, len of y_target:236\n",
      "SP-[1] Epoch: 84/1200 | Time: 0m12s (Train 0m11s  Val 0m00s) | Train: LR 0.1  Loss 0.52  Acc 51.42% | Val: Loss nan  Acc(top1) 69.92% | HA 77.54@61\n",
      "shape of y_pred:torch.Size([472, 3])\n",
      "shape of y_target:torch.Size([472, 3])\n",
      "after: len of y_pred:236, len of y_target:236\n",
      "SP-[1] Epoch: 85/1200 | Time: 0m10s (Train 0m10s  Val 0m00s) | Train: LR 0.1  Loss 0.50  Acc 52.84% | Val: Loss nan  Acc(top1) 70.76% | HA 77.54@61\n",
      "shape of y_pred:torch.Size([472, 3])\n",
      "shape of y_target:torch.Size([472, 3])\n",
      "after: len of y_pred:236, len of y_target:236\n",
      "SP-[1] Epoch: 86/1200 | Time: 0m12s (Train 0m11s  Val 0m00s) | Train: LR 0.1  Loss 0.51  Acc 50.00% | Val: Loss nan  Acc(top1) 74.15% | HA 77.54@61\n",
      "shape of y_pred:torch.Size([472, 3])\n",
      "shape of y_target:torch.Size([472, 3])\n",
      "after: len of y_pred:236, len of y_target:236\n",
      "SP-[1] Epoch: 87/1200 | Time: 0m11s (Train 0m11s  Val 0m00s) | Train: LR 0.1  Loss 0.49  Acc 50.43% | Val: Loss nan  Acc(top1) 73.31% | HA 77.54@61\n",
      "shape of y_pred:torch.Size([472, 3])\n",
      "shape of y_target:torch.Size([472, 3])\n",
      "after: len of y_pred:236, len of y_target:236\n",
      "SP-[1] Epoch: 88/1200 | Time: 0m10s (Train 0m10s  Val 0m00s) | Train: LR 0.1  Loss 0.49  Acc 51.70% | Val: Loss nan  Acc(top1) 73.73% | HA 77.54@61\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13480e12-5d04-42ac-8269-c43f3821ccb7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec65ae33-fd2c-4b69-aebb-88131d80a3ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51dea8ff-4d7c-4c42-befd-66498d45dd0e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
