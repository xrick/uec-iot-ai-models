{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a9872611-fa8c-4f4d-89dc-ebea772c16a8",
   "metadata": {},
   "source": [
    "# Weight Pruning Records and Notes\n",
    "## setting\n",
    "- current pruning ratio : 0.7\n",
    "- result: to-add how to observe weight-pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15eb05a5-0216-4c21-9226-27bca5bb4b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys;\n",
    "import os;\n",
    "import glob;\n",
    "import math;\n",
    "import numpy as np;\n",
    "import random;\n",
    "import time;\n",
    "import torch\n",
    "import torch.optim as optim;\n",
    "import torch.nn as nn;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a4fd5d8-421c-438e-a7b9-ea48ef39fcc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"../../../src/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "886f8b70-1961-4c4f-823f-55393ff9c03e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import common.utils as U;\n",
    "import common.opts as opt;\n",
    "import th.resources.models as models;\n",
    "import th.resources.calculator as calc;\n",
    "import th.resources.train_generator as train_generator;\n",
    "import th.resources.pruning_tools.weight_pruning as weight_pruner;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cd58c73b-11bf-48dc-895b-0959625f38ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import common.tlopts as tlopts\n",
    "import th.resources.calculator as calc;\n",
    "from datetime import datetime;\n",
    "import pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8bb31f54-0d24-4942-ad4c-f498900e61d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#log file object\n",
    "logObj = None;\n",
    "def ChkAndCreateSingleDir(dir_path):\n",
    "    if not pathlib.Path(dir_path).is_dir():\n",
    "        os.mkdir(dir_path);\n",
    "        print(f\"'{dir_path}' folder is created.\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "944e5af4-56fa-45e2-8ef8-a1b3beb25156",
   "metadata": {},
   "outputs": [],
   "source": [
    "def genDataTimeStr():\n",
    "    return datetime.today().strftime('%Y-%m-%d %H:%M:%S').replace('-',\"\").replace(' ',\"\").replace(':',\"\");\n",
    "\n",
    "def getDateStr():\n",
    "    return datetime.today().strftime('%Y-%m-%d %H').replace('-',\"\").replace(' ',\"\")#.replace(':',\"\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "02f626e5-5ed6-4aef-908f-2a39342bb0c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TLGenerator():\n",
    "    #Generates data for Keras\n",
    "    def __init__(self, samples, labels, options):\n",
    "        random.seed(42);\n",
    "        #Initialization\n",
    "        print(f\"length of samples:{len(samples)}\")\n",
    "        self.data = [(samples[i], labels[i]) for i in range (0, len(samples))];\n",
    "        self.opt = options;\n",
    "        self.batch_size = options.batchSize;\n",
    "        self.preprocess_funcs = self.preprocess_setup();\n",
    "        self.mapdict = dict([('52',1),('56',2),('99',3)])\n",
    "\n",
    "    def __len__(self):\n",
    "        #Denotes the number of batches per epoch\n",
    "        return int(np.floor(len(self.data) / self.batch_size));\n",
    "        #return len(self.samples);\n",
    "\n",
    "    def __getitem__(self, batchIndex):\n",
    "        #Generate one batch of data\n",
    "        batchX, batchY = self.generate_batch(batchIndex);\n",
    "        batchX = np.expand_dims(batchX, axis=1);\n",
    "        batchX = np.expand_dims(batchX, axis=3);\n",
    "        return batchX, batchY\n",
    "\n",
    "    def generate_batch(self, batchIndex):\n",
    "        #Generates data containing batch_size samples\n",
    "        sounds = [];\n",
    "        labels = [];\n",
    "        indexes = None;\n",
    "        for i in range(self.batch_size):\n",
    "            # Training phase of BC learning\n",
    "            # Select two training examples\n",
    "            while True:\n",
    "                sound1, label1 = self.data[random.randint(0, len(self.data) - 1)]\n",
    "                sound2, label2 = self.data[random.randint(0, len(self.data) - 1)]\n",
    "                if label1 != label2:\n",
    "                    break\n",
    "            sound1 = self.preprocess(sound1)\n",
    "            sound2 = self.preprocess(sound2)\n",
    "\n",
    "            # Mix two examples\n",
    "            r = np.array(random.random())\n",
    "            sound = U.mix(sound1, sound2, r, self.opt.sr).astype(np.float32)\n",
    "            # print(f\"sound length after U.mix is {len(sound)}\")\n",
    "            eye = np.eye(self.opt.nClasses)\n",
    "            idx1 = self.mapdict[str(label1)]- 1\n",
    "            idx2 = self.mapdict[str(label2)] - 1\n",
    "            label = (eye[idx1] * r + eye[idx2] * (1 - r)).astype(np.float32)\n",
    "            # label = (eye[label1] * r + eye[label2] * (1 - r)).astype(np.float32)\n",
    "\n",
    "            #For stronger augmentation\n",
    "            sound = U.random_gain(6)(sound).astype(np.float32)\n",
    "            # print(f\"sound length after U.random_gain is {len(sound)}\")\n",
    "            sounds.append(sound);\n",
    "            labels.append(label);\n",
    "\n",
    "        sounds = np.asarray(sounds);\n",
    "        labels = np.asarray(labels);\n",
    "        \n",
    "\n",
    "        return sounds, labels;\n",
    "\n",
    "    def preprocess_setup(self):\n",
    "        funcs = []\n",
    "        if self.opt.strongAugment:\n",
    "            funcs += [U.random_scale(1.25)]\n",
    "\n",
    "        funcs += [U.padding(self.opt.inputLength // 2),\n",
    "                  U.random_crop(self.opt.inputLength),\n",
    "                  U.normalize(32768.0)]\n",
    "        return funcs\n",
    "\n",
    "    def preprocess(self, sound):\n",
    "        for f in self.preprocess_funcs:\n",
    "            sound = f(sound)\n",
    "\n",
    "        return sound;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e473f603-d73b-4aff-bda7-2aaf0bdab6b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ACDNetV2(nn.Module):\n",
    "    def __init__(self, input_length, n_class, sr, ch_conf=None):\n",
    "        super(ACDNetV2, self).__init__();\n",
    "        self.input_length = input_length;\n",
    "        self.ch_config = ch_conf;\n",
    "\n",
    "        stride1 = 2;\n",
    "        stride2 = 2;\n",
    "        channels = 8;\n",
    "        k_size = (3, 3);\n",
    "        n_frames = (sr/1000)*10; #No of frames per 10ms\n",
    "\n",
    "        sfeb_pool_size = int(n_frames/(stride1*stride2));\n",
    "        # tfeb_pool_size = (2,2);\n",
    "        if self.ch_config is None:\n",
    "            self.ch_config = [channels, channels*8, channels*4, channels*8, channels*8, channels*16, channels*16, channels*32, channels*32, channels*64, channels*64, n_class];\n",
    "        # avg_pool_kernel_size = (1,4) if self.ch_config[1] < 64 else (2,4);\n",
    "        fcn_no_of_inputs = self.ch_config[-1];\n",
    "        conv1, bn1 = self.make_layers(1, self.ch_config[0], (1, 9), (1, stride1));\n",
    "        conv2, bn2 = self.make_layers(self.ch_config[0], self.ch_config[1], (1, 5), (1, stride2));\n",
    "        conv3, bn3 = self.make_layers(1, self.ch_config[2], k_size, padding=1);\n",
    "        conv4, bn4 = self.make_layers(self.ch_config[2], self.ch_config[3], k_size, padding=1);\n",
    "        conv5, bn5 = self.make_layers(self.ch_config[3], self.ch_config[4], k_size, padding=1);\n",
    "        conv6, bn6 = self.make_layers(self.ch_config[4], self.ch_config[5], k_size, padding=1);\n",
    "        conv7, bn7 = self.make_layers(self.ch_config[5], self.ch_config[6], k_size, padding=1);\n",
    "        conv8, bn8 = self.make_layers(self.ch_config[6], self.ch_config[7], k_size, padding=1);\n",
    "        conv9, bn9 = self.make_layers(self.ch_config[7], self.ch_config[8], k_size, padding=1);\n",
    "        conv10, bn10 = self.make_layers(self.ch_config[8], self.ch_config[9], k_size, padding=1);\n",
    "        conv11, bn11 = self.make_layers(self.ch_config[9], self.ch_config[10], k_size, padding=1);\n",
    "        conv12, bn12 = self.make_layers(self.ch_config[10], self.ch_config[11], (1, 1));\n",
    "        fcn = nn.Linear(fcn_no_of_inputs, n_class);\n",
    "        nn.init.kaiming_normal_(fcn.weight, nonlinearity='sigmoid') # kaiming with sigoid is equivalent to lecun_normal in keras\n",
    "\n",
    "        self.sfeb = nn.Sequential(\n",
    "            #Start: Filter bank\n",
    "            conv1, bn1, nn.ReLU(),\\\n",
    "            conv2, bn2, nn.ReLU(),\\\n",
    "            nn.MaxPool2d(kernel_size=(1, sfeb_pool_size))\n",
    "        );\n",
    "\n",
    "        tfeb_modules = [];\n",
    "        self.tfeb_width = int(((self.input_length / sr)*1000)/10); # 10ms frames of audio length in seconds\n",
    "        tfeb_pool_sizes = self.get_tfeb_pool_sizes(self.ch_config[1], self.tfeb_width);\n",
    "        p_index = 0;\n",
    "        for i in [3,4,6,8,10]:\n",
    "            tfeb_modules.extend([eval('conv{}'.format(i)), eval('bn{}'.format(i)), nn.ReLU()]);\n",
    "\n",
    "            if i != 3:\n",
    "                tfeb_modules.extend([eval('conv{}'.format(i+1)), eval('bn{}'.format(i+1)), nn.ReLU()]);\n",
    "\n",
    "            h, w = tfeb_pool_sizes[p_index];\n",
    "            if h>1 or w>1:\n",
    "                tfeb_modules.append(nn.MaxPool2d(kernel_size = (h,w)));\n",
    "            p_index += 1;\n",
    "\n",
    "        tfeb_modules.append(nn.Dropout(0.2));\n",
    "        tfeb_modules.extend([conv12, bn12, nn.ReLU()]);\n",
    "        h, w = tfeb_pool_sizes[-1];\n",
    "        if h>1 or w>1:\n",
    "            tfeb_modules.append(nn.AvgPool2d(kernel_size = (h,w)));\n",
    "        tfeb_modules.extend([nn.Flatten(), fcn]);\n",
    "\n",
    "        self.tfeb = nn.Sequential(*tfeb_modules);\n",
    "\n",
    "        self.output = nn.Sequential(\n",
    "            nn.Softmax(dim=1)\n",
    "        );\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.sfeb(x);\n",
    "        #swapaxes\n",
    "        x = x.permute((0, 2, 1, 3));\n",
    "        x = self.tfeb(x);\n",
    "        y = self.output[0](x);\n",
    "        return y;\n",
    "\n",
    "    def make_layers(self, in_channels, out_channels, kernel_size, stride=(1,1), padding=0, bias=False):\n",
    "        conv = nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, stride=stride, padding=padding, bias=bias);\n",
    "        nn.init.kaiming_normal_(conv.weight, nonlinearity='relu'); # kaiming with relu is equivalent to he_normal in keras\n",
    "        bn = nn.BatchNorm2d(out_channels);\n",
    "        return conv, bn;\n",
    "\n",
    "    def get_tfeb_pool_sizes(self, con2_ch, width):\n",
    "        h = self.get_tfeb_pool_size_component(con2_ch);\n",
    "        w = self.get_tfeb_pool_size_component(width);\n",
    "        # print(w);\n",
    "        pool_size = [];\n",
    "        for  (h1, w1) in zip(h, w):\n",
    "            pool_size.append((h1, w1));\n",
    "        return pool_size;\n",
    "\n",
    "    def get_tfeb_pool_size_component(self, length):\n",
    "        # print(length);\n",
    "        c = [];\n",
    "        index = 1;\n",
    "        while index <= 6:\n",
    "            if length >= 2:\n",
    "                if index == 6:\n",
    "                    c.append(length);\n",
    "                else:\n",
    "                    c.append(2);\n",
    "                    length = length // 2;\n",
    "            else:\n",
    "               c.append(1);\n",
    "\n",
    "            index += 1;\n",
    "\n",
    "        return c;\n",
    "\n",
    "def GetACDNetModel(input_len=30225, nclass=50, sr=20000, channel_config=None):\n",
    "    net = ACDNetV2(input_len, nclass, sr, ch_conf=channel_config);\n",
    "    return net;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5d298ee4-f3f7-4001-8224-54b8817a2171",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42;\n",
    "random.seed(seed);\n",
    "np.random.seed(seed);\n",
    "torch.manual_seed(seed);\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(seed);\n",
    "torch.backends.cudnn.deterministic = True;\n",
    "torch.backends.cudnn.benchmark = False;\n",
    "###########################################\n",
    "\n",
    "class Customed_ACDNetV2(nn.Module):\n",
    "    def __init__(self, input_length, n_class, sr, ch_conf=None):\n",
    "        super(Customed_ACDNetV2, self).__init__();\n",
    "        self.input_length = input_length;\n",
    "        self.ch_config = ch_conf;\n",
    "\n",
    "        stride1 = 2;\n",
    "        stride2 = 2;\n",
    "        channels = 8;\n",
    "        k_size = (3, 3);\n",
    "        n_frames = (sr/1000)*10; #No of frames per 10ms\n",
    "\n",
    "        sfeb_pool_size = int(n_frames/(stride1*stride2));\n",
    "        # tfeb_pool_size = (2,2);\n",
    "        if self.ch_config is None:\n",
    "            self.ch_config = [channels, channels*8, channels*4, channels*8, channels*8, channels*16, channels*16, channels*32, channels*32, channels*64, channels*64, n_class];\n",
    "        # avg_pool_kernel_size = (1,4) if self.ch_config[1] < 64 else (2,4);\n",
    "        fcn_no_of_inputs =  n_class #self.ch_config[-1];\n",
    "        ch_confing_10 = 512 #8 * 64\n",
    "        ch_n_class = n_class\n",
    "        conv1, bn1 = self.make_layers(1, self.ch_config[0], (1, 9), (1, stride1));\n",
    "        conv2, bn2 = self.make_layers(self.ch_config[0], self.ch_config[1], (1, 5), (1, stride2));\n",
    "        conv3, bn3 = self.make_layers(1, self.ch_config[2], k_size, padding=1);\n",
    "        conv4, bn4 = self.make_layers(self.ch_config[2], self.ch_config[3], k_size, padding=1);\n",
    "        conv5, bn5 = self.make_layers(self.ch_config[3], self.ch_config[4], k_size, padding=1);\n",
    "        conv6, bn6 = self.make_layers(self.ch_config[4], self.ch_config[5], k_size, padding=1);\n",
    "        conv7, bn7 = self.make_layers(self.ch_config[5], self.ch_config[6], k_size, padding=1);\n",
    "        conv8, bn8 = self.make_layers(self.ch_config[6], self.ch_config[7], k_size, padding=1);\n",
    "        conv9, bn9 = self.make_layers(self.ch_config[7], self.ch_config[8], k_size, padding=1);\n",
    "        conv10, bn10 = self.make_layers(self.ch_config[8], self.ch_config[9], k_size, padding=1);\n",
    "        conv11, bn11 = self.make_layers(self.ch_config[9], self.ch_config[10], k_size, padding=1);\n",
    "        conv12, bn12 = self.make_layers(ch_confing_10, ch_n_class, (1, 1));\n",
    "        fcn = nn.Linear(fcn_no_of_inputs, ch_n_class);\n",
    "        nn.init.kaiming_normal_(fcn.weight, nonlinearity='sigmoid') # kaiming with sigoid is equivalent to lecun_normal in keras\n",
    "\n",
    "        self.sfeb = nn.Sequential(\n",
    "            #Start: Filter bank\n",
    "            conv1, bn1, nn.ReLU(),\\\n",
    "            conv2, bn2, nn.ReLU(),\\\n",
    "            nn.MaxPool2d(kernel_size=(1, sfeb_pool_size))\n",
    "        );\n",
    "\n",
    "        tfeb_modules = [];\n",
    "        self.tfeb_width = int(((self.input_length / sr)*1000)/10); # 10ms frames of audio length in seconds\n",
    "        tfeb_pool_sizes = self.get_tfeb_pool_sizes(self.ch_config[1], self.tfeb_width);\n",
    "        p_index = 0;\n",
    "        for i in [3,4,6,8,10]:\n",
    "            tfeb_modules.extend([eval('conv{}'.format(i)), eval('bn{}'.format(i)), nn.ReLU()]);\n",
    "\n",
    "            if i != 3:\n",
    "                tfeb_modules.extend([eval('conv{}'.format(i+1)), eval('bn{}'.format(i+1)), nn.ReLU()]);\n",
    "\n",
    "            h, w = tfeb_pool_sizes[p_index];\n",
    "            if h>1 or w>1:\n",
    "                tfeb_modules.append(nn.MaxPool2d(kernel_size = (h,w)));\n",
    "            p_index += 1;\n",
    "\n",
    "        tfeb_modules.append(nn.Dropout(0.2));\n",
    "        tfeb_modules.extend([conv12, bn12, nn.ReLU()]);\n",
    "        h, w = tfeb_pool_sizes[-1];\n",
    "        if h>1 or w>1:\n",
    "            tfeb_modules.append(nn.AvgPool2d(kernel_size = (2,4)));\n",
    "        tfeb_modules.extend([nn.Flatten(), fcn]);\n",
    "\n",
    "        self.tfeb = nn.Sequential(*tfeb_modules);\n",
    "\n",
    "        self.output = nn.Sequential(\n",
    "            nn.Softmax(dim=1)\n",
    "        );\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        # print(f\"sfeb:\\n{list(self.sfeb.children())}\");\n",
    "        # print(f\"input x shape:{x.size()}\");\n",
    "        \"\"\"\n",
    "        input dim should be input x shape:torch.Size([32, 1, 1, 30225])\n",
    "        if you got input x shape:[32, 30225, 1, 1], that is wrong.\n",
    "        \"\"\"\n",
    "        x = self.sfeb(x);\n",
    "        #swapaxes\n",
    "        x = x.permute((0, 2, 1, 3));\n",
    "        x = self.tfeb(x);\n",
    "        y = self.output[0](x);\n",
    "        return y;\n",
    "\n",
    "    def make_layers(self, in_channels, out_channels, kernel_size, stride=(1,1), padding=0, bias=False):\n",
    "        conv = nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, stride=stride, padding=padding, bias=bias);\n",
    "        nn.init.kaiming_normal_(conv.weight, nonlinearity='relu'); # kaiming with relu is equivalent to he_normal in keras\n",
    "        bn = nn.BatchNorm2d(out_channels);\n",
    "        return conv, bn;\n",
    "\n",
    "    def get_tfeb_pool_sizes(self, con2_ch, width):\n",
    "        h = self.get_tfeb_pool_size_component(con2_ch);\n",
    "        w = self.get_tfeb_pool_size_component(width);\n",
    "        # print(w);\n",
    "        pool_size = [];\n",
    "        for  (h1, w1) in zip(h, w):\n",
    "            pool_size.append((h1, w1));\n",
    "        return pool_size;\n",
    "\n",
    "    def get_tfeb_pool_size_component(self, length):\n",
    "        # print(length);\n",
    "        c = [];\n",
    "        index = 1;\n",
    "        while index <= 6:\n",
    "            if length >= 2:\n",
    "                if index == 6:\n",
    "                    c.append(length);\n",
    "                else:\n",
    "                    c.append(2);\n",
    "                    length = length // 2;\n",
    "            else:\n",
    "               c.append(1);\n",
    "\n",
    "            index += 1;\n",
    "\n",
    "        return c;\n",
    "\n",
    "def GetCustomedACDNetModel(input_len=30225, nclass=3, sr=20000, channel_config=None):\n",
    "    net = Customed_ACDNetV2(input_len, nclass, sr, ch_conf=channel_config);\n",
    "    return net;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "22423f68-d925-450f-a24b-567422ef736b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getOpts():\n",
    "    parser = argparse.ArgumentParser(description='Transfer Learning for ACDNet');\n",
    "    parser.add_argument('--netType', default='TLACDNet',  required=False);\n",
    "    parser.add_argument('--data', default='../datasets/processed/',  required=False);\n",
    "    parser.add_argument('--dataset', required=False, default='uec_iot', choices=['10']);\n",
    "    parser.add_argument('--BC', default=True, action='store_true', help='BC learning');\n",
    "    parser.add_argument('--strongAugment', default=True,  action='store_true', help='Add scale and gain augmentation');\n",
    "    #在ipynb中，不能使用parser.parse，要改用parser.parse_known_args()\n",
    "    opt, unknown = parser.parse_known_args()\n",
    "    #Leqarning settings\n",
    "   \n",
    "    opt.batchSize = 64;\n",
    "    opt.LR = 0.1;\n",
    "    opt.momentum = 0.9;\n",
    "    opt.weightDecay = 5e-4;\n",
    "    opt.schedule = [0.15, 0.30, 0.45, 0.60, 0.75];#default:[0.15, 0.30, 0.45, 0.60, 0.75];\n",
    "    opt.warmup = 10;\n",
    "    opt.nEpochs = 500;\n",
    "    # opt.LR = 0.1;\n",
    "    # opt.momentum = 0.09;\n",
    "    # opt.nEpochs = 1000;#2000;\n",
    "    # opt.schedule = [0.3, 0.6, 0.9];\n",
    "    # opt.warmup = 10;\n",
    "\n",
    "    #Basic Net Settings\n",
    "    opt.nClasses = 3#50;\n",
    "    opt.nFolds = 1;#5;\n",
    "    opt.split = 1#[i for i in range(1, opt.nFolds + 1)];\n",
    "    opt.sr = 20000;\n",
    "    opt.inputLength = 30225;\n",
    "    #Test data\n",
    "    opt.nCrops = 2;\n",
    "    return opt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8d6e457-9c01-4aeb-bf23-6ae046b2d781",
   "metadata": {},
   "source": [
    "- <font size=2 color='#FF6600'>For the accuracy and model generation capacity it is better to add more data to the training and validation datasets.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "48a4c5d5-e2b4-4775-b7f6-4de0c5147e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTrainGen(opt=None, split=None):\n",
    "    # dataset = np.load(os.path.join(opt.data, opt.dataset, 'wav{}.npz'.format(opt.sr // 1000)), allow_pickle=True);\n",
    "    # dataset = np.load(\"../datasets/fold1_test16000.npz\", allow_pickle=True);\n",
    "    dataset = np.load(\"../../../datasets/CurrentUse/generated_datasets/train/version4/single_fold_train_20240502114607.npz\", allow_pickle=True);\n",
    "    train_sounds = []\n",
    "    train_labels = []\n",
    "    # print(len(dataset['x']))\n",
    "    # for i in range(1, opt.nFolds + 1):\n",
    "\n",
    "    # train_sounds = [dataset['x'][i][0] for i in range(len(dataset['x']))]\n",
    "    # train_labels = [dataset['y'][i][0] for i in range(len(dataset['y']))]\n",
    "    train_sounds = dataset['fold{}'.format(1)].item()['sounds']\n",
    "    train_labels = dataset['fold{}'.format(1)].item()['labels']\n",
    "    # print(train_sounds)\n",
    "\n",
    "    trainGen = TLGenerator(train_sounds, train_labels, opt);\n",
    "    return trainGen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ec8011c4-e99c-4675-b692-204ee0cfd268",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PruningTrainer:\n",
    "    def __init__(self, opt):\n",
    "        self.opt = opt;\n",
    "        #Conditional compression settings\n",
    "        # self.opt.LR = 0.01;\n",
    "        # self.opt.momentum = 0.09;\n",
    "        # self.opt.schedule = [0.15, 0.30, 0.45, 0.60, 0.75];\n",
    "        # self.opt.warmup = 0;\n",
    "        self.opt.prune_algo = 'l0norm';\n",
    "        self.opt.prune_interval = 1;\n",
    "        # self.opt.nEpochs = 1000;\n",
    "        self.testX = None;\n",
    "        self.testY = None;\n",
    "        self.bestAcc = 0.0;\n",
    "        self.bestAccEpoch = 0;\n",
    "        self.trainGen = getTrainGen(opt)#train_generator.setup(self.opt, self.opt.split);\n",
    "        # if torch.device == \"cuda:0\":\n",
    "        #     self.device = '\"cuda:0\"'\n",
    "        # elif torch.device == \"mps\":\n",
    "        #     self.device = \"mps\"\n",
    "        # else:\n",
    "        #     self.device = \"cpu\"\n",
    "        self.device=\"cuda:0\"\n",
    "        print(f\"In PruningTrainer:: current used device:{self.device}\")\n",
    "        # self.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\");\n",
    "        self.start_time = time.time();\n",
    "\n",
    "    def PruneAndTrain(self):\n",
    "        self.load_test_data();\n",
    "        print(self.device);\n",
    "        loss_func = torch.nn.KLDivLoss(reduction='batchmean');\n",
    "\n",
    "        #Load saved model dict\n",
    "        net = GetCustomedACDNetModel()#GetACDNetModel()\n",
    "        net.load_state_dict(torch.load(\"../../../trained_models/step_1_base_train/base_train_lr0.1_bs128_wd0.0005_20240502121915/sp_ai_model_3Classes_20240502123449_acc_93.64407348632812_188th_epoch.pt\", map_location=self.device)['weight']);\n",
    "        calc.summary(net, (1,1,self.opt.inputLength))\n",
    "        net.eval();\n",
    "        val_acc, val_loss = self.__validate(net, loss_func);\n",
    "        print('Testing - Val: Loss {:.3f}  Acc(top1) {:.3f}%'.format(val_loss, val_acc));\n",
    "        net.train();\n",
    "\n",
    "        optimizer = optim.SGD(net.parameters(), lr=self.opt.LR, weight_decay=self.opt.weightDecay, momentum=self.opt.momentum, nesterov=True)\n",
    "\n",
    "        weight_name = [\"weight\"]# if not self.opt.factorize else [\"weightA\", \"weightB\", \"weightC\"]\n",
    "        layers_n = weight_pruner.layers_n(net, param_name=[\"weight\"])[1];\n",
    "        all_num = sum(layers_n.values());\n",
    "        print(\"\\t TOTAL PRUNABLE PARAMS: {}\".format(all_num));\n",
    "        print(\"\\t PRUNE RATIO :{}\".format(self.opt.prune_ratio));\n",
    "        sparse_factor = int(all_num * (1-self.opt.prune_ratio));\n",
    "        print(\"\\t SPARSE FACTOR: {}\".format(sparse_factor));\n",
    "        model_size = (sparse_factor * 4)/1024**2;\n",
    "        print(\"\\t MODEL SIZE: {:.2f} MB\".format(model_size));\n",
    "        prune_algo = getattr(weight_pruner, self.opt.prune_algo);\n",
    "        prune_func = lambda m: prune_algo(m, sparse_factor, param_name=weight_name);\n",
    "\n",
    "        for epoch_idx in range(self.opt.nEpochs):\n",
    "            epoch_start_time = time.time();\n",
    "            optimizer.param_groups[0]['lr'] = self.__get_lr(epoch_idx+1);\n",
    "            cur_lr = optimizer.param_groups[0]['lr'];\n",
    "            running_loss = 0.0;\n",
    "            running_acc = 0.0;\n",
    "            n_batches = math.ceil(len(self.trainGen.data)/self.opt.batchSize);\n",
    "            net.train();\n",
    "            for batch_idx in range(n_batches):\n",
    "                # with torch.no_grad():\n",
    "                x,y = self.trainGen.__getitem__(batch_idx)\n",
    "                x = torch.tensor(np.moveaxis(x, 3, 1)).to(self.device);\n",
    "                y = torch.tensor(y).to(self.device);\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad();\n",
    "\n",
    "                # forward + backward + optimize\n",
    "                # outputs = net(x);#in office and use cpu\n",
    "                x = x.type(torch.FloatTensor)\n",
    "                outputs = net(x);\n",
    "                res_y = y.argmax(dim=1)\n",
    "                res_y = res_y.type(torch.FloatTensor)\n",
    "                running_acc += ((( outputs.data.argmax(dim=1) == res_y)*1).float().mean()).item();\n",
    "                y = y.type(torch.FloatTensor)\n",
    "                loss = loss_func(outputs.log(), y);\n",
    "\n",
    "                loss.backward();\n",
    "                optimizer.step();\n",
    "\n",
    "                running_loss += loss.item();\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    prune_func(net);\n",
    "\n",
    "            prune_func(net)\n",
    "\n",
    "            tr_acc = (running_acc / n_batches)*100;\n",
    "            tr_loss = running_loss / n_batches;\n",
    "\n",
    "            #Epoch wise validation Validation\n",
    "            epoch_train_time = time.time() - epoch_start_time;\n",
    "            net.eval();\n",
    "            val_acc, val_loss = self.__validate(net, loss_func);\n",
    "            #Save best model\n",
    "            self.__save_model(val_acc, tr_acc, epoch_idx, net);\n",
    "\n",
    "            self.__on_epoch_end(epoch_start_time, epoch_train_time, epoch_idx, cur_lr, tr_loss, tr_acc, val_loss, val_acc);\n",
    "\n",
    "            running_loss = 0;\n",
    "            running_acc = 0;\n",
    "            net.train();\n",
    "\n",
    "        total_time_taken = time.time() - self.start_time;\n",
    "        print(\"Execution finished in: {}\".format(U.to_hms(total_time_taken)));\n",
    "\n",
    "    def load_test_data(self):\n",
    "        if(self.testX is None):\n",
    "            data = np.load(\"../../../datasets/CurrentUse/generated_datasets/val/version4/final_single_val_20240502120516.npz\", allow_pickle=True);\n",
    "            dataX = np.moveaxis(data['x'], 3, 1).astype(np.float32);\n",
    "            self.testX = torch.tensor(dataX).to(self.device);\n",
    "            self.testY = torch.FloatTensor(data['y']).to(self.device);\n",
    "\n",
    "    def __get_lr(self, epoch):\n",
    "        divide_epoch = np.array([self.opt.nEpochs * i for i in self.opt.schedule]);\n",
    "        decay = sum(epoch > divide_epoch);\n",
    "        if epoch <= self.opt.warmup:\n",
    "            decay = 1;\n",
    "        return self.opt.LR * np.power(0.1, decay);\n",
    "\n",
    "    def __validate(self, net, lossFunc):\n",
    "        with torch.no_grad():\n",
    "            y_pred = None;\n",
    "            batch_size = (self.opt.batchSize//self.opt.nCrops)*self.opt.nCrops\n",
    "            for idx in range(math.ceil(len(self.testX)/batch_size)):\n",
    "                x = self.testX[idx*batch_size : (idx+1)*batch_size];\n",
    "                x = torch.tensor(x)\n",
    "                x = x.type(torch.FloatTensor) # use apple mp2\n",
    "                scores = net(x);\n",
    "                y_pred = scores.data if y_pred is None else torch.cat((y_pred, scores.data));\n",
    "\n",
    "            acc, loss = self.__compute_accuracy(y_pred, self.testY, lossFunc);\n",
    "        return acc, loss;\n",
    "\n",
    "    #Calculating average prediction (10 crops) and final accuracy\n",
    "    def __compute_accuracy(self, y_pred, y_target, lossFunc):\n",
    "        with torch.no_grad():\n",
    "            #Reshape to shape theme like each sample comtains 10 samples, calculate mean and find theindices that has highest average value for each sample\n",
    "            y_pred = (y_pred.reshape(y_pred.shape[0]//self.opt.nCrops, self.opt.nCrops, y_pred.shape[1])).mean(dim=1).argmax(dim=1);\n",
    "            y_target = (y_target.reshape(y_target.shape[0]//self.opt.nCrops, self.opt.nCrops, y_target.shape[1])).mean(dim=1).argmax(dim=1);\n",
    "            # print(f\"y_pred:{type(y_pred)}, y_target:{type(y_target)}\")\n",
    "            y_target = y_target.cpu() #use apple m2, in office use cuda\n",
    "            acc = (((y_pred==y_target)*1).float().mean()*100).item();\n",
    "            # valLossFunc = torch.nn.KLDivLoss();\n",
    "            loss = lossFunc(y_pred.float().log(), y_target.float()).item();\n",
    "            # loss = 0.0;\n",
    "        return acc, loss;\n",
    "\n",
    "    def __on_epoch_end(self, epoch_start_time, train_time, epochIdx, lr, tr_loss, tr_acc, val_loss, val_acc):\n",
    "        epoch_time = time.time() - epoch_start_time;\n",
    "        val_time = epoch_time - train_time;\n",
    "        total_time = time.time() - self.start_time;\n",
    "        line = '{} Epoch: {}/{} | Time: {} (Train {}  Val {}) | Train: LR {}  Loss {:.2f}  Acc {:.2f}% | Val: Loss {:.2f}  Acc(top1) {:.2f}% | HA {:.2f}@{}\\n'.format(\n",
    "            U.to_hms(total_time), epochIdx+1, self.opt.nEpochs, U.to_hms(epoch_time), U.to_hms(train_time), U.to_hms(val_time),\n",
    "            lr, tr_loss, tr_acc, val_loss, val_acc, self.bestAcc, self.bestAccEpoch);\n",
    "        # print(line)\n",
    "        sys.stdout.write(line);\n",
    "        sys.stdout.flush();\n",
    "\n",
    "    def __save_model(self, acc, train_acc, epochIdx, net):\n",
    "        if acc > self.bestAcc and acc > self.opt.first_save_acc:\n",
    "            self.bestAcc = acc;\n",
    "            self.bestAccEpoch = epochIdx +1;\n",
    "            self.__do_save_model(acc, train_acc, self.bestAccEpoch, net);\n",
    "        else:\n",
    "            if acc > self.opt.save_val_acc and train_acc > self.opt.save_train_acc: \n",
    "                self.__do_save_model(self, acc, train_acc, epochIdx, net);\n",
    "            else:\n",
    "                pass\n",
    "\n",
    "    def __do_save_model(self, acc, tr_acc, epochIdx, net):\n",
    "        save_model_name = self.opt.model_name.format(self.bestAcc, acc, train_acc, epochIdx, genDataTimeStr());\n",
    "        save_model_fullpath = self.opt.save_dir + save_model_name;\n",
    "        print(f\"save model to {save_model_fullpath}\")\n",
    "        torch.save({'weight':net.state_dict(), 'config':net.ch_config}, save_model_fullpath);\n",
    "        logObj.write(f\"save model:{self.opt.model_name}, bestAcc:{self.bestAcc}, valAcc:{acc}, trainAcc:{}, record@{epochIdx}-epoch\");\n",
    "        logObj.write(\"\\n\");\n",
    "        logObj.flush();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "cbb69075-8799-469d-b9c1-a545cee964d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n-----------------------------------------------------------------------------------------------\\npruning ration : 0.9\\nfinal accuracy : \\nepoch: \\nself.opt.LR = 0.01;\\nopt.momentum = 0.9;\\nself.opt.schedule = [0.15, 0.30, 0.45, 0.60, 0.75];\\nself.opt.warmup = 0;\\nself.opt.prune_algo = 'l0norm';\\nself.opt.prune_interval = 1;\\nself.opt.nEpochs = 1000;\\n########################## Trainig Data Version 4 ##########################\\nopt.batchSize = 64;\\nopt.LR = 0.1;\\nopt.momentum = 0.9;\\nopt.weightDecay = 5e-4;\\nopt.schedule = [0.15, 0.30, 0.45, 0.60, 0.75];#default:[0.15, 0.30, 0.45, 0.60, 0.75];\\nopt.warmup = 10;\\nopt.nEpochs = 600;\\n==============================================================\\n\""
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "-----------------------------------------------------------------------------------------------\n",
    "pruning ration : 0.9\n",
    "final accuracy : \n",
    "epoch: \n",
    "self.opt.LR = 0.01;\n",
    "opt.momentum = 0.9;\n",
    "self.opt.schedule = [0.15, 0.30, 0.45, 0.60, 0.75];\n",
    "self.opt.warmup = 0;\n",
    "self.opt.prune_algo = 'l0norm';\n",
    "self.opt.prune_interval = 1;\n",
    "self.opt.nEpochs = 1000;\n",
    "########################## Trainig Data Version 4 ##########################\n",
    "opt.batchSize = 64;\n",
    "opt.LR = 0.1;\n",
    "opt.momentum = 0.9;\n",
    "opt.weightDecay = 5e-4;\n",
    "opt.schedule = [0.15, 0.30, 0.45, 0.60, 0.75];#default:[0.15, 0.30, 0.45, 0.60, 0.75];\n",
    "opt.warmup = 10;\n",
    "opt.nEpochs = 600;\n",
    "==============================================================\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c9fd15f0-cbdf-4b2f-b3c9-96f694eb4a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    opt = getOpts()\n",
    "    opt.sr = 20000;\n",
    "    opt.inputLength = 30225;\n",
    "    opt.trainer = None\n",
    "    opt.prune_ratio = 0.8\n",
    "    opt.first_save_acc = 91.0;\n",
    "    opt.save_val_acc = 94.0;\n",
    "    opt.save_train_acc = 77.0;\n",
    "    trainStartTime = getDateStr();\n",
    "    save_dir = \"../../../trained_models/step_2_first_stage_pruning/pruning_time_{}_prunratio{}/\".format(trainStartTime,opt.prune_ratio*100)\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.mkdir(save_dir)\n",
    "    opt.save_dir = save_dir;\n",
    "    opt.model_name = \"sp_ai_model_first_stage_prun_haacc_{}_valacc{}_tracc{}_epoch_{}_{}.pt\";\n",
    "    print(\"Initializing PruneAndTrain Object.....\")\n",
    "    trainer = PruningTrainer(opt)#TLTrainer(opt)\n",
    "    print(\"Start to pruning.....\")\n",
    "    logSaveDir = \"./first_stage_pruning_logs/\"\n",
    "    ChkAndCreateSingleDir(logSaveDir);\n",
    "    logName = \"FirstPruningLog_{}.log\".format(trainStartTime);\n",
    "    logObj = open(os.path.join(logSaveDir,logName),'w');\n",
    "    trainer.PruneAndTrain();\n",
    "    logObj.flush();\n",
    "    logObj.close();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8780ef94-ad0c-46bc-abb9-a5573b8b3480",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing PruneAndTrain Object.....\n",
      "length of samples:651\n",
      "In PruningTrainer:: current used device:cuda:0\n",
      "Start to pruning.....\n",
      "cuda:0\n",
      "+----------------------------------------------------------------------------+\n",
      "+                           Pytorch Model Summary                            +\n",
      "------------------------------------------------------------------------------\n",
      "   Layer (type)       Input Shape      Output Shape    Param #      FLOPS #\n",
      "==============================================================================\n",
      "       Conv2d-1     (1, 1, 30225)     (8, 1, 15109)         72    1,087,848\n",
      "  BatchNorm2d-2     (8, 1, 15109)     (8, 1, 15109)         16            0\n",
      "         ReLu-3     (8, 1, 15109)     (8, 1, 15109)          0      120,872\n",
      "       Conv2d-4     (8, 1, 15109)     (64, 1, 7553)      2,560   19,335,680\n",
      "  BatchNorm2d-5     (64, 1, 7553)     (64, 1, 7553)        128            0\n",
      "         ReLu-6     (64, 1, 7553)     (64, 1, 7553)          0      483,392\n",
      "    MaxPool2d-7     (64, 1, 7553)      (64, 1, 151)          0      483,200\n",
      "      Permute-8      (64, 1, 151)      (1, 64, 151)          0            0\n",
      "       Conv2d-9      (1, 64, 151)     (32, 64, 151)        288    2,783,232\n",
      " BatchNorm2d-10     (32, 64, 151)     (32, 64, 151)         64            0\n",
      "        ReLu-11     (32, 64, 151)     (32, 64, 151)          0      309,248\n",
      "   MaxPool2d-12     (32, 64, 151)      (32, 32, 75)          0      307,200\n",
      "      Conv2d-13      (32, 32, 75)      (64, 32, 75)     18,432   44,236,800\n",
      " BatchNorm2d-14      (64, 32, 75)      (64, 32, 75)        128            0\n",
      "        ReLu-15      (64, 32, 75)      (64, 32, 75)          0      153,600\n",
      "      Conv2d-16      (64, 32, 75)      (64, 32, 75)     36,864   88,473,600\n",
      " BatchNorm2d-17      (64, 32, 75)      (64, 32, 75)        128            0\n",
      "        ReLu-18      (64, 32, 75)      (64, 32, 75)          0      153,600\n",
      "   MaxPool2d-19      (64, 32, 75)      (64, 16, 37)          0      151,552\n",
      "      Conv2d-20      (64, 16, 37)     (128, 16, 37)     73,728   43,646,976\n",
      " BatchNorm2d-21     (128, 16, 37)     (128, 16, 37)        256            0\n",
      "        ReLu-22     (128, 16, 37)     (128, 16, 37)          0       75,776\n",
      "      Conv2d-23     (128, 16, 37)     (128, 16, 37)    147,456   87,293,952\n",
      " BatchNorm2d-24     (128, 16, 37)     (128, 16, 37)        256            0\n",
      "        ReLu-25     (128, 16, 37)     (128, 16, 37)          0       75,776\n",
      "   MaxPool2d-26     (128, 16, 37)      (128, 8, 18)          0       73,728\n",
      "      Conv2d-27      (128, 8, 18)      (256, 8, 18)    294,912   42,467,328\n",
      " BatchNorm2d-28      (256, 8, 18)      (256, 8, 18)        512            0\n",
      "        ReLu-29      (256, 8, 18)      (256, 8, 18)          0       36,864\n",
      "      Conv2d-30      (256, 8, 18)      (256, 8, 18)    589,824   84,934,656\n",
      " BatchNorm2d-31      (256, 8, 18)      (256, 8, 18)        512            0\n",
      "        ReLu-32      (256, 8, 18)      (256, 8, 18)          0       36,864\n",
      "   MaxPool2d-33      (256, 8, 18)       (256, 4, 9)          0       36,864\n",
      "      Conv2d-34       (256, 4, 9)       (512, 4, 9)  1,179,648   42,467,328\n",
      " BatchNorm2d-35       (512, 4, 9)       (512, 4, 9)      1,024            0\n",
      "        ReLu-36       (512, 4, 9)       (512, 4, 9)          0       18,432\n",
      "      Conv2d-37       (512, 4, 9)       (512, 4, 9)  2,359,296   84,934,656\n",
      " BatchNorm2d-38       (512, 4, 9)       (512, 4, 9)      1,024            0\n",
      "        ReLu-39       (512, 4, 9)       (512, 4, 9)          0       18,432\n",
      "   MaxPool2d-40       (512, 4, 9)       (512, 2, 4)          0       16,384\n",
      "      Conv2d-41       (512, 2, 4)         (3, 2, 4)      1,536       12,288\n",
      " BatchNorm2d-42         (3, 2, 4)         (3, 2, 4)          6            0\n",
      "        ReLu-43         (3, 2, 4)         (3, 2, 4)          0           24\n",
      "   AvgPool2d-44         (3, 2, 4)         (3, 1, 1)          0           24\n",
      "     Flatten-45         (3, 1, 1)            (1, 3)          0            0\n",
      "      Linear-46            (1, 3)            (1, 3)         12           12\n",
      "     Softmax-47            (1, 3)            (1, 3)          0            3\n",
      "==============================================================================\n",
      "Total Params: 4,708,682\n",
      "Total FLOPs : 544,226,191\n",
      "------------------------------------------------------------------------------\n",
      "Input size (MB) : 0.12\n",
      "Params size (MB): 17.96\n",
      "Total size (MB) : 18.08\n",
      "------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_136694/630219043.py:144: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing - Val: Loss nan  Acc(top1) 93.644%\n",
      "\t TOTAL PRUNABLE PARAMS: 4704625\n",
      "\t PRUNE RATIO :0.8\n",
      "\t SPARSE FACTOR: 940924\n",
      "\t MODEL SIZE: 3.59 MB\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc80.08474731445312_epoch_0_20240502141514.pt\n",
      "0m15s Epoch: 1/600 | Time: 0m12s (Train 0m11s  Val 0m01s) | Train: LR 0.010000000000000002  Loss 0.32  Acc 69.46% | Val: Loss nan  Acc(top1) 80.08% | HA 80.08@1\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc86.8644027709961_epoch_1_20240502141527.pt\n",
      "0m28s Epoch: 2/600 | Time: 0m12s (Train 0m11s  Val 0m01s) | Train: LR 0.010000000000000002  Loss 0.31  Acc 72.59% | Val: Loss nan  Acc(top1) 86.86% | HA 86.86@2\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc89.40678405761719_epoch_2_20240502141540.pt\n",
      "0m41s Epoch: 3/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 0.010000000000000002  Loss 0.27  Acc 74.86% | Val: Loss nan  Acc(top1) 89.41% | HA 89.41@3\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc89.83050537109375_epoch_3_20240502141553.pt\n",
      "0m54s Epoch: 4/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 0.010000000000000002  Loss 0.28  Acc 74.01% | Val: Loss nan  Acc(top1) 89.83% | HA 89.83@4\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc90.67796325683594_epoch_4_20240502141606.pt\n",
      "1m07s Epoch: 5/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 0.010000000000000002  Loss 0.27  Acc 75.57% | Val: Loss nan  Acc(top1) 90.68% | HA 90.68@5\n",
      "1m20s Epoch: 6/600 | Time: 0m12s (Train 0m11s  Val 0m01s) | Train: LR 0.010000000000000002  Loss 0.24  Acc 79.83% | Val: Loss nan  Acc(top1) 88.56% | HA 90.68@5\n",
      "1m33s Epoch: 7/600 | Time: 0m12s (Train 0m11s  Val 0m01s) | Train: LR 0.010000000000000002  Loss 0.24  Acc 77.84% | Val: Loss nan  Acc(top1) 89.83% | HA 90.68@5\n",
      "1m46s Epoch: 8/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 0.010000000000000002  Loss 0.23  Acc 79.26% | Val: Loss nan  Acc(top1) 90.25% | HA 90.68@5\n",
      "1m59s Epoch: 9/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 0.010000000000000002  Loss 0.24  Acc 79.26% | Val: Loss nan  Acc(top1) 89.83% | HA 90.68@5\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc91.52542114257812_epoch_9_20240502141711.pt\n",
      "2m12s Epoch: 10/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 0.010000000000000002  Loss 0.22  Acc 78.69% | Val: Loss nan  Acc(top1) 91.53% | HA 91.53@10\n",
      "2m25s Epoch: 11/600 | Time: 0m12s (Train 0m11s  Val 0m01s) | Train: LR 0.1  Loss 0.28  Acc 74.01% | Val: Loss nan  Acc(top1) 81.78% | HA 91.53@10\n",
      "2m38s Epoch: 12/600 | Time: 0m12s (Train 0m11s  Val 0m01s) | Train: LR 0.1  Loss 0.34  Acc 69.60% | Val: Loss nan  Acc(top1) 77.54% | HA 91.53@10\n",
      "2m51s Epoch: 13/600 | Time: 0m12s (Train 0m11s  Val 0m01s) | Train: LR 0.1  Loss 0.30  Acc 75.85% | Val: Loss nan  Acc(top1) 77.12% | HA 91.53@10\n",
      "3m04s Epoch: 14/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 0.1  Loss 0.30  Acc 76.14% | Val: Loss nan  Acc(top1) 76.69% | HA 91.53@10\n",
      "3m17s Epoch: 15/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 0.1  Loss 0.29  Acc 73.58% | Val: Loss nan  Acc(top1) 85.17% | HA 91.53@10\n",
      "3m30s Epoch: 16/600 | Time: 0m12s (Train 0m11s  Val 0m01s) | Train: LR 0.1  Loss 0.27  Acc 76.85% | Val: Loss nan  Acc(top1) 89.83% | HA 91.53@10\n",
      "3m43s Epoch: 17/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 0.1  Loss 0.28  Acc 75.14% | Val: Loss nan  Acc(top1) 88.56% | HA 91.53@10\n",
      "3m56s Epoch: 18/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 0.1  Loss 0.26  Acc 78.55% | Val: Loss nan  Acc(top1) 85.59% | HA 91.53@10\n",
      "4m09s Epoch: 19/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 0.1  Loss 0.26  Acc 77.13% | Val: Loss nan  Acc(top1) 72.88% | HA 91.53@10\n",
      "4m22s Epoch: 20/600 | Time: 0m12s (Train 0m11s  Val 0m01s) | Train: LR 0.1  Loss 0.25  Acc 79.26% | Val: Loss nan  Acc(top1) 88.56% | HA 91.53@10\n",
      "4m36s Epoch: 21/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 0.1  Loss 0.26  Acc 78.27% | Val: Loss nan  Acc(top1) 91.10% | HA 91.53@10\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc88.1355972290039_epoch_21_20240502141948.pt\n",
      "4m49s Epoch: 22/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 0.1  Loss 0.26  Acc 82.53% | Val: Loss nan  Acc(top1) 88.14% | HA 88.14@22\n",
      "5m02s Epoch: 23/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 0.1  Loss 0.25  Acc 77.13% | Val: Loss nan  Acc(top1) 84.75% | HA 88.14@22\n",
      "5m15s Epoch: 24/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 0.1  Loss 0.26  Acc 76.70% | Val: Loss nan  Acc(top1) 88.14% | HA 88.14@22\n",
      "5m28s Epoch: 25/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 0.1  Loss 0.26  Acc 76.42% | Val: Loss nan  Acc(top1) 83.90% | HA 88.14@22\n",
      "5m41s Epoch: 26/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 0.1  Loss 0.27  Acc 77.13% | Val: Loss nan  Acc(top1) 84.75% | HA 88.14@22\n",
      "5m55s Epoch: 27/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 0.1  Loss 0.25  Acc 78.55% | Val: Loss nan  Acc(top1) 84.32% | HA 88.14@22\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc82.20338439941406_epoch_27_20240502142107.pt\n",
      "6m08s Epoch: 28/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 0.1  Loss 0.24  Acc 80.40% | Val: Loss nan  Acc(top1) 82.20% | HA 82.20@28\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc93.22034454345703_epoch_28_20240502142120.pt\n",
      "6m21s Epoch: 29/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 0.1  Loss 0.24  Acc 77.98% | Val: Loss nan  Acc(top1) 93.22% | HA 93.22@29\n",
      "6m35s Epoch: 30/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 0.1  Loss 0.25  Acc 78.84% | Val: Loss nan  Acc(top1) 90.68% | HA 93.22@29\n",
      "6m48s Epoch: 31/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 0.1  Loss 0.24  Acc 78.27% | Val: Loss nan  Acc(top1) 89.41% | HA 93.22@29\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc85.59321594238281_epoch_31_20240502142200.pt\n",
      "7m01s Epoch: 32/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 0.1  Loss 0.24  Acc 81.39% | Val: Loss nan  Acc(top1) 85.59% | HA 85.59@32\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc88.559326171875_epoch_32_20240502142214.pt\n",
      "7m15s Epoch: 33/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 0.1  Loss 0.24  Acc 76.85% | Val: Loss nan  Acc(top1) 88.56% | HA 88.56@33\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc90.67796325683594_epoch_33_20240502142227.pt\n",
      "7m28s Epoch: 34/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 0.1  Loss 0.25  Acc 77.84% | Val: Loss nan  Acc(top1) 90.68% | HA 90.68@34\n",
      "7m41s Epoch: 35/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 0.1  Loss 0.25  Acc 77.70% | Val: Loss nan  Acc(top1) 88.56% | HA 90.68@34\n",
      "7m55s Epoch: 36/600 | Time: 0m13s (Train 0m12s  Val 0m01s) | Train: LR 0.1  Loss 0.26  Acc 73.72% | Val: Loss nan  Acc(top1) 84.32% | HA 90.68@34\n",
      "8m09s Epoch: 37/600 | Time: 0m13s (Train 0m12s  Val 0m01s) | Train: LR 0.1  Loss 0.23  Acc 79.40% | Val: Loss nan  Acc(top1) 89.83% | HA 90.68@34\n",
      "8m22s Epoch: 38/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 0.1  Loss 0.24  Acc 78.41% | Val: Loss nan  Acc(top1) 90.68% | HA 90.68@34\n",
      "8m36s Epoch: 39/600 | Time: 0m13s (Train 0m12s  Val 0m01s) | Train: LR 0.1  Loss 0.24  Acc 77.70% | Val: Loss nan  Acc(top1) 89.41% | HA 90.68@34\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc90.67796325683594_epoch_39_20240502142348.pt\n",
      "8m49s Epoch: 40/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 0.1  Loss 0.24  Acc 81.68% | Val: Loss nan  Acc(top1) 90.68% | HA 90.68@40\n",
      "9m03s Epoch: 41/600 | Time: 0m13s (Train 0m12s  Val 0m01s) | Train: LR 0.1  Loss 0.23  Acc 78.41% | Val: Loss nan  Acc(top1) 88.56% | HA 90.68@40\n",
      "9m16s Epoch: 42/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 0.1  Loss 0.23  Acc 77.98% | Val: Loss nan  Acc(top1) 89.41% | HA 90.68@40\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc91.10169219970703_epoch_42_20240502142429.pt\n",
      "9m30s Epoch: 43/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 0.1  Loss 0.22  Acc 77.70% | Val: Loss nan  Acc(top1) 91.10% | HA 91.10@43\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc86.0169448852539_epoch_43_20240502142443.pt\n",
      "9m44s Epoch: 44/600 | Time: 0m13s (Train 0m12s  Val 0m01s) | Train: LR 0.1  Loss 0.23  Acc 80.40% | Val: Loss nan  Acc(top1) 86.02% | HA 86.02@44\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc87.28813171386719_epoch_44_20240502142456.pt\n",
      "9m57s Epoch: 45/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 0.1  Loss 0.21  Acc 79.83% | Val: Loss nan  Acc(top1) 87.29% | HA 87.29@45\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc90.67796325683594_epoch_45_20240502142510.pt\n",
      "10m11s Epoch: 46/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 0.1  Loss 0.21  Acc 78.55% | Val: Loss nan  Acc(top1) 90.68% | HA 90.68@46\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc84.32203674316406_epoch_46_20240502142523.pt\n",
      "10m24s Epoch: 47/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 0.1  Loss 0.23  Acc 81.25% | Val: Loss nan  Acc(top1) 84.32% | HA 84.32@47\n",
      "10m38s Epoch: 48/600 | Time: 0m13s (Train 0m12s  Val 0m01s) | Train: LR 0.1  Loss 0.22  Acc 77.98% | Val: Loss nan  Acc(top1) 83.90% | HA 84.32@47\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc92.79661560058594_epoch_48_20240502142550.pt\n",
      "10m51s Epoch: 49/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 0.1  Loss 0.23  Acc 78.55% | Val: Loss nan  Acc(top1) 92.80% | HA 92.80@49\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc88.9830551147461_epoch_49_20240502142604.pt\n",
      "11m05s Epoch: 50/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 0.1  Loss 0.23  Acc 80.11% | Val: Loss nan  Acc(top1) 88.98% | HA 88.98@50\n",
      "11m18s Epoch: 51/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 0.1  Loss 0.23  Acc 79.12% | Val: Loss nan  Acc(top1) 80.51% | HA 88.98@50\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc88.559326171875_epoch_51_20240502142630.pt\n",
      "11m31s Epoch: 52/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 0.1  Loss 0.22  Acc 81.39% | Val: Loss nan  Acc(top1) 88.56% | HA 88.56@52\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc91.94915008544922_epoch_52_20240502142644.pt\n",
      "11m45s Epoch: 53/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 0.1  Loss 0.21  Acc 79.26% | Val: Loss nan  Acc(top1) 91.95% | HA 91.95@53\n",
      "11m58s Epoch: 54/600 | Time: 0m12s (Train 0m11s  Val 0m01s) | Train: LR 0.1  Loss 0.24  Acc 78.84% | Val: Loss nan  Acc(top1) 88.98% | HA 91.95@53\n",
      "12m11s Epoch: 55/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 0.1  Loss 0.26  Acc 76.85% | Val: Loss nan  Acc(top1) 89.83% | HA 91.95@53\n",
      "12m24s Epoch: 56/600 | Time: 0m13s (Train 0m12s  Val 0m01s) | Train: LR 0.1  Loss 0.23  Acc 79.69% | Val: Loss nan  Acc(top1) 89.41% | HA 91.95@53\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc92.79661560058594_epoch_56_20240502142737.pt\n",
      "12m38s Epoch: 57/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 0.1  Loss 0.22  Acc 81.96% | Val: Loss nan  Acc(top1) 92.80% | HA 92.80@57\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc89.83050537109375_epoch_57_20240502142750.pt\n",
      "12m51s Epoch: 58/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 0.1  Loss 0.19  Acc 83.38% | Val: Loss nan  Acc(top1) 89.83% | HA 89.83@58\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc90.67796325683594_epoch_58_20240502142803.pt\n",
      "13m04s Epoch: 59/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 0.1  Loss 0.23  Acc 81.11% | Val: Loss nan  Acc(top1) 90.68% | HA 90.68@59\n",
      "13m17s Epoch: 60/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 0.1  Loss 0.24  Acc 78.12% | Val: Loss nan  Acc(top1) 90.25% | HA 90.68@59\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc92.37287902832031_epoch_60_20240502142830.pt\n",
      "13m31s Epoch: 61/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 0.1  Loss 0.24  Acc 80.97% | Val: Loss nan  Acc(top1) 92.37% | HA 92.37@61\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc84.74576568603516_epoch_61_20240502142844.pt\n",
      "13m44s Epoch: 62/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 0.1  Loss 0.23  Acc 80.40% | Val: Loss nan  Acc(top1) 84.75% | HA 84.75@62\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc90.25423431396484_epoch_62_20240502142857.pt\n",
      "13m58s Epoch: 63/600 | Time: 0m13s (Train 0m12s  Val 0m01s) | Train: LR 0.1  Loss 0.24  Acc 78.41% | Val: Loss nan  Acc(top1) 90.25% | HA 90.25@63\n",
      "14m12s Epoch: 64/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 0.1  Loss 0.23  Acc 79.40% | Val: Loss nan  Acc(top1) 90.25% | HA 90.25@63\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc89.40678405761719_epoch_64_20240502142925.pt\n",
      "14m25s Epoch: 65/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 0.1  Loss 0.22  Acc 80.68% | Val: Loss nan  Acc(top1) 89.41% | HA 89.41@65\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc91.10169219970703_epoch_65_20240502142938.pt\n",
      "14m39s Epoch: 66/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 0.1  Loss 0.23  Acc 79.69% | Val: Loss nan  Acc(top1) 91.10% | HA 91.10@66\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc89.83050537109375_epoch_66_20240502142951.pt\n",
      "14m52s Epoch: 67/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 0.1  Loss 0.22  Acc 81.25% | Val: Loss nan  Acc(top1) 89.83% | HA 89.83@67\n",
      "15m05s Epoch: 68/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 0.1  Loss 0.24  Acc 79.12% | Val: Loss nan  Acc(top1) 75.85% | HA 89.83@67\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc90.67796325683594_epoch_68_20240502143018.pt\n",
      "15m19s Epoch: 69/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 0.1  Loss 0.22  Acc 78.27% | Val: Loss nan  Acc(top1) 90.68% | HA 90.68@69\n",
      "15m32s Epoch: 70/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 0.1  Loss 0.23  Acc 79.69% | Val: Loss nan  Acc(top1) 88.14% | HA 90.68@69\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc86.0169448852539_epoch_70_20240502143045.pt\n",
      "15m45s Epoch: 71/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 0.1  Loss 0.22  Acc 82.39% | Val: Loss nan  Acc(top1) 86.02% | HA 86.02@71\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc83.47457885742188_epoch_71_20240502143058.pt\n",
      "15m59s Epoch: 72/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 0.1  Loss 0.22  Acc 80.40% | Val: Loss nan  Acc(top1) 83.47% | HA 83.47@72\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc88.9830551147461_epoch_72_20240502143112.pt\n",
      "16m12s Epoch: 73/600 | Time: 0m13s (Train 0m12s  Val 0m01s) | Train: LR 0.1  Loss 0.21  Acc 81.39% | Val: Loss nan  Acc(top1) 88.98% | HA 88.98@73\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc71.18643951416016_epoch_73_20240502143125.pt\n",
      "16m26s Epoch: 74/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 0.1  Loss 0.23  Acc 80.11% | Val: Loss nan  Acc(top1) 71.19% | HA 71.19@74\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc80.08474731445312_epoch_74_20240502143138.pt\n",
      "16m39s Epoch: 75/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 0.1  Loss 0.24  Acc 75.43% | Val: Loss nan  Acc(top1) 80.08% | HA 80.08@75\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc87.71186828613281_epoch_75_20240502143152.pt\n",
      "16m53s Epoch: 76/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 0.1  Loss 0.22  Acc 81.39% | Val: Loss nan  Acc(top1) 87.71% | HA 87.71@76\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc87.28813171386719_epoch_76_20240502143205.pt\n",
      "17m06s Epoch: 77/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 0.1  Loss 0.20  Acc 80.26% | Val: Loss nan  Acc(top1) 87.29% | HA 87.29@77\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc91.94915008544922_epoch_77_20240502143219.pt\n",
      "17m20s Epoch: 78/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 0.1  Loss 0.21  Acc 80.54% | Val: Loss nan  Acc(top1) 91.95% | HA 91.95@78\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc85.16949462890625_epoch_78_20240502143232.pt\n",
      "17m33s Epoch: 79/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 0.1  Loss 0.22  Acc 83.38% | Val: Loss nan  Acc(top1) 85.17% | HA 85.17@79\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc88.9830551147461_epoch_79_20240502143245.pt\n",
      "17m46s Epoch: 80/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 0.1  Loss 0.23  Acc 80.11% | Val: Loss nan  Acc(top1) 88.98% | HA 88.98@80\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc91.94915008544922_epoch_80_20240502143259.pt\n",
      "18m00s Epoch: 81/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 0.1  Loss 0.22  Acc 79.55% | Val: Loss nan  Acc(top1) 91.95% | HA 91.95@81\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc90.25423431396484_epoch_81_20240502143312.pt\n",
      "18m13s Epoch: 82/600 | Time: 0m13s (Train 0m12s  Val 0m01s) | Train: LR 0.1  Loss 0.21  Acc 80.82% | Val: Loss nan  Acc(top1) 90.25% | HA 90.25@82\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc88.559326171875_epoch_82_20240502143326.pt\n",
      "18m27s Epoch: 83/600 | Time: 0m13s (Train 0m12s  Val 0m01s) | Train: LR 0.1  Loss 0.22  Acc 81.68% | Val: Loss nan  Acc(top1) 88.56% | HA 88.56@83\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc91.10169219970703_epoch_83_20240502143339.pt\n",
      "18m40s Epoch: 84/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 0.1  Loss 0.20  Acc 81.53% | Val: Loss nan  Acc(top1) 91.10% | HA 91.10@84\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc92.37287902832031_epoch_84_20240502143352.pt\n",
      "18m53s Epoch: 85/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 0.1  Loss 0.21  Acc 82.10% | Val: Loss nan  Acc(top1) 92.37% | HA 92.37@85\n",
      "19m07s Epoch: 86/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 0.1  Loss 0.24  Acc 78.41% | Val: Loss nan  Acc(top1) 92.37% | HA 92.37@85\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc91.52542114257812_epoch_86_20240502143419.pt\n",
      "19m20s Epoch: 87/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 0.1  Loss 0.20  Acc 81.82% | Val: Loss nan  Acc(top1) 91.53% | HA 91.53@87\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc91.52542114257812_epoch_87_20240502143432.pt\n",
      "19m33s Epoch: 88/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 0.1  Loss 0.21  Acc 81.11% | Val: Loss nan  Acc(top1) 91.53% | HA 91.53@88\n",
      "19m47s Epoch: 89/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 0.1  Loss 0.22  Acc 77.84% | Val: Loss nan  Acc(top1) 82.63% | HA 91.53@88\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc91.52542114257812_epoch_89_20240502143459.pt\n",
      "20m00s Epoch: 90/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 0.1  Loss 0.23  Acc 80.26% | Val: Loss nan  Acc(top1) 91.53% | HA 91.53@90\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc91.94915008544922_epoch_90_20240502143513.pt\n",
      "20m14s Epoch: 91/600 | Time: 0m13s (Train 0m12s  Val 0m01s) | Train: LR 0.010000000000000002  Loss 0.21  Acc 81.39% | Val: Loss nan  Acc(top1) 91.95% | HA 91.95@91\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc94.49152374267578_epoch_91_20240502143527.pt\n",
      "20m27s Epoch: 92/600 | Time: 0m13s (Train 0m12s  Val 0m01s) | Train: LR 0.010000000000000002  Loss 0.20  Acc 81.68% | Val: Loss nan  Acc(top1) 94.49% | HA 94.49@92\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc92.79661560058594_epoch_92_20240502143540.pt\n",
      "20m41s Epoch: 93/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 0.010000000000000002  Loss 0.18  Acc 83.10% | Val: Loss nan  Acc(top1) 92.80% | HA 92.80@93\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc93.22034454345703_epoch_93_20240502143553.pt\n",
      "20m54s Epoch: 94/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 0.010000000000000002  Loss 0.19  Acc 82.95% | Val: Loss nan  Acc(top1) 93.22% | HA 93.22@94\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc93.64407348632812_epoch_94_20240502143607.pt\n",
      "21m08s Epoch: 95/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 0.010000000000000002  Loss 0.18  Acc 85.80% | Val: Loss nan  Acc(top1) 93.64% | HA 93.64@95\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc93.22034454345703_epoch_95_20240502143620.pt\n",
      "21m21s Epoch: 96/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 0.010000000000000002  Loss 0.18  Acc 83.81% | Val: Loss nan  Acc(top1) 93.22% | HA 93.22@96\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc94.06779479980469_epoch_96_20240502143634.pt\n",
      "21m34s Epoch: 97/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 0.010000000000000002  Loss 0.18  Acc 82.24% | Val: Loss nan  Acc(top1) 94.07% | HA 94.07@97\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc92.37287902832031_epoch_97_20240502143647.pt\n",
      "21m48s Epoch: 98/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 0.010000000000000002  Loss 0.18  Acc 83.38% | Val: Loss nan  Acc(top1) 92.37% | HA 92.37@98\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc91.94915008544922_epoch_98_20240502143700.pt\n",
      "22m01s Epoch: 99/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 0.010000000000000002  Loss 0.18  Acc 82.10% | Val: Loss nan  Acc(top1) 91.95% | HA 91.95@99\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc91.94915008544922_epoch_99_20240502143714.pt\n",
      "22m15s Epoch: 100/600 | Time: 0m13s (Train 0m12s  Val 0m01s) | Train: LR 0.010000000000000002  Loss 0.18  Acc 83.52% | Val: Loss nan  Acc(top1) 91.95% | HA 91.95@100\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc91.94915008544922_epoch_100_20240502143727.pt\n",
      "22m28s Epoch: 101/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 0.010000000000000002  Loss 0.18  Acc 84.80% | Val: Loss nan  Acc(top1) 91.95% | HA 91.95@101\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc92.37287902832031_epoch_101_20240502143740.pt\n",
      "22m41s Epoch: 102/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 0.010000000000000002  Loss 0.18  Acc 83.38% | Val: Loss nan  Acc(top1) 92.37% | HA 92.37@102\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc93.64407348632812_epoch_102_20240502143754.pt\n",
      "22m55s Epoch: 103/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 0.010000000000000002  Loss 0.16  Acc 82.95% | Val: Loss nan  Acc(top1) 93.64% | HA 93.64@103\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc94.49152374267578_epoch_103_20240502143807.pt\n",
      "23m08s Epoch: 104/600 | Time: 0m13s (Train 0m12s  Val 0m01s) | Train: LR 0.010000000000000002  Loss 0.17  Acc 84.66% | Val: Loss nan  Acc(top1) 94.49% | HA 94.49@104\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc94.06779479980469_epoch_104_20240502143821.pt\n",
      "23m22s Epoch: 105/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 0.010000000000000002  Loss 0.16  Acc 85.09% | Val: Loss nan  Acc(top1) 94.07% | HA 94.07@105\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc93.64407348632812_epoch_105_20240502143834.pt\n",
      "23m35s Epoch: 106/600 | Time: 0m13s (Train 0m12s  Val 0m01s) | Train: LR 0.010000000000000002  Loss 0.16  Acc 83.95% | Val: Loss nan  Acc(top1) 93.64% | HA 93.64@106\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc93.22034454345703_epoch_106_20240502143848.pt\n",
      "23m49s Epoch: 107/600 | Time: 0m13s (Train 0m12s  Val 0m01s) | Train: LR 0.010000000000000002  Loss 0.16  Acc 86.79% | Val: Loss nan  Acc(top1) 93.22% | HA 93.22@107\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc94.06779479980469_epoch_107_20240502143901.pt\n",
      "24m02s Epoch: 108/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 0.010000000000000002  Loss 0.15  Acc 85.65% | Val: Loss nan  Acc(top1) 94.07% | HA 94.07@108\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc94.06779479980469_epoch_108_20240502143914.pt\n",
      "24m15s Epoch: 109/600 | Time: 0m12s (Train 0m11s  Val 0m01s) | Train: LR 0.010000000000000002  Loss 0.17  Acc 86.51% | Val: Loss nan  Acc(top1) 94.07% | HA 94.07@109\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc92.79661560058594_epoch_109_20240502143927.pt\n",
      "24m28s Epoch: 110/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 0.010000000000000002  Loss 0.17  Acc 83.38% | Val: Loss nan  Acc(top1) 92.80% | HA 92.80@110\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc92.37287902832031_epoch_110_20240502143940.pt\n",
      "24m41s Epoch: 111/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 0.010000000000000002  Loss 0.15  Acc 83.38% | Val: Loss nan  Acc(top1) 92.37% | HA 92.37@111\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc94.06779479980469_epoch_111_20240502143954.pt\n",
      "24m55s Epoch: 112/600 | Time: 0m13s (Train 0m12s  Val 0m01s) | Train: LR 0.010000000000000002  Loss 0.16  Acc 84.66% | Val: Loss nan  Acc(top1) 94.07% | HA 94.07@112\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc94.06779479980469_epoch_112_20240502144007.pt\n",
      "25m08s Epoch: 113/600 | Time: 0m13s (Train 0m12s  Val 0m01s) | Train: LR 0.010000000000000002  Loss 0.16  Acc 86.51% | Val: Loss nan  Acc(top1) 94.07% | HA 94.07@113\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc94.91525268554688_epoch_113_20240502144021.pt\n",
      "25m22s Epoch: 114/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 0.010000000000000002  Loss 0.15  Acc 86.36% | Val: Loss nan  Acc(top1) 94.92% | HA 94.92@114\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc93.64407348632812_epoch_114_20240502144034.pt\n",
      "25m35s Epoch: 115/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 0.010000000000000002  Loss 0.16  Acc 83.81% | Val: Loss nan  Acc(top1) 93.64% | HA 93.64@115\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc92.79661560058594_epoch_115_20240502144047.pt\n",
      "25m48s Epoch: 116/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 0.010000000000000002  Loss 0.16  Acc 84.94% | Val: Loss nan  Acc(top1) 92.80% | HA 92.80@116\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc93.64407348632812_epoch_116_20240502144101.pt\n",
      "26m02s Epoch: 117/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 0.010000000000000002  Loss 0.15  Acc 84.80% | Val: Loss nan  Acc(top1) 93.64% | HA 93.64@117\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc93.22034454345703_epoch_117_20240502144114.pt\n",
      "26m15s Epoch: 118/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 0.010000000000000002  Loss 0.16  Acc 85.65% | Val: Loss nan  Acc(top1) 93.22% | HA 93.22@118\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc94.06779479980469_epoch_118_20240502144127.pt\n",
      "26m28s Epoch: 119/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 0.010000000000000002  Loss 0.15  Acc 86.22% | Val: Loss nan  Acc(top1) 94.07% | HA 94.07@119\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc93.64407348632812_epoch_119_20240502144141.pt\n",
      "26m42s Epoch: 120/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 0.010000000000000002  Loss 0.16  Acc 85.23% | Val: Loss nan  Acc(top1) 93.64% | HA 93.64@120\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc93.22034454345703_epoch_120_20240502144154.pt\n",
      "26m55s Epoch: 121/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 0.010000000000000002  Loss 0.14  Acc 87.93% | Val: Loss nan  Acc(top1) 93.22% | HA 93.22@121\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc94.06779479980469_epoch_121_20240502144207.pt\n",
      "27m08s Epoch: 122/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 0.010000000000000002  Loss 0.15  Acc 83.95% | Val: Loss nan  Acc(top1) 94.07% | HA 94.07@122\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc94.91525268554688_epoch_122_20240502144221.pt\n",
      "27m22s Epoch: 123/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 0.010000000000000002  Loss 0.15  Acc 85.65% | Val: Loss nan  Acc(top1) 94.92% | HA 94.92@123\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc94.06779479980469_epoch_123_20240502144234.pt\n",
      "27m35s Epoch: 124/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 0.010000000000000002  Loss 0.15  Acc 84.80% | Val: Loss nan  Acc(top1) 94.07% | HA 94.07@124\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc94.06779479980469_epoch_124_20240502144247.pt\n",
      "27m48s Epoch: 125/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 0.010000000000000002  Loss 0.16  Acc 83.95% | Val: Loss nan  Acc(top1) 94.07% | HA 94.07@125\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc94.91525268554688_epoch_125_20240502144300.pt\n",
      "28m01s Epoch: 126/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 0.010000000000000002  Loss 0.17  Acc 84.94% | Val: Loss nan  Acc(top1) 94.92% | HA 94.92@126\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc94.91525268554688_epoch_126_20240502144314.pt\n",
      "28m15s Epoch: 127/600 | Time: 0m13s (Train 0m12s  Val 0m01s) | Train: LR 0.010000000000000002  Loss 0.17  Acc 84.80% | Val: Loss nan  Acc(top1) 94.92% | HA 94.92@127\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc94.91525268554688_epoch_127_20240502144327.pt\n",
      "28m28s Epoch: 128/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 0.010000000000000002  Loss 0.16  Acc 85.37% | Val: Loss nan  Acc(top1) 94.92% | HA 94.92@128\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.33898162841797_epoch_128_20240502144341.pt\n",
      "28m42s Epoch: 129/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 0.010000000000000002  Loss 0.16  Acc 85.23% | Val: Loss nan  Acc(top1) 95.34% | HA 95.34@129\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc94.49152374267578_epoch_129_20240502144354.pt\n",
      "28m55s Epoch: 130/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 0.010000000000000002  Loss 0.17  Acc 83.10% | Val: Loss nan  Acc(top1) 94.49% | HA 94.49@130\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc94.49152374267578_epoch_130_20240502144407.pt\n",
      "29m08s Epoch: 131/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 0.010000000000000002  Loss 0.16  Acc 87.64% | Val: Loss nan  Acc(top1) 94.49% | HA 94.49@131\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc94.06779479980469_epoch_131_20240502144420.pt\n",
      "29m21s Epoch: 132/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 0.010000000000000002  Loss 0.15  Acc 84.38% | Val: Loss nan  Acc(top1) 94.07% | HA 94.07@132\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc94.06779479980469_epoch_132_20240502144434.pt\n",
      "29m35s Epoch: 133/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 0.010000000000000002  Loss 0.16  Acc 84.38% | Val: Loss nan  Acc(top1) 94.07% | HA 94.07@133\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc94.91525268554688_epoch_133_20240502144447.pt\n",
      "29m48s Epoch: 134/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 0.010000000000000002  Loss 0.16  Acc 84.23% | Val: Loss nan  Acc(top1) 94.92% | HA 94.92@134\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc94.91525268554688_epoch_134_20240502144500.pt\n",
      "30m01s Epoch: 135/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 0.010000000000000002  Loss 0.15  Acc 85.23% | Val: Loss nan  Acc(top1) 94.92% | HA 94.92@135\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc94.49152374267578_epoch_135_20240502144514.pt\n",
      "30m15s Epoch: 136/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 0.010000000000000002  Loss 0.16  Acc 85.80% | Val: Loss nan  Acc(top1) 94.49% | HA 94.49@136\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc94.06779479980469_epoch_136_20240502144527.pt\n",
      "30m28s Epoch: 137/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 0.010000000000000002  Loss 0.14  Acc 85.09% | Val: Loss nan  Acc(top1) 94.07% | HA 94.07@137\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc94.91525268554688_epoch_137_20240502144541.pt\n",
      "30m41s Epoch: 138/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 0.010000000000000002  Loss 0.17  Acc 81.39% | Val: Loss nan  Acc(top1) 94.92% | HA 94.92@138\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc94.91525268554688_epoch_138_20240502144554.pt\n",
      "30m55s Epoch: 139/600 | Time: 0m13s (Train 0m12s  Val 0m01s) | Train: LR 0.010000000000000002  Loss 0.16  Acc 85.09% | Val: Loss nan  Acc(top1) 94.92% | HA 94.92@139\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc94.06779479980469_epoch_139_20240502144607.pt\n",
      "31m08s Epoch: 140/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 0.010000000000000002  Loss 0.14  Acc 86.79% | Val: Loss nan  Acc(top1) 94.07% | HA 94.07@140\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc94.49152374267578_epoch_140_20240502144620.pt\n",
      "31m21s Epoch: 141/600 | Time: 0m12s (Train 0m11s  Val 0m01s) | Train: LR 0.010000000000000002  Loss 0.15  Acc 84.66% | Val: Loss nan  Acc(top1) 94.49% | HA 94.49@141\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc94.49152374267578_epoch_141_20240502144633.pt\n",
      "31m34s Epoch: 142/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 0.010000000000000002  Loss 0.16  Acc 84.80% | Val: Loss nan  Acc(top1) 94.49% | HA 94.49@142\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.33898162841797_epoch_142_20240502144647.pt\n",
      "31m48s Epoch: 143/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 0.010000000000000002  Loss 0.14  Acc 84.80% | Val: Loss nan  Acc(top1) 95.34% | HA 95.34@143\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc94.91525268554688_epoch_143_20240502144700.pt\n",
      "32m01s Epoch: 144/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 0.010000000000000002  Loss 0.15  Acc 84.80% | Val: Loss nan  Acc(top1) 94.92% | HA 94.92@144\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc94.91525268554688_epoch_144_20240502144713.pt\n",
      "32m14s Epoch: 145/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 0.010000000000000002  Loss 0.16  Acc 85.94% | Val: Loss nan  Acc(top1) 94.92% | HA 94.92@145\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_145_20240502144727.pt\n",
      "32m28s Epoch: 146/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 0.010000000000000002  Loss 0.15  Acc 83.81% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@146\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc94.49152374267578_epoch_146_20240502144740.pt\n",
      "32m41s Epoch: 147/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 0.010000000000000002  Loss 0.14  Acc 83.52% | Val: Loss nan  Acc(top1) 94.49% | HA 94.49@147\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc94.49152374267578_epoch_147_20240502144753.pt\n",
      "32m54s Epoch: 148/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 0.010000000000000002  Loss 0.15  Acc 86.51% | Val: Loss nan  Acc(top1) 94.49% | HA 94.49@148\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc94.06779479980469_epoch_148_20240502144807.pt\n",
      "33m07s Epoch: 149/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 0.010000000000000002  Loss 0.14  Acc 85.80% | Val: Loss nan  Acc(top1) 94.07% | HA 94.07@149\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc94.06779479980469_epoch_149_20240502144820.pt\n",
      "33m21s Epoch: 150/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 0.010000000000000002  Loss 0.14  Acc 87.07% | Val: Loss nan  Acc(top1) 94.07% | HA 94.07@150\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc94.91525268554688_epoch_150_20240502144833.pt\n",
      "33m33s Epoch: 151/600 | Time: 0m12s (Train 0m11s  Val 0m01s) | Train: LR 0.010000000000000002  Loss 0.14  Acc 86.65% | Val: Loss nan  Acc(top1) 94.92% | HA 94.92@151\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc94.06779479980469_epoch_151_20240502144846.pt\n",
      "33m47s Epoch: 152/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 0.010000000000000002  Loss 0.16  Acc 86.93% | Val: Loss nan  Acc(top1) 94.07% | HA 94.07@152\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc94.06779479980469_epoch_152_20240502144859.pt\n",
      "34m00s Epoch: 153/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 0.010000000000000002  Loss 0.15  Acc 86.22% | Val: Loss nan  Acc(top1) 94.07% | HA 94.07@153\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc92.79661560058594_epoch_153_20240502144912.pt\n",
      "34m13s Epoch: 154/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 0.010000000000000002  Loss 0.15  Acc 86.22% | Val: Loss nan  Acc(top1) 92.80% | HA 92.80@154\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc93.64407348632812_epoch_154_20240502144925.pt\n",
      "34m26s Epoch: 155/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 0.010000000000000002  Loss 0.15  Acc 88.35% | Val: Loss nan  Acc(top1) 93.64% | HA 93.64@155\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc94.06779479980469_epoch_155_20240502144939.pt\n",
      "34m40s Epoch: 156/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 0.010000000000000002  Loss 0.15  Acc 84.66% | Val: Loss nan  Acc(top1) 94.07% | HA 94.07@156\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc92.79661560058594_epoch_156_20240502144952.pt\n",
      "34m53s Epoch: 157/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 0.010000000000000002  Loss 0.14  Acc 87.07% | Val: Loss nan  Acc(top1) 92.80% | HA 92.80@157\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc93.22034454345703_epoch_157_20240502145006.pt\n",
      "35m07s Epoch: 158/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 0.010000000000000002  Loss 0.15  Acc 86.08% | Val: Loss nan  Acc(top1) 93.22% | HA 93.22@158\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc94.49152374267578_epoch_158_20240502145019.pt\n",
      "35m20s Epoch: 159/600 | Time: 0m13s (Train 0m12s  Val 0m01s) | Train: LR 0.010000000000000002  Loss 0.16  Acc 84.66% | Val: Loss nan  Acc(top1) 94.49% | HA 94.49@159\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_159_20240502145032.pt\n",
      "35m33s Epoch: 160/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 0.010000000000000002  Loss 0.13  Acc 85.51% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@160\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc96.18643951416016_epoch_160_20240502145046.pt\n",
      "35m47s Epoch: 161/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 0.010000000000000002  Loss 0.15  Acc 85.94% | Val: Loss nan  Acc(top1) 96.19% | HA 96.19@161\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc94.49152374267578_epoch_161_20240502145059.pt\n",
      "36m00s Epoch: 162/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 0.010000000000000002  Loss 0.13  Acc 87.64% | Val: Loss nan  Acc(top1) 94.49% | HA 94.49@162\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc96.18643951416016_epoch_162_20240502145113.pt\n",
      "36m14s Epoch: 163/600 | Time: 0m13s (Train 0m12s  Val 0m01s) | Train: LR 0.010000000000000002  Loss 0.16  Acc 85.65% | Val: Loss nan  Acc(top1) 96.19% | HA 96.19@163\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc94.91525268554688_epoch_163_20240502145126.pt\n",
      "36m27s Epoch: 164/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 0.010000000000000002  Loss 0.15  Acc 85.37% | Val: Loss nan  Acc(top1) 94.92% | HA 94.92@164\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc94.06779479980469_epoch_164_20240502145140.pt\n",
      "36m40s Epoch: 165/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 0.010000000000000002  Loss 0.14  Acc 86.65% | Val: Loss nan  Acc(top1) 94.07% | HA 94.07@165\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc93.64407348632812_epoch_165_20240502145153.pt\n",
      "36m54s Epoch: 166/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 0.010000000000000002  Loss 0.15  Acc 86.51% | Val: Loss nan  Acc(top1) 93.64% | HA 93.64@166\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc92.79661560058594_epoch_166_20240502145206.pt\n",
      "37m07s Epoch: 167/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 0.010000000000000002  Loss 0.15  Acc 85.80% | Val: Loss nan  Acc(top1) 92.80% | HA 92.80@167\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc92.79661560058594_epoch_167_20240502145220.pt\n",
      "37m21s Epoch: 168/600 | Time: 0m13s (Train 0m12s  Val 0m01s) | Train: LR 0.010000000000000002  Loss 0.15  Acc 87.36% | Val: Loss nan  Acc(top1) 92.80% | HA 92.80@168\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc92.79661560058594_epoch_168_20240502145233.pt\n",
      "37m34s Epoch: 169/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 0.010000000000000002  Loss 0.14  Acc 85.37% | Val: Loss nan  Acc(top1) 92.80% | HA 92.80@169\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc94.06779479980469_epoch_169_20240502145247.pt\n",
      "37m48s Epoch: 170/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 0.010000000000000002  Loss 0.15  Acc 86.08% | Val: Loss nan  Acc(top1) 94.07% | HA 94.07@170\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc94.49152374267578_epoch_170_20240502145300.pt\n",
      "38m01s Epoch: 171/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 0.010000000000000002  Loss 0.15  Acc 86.22% | Val: Loss nan  Acc(top1) 94.49% | HA 94.49@171\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc94.49152374267578_epoch_171_20240502145313.pt\n",
      "38m14s Epoch: 172/600 | Time: 0m13s (Train 0m12s  Val 0m01s) | Train: LR 0.010000000000000002  Loss 0.14  Acc 84.66% | Val: Loss nan  Acc(top1) 94.49% | HA 94.49@172\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc94.49152374267578_epoch_172_20240502145327.pt\n",
      "38m28s Epoch: 173/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 0.010000000000000002  Loss 0.15  Acc 86.36% | Val: Loss nan  Acc(top1) 94.49% | HA 94.49@173\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc94.49152374267578_epoch_173_20240502145340.pt\n",
      "38m41s Epoch: 174/600 | Time: 0m13s (Train 0m12s  Val 0m01s) | Train: LR 0.010000000000000002  Loss 0.14  Acc 84.94% | Val: Loss nan  Acc(top1) 94.49% | HA 94.49@174\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc94.49152374267578_epoch_174_20240502145354.pt\n",
      "38m55s Epoch: 175/600 | Time: 0m13s (Train 0m12s  Val 0m01s) | Train: LR 0.010000000000000002  Loss 0.13  Acc 86.79% | Val: Loss nan  Acc(top1) 94.49% | HA 94.49@175\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc94.49152374267578_epoch_175_20240502145408.pt\n",
      "39m08s Epoch: 176/600 | Time: 0m13s (Train 0m12s  Val 0m01s) | Train: LR 0.010000000000000002  Loss 0.15  Acc 83.66% | Val: Loss nan  Acc(top1) 94.49% | HA 94.49@176\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc94.91525268554688_epoch_176_20240502145421.pt\n",
      "39m22s Epoch: 177/600 | Time: 0m13s (Train 0m12s  Val 0m01s) | Train: LR 0.010000000000000002  Loss 0.14  Acc 85.09% | Val: Loss nan  Acc(top1) 94.92% | HA 94.92@177\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc94.91525268554688_epoch_177_20240502145435.pt\n",
      "39m36s Epoch: 178/600 | Time: 0m13s (Train 0m12s  Val 0m01s) | Train: LR 0.010000000000000002  Loss 0.14  Acc 86.08% | Val: Loss nan  Acc(top1) 94.92% | HA 94.92@178\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc93.64407348632812_epoch_178_20240502145448.pt\n",
      "39m49s Epoch: 179/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 0.010000000000000002  Loss 0.15  Acc 85.65% | Val: Loss nan  Acc(top1) 93.64% | HA 93.64@179\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc93.64407348632812_epoch_179_20240502145502.pt\n",
      "40m03s Epoch: 180/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 0.010000000000000002  Loss 0.15  Acc 86.36% | Val: Loss nan  Acc(top1) 93.64% | HA 93.64@180\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc94.49152374267578_epoch_180_20240502145515.pt\n",
      "40m16s Epoch: 181/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 0.0010000000000000002  Loss 0.15  Acc 84.38% | Val: Loss nan  Acc(top1) 94.49% | HA 94.49@181\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc94.49152374267578_epoch_181_20240502145528.pt\n",
      "40m29s Epoch: 182/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 0.0010000000000000002  Loss 0.16  Acc 85.65% | Val: Loss nan  Acc(top1) 94.49% | HA 94.49@182\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc94.06779479980469_epoch_182_20240502145542.pt\n",
      "40m43s Epoch: 183/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 0.0010000000000000002  Loss 0.13  Acc 85.80% | Val: Loss nan  Acc(top1) 94.07% | HA 94.07@183\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc94.49152374267578_epoch_183_20240502145555.pt\n",
      "40m56s Epoch: 184/600 | Time: 0m13s (Train 0m12s  Val 0m01s) | Train: LR 0.0010000000000000002  Loss 0.14  Acc 85.23% | Val: Loss nan  Acc(top1) 94.49% | HA 94.49@184\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc94.91525268554688_epoch_184_20240502145609.pt\n",
      "41m10s Epoch: 185/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 0.0010000000000000002  Loss 0.15  Acc 85.51% | Val: Loss nan  Acc(top1) 94.92% | HA 94.92@185\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc94.49152374267578_epoch_185_20240502145622.pt\n",
      "41m23s Epoch: 186/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 0.0010000000000000002  Loss 0.14  Acc 87.07% | Val: Loss nan  Acc(top1) 94.49% | HA 94.49@186\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.33898162841797_epoch_186_20240502145636.pt\n",
      "41m37s Epoch: 187/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 0.0010000000000000002  Loss 0.14  Acc 85.51% | Val: Loss nan  Acc(top1) 95.34% | HA 95.34@187\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc94.49152374267578_epoch_187_20240502145649.pt\n",
      "41m50s Epoch: 188/600 | Time: 0m13s (Train 0m12s  Val 0m01s) | Train: LR 0.0010000000000000002  Loss 0.15  Acc 87.50% | Val: Loss nan  Acc(top1) 94.49% | HA 94.49@188\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc94.49152374267578_epoch_188_20240502145703.pt\n",
      "42m04s Epoch: 189/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 0.0010000000000000002  Loss 0.13  Acc 87.50% | Val: Loss nan  Acc(top1) 94.49% | HA 94.49@189\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc94.91525268554688_epoch_189_20240502145716.pt\n",
      "42m17s Epoch: 190/600 | Time: 0m13s (Train 0m12s  Val 0m01s) | Train: LR 0.0010000000000000002  Loss 0.14  Acc 84.80% | Val: Loss nan  Acc(top1) 94.92% | HA 94.92@190\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc94.91525268554688_epoch_190_20240502145730.pt\n",
      "42m31s Epoch: 191/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 0.0010000000000000002  Loss 0.13  Acc 87.93% | Val: Loss nan  Acc(top1) 94.92% | HA 94.92@191\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc94.91525268554688_epoch_191_20240502145743.pt\n",
      "42m44s Epoch: 192/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 0.0010000000000000002  Loss 0.14  Acc 83.38% | Val: Loss nan  Acc(top1) 94.92% | HA 94.92@192\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc94.91525268554688_epoch_192_20240502145756.pt\n",
      "42m57s Epoch: 193/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 0.0010000000000000002  Loss 0.14  Acc 85.51% | Val: Loss nan  Acc(top1) 94.92% | HA 94.92@193\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc94.49152374267578_epoch_193_20240502145810.pt\n",
      "43m11s Epoch: 194/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 0.0010000000000000002  Loss 0.12  Acc 87.50% | Val: Loss nan  Acc(top1) 94.49% | HA 94.49@194\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc94.91525268554688_epoch_194_20240502145823.pt\n",
      "43m24s Epoch: 195/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 0.0010000000000000002  Loss 0.14  Acc 85.65% | Val: Loss nan  Acc(top1) 94.92% | HA 94.92@195\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc94.91525268554688_epoch_195_20240502145837.pt\n",
      "43m38s Epoch: 196/600 | Time: 0m13s (Train 0m12s  Val 0m01s) | Train: LR 0.0010000000000000002  Loss 0.14  Acc 85.51% | Val: Loss nan  Acc(top1) 94.92% | HA 94.92@196\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc94.91525268554688_epoch_196_20240502145850.pt\n",
      "43m51s Epoch: 197/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 0.0010000000000000002  Loss 0.14  Acc 85.23% | Val: Loss nan  Acc(top1) 94.92% | HA 94.92@197\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc94.91525268554688_epoch_197_20240502145903.pt\n",
      "44m04s Epoch: 198/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 0.0010000000000000002  Loss 0.13  Acc 86.22% | Val: Loss nan  Acc(top1) 94.92% | HA 94.92@198\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc94.91525268554688_epoch_198_20240502145916.pt\n",
      "44m17s Epoch: 199/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 0.0010000000000000002  Loss 0.14  Acc 86.22% | Val: Loss nan  Acc(top1) 94.92% | HA 94.92@199\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc94.49152374267578_epoch_199_20240502145929.pt\n",
      "44m30s Epoch: 200/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 0.0010000000000000002  Loss 0.14  Acc 87.07% | Val: Loss nan  Acc(top1) 94.49% | HA 94.49@200\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.33898162841797_epoch_200_20240502145943.pt\n",
      "44m44s Epoch: 201/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 0.0010000000000000002  Loss 0.14  Acc 84.23% | Val: Loss nan  Acc(top1) 95.34% | HA 95.34@201\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc94.91525268554688_epoch_201_20240502145956.pt\n",
      "44m57s Epoch: 202/600 | Time: 0m13s (Train 0m12s  Val 0m01s) | Train: LR 0.0010000000000000002  Loss 0.13  Acc 86.65% | Val: Loss nan  Acc(top1) 94.92% | HA 94.92@202\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc94.91525268554688_epoch_202_20240502150010.pt\n",
      "45m11s Epoch: 203/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 0.0010000000000000002  Loss 0.14  Acc 84.94% | Val: Loss nan  Acc(top1) 94.92% | HA 94.92@203\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc94.91525268554688_epoch_203_20240502150023.pt\n",
      "45m24s Epoch: 204/600 | Time: 0m13s (Train 0m12s  Val 0m01s) | Train: LR 0.0010000000000000002  Loss 0.13  Acc 86.36% | Val: Loss nan  Acc(top1) 94.92% | HA 94.92@204\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc94.91525268554688_epoch_204_20240502150037.pt\n",
      "45m38s Epoch: 205/600 | Time: 0m13s (Train 0m12s  Val 0m01s) | Train: LR 0.0010000000000000002  Loss 0.13  Acc 87.64% | Val: Loss nan  Acc(top1) 94.92% | HA 94.92@205\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc94.91525268554688_epoch_205_20240502150051.pt\n",
      "45m51s Epoch: 206/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 0.0010000000000000002  Loss 0.12  Acc 88.49% | Val: Loss nan  Acc(top1) 94.92% | HA 94.92@206\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.33898162841797_epoch_206_20240502150104.pt\n",
      "46m05s Epoch: 207/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 0.0010000000000000002  Loss 0.15  Acc 84.23% | Val: Loss nan  Acc(top1) 95.34% | HA 95.34@207\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc94.91525268554688_epoch_207_20240502150118.pt\n",
      "46m19s Epoch: 208/600 | Time: 0m13s (Train 0m12s  Val 0m01s) | Train: LR 0.0010000000000000002  Loss 0.13  Acc 88.35% | Val: Loss nan  Acc(top1) 94.92% | HA 94.92@208\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.33898162841797_epoch_208_20240502150131.pt\n",
      "46m32s Epoch: 209/600 | Time: 0m13s (Train 0m12s  Val 0m01s) | Train: LR 0.0010000000000000002  Loss 0.13  Acc 89.35% | Val: Loss nan  Acc(top1) 95.34% | HA 95.34@209\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.33898162841797_epoch_209_20240502150145.pt\n",
      "46m46s Epoch: 210/600 | Time: 0m13s (Train 0m12s  Val 0m01s) | Train: LR 0.0010000000000000002  Loss 0.13  Acc 86.51% | Val: Loss nan  Acc(top1) 95.34% | HA 95.34@210\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc94.91525268554688_epoch_210_20240502150158.pt\n",
      "46m59s Epoch: 211/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 0.0010000000000000002  Loss 0.14  Acc 87.64% | Val: Loss nan  Acc(top1) 94.92% | HA 94.92@211\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.33898162841797_epoch_211_20240502150212.pt\n",
      "47m13s Epoch: 212/600 | Time: 0m13s (Train 0m12s  Val 0m01s) | Train: LR 0.0010000000000000002  Loss 0.13  Acc 85.23% | Val: Loss nan  Acc(top1) 95.34% | HA 95.34@212\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.33898162841797_epoch_212_20240502150225.pt\n",
      "47m26s Epoch: 213/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 0.0010000000000000002  Loss 0.14  Acc 87.50% | Val: Loss nan  Acc(top1) 95.34% | HA 95.34@213\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.33898162841797_epoch_213_20240502150239.pt\n",
      "47m40s Epoch: 214/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 0.0010000000000000002  Loss 0.13  Acc 86.93% | Val: Loss nan  Acc(top1) 95.34% | HA 95.34@214\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.33898162841797_epoch_214_20240502150252.pt\n",
      "47m53s Epoch: 215/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 0.0010000000000000002  Loss 0.14  Acc 86.51% | Val: Loss nan  Acc(top1) 95.34% | HA 95.34@215\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.33898162841797_epoch_215_20240502150305.pt\n",
      "48m06s Epoch: 216/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 0.0010000000000000002  Loss 0.14  Acc 84.66% | Val: Loss nan  Acc(top1) 95.34% | HA 95.34@216\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.33898162841797_epoch_216_20240502150318.pt\n",
      "48m19s Epoch: 217/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 0.0010000000000000002  Loss 0.13  Acc 87.64% | Val: Loss nan  Acc(top1) 95.34% | HA 95.34@217\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.33898162841797_epoch_217_20240502150332.pt\n",
      "48m32s Epoch: 218/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 0.0010000000000000002  Loss 0.14  Acc 87.93% | Val: Loss nan  Acc(top1) 95.34% | HA 95.34@218\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.33898162841797_epoch_218_20240502150345.pt\n",
      "48m46s Epoch: 219/600 | Time: 0m13s (Train 0m12s  Val 0m01s) | Train: LR 0.0010000000000000002  Loss 0.14  Acc 86.22% | Val: Loss nan  Acc(top1) 95.34% | HA 95.34@219\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_219_20240502150359.pt\n",
      "49m00s Epoch: 220/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 0.0010000000000000002  Loss 0.14  Acc 86.08% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@220\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.33898162841797_epoch_220_20240502150412.pt\n",
      "49m13s Epoch: 221/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 0.0010000000000000002  Loss 0.14  Acc 87.78% | Val: Loss nan  Acc(top1) 95.34% | HA 95.34@221\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc94.91525268554688_epoch_221_20240502150425.pt\n",
      "49m26s Epoch: 222/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 0.0010000000000000002  Loss 0.15  Acc 83.81% | Val: Loss nan  Acc(top1) 94.92% | HA 94.92@222\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.33898162841797_epoch_222_20240502150438.pt\n",
      "49m39s Epoch: 223/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 0.0010000000000000002  Loss 0.13  Acc 86.51% | Val: Loss nan  Acc(top1) 95.34% | HA 95.34@223\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.33898162841797_epoch_223_20240502150452.pt\n",
      "49m53s Epoch: 224/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 0.0010000000000000002  Loss 0.14  Acc 86.93% | Val: Loss nan  Acc(top1) 95.34% | HA 95.34@224\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.33898162841797_epoch_224_20240502150505.pt\n",
      "50m06s Epoch: 225/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 0.0010000000000000002  Loss 0.14  Acc 84.94% | Val: Loss nan  Acc(top1) 95.34% | HA 95.34@225\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.33898162841797_epoch_225_20240502150518.pt\n",
      "50m19s Epoch: 226/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 0.0010000000000000002  Loss 0.13  Acc 86.65% | Val: Loss nan  Acc(top1) 95.34% | HA 95.34@226\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.33898162841797_epoch_226_20240502150531.pt\n",
      "50m32s Epoch: 227/600 | Time: 0m12s (Train 0m11s  Val 0m01s) | Train: LR 0.0010000000000000002  Loss 0.14  Acc 86.36% | Val: Loss nan  Acc(top1) 95.34% | HA 95.34@227\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_227_20240502150544.pt\n",
      "50m45s Epoch: 228/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 0.0010000000000000002  Loss 0.15  Acc 86.93% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@228\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.33898162841797_epoch_228_20240502150558.pt\n",
      "50m59s Epoch: 229/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 0.0010000000000000002  Loss 0.14  Acc 87.22% | Val: Loss nan  Acc(top1) 95.34% | HA 95.34@229\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.33898162841797_epoch_229_20240502150611.pt\n",
      "51m12s Epoch: 230/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 0.0010000000000000002  Loss 0.13  Acc 87.36% | Val: Loss nan  Acc(top1) 95.34% | HA 95.34@230\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.33898162841797_epoch_230_20240502150624.pt\n",
      "51m25s Epoch: 231/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 0.0010000000000000002  Loss 0.14  Acc 85.94% | Val: Loss nan  Acc(top1) 95.34% | HA 95.34@231\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.33898162841797_epoch_231_20240502150637.pt\n",
      "51m38s Epoch: 232/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 0.0010000000000000002  Loss 0.13  Acc 84.52% | Val: Loss nan  Acc(top1) 95.34% | HA 95.34@232\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.33898162841797_epoch_232_20240502150651.pt\n",
      "51m52s Epoch: 233/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 0.0010000000000000002  Loss 0.15  Acc 86.65% | Val: Loss nan  Acc(top1) 95.34% | HA 95.34@233\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.33898162841797_epoch_233_20240502150704.pt\n",
      "52m05s Epoch: 234/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 0.0010000000000000002  Loss 0.13  Acc 86.79% | Val: Loss nan  Acc(top1) 95.34% | HA 95.34@234\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.33898162841797_epoch_234_20240502150717.pt\n",
      "52m18s Epoch: 235/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 0.0010000000000000002  Loss 0.13  Acc 87.22% | Val: Loss nan  Acc(top1) 95.34% | HA 95.34@235\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc94.49152374267578_epoch_235_20240502150731.pt\n",
      "52m32s Epoch: 236/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 0.0010000000000000002  Loss 0.15  Acc 84.80% | Val: Loss nan  Acc(top1) 94.49% | HA 94.49@236\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc94.91525268554688_epoch_236_20240502150744.pt\n",
      "52m45s Epoch: 237/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 0.0010000000000000002  Loss 0.12  Acc 88.64% | Val: Loss nan  Acc(top1) 94.92% | HA 94.92@237\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.33898162841797_epoch_237_20240502150757.pt\n",
      "52m58s Epoch: 238/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 0.0010000000000000002  Loss 0.13  Acc 86.51% | Val: Loss nan  Acc(top1) 95.34% | HA 95.34@238\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.33898162841797_epoch_238_20240502150810.pt\n",
      "53m11s Epoch: 239/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 0.0010000000000000002  Loss 0.13  Acc 85.80% | Val: Loss nan  Acc(top1) 95.34% | HA 95.34@239\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.33898162841797_epoch_239_20240502150824.pt\n",
      "53m25s Epoch: 240/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 0.0010000000000000002  Loss 0.12  Acc 87.78% | Val: Loss nan  Acc(top1) 95.34% | HA 95.34@240\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.33898162841797_epoch_240_20240502150837.pt\n",
      "53m38s Epoch: 241/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 0.0010000000000000002  Loss 0.15  Acc 87.93% | Val: Loss nan  Acc(top1) 95.34% | HA 95.34@241\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.33898162841797_epoch_241_20240502150850.pt\n",
      "53m51s Epoch: 242/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 0.0010000000000000002  Loss 0.16  Acc 84.38% | Val: Loss nan  Acc(top1) 95.34% | HA 95.34@242\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.33898162841797_epoch_242_20240502150903.pt\n",
      "54m04s Epoch: 243/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 0.0010000000000000002  Loss 0.13  Acc 86.51% | Val: Loss nan  Acc(top1) 95.34% | HA 95.34@243\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.33898162841797_epoch_243_20240502150916.pt\n",
      "54m17s Epoch: 244/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 0.0010000000000000002  Loss 0.13  Acc 85.65% | Val: Loss nan  Acc(top1) 95.34% | HA 95.34@244\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.33898162841797_epoch_244_20240502150930.pt\n",
      "54m31s Epoch: 245/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 0.0010000000000000002  Loss 0.14  Acc 86.51% | Val: Loss nan  Acc(top1) 95.34% | HA 95.34@245\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_245_20240502150943.pt\n",
      "54m44s Epoch: 246/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 0.0010000000000000002  Loss 0.13  Acc 88.92% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@246\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc94.91525268554688_epoch_246_20240502150956.pt\n",
      "54m57s Epoch: 247/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 0.0010000000000000002  Loss 0.12  Acc 86.51% | Val: Loss nan  Acc(top1) 94.92% | HA 94.92@247\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.33898162841797_epoch_247_20240502151009.pt\n",
      "55m10s Epoch: 248/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 0.0010000000000000002  Loss 0.14  Acc 88.07% | Val: Loss nan  Acc(top1) 95.34% | HA 95.34@248\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc94.91525268554688_epoch_248_20240502151023.pt\n",
      "55m23s Epoch: 249/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 0.0010000000000000002  Loss 0.13  Acc 88.21% | Val: Loss nan  Acc(top1) 94.92% | HA 94.92@249\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.33898162841797_epoch_249_20240502151036.pt\n",
      "55m37s Epoch: 250/600 | Time: 0m13s (Train 0m12s  Val 0m01s) | Train: LR 0.0010000000000000002  Loss 0.13  Acc 85.23% | Val: Loss nan  Acc(top1) 95.34% | HA 95.34@250\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.33898162841797_epoch_250_20240502151050.pt\n",
      "55m51s Epoch: 251/600 | Time: 0m13s (Train 0m12s  Val 0m01s) | Train: LR 0.0010000000000000002  Loss 0.14  Acc 87.07% | Val: Loss nan  Acc(top1) 95.34% | HA 95.34@251\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_251_20240502151104.pt\n",
      "56m05s Epoch: 252/600 | Time: 0m13s (Train 0m12s  Val 0m01s) | Train: LR 0.0010000000000000002  Loss 0.13  Acc 86.08% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@252\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_252_20240502151118.pt\n",
      "56m19s Epoch: 253/600 | Time: 0m13s (Train 0m12s  Val 0m01s) | Train: LR 0.0010000000000000002  Loss 0.13  Acc 85.94% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@253\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_253_20240502151131.pt\n",
      "56m32s Epoch: 254/600 | Time: 0m13s (Train 0m12s  Val 0m01s) | Train: LR 0.0010000000000000002  Loss 0.14  Acc 86.93% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@254\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.33898162841797_epoch_254_20240502151145.pt\n",
      "56m46s Epoch: 255/600 | Time: 0m13s (Train 0m12s  Val 0m01s) | Train: LR 0.0010000000000000002  Loss 0.14  Acc 87.36% | Val: Loss nan  Acc(top1) 95.34% | HA 95.34@255\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_255_20240502151159.pt\n",
      "57m00s Epoch: 256/600 | Time: 0m13s (Train 0m12s  Val 0m01s) | Train: LR 0.0010000000000000002  Loss 0.12  Acc 88.64% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@256\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_256_20240502151213.pt\n",
      "57m14s Epoch: 257/600 | Time: 0m13s (Train 0m12s  Val 0m01s) | Train: LR 0.0010000000000000002  Loss 0.12  Acc 87.36% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@257\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_257_20240502151226.pt\n",
      "57m27s Epoch: 258/600 | Time: 0m13s (Train 0m12s  Val 0m01s) | Train: LR 0.0010000000000000002  Loss 0.14  Acc 86.36% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@258\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_258_20240502151240.pt\n",
      "57m41s Epoch: 259/600 | Time: 0m13s (Train 0m12s  Val 0m01s) | Train: LR 0.0010000000000000002  Loss 0.14  Acc 86.65% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@259\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_259_20240502151254.pt\n",
      "57m55s Epoch: 260/600 | Time: 0m13s (Train 0m12s  Val 0m01s) | Train: LR 0.0010000000000000002  Loss 0.13  Acc 87.50% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@260\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.33898162841797_epoch_260_20240502151308.pt\n",
      "58m09s Epoch: 261/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 0.0010000000000000002  Loss 0.13  Acc 86.08% | Val: Loss nan  Acc(top1) 95.34% | HA 95.34@261\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.33898162841797_epoch_261_20240502151321.pt\n",
      "58m22s Epoch: 262/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 0.0010000000000000002  Loss 0.14  Acc 86.65% | Val: Loss nan  Acc(top1) 95.34% | HA 95.34@262\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_262_20240502151335.pt\n",
      "58m35s Epoch: 263/600 | Time: 0m13s (Train 0m12s  Val 0m01s) | Train: LR 0.0010000000000000002  Loss 0.13  Acc 83.24% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@263\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_263_20240502151348.pt\n",
      "58m49s Epoch: 264/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 0.0010000000000000002  Loss 0.14  Acc 86.08% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@264\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_264_20240502151401.pt\n",
      "59m02s Epoch: 265/600 | Time: 0m13s (Train 0m12s  Val 0m01s) | Train: LR 0.0010000000000000002  Loss 0.14  Acc 83.81% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@265\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.33898162841797_epoch_265_20240502151415.pt\n",
      "59m16s Epoch: 266/600 | Time: 0m13s (Train 0m12s  Val 0m01s) | Train: LR 0.0010000000000000002  Loss 0.13  Acc 87.22% | Val: Loss nan  Acc(top1) 95.34% | HA 95.34@266\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_266_20240502151429.pt\n",
      "59m30s Epoch: 267/600 | Time: 0m13s (Train 0m12s  Val 0m01s) | Train: LR 0.0010000000000000002  Loss 0.13  Acc 88.21% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@267\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_267_20240502151443.pt\n",
      "59m44s Epoch: 268/600 | Time: 0m13s (Train 0m12s  Val 0m01s) | Train: LR 0.0010000000000000002  Loss 0.13  Acc 86.22% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@268\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.33898162841797_epoch_268_20240502151457.pt\n",
      "59m58s Epoch: 269/600 | Time: 0m13s (Train 0m12s  Val 0m01s) | Train: LR 0.0010000000000000002  Loss 0.14  Acc 89.35% | Val: Loss nan  Acc(top1) 95.34% | HA 95.34@269\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.33898162841797_epoch_269_20240502151510.pt\n",
      "1h00m Epoch: 270/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 0.0010000000000000002  Loss 0.12  Acc 87.93% | Val: Loss nan  Acc(top1) 95.34% | HA 95.34@270\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.33898162841797_epoch_270_20240502151524.pt\n",
      "1h00m Epoch: 271/600 | Time: 0m13s (Train 0m12s  Val 0m01s) | Train: LR 0.00010000000000000003  Loss 0.15  Acc 86.79% | Val: Loss nan  Acc(top1) 95.34% | HA 95.34@271\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_271_20240502151538.pt\n",
      "1h00m Epoch: 272/600 | Time: 0m13s (Train 0m12s  Val 0m01s) | Train: LR 0.00010000000000000003  Loss 0.14  Acc 85.09% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@272\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.33898162841797_epoch_272_20240502151552.pt\n",
      "1h00m Epoch: 273/600 | Time: 0m13s (Train 0m12s  Val 0m01s) | Train: LR 0.00010000000000000003  Loss 0.13  Acc 88.92% | Val: Loss nan  Acc(top1) 95.34% | HA 95.34@273\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_273_20240502151605.pt\n",
      "1h01m Epoch: 274/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 0.00010000000000000003  Loss 0.14  Acc 87.22% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@274\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.33898162841797_epoch_274_20240502151619.pt\n",
      "1h01m Epoch: 275/600 | Time: 0m13s (Train 0m12s  Val 0m01s) | Train: LR 0.00010000000000000003  Loss 0.13  Acc 86.65% | Val: Loss nan  Acc(top1) 95.34% | HA 95.34@275\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_275_20240502151633.pt\n",
      "1h01m Epoch: 276/600 | Time: 0m13s (Train 0m12s  Val 0m01s) | Train: LR 0.00010000000000000003  Loss 0.15  Acc 87.22% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@276\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_276_20240502151646.pt\n",
      "1h01m Epoch: 277/600 | Time: 0m13s (Train 0m12s  Val 0m01s) | Train: LR 0.00010000000000000003  Loss 0.13  Acc 86.36% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@277\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_277_20240502151700.pt\n",
      "1h02m Epoch: 278/600 | Time: 0m13s (Train 0m12s  Val 0m01s) | Train: LR 0.00010000000000000003  Loss 0.13  Acc 86.08% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@278\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_278_20240502151714.pt\n",
      "1h02m Epoch: 279/600 | Time: 0m13s (Train 0m12s  Val 0m01s) | Train: LR 0.00010000000000000003  Loss 0.13  Acc 85.51% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@279\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.33898162841797_epoch_279_20240502151728.pt\n",
      "1h02m Epoch: 280/600 | Time: 0m13s (Train 0m12s  Val 0m01s) | Train: LR 0.00010000000000000003  Loss 0.13  Acc 85.94% | Val: Loss nan  Acc(top1) 95.34% | HA 95.34@280\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.33898162841797_epoch_280_20240502151741.pt\n",
      "1h02m Epoch: 281/600 | Time: 0m13s (Train 0m12s  Val 0m01s) | Train: LR 0.00010000000000000003  Loss 0.13  Acc 88.07% | Val: Loss nan  Acc(top1) 95.34% | HA 95.34@281\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.33898162841797_epoch_281_20240502151755.pt\n",
      "1h02m Epoch: 282/600 | Time: 0m13s (Train 0m12s  Val 0m01s) | Train: LR 0.00010000000000000003  Loss 0.13  Acc 87.22% | Val: Loss nan  Acc(top1) 95.34% | HA 95.34@282\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_282_20240502151809.pt\n",
      "1h03m Epoch: 283/600 | Time: 0m13s (Train 0m12s  Val 0m01s) | Train: LR 0.00010000000000000003  Loss 0.12  Acc 86.65% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@283\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_283_20240502151822.pt\n",
      "1h03m Epoch: 284/600 | Time: 0m13s (Train 0m12s  Val 0m01s) | Train: LR 0.00010000000000000003  Loss 0.12  Acc 86.79% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@284\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_284_20240502151836.pt\n",
      "1h03m Epoch: 285/600 | Time: 0m13s (Train 0m12s  Val 0m01s) | Train: LR 0.00010000000000000003  Loss 0.13  Acc 88.21% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@285\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc94.91525268554688_epoch_285_20240502151849.pt\n",
      "1h03m Epoch: 286/600 | Time: 0m13s (Train 0m12s  Val 0m01s) | Train: LR 0.00010000000000000003  Loss 0.14  Acc 83.81% | Val: Loss nan  Acc(top1) 94.92% | HA 94.92@286\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc94.91525268554688_epoch_286_20240502151903.pt\n",
      "1h04m Epoch: 287/600 | Time: 0m13s (Train 0m12s  Val 0m01s) | Train: LR 0.00010000000000000003  Loss 0.14  Acc 86.22% | Val: Loss nan  Acc(top1) 94.92% | HA 94.92@287\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_287_20240502151918.pt\n",
      "1h04m Epoch: 288/600 | Time: 0m14s (Train 0m12s  Val 0m01s) | Train: LR 0.00010000000000000003  Loss 0.14  Acc 88.07% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@288\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_288_20240502151931.pt\n",
      "1h04m Epoch: 289/600 | Time: 0m13s (Train 0m12s  Val 0m01s) | Train: LR 0.00010000000000000003  Loss 0.14  Acc 85.23% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@289\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_289_20240502151945.pt\n",
      "1h04m Epoch: 290/600 | Time: 0m13s (Train 0m12s  Val 0m01s) | Train: LR 0.00010000000000000003  Loss 0.13  Acc 87.64% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@290\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_290_20240502151959.pt\n",
      "1h05m Epoch: 291/600 | Time: 0m13s (Train 0m12s  Val 0m01s) | Train: LR 0.00010000000000000003  Loss 0.13  Acc 89.49% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@291\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_291_20240502152013.pt\n",
      "1h05m Epoch: 292/600 | Time: 0m14s (Train 0m12s  Val 0m01s) | Train: LR 0.00010000000000000003  Loss 0.13  Acc 87.78% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@292\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_292_20240502152027.pt\n",
      "1h05m Epoch: 293/600 | Time: 0m13s (Train 0m12s  Val 0m01s) | Train: LR 0.00010000000000000003  Loss 0.12  Acc 89.49% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@293\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.33898162841797_epoch_293_20240502152040.pt\n",
      "1h05m Epoch: 294/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 0.00010000000000000003  Loss 0.15  Acc 84.23% | Val: Loss nan  Acc(top1) 95.34% | HA 95.34@294\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_294_20240502152053.pt\n",
      "1h05m Epoch: 295/600 | Time: 0m13s (Train 0m12s  Val 0m01s) | Train: LR 0.00010000000000000003  Loss 0.15  Acc 86.65% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@295\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_295_20240502152107.pt\n",
      "1h06m Epoch: 296/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 0.00010000000000000003  Loss 0.13  Acc 87.50% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@296\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.33898162841797_epoch_296_20240502152120.pt\n",
      "1h06m Epoch: 297/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 0.00010000000000000003  Loss 0.13  Acc 85.51% | Val: Loss nan  Acc(top1) 95.34% | HA 95.34@297\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc94.91525268554688_epoch_297_20240502152134.pt\n",
      "1h06m Epoch: 298/600 | Time: 0m13s (Train 0m12s  Val 0m01s) | Train: LR 0.00010000000000000003  Loss 0.12  Acc 86.08% | Val: Loss nan  Acc(top1) 94.92% | HA 94.92@298\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_298_20240502152148.pt\n",
      "1h06m Epoch: 299/600 | Time: 0m13s (Train 0m12s  Val 0m01s) | Train: LR 0.00010000000000000003  Loss 0.13  Acc 86.79% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@299\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.33898162841797_epoch_299_20240502152201.pt\n",
      "1h07m Epoch: 300/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 0.00010000000000000003  Loss 0.14  Acc 87.64% | Val: Loss nan  Acc(top1) 95.34% | HA 95.34@300\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.33898162841797_epoch_300_20240502152215.pt\n",
      "1h07m Epoch: 301/600 | Time: 0m13s (Train 0m12s  Val 0m01s) | Train: LR 0.00010000000000000003  Loss 0.13  Acc 86.08% | Val: Loss nan  Acc(top1) 95.34% | HA 95.34@301\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_301_20240502152229.pt\n",
      "1h07m Epoch: 302/600 | Time: 0m13s (Train 0m12s  Val 0m01s) | Train: LR 0.00010000000000000003  Loss 0.14  Acc 85.94% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@302\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_302_20240502152242.pt\n",
      "1h07m Epoch: 303/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 0.00010000000000000003  Loss 0.15  Acc 86.08% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@303\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_303_20240502152255.pt\n",
      "1h07m Epoch: 304/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 0.00010000000000000003  Loss 0.13  Acc 86.36% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@304\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_304_20240502152309.pt\n",
      "1h08m Epoch: 305/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 0.00010000000000000003  Loss 0.13  Acc 87.78% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@305\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_305_20240502152323.pt\n",
      "1h08m Epoch: 306/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 0.00010000000000000003  Loss 0.13  Acc 85.65% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@306\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_306_20240502152336.pt\n",
      "1h08m Epoch: 307/600 | Time: 0m13s (Train 0m12s  Val 0m01s) | Train: LR 0.00010000000000000003  Loss 0.14  Acc 86.22% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@307\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_307_20240502152350.pt\n",
      "1h08m Epoch: 308/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 0.00010000000000000003  Loss 0.13  Acc 86.22% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@308\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.33898162841797_epoch_308_20240502152403.pt\n",
      "1h09m Epoch: 309/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 0.00010000000000000003  Loss 0.13  Acc 84.23% | Val: Loss nan  Acc(top1) 95.34% | HA 95.34@309\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.33898162841797_epoch_309_20240502152417.pt\n",
      "1h09m Epoch: 310/600 | Time: 0m13s (Train 0m12s  Val 0m01s) | Train: LR 0.00010000000000000003  Loss 0.14  Acc 87.07% | Val: Loss nan  Acc(top1) 95.34% | HA 95.34@310\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.33898162841797_epoch_310_20240502152431.pt\n",
      "1h09m Epoch: 311/600 | Time: 0m13s (Train 0m12s  Val 0m01s) | Train: LR 0.00010000000000000003  Loss 0.13  Acc 87.50% | Val: Loss nan  Acc(top1) 95.34% | HA 95.34@311\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_311_20240502152444.pt\n",
      "1h09m Epoch: 312/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 0.00010000000000000003  Loss 0.14  Acc 85.09% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@312\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_312_20240502152457.pt\n",
      "1h09m Epoch: 313/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 0.00010000000000000003  Loss 0.13  Acc 85.23% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@313\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_313_20240502152511.pt\n",
      "1h10m Epoch: 314/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 0.00010000000000000003  Loss 0.13  Acc 88.07% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@314\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.33898162841797_epoch_314_20240502152524.pt\n",
      "1h10m Epoch: 315/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 0.00010000000000000003  Loss 0.13  Acc 85.80% | Val: Loss nan  Acc(top1) 95.34% | HA 95.34@315\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_315_20240502152538.pt\n",
      "1h10m Epoch: 316/600 | Time: 0m13s (Train 0m12s  Val 0m01s) | Train: LR 0.00010000000000000003  Loss 0.14  Acc 86.65% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@316\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_316_20240502152551.pt\n",
      "1h10m Epoch: 317/600 | Time: 0m13s (Train 0m12s  Val 0m01s) | Train: LR 0.00010000000000000003  Loss 0.13  Acc 88.35% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@317\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_317_20240502152605.pt\n",
      "1h11m Epoch: 318/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 0.00010000000000000003  Loss 0.14  Acc 84.09% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@318\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_318_20240502152618.pt\n",
      "1h11m Epoch: 319/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 0.00010000000000000003  Loss 0.12  Acc 88.07% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@319\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_319_20240502152632.pt\n",
      "1h11m Epoch: 320/600 | Time: 0m13s (Train 0m12s  Val 0m01s) | Train: LR 0.00010000000000000003  Loss 0.13  Acc 85.65% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@320\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_320_20240502152645.pt\n",
      "1h11m Epoch: 321/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 0.00010000000000000003  Loss 0.14  Acc 85.94% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@321\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_321_20240502152658.pt\n",
      "1h11m Epoch: 322/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 0.00010000000000000003  Loss 0.12  Acc 86.79% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@322\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_322_20240502152711.pt\n",
      "1h12m Epoch: 323/600 | Time: 0m12s (Train 0m11s  Val 0m01s) | Train: LR 0.00010000000000000003  Loss 0.13  Acc 84.52% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@323\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.33898162841797_epoch_323_20240502152724.pt\n",
      "1h12m Epoch: 324/600 | Time: 0m12s (Train 0m11s  Val 0m01s) | Train: LR 0.00010000000000000003  Loss 0.13  Acc 84.80% | Val: Loss nan  Acc(top1) 95.34% | HA 95.34@324\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_324_20240502152737.pt\n",
      "1h12m Epoch: 325/600 | Time: 0m12s (Train 0m11s  Val 0m01s) | Train: LR 0.00010000000000000003  Loss 0.14  Acc 86.08% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@325\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_325_20240502152749.pt\n",
      "1h12m Epoch: 326/600 | Time: 0m12s (Train 0m11s  Val 0m01s) | Train: LR 0.00010000000000000003  Loss 0.13  Acc 87.22% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@326\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_326_20240502152802.pt\n",
      "1h13m Epoch: 327/600 | Time: 0m12s (Train 0m11s  Val 0m01s) | Train: LR 0.00010000000000000003  Loss 0.14  Acc 86.79% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@327\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_327_20240502152815.pt\n",
      "1h13m Epoch: 328/600 | Time: 0m12s (Train 0m11s  Val 0m01s) | Train: LR 0.00010000000000000003  Loss 0.14  Acc 88.21% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@328\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_328_20240502152828.pt\n",
      "1h13m Epoch: 329/600 | Time: 0m12s (Train 0m11s  Val 0m01s) | Train: LR 0.00010000000000000003  Loss 0.15  Acc 85.09% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@329\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.33898162841797_epoch_329_20240502152841.pt\n",
      "1h13m Epoch: 330/600 | Time: 0m12s (Train 0m11s  Val 0m01s) | Train: LR 0.00010000000000000003  Loss 0.15  Acc 85.65% | Val: Loss nan  Acc(top1) 95.34% | HA 95.34@330\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_330_20240502152853.pt\n",
      "1h13m Epoch: 331/600 | Time: 0m12s (Train 0m11s  Val 0m01s) | Train: LR 0.00010000000000000003  Loss 0.13  Acc 87.64% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@331\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_331_20240502152906.pt\n",
      "1h14m Epoch: 332/600 | Time: 0m12s (Train 0m11s  Val 0m01s) | Train: LR 0.00010000000000000003  Loss 0.13  Acc 87.78% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@332\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_332_20240502152919.pt\n",
      "1h14m Epoch: 333/600 | Time: 0m12s (Train 0m11s  Val 0m01s) | Train: LR 0.00010000000000000003  Loss 0.14  Acc 86.22% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@333\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_333_20240502152932.pt\n",
      "1h14m Epoch: 334/600 | Time: 0m12s (Train 0m11s  Val 0m01s) | Train: LR 0.00010000000000000003  Loss 0.13  Acc 87.22% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@334\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_334_20240502152944.pt\n",
      "1h14m Epoch: 335/600 | Time: 0m12s (Train 0m11s  Val 0m01s) | Train: LR 0.00010000000000000003  Loss 0.14  Acc 87.22% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@335\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_335_20240502152957.pt\n",
      "1h14m Epoch: 336/600 | Time: 0m12s (Train 0m11s  Val 0m01s) | Train: LR 0.00010000000000000003  Loss 0.13  Acc 87.07% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@336\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_336_20240502153010.pt\n",
      "1h15m Epoch: 337/600 | Time: 0m12s (Train 0m11s  Val 0m01s) | Train: LR 0.00010000000000000003  Loss 0.12  Acc 89.20% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@337\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.33898162841797_epoch_337_20240502153023.pt\n",
      "1h15m Epoch: 338/600 | Time: 0m12s (Train 0m11s  Val 0m01s) | Train: LR 0.00010000000000000003  Loss 0.12  Acc 88.64% | Val: Loss nan  Acc(top1) 95.34% | HA 95.34@338\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.33898162841797_epoch_338_20240502153035.pt\n",
      "1h15m Epoch: 339/600 | Time: 0m12s (Train 0m11s  Val 0m01s) | Train: LR 0.00010000000000000003  Loss 0.13  Acc 87.22% | Val: Loss nan  Acc(top1) 95.34% | HA 95.34@339\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_339_20240502153048.pt\n",
      "1h15m Epoch: 340/600 | Time: 0m12s (Train 0m11s  Val 0m01s) | Train: LR 0.00010000000000000003  Loss 0.14  Acc 85.80% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@340\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_340_20240502153101.pt\n",
      "1h16m Epoch: 341/600 | Time: 0m12s (Train 0m11s  Val 0m01s) | Train: LR 0.00010000000000000003  Loss 0.13  Acc 88.21% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@341\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_341_20240502153114.pt\n",
      "1h16m Epoch: 342/600 | Time: 0m12s (Train 0m11s  Val 0m01s) | Train: LR 0.00010000000000000003  Loss 0.14  Acc 85.23% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@342\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_342_20240502153126.pt\n",
      "1h16m Epoch: 343/600 | Time: 0m12s (Train 0m11s  Val 0m01s) | Train: LR 0.00010000000000000003  Loss 0.13  Acc 86.22% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@343\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_343_20240502153139.pt\n",
      "1h16m Epoch: 344/600 | Time: 0m12s (Train 0m11s  Val 0m01s) | Train: LR 0.00010000000000000003  Loss 0.14  Acc 86.65% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@344\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_344_20240502153152.pt\n",
      "1h16m Epoch: 345/600 | Time: 0m12s (Train 0m11s  Val 0m01s) | Train: LR 0.00010000000000000003  Loss 0.13  Acc 86.22% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@345\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.33898162841797_epoch_345_20240502153205.pt\n",
      "1h17m Epoch: 346/600 | Time: 0m12s (Train 0m11s  Val 0m01s) | Train: LR 0.00010000000000000003  Loss 0.13  Acc 85.37% | Val: Loss nan  Acc(top1) 95.34% | HA 95.34@346\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_346_20240502153218.pt\n",
      "1h17m Epoch: 347/600 | Time: 0m12s (Train 0m11s  Val 0m01s) | Train: LR 0.00010000000000000003  Loss 0.14  Acc 83.66% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@347\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_347_20240502153231.pt\n",
      "1h17m Epoch: 348/600 | Time: 0m12s (Train 0m11s  Val 0m01s) | Train: LR 0.00010000000000000003  Loss 0.12  Acc 86.51% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@348\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.33898162841797_epoch_348_20240502153243.pt\n",
      "1h17m Epoch: 349/600 | Time: 0m12s (Train 0m11s  Val 0m01s) | Train: LR 0.00010000000000000003  Loss 0.13  Acc 88.92% | Val: Loss nan  Acc(top1) 95.34% | HA 95.34@349\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_349_20240502153256.pt\n",
      "1h17m Epoch: 350/600 | Time: 0m12s (Train 0m11s  Val 0m01s) | Train: LR 0.00010000000000000003  Loss 0.13  Acc 86.79% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@350\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_350_20240502153309.pt\n",
      "1h18m Epoch: 351/600 | Time: 0m12s (Train 0m11s  Val 0m01s) | Train: LR 0.00010000000000000003  Loss 0.15  Acc 85.09% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@351\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_351_20240502153322.pt\n",
      "1h18m Epoch: 352/600 | Time: 0m12s (Train 0m11s  Val 0m01s) | Train: LR 0.00010000000000000003  Loss 0.14  Acc 86.65% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@352\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_352_20240502153334.pt\n",
      "1h18m Epoch: 353/600 | Time: 0m12s (Train 0m11s  Val 0m01s) | Train: LR 0.00010000000000000003  Loss 0.14  Acc 87.36% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@353\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_353_20240502153347.pt\n",
      "1h18m Epoch: 354/600 | Time: 0m12s (Train 0m11s  Val 0m01s) | Train: LR 0.00010000000000000003  Loss 0.12  Acc 86.65% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@354\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.33898162841797_epoch_354_20240502153400.pt\n",
      "1h19m Epoch: 355/600 | Time: 0m12s (Train 0m11s  Val 0m01s) | Train: LR 0.00010000000000000003  Loss 0.12  Acc 88.92% | Val: Loss nan  Acc(top1) 95.34% | HA 95.34@355\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_355_20240502153412.pt\n",
      "1h19m Epoch: 356/600 | Time: 0m12s (Train 0m11s  Val 0m01s) | Train: LR 0.00010000000000000003  Loss 0.14  Acc 88.35% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@356\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.33898162841797_epoch_356_20240502153425.pt\n",
      "1h19m Epoch: 357/600 | Time: 0m12s (Train 0m11s  Val 0m01s) | Train: LR 0.00010000000000000003  Loss 0.13  Acc 87.64% | Val: Loss nan  Acc(top1) 95.34% | HA 95.34@357\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_357_20240502153438.pt\n",
      "1h19m Epoch: 358/600 | Time: 0m12s (Train 0m11s  Val 0m01s) | Train: LR 0.00010000000000000003  Loss 0.14  Acc 85.65% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@358\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.33898162841797_epoch_358_20240502153451.pt\n",
      "1h19m Epoch: 359/600 | Time: 0m12s (Train 0m11s  Val 0m01s) | Train: LR 0.00010000000000000003  Loss 0.13  Acc 87.22% | Val: Loss nan  Acc(top1) 95.34% | HA 95.34@359\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_359_20240502153504.pt\n",
      "1h20m Epoch: 360/600 | Time: 0m12s (Train 0m11s  Val 0m01s) | Train: LR 0.00010000000000000003  Loss 0.14  Acc 88.21% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@360\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_360_20240502153516.pt\n",
      "1h20m Epoch: 361/600 | Time: 0m12s (Train 0m11s  Val 0m01s) | Train: LR 1.0000000000000003e-05  Loss 0.14  Acc 85.37% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@361\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.33898162841797_epoch_361_20240502153529.pt\n",
      "1h20m Epoch: 362/600 | Time: 0m12s (Train 0m11s  Val 0m01s) | Train: LR 1.0000000000000003e-05  Loss 0.13  Acc 86.51% | Val: Loss nan  Acc(top1) 95.34% | HA 95.34@362\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.33898162841797_epoch_362_20240502153542.pt\n",
      "1h20m Epoch: 363/600 | Time: 0m12s (Train 0m11s  Val 0m01s) | Train: LR 1.0000000000000003e-05  Loss 0.12  Acc 88.35% | Val: Loss nan  Acc(top1) 95.34% | HA 95.34@363\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_363_20240502153554.pt\n",
      "1h20m Epoch: 364/600 | Time: 0m12s (Train 0m11s  Val 0m01s) | Train: LR 1.0000000000000003e-05  Loss 0.14  Acc 83.95% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@364\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.33898162841797_epoch_364_20240502153607.pt\n",
      "1h21m Epoch: 365/600 | Time: 0m12s (Train 0m11s  Val 0m01s) | Train: LR 1.0000000000000003e-05  Loss 0.13  Acc 88.64% | Val: Loss nan  Acc(top1) 95.34% | HA 95.34@365\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.33898162841797_epoch_365_20240502153620.pt\n",
      "1h21m Epoch: 366/600 | Time: 0m12s (Train 0m11s  Val 0m01s) | Train: LR 1.0000000000000003e-05  Loss 0.13  Acc 86.36% | Val: Loss nan  Acc(top1) 95.34% | HA 95.34@366\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_366_20240502153632.pt\n",
      "1h21m Epoch: 367/600 | Time: 0m12s (Train 0m11s  Val 0m01s) | Train: LR 1.0000000000000003e-05  Loss 0.12  Acc 88.35% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@367\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_367_20240502153645.pt\n",
      "1h21m Epoch: 368/600 | Time: 0m12s (Train 0m11s  Val 0m01s) | Train: LR 1.0000000000000003e-05  Loss 0.13  Acc 86.36% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@368\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_368_20240502153658.pt\n",
      "1h21m Epoch: 369/600 | Time: 0m12s (Train 0m11s  Val 0m01s) | Train: LR 1.0000000000000003e-05  Loss 0.13  Acc 86.36% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@369\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_369_20240502153711.pt\n",
      "1h22m Epoch: 370/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 1.0000000000000003e-05  Loss 0.13  Acc 89.20% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@370\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.33898162841797_epoch_370_20240502153724.pt\n",
      "1h22m Epoch: 371/600 | Time: 0m12s (Train 0m11s  Val 0m01s) | Train: LR 1.0000000000000003e-05  Loss 0.14  Acc 87.93% | Val: Loss nan  Acc(top1) 95.34% | HA 95.34@371\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_371_20240502153736.pt\n",
      "1h22m Epoch: 372/600 | Time: 0m12s (Train 0m11s  Val 0m01s) | Train: LR 1.0000000000000003e-05  Loss 0.13  Acc 85.65% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@372\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_372_20240502153749.pt\n",
      "1h22m Epoch: 373/600 | Time: 0m12s (Train 0m11s  Val 0m01s) | Train: LR 1.0000000000000003e-05  Loss 0.13  Acc 86.79% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@373\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_373_20240502153802.pt\n",
      "1h23m Epoch: 374/600 | Time: 0m12s (Train 0m11s  Val 0m01s) | Train: LR 1.0000000000000003e-05  Loss 0.14  Acc 84.94% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@374\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_374_20240502153815.pt\n",
      "1h23m Epoch: 375/600 | Time: 0m12s (Train 0m11s  Val 0m01s) | Train: LR 1.0000000000000003e-05  Loss 0.12  Acc 88.49% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@375\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_375_20240502153827.pt\n",
      "1h23m Epoch: 376/600 | Time: 0m12s (Train 0m11s  Val 0m01s) | Train: LR 1.0000000000000003e-05  Loss 0.15  Acc 87.36% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@376\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_376_20240502153840.pt\n",
      "1h23m Epoch: 377/600 | Time: 0m12s (Train 0m11s  Val 0m01s) | Train: LR 1.0000000000000003e-05  Loss 0.14  Acc 86.22% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@377\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.33898162841797_epoch_377_20240502153853.pt\n",
      "1h23m Epoch: 378/600 | Time: 0m12s (Train 0m11s  Val 0m01s) | Train: LR 1.0000000000000003e-05  Loss 0.13  Acc 85.94% | Val: Loss nan  Acc(top1) 95.34% | HA 95.34@378\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_378_20240502153905.pt\n",
      "1h24m Epoch: 379/600 | Time: 0m12s (Train 0m11s  Val 0m01s) | Train: LR 1.0000000000000003e-05  Loss 0.13  Acc 87.50% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@379\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_379_20240502153918.pt\n",
      "1h24m Epoch: 380/600 | Time: 0m12s (Train 0m11s  Val 0m01s) | Train: LR 1.0000000000000003e-05  Loss 0.14  Acc 86.65% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@380\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.33898162841797_epoch_380_20240502153931.pt\n",
      "1h24m Epoch: 381/600 | Time: 0m12s (Train 0m11s  Val 0m01s) | Train: LR 1.0000000000000003e-05  Loss 0.14  Acc 84.94% | Val: Loss nan  Acc(top1) 95.34% | HA 95.34@381\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_381_20240502153944.pt\n",
      "1h24m Epoch: 382/600 | Time: 0m12s (Train 0m11s  Val 0m01s) | Train: LR 1.0000000000000003e-05  Loss 0.14  Acc 86.22% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@382\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_382_20240502153956.pt\n",
      "1h24m Epoch: 383/600 | Time: 0m12s (Train 0m11s  Val 0m01s) | Train: LR 1.0000000000000003e-05  Loss 0.13  Acc 86.51% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@383\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_383_20240502154009.pt\n",
      "1h25m Epoch: 384/600 | Time: 0m12s (Train 0m11s  Val 0m01s) | Train: LR 1.0000000000000003e-05  Loss 0.15  Acc 85.65% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@384\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_384_20240502154022.pt\n",
      "1h25m Epoch: 385/600 | Time: 0m12s (Train 0m11s  Val 0m01s) | Train: LR 1.0000000000000003e-05  Loss 0.13  Acc 85.94% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@385\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_385_20240502154035.pt\n",
      "1h25m Epoch: 386/600 | Time: 0m12s (Train 0m11s  Val 0m01s) | Train: LR 1.0000000000000003e-05  Loss 0.13  Acc 86.36% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@386\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_386_20240502154048.pt\n",
      "1h25m Epoch: 387/600 | Time: 0m12s (Train 0m11s  Val 0m01s) | Train: LR 1.0000000000000003e-05  Loss 0.12  Acc 88.35% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@387\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_387_20240502154100.pt\n",
      "1h26m Epoch: 388/600 | Time: 0m12s (Train 0m11s  Val 0m01s) | Train: LR 1.0000000000000003e-05  Loss 0.14  Acc 86.08% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@388\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_388_20240502154113.pt\n",
      "1h26m Epoch: 389/600 | Time: 0m12s (Train 0m11s  Val 0m01s) | Train: LR 1.0000000000000003e-05  Loss 0.13  Acc 88.35% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@389\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_389_20240502154125.pt\n",
      "1h26m Epoch: 390/600 | Time: 0m12s (Train 0m11s  Val 0m01s) | Train: LR 1.0000000000000003e-05  Loss 0.14  Acc 87.22% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@390\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_390_20240502154138.pt\n",
      "1h26m Epoch: 391/600 | Time: 0m12s (Train 0m11s  Val 0m01s) | Train: LR 1.0000000000000003e-05  Loss 0.13  Acc 85.37% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@391\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_391_20240502154151.pt\n",
      "1h26m Epoch: 392/600 | Time: 0m12s (Train 0m11s  Val 0m01s) | Train: LR 1.0000000000000003e-05  Loss 0.13  Acc 91.05% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@392\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.33898162841797_epoch_392_20240502154204.pt\n",
      "1h27m Epoch: 393/600 | Time: 0m12s (Train 0m11s  Val 0m01s) | Train: LR 1.0000000000000003e-05  Loss 0.15  Acc 86.22% | Val: Loss nan  Acc(top1) 95.34% | HA 95.34@393\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.33898162841797_epoch_393_20240502154216.pt\n",
      "1h27m Epoch: 394/600 | Time: 0m12s (Train 0m11s  Val 0m01s) | Train: LR 1.0000000000000003e-05  Loss 0.13  Acc 87.07% | Val: Loss nan  Acc(top1) 95.34% | HA 95.34@394\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.33898162841797_epoch_394_20240502154230.pt\n",
      "1h27m Epoch: 395/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 1.0000000000000003e-05  Loss 0.13  Acc 83.66% | Val: Loss nan  Acc(top1) 95.34% | HA 95.34@395\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.33898162841797_epoch_395_20240502154243.pt\n",
      "1h27m Epoch: 396/600 | Time: 0m12s (Train 0m11s  Val 0m01s) | Train: LR 1.0000000000000003e-05  Loss 0.14  Acc 84.80% | Val: Loss nan  Acc(top1) 95.34% | HA 95.34@396\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_396_20240502154256.pt\n",
      "1h27m Epoch: 397/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 1.0000000000000003e-05  Loss 0.15  Acc 86.93% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@397\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_397_20240502154309.pt\n",
      "1h28m Epoch: 398/600 | Time: 0m12s (Train 0m11s  Val 0m01s) | Train: LR 1.0000000000000003e-05  Loss 0.14  Acc 85.65% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@398\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.33898162841797_epoch_398_20240502154322.pt\n",
      "1h28m Epoch: 399/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 1.0000000000000003e-05  Loss 0.13  Acc 88.78% | Val: Loss nan  Acc(top1) 95.34% | HA 95.34@399\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.33898162841797_epoch_399_20240502154335.pt\n",
      "1h28m Epoch: 400/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 1.0000000000000003e-05  Loss 0.13  Acc 85.51% | Val: Loss nan  Acc(top1) 95.34% | HA 95.34@400\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.33898162841797_epoch_400_20240502154348.pt\n",
      "1h28m Epoch: 401/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 1.0000000000000003e-05  Loss 0.13  Acc 87.78% | Val: Loss nan  Acc(top1) 95.34% | HA 95.34@401\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_401_20240502154401.pt\n",
      "1h29m Epoch: 402/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 1.0000000000000003e-05  Loss 0.13  Acc 87.07% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@402\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_402_20240502154414.pt\n",
      "1h29m Epoch: 403/600 | Time: 0m12s (Train 0m11s  Val 0m01s) | Train: LR 1.0000000000000003e-05  Loss 0.13  Acc 86.79% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@403\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_403_20240502154427.pt\n",
      "1h29m Epoch: 404/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 1.0000000000000003e-05  Loss 0.14  Acc 85.23% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@404\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_404_20240502154440.pt\n",
      "1h29m Epoch: 405/600 | Time: 0m12s (Train 0m11s  Val 0m01s) | Train: LR 1.0000000000000003e-05  Loss 0.14  Acc 85.94% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@405\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_405_20240502154454.pt\n",
      "1h29m Epoch: 406/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 1.0000000000000003e-05  Loss 0.14  Acc 87.50% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@406\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_406_20240502154507.pt\n",
      "1h30m Epoch: 407/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 1.0000000000000003e-05  Loss 0.13  Acc 88.49% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@407\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.33898162841797_epoch_407_20240502154520.pt\n",
      "1h30m Epoch: 408/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 1.0000000000000003e-05  Loss 0.14  Acc 87.07% | Val: Loss nan  Acc(top1) 95.34% | HA 95.34@408\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.33898162841797_epoch_408_20240502154533.pt\n",
      "1h30m Epoch: 409/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 1.0000000000000003e-05  Loss 0.14  Acc 86.36% | Val: Loss nan  Acc(top1) 95.34% | HA 95.34@409\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_409_20240502154546.pt\n",
      "1h30m Epoch: 410/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 1.0000000000000003e-05  Loss 0.13  Acc 84.66% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@410\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_410_20240502154559.pt\n",
      "1h31m Epoch: 411/600 | Time: 0m12s (Train 0m11s  Val 0m01s) | Train: LR 1.0000000000000003e-05  Loss 0.13  Acc 88.35% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@411\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_411_20240502154612.pt\n",
      "1h31m Epoch: 412/600 | Time: 0m12s (Train 0m11s  Val 0m01s) | Train: LR 1.0000000000000003e-05  Loss 0.13  Acc 87.78% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@412\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_412_20240502154625.pt\n",
      "1h31m Epoch: 413/600 | Time: 0m12s (Train 0m11s  Val 0m01s) | Train: LR 1.0000000000000003e-05  Loss 0.14  Acc 87.22% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@413\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_413_20240502154638.pt\n",
      "1h31m Epoch: 414/600 | Time: 0m12s (Train 0m11s  Val 0m01s) | Train: LR 1.0000000000000003e-05  Loss 0.12  Acc 86.36% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@414\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_414_20240502154650.pt\n",
      "1h31m Epoch: 415/600 | Time: 0m12s (Train 0m11s  Val 0m01s) | Train: LR 1.0000000000000003e-05  Loss 0.14  Acc 87.36% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@415\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.33898162841797_epoch_415_20240502154703.pt\n",
      "1h32m Epoch: 416/600 | Time: 0m12s (Train 0m11s  Val 0m01s) | Train: LR 1.0000000000000003e-05  Loss 0.14  Acc 87.07% | Val: Loss nan  Acc(top1) 95.34% | HA 95.34@416\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_416_20240502154716.pt\n",
      "1h32m Epoch: 417/600 | Time: 0m12s (Train 0m11s  Val 0m01s) | Train: LR 1.0000000000000003e-05  Loss 0.14  Acc 86.93% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@417\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_417_20240502154729.pt\n",
      "1h32m Epoch: 418/600 | Time: 0m12s (Train 0m11s  Val 0m01s) | Train: LR 1.0000000000000003e-05  Loss 0.13  Acc 85.80% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@418\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.33898162841797_epoch_418_20240502154741.pt\n",
      "1h32m Epoch: 419/600 | Time: 0m12s (Train 0m11s  Val 0m01s) | Train: LR 1.0000000000000003e-05  Loss 0.13  Acc 87.22% | Val: Loss nan  Acc(top1) 95.34% | HA 95.34@419\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_419_20240502154754.pt\n",
      "1h32m Epoch: 420/600 | Time: 0m12s (Train 0m11s  Val 0m01s) | Train: LR 1.0000000000000003e-05  Loss 0.13  Acc 87.50% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@420\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_420_20240502154807.pt\n",
      "1h33m Epoch: 421/600 | Time: 0m12s (Train 0m11s  Val 0m01s) | Train: LR 1.0000000000000003e-05  Loss 0.13  Acc 87.22% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@421\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_421_20240502154820.pt\n",
      "1h33m Epoch: 422/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 1.0000000000000003e-05  Loss 0.14  Acc 86.22% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@422\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_422_20240502154833.pt\n",
      "1h33m Epoch: 423/600 | Time: 0m12s (Train 0m11s  Val 0m01s) | Train: LR 1.0000000000000003e-05  Loss 0.14  Acc 85.65% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@423\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_423_20240502154846.pt\n",
      "1h33m Epoch: 424/600 | Time: 0m12s (Train 0m11s  Val 0m01s) | Train: LR 1.0000000000000003e-05  Loss 0.13  Acc 87.36% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@424\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.33898162841797_epoch_424_20240502154858.pt\n",
      "1h33m Epoch: 425/600 | Time: 0m12s (Train 0m11s  Val 0m01s) | Train: LR 1.0000000000000003e-05  Loss 0.13  Acc 87.50% | Val: Loss nan  Acc(top1) 95.34% | HA 95.34@425\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_425_20240502154912.pt\n",
      "1h34m Epoch: 426/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 1.0000000000000003e-05  Loss 0.12  Acc 86.93% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@426\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_426_20240502154925.pt\n",
      "1h34m Epoch: 427/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 1.0000000000000003e-05  Loss 0.13  Acc 86.93% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@427\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_427_20240502154938.pt\n",
      "1h34m Epoch: 428/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 1.0000000000000003e-05  Loss 0.13  Acc 87.78% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@428\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.33898162841797_epoch_428_20240502154951.pt\n",
      "1h34m Epoch: 429/600 | Time: 0m12s (Train 0m11s  Val 0m01s) | Train: LR 1.0000000000000003e-05  Loss 0.14  Acc 86.08% | Val: Loss nan  Acc(top1) 95.34% | HA 95.34@429\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.33898162841797_epoch_429_20240502155003.pt\n",
      "1h35m Epoch: 430/600 | Time: 0m12s (Train 0m11s  Val 0m01s) | Train: LR 1.0000000000000003e-05  Loss 0.13  Acc 88.64% | Val: Loss nan  Acc(top1) 95.34% | HA 95.34@430\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_430_20240502155017.pt\n",
      "1h35m Epoch: 431/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 1.0000000000000003e-05  Loss 0.13  Acc 85.09% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@431\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.33898162841797_epoch_431_20240502155029.pt\n",
      "1h35m Epoch: 432/600 | Time: 0m12s (Train 0m11s  Val 0m01s) | Train: LR 1.0000000000000003e-05  Loss 0.13  Acc 87.36% | Val: Loss nan  Acc(top1) 95.34% | HA 95.34@432\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_432_20240502155042.pt\n",
      "1h35m Epoch: 433/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 1.0000000000000003e-05  Loss 0.15  Acc 85.94% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@433\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_433_20240502155055.pt\n",
      "1h35m Epoch: 434/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 1.0000000000000003e-05  Loss 0.14  Acc 85.80% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@434\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_434_20240502155109.pt\n",
      "1h36m Epoch: 435/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 1.0000000000000003e-05  Loss 0.13  Acc 87.93% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@435\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_435_20240502155122.pt\n",
      "1h36m Epoch: 436/600 | Time: 0m12s (Train 0m11s  Val 0m01s) | Train: LR 1.0000000000000003e-05  Loss 0.14  Acc 86.65% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@436\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc94.91525268554688_epoch_436_20240502155134.pt\n",
      "1h36m Epoch: 437/600 | Time: 0m12s (Train 0m11s  Val 0m01s) | Train: LR 1.0000000000000003e-05  Loss 0.13  Acc 87.50% | Val: Loss nan  Acc(top1) 94.92% | HA 94.92@437\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_437_20240502155147.pt\n",
      "1h36m Epoch: 438/600 | Time: 0m12s (Train 0m11s  Val 0m01s) | Train: LR 1.0000000000000003e-05  Loss 0.13  Acc 84.52% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@438\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_438_20240502155200.pt\n",
      "1h37m Epoch: 439/600 | Time: 0m12s (Train 0m11s  Val 0m01s) | Train: LR 1.0000000000000003e-05  Loss 0.13  Acc 87.36% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@439\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_439_20240502155212.pt\n",
      "1h37m Epoch: 440/600 | Time: 0m12s (Train 0m11s  Val 0m01s) | Train: LR 1.0000000000000003e-05  Loss 0.13  Acc 85.51% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@440\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_440_20240502155225.pt\n",
      "1h37m Epoch: 441/600 | Time: 0m12s (Train 0m11s  Val 0m01s) | Train: LR 1.0000000000000003e-05  Loss 0.14  Acc 87.50% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@441\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.33898162841797_epoch_441_20240502155238.pt\n",
      "1h37m Epoch: 442/600 | Time: 0m12s (Train 0m11s  Val 0m01s) | Train: LR 1.0000000000000003e-05  Loss 0.14  Acc 85.51% | Val: Loss nan  Acc(top1) 95.34% | HA 95.34@442\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc94.91525268554688_epoch_442_20240502155251.pt\n",
      "1h37m Epoch: 443/600 | Time: 0m12s (Train 0m11s  Val 0m01s) | Train: LR 1.0000000000000003e-05  Loss 0.14  Acc 85.80% | Val: Loss nan  Acc(top1) 94.92% | HA 94.92@443\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_443_20240502155303.pt\n",
      "1h38m Epoch: 444/600 | Time: 0m12s (Train 0m10s  Val 0m01s) | Train: LR 1.0000000000000003e-05  Loss 0.13  Acc 84.52% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@444\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_444_20240502155316.pt\n",
      "1h38m Epoch: 445/600 | Time: 0m12s (Train 0m11s  Val 0m01s) | Train: LR 1.0000000000000003e-05  Loss 0.14  Acc 86.79% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@445\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.33898162841797_epoch_445_20240502155328.pt\n",
      "1h38m Epoch: 446/600 | Time: 0m12s (Train 0m11s  Val 0m01s) | Train: LR 1.0000000000000003e-05  Loss 0.14  Acc 85.51% | Val: Loss nan  Acc(top1) 95.34% | HA 95.34@446\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_446_20240502155341.pt\n",
      "1h38m Epoch: 447/600 | Time: 0m12s (Train 0m11s  Val 0m01s) | Train: LR 1.0000000000000003e-05  Loss 0.13  Acc 87.07% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@447\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_447_20240502155354.pt\n",
      "1h38m Epoch: 448/600 | Time: 0m12s (Train 0m11s  Val 0m01s) | Train: LR 1.0000000000000003e-05  Loss 0.14  Acc 88.49% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@448\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_448_20240502155407.pt\n",
      "1h39m Epoch: 449/600 | Time: 0m12s (Train 0m11s  Val 0m01s) | Train: LR 1.0000000000000003e-05  Loss 0.13  Acc 83.95% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@449\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_449_20240502155419.pt\n",
      "1h39m Epoch: 450/600 | Time: 0m12s (Train 0m11s  Val 0m01s) | Train: LR 1.0000000000000003e-05  Loss 0.12  Acc 85.65% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@450\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_450_20240502155432.pt\n",
      "1h39m Epoch: 451/600 | Time: 0m12s (Train 0m11s  Val 0m01s) | Train: LR 1.0000000000000004e-06  Loss 0.13  Acc 86.93% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@451\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_451_20240502155445.pt\n",
      "1h39m Epoch: 452/600 | Time: 0m12s (Train 0m11s  Val 0m01s) | Train: LR 1.0000000000000004e-06  Loss 0.14  Acc 85.65% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@452\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_452_20240502155458.pt\n",
      "1h39m Epoch: 453/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 1.0000000000000004e-06  Loss 0.13  Acc 87.78% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@453\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.33898162841797_epoch_453_20240502155511.pt\n",
      "1h40m Epoch: 454/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 1.0000000000000004e-06  Loss 0.13  Acc 86.79% | Val: Loss nan  Acc(top1) 95.34% | HA 95.34@454\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_454_20240502155524.pt\n",
      "1h40m Epoch: 455/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 1.0000000000000004e-06  Loss 0.15  Acc 85.23% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@455\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_455_20240502155537.pt\n",
      "1h40m Epoch: 456/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 1.0000000000000004e-06  Loss 0.13  Acc 87.22% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@456\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_456_20240502155551.pt\n",
      "1h40m Epoch: 457/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 1.0000000000000004e-06  Loss 0.13  Acc 88.35% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@457\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_457_20240502155604.pt\n",
      "1h41m Epoch: 458/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 1.0000000000000004e-06  Loss 0.13  Acc 86.51% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@458\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_458_20240502155617.pt\n",
      "1h41m Epoch: 459/600 | Time: 0m12s (Train 0m11s  Val 0m01s) | Train: LR 1.0000000000000004e-06  Loss 0.13  Acc 88.78% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@459\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_459_20240502155630.pt\n",
      "1h41m Epoch: 460/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 1.0000000000000004e-06  Loss 0.14  Acc 85.23% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@460\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_460_20240502155643.pt\n",
      "1h41m Epoch: 461/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 1.0000000000000004e-06  Loss 0.12  Acc 87.22% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@461\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_461_20240502155656.pt\n",
      "1h41m Epoch: 462/600 | Time: 0m12s (Train 0m11s  Val 0m01s) | Train: LR 1.0000000000000004e-06  Loss 0.14  Acc 88.35% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@462\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_462_20240502155709.pt\n",
      "1h42m Epoch: 463/600 | Time: 0m12s (Train 0m11s  Val 0m01s) | Train: LR 1.0000000000000004e-06  Loss 0.14  Acc 86.51% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@463\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_463_20240502155722.pt\n",
      "1h42m Epoch: 464/600 | Time: 0m12s (Train 0m11s  Val 0m01s) | Train: LR 1.0000000000000004e-06  Loss 0.13  Acc 88.21% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@464\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.33898162841797_epoch_464_20240502155735.pt\n",
      "1h42m Epoch: 465/600 | Time: 0m12s (Train 0m11s  Val 0m01s) | Train: LR 1.0000000000000004e-06  Loss 0.13  Acc 87.36% | Val: Loss nan  Acc(top1) 95.34% | HA 95.34@465\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.33898162841797_epoch_465_20240502155748.pt\n",
      "1h42m Epoch: 466/600 | Time: 0m12s (Train 0m11s  Val 0m01s) | Train: LR 1.0000000000000004e-06  Loss 0.15  Acc 85.51% | Val: Loss nan  Acc(top1) 95.34% | HA 95.34@466\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_466_20240502155800.pt\n",
      "1h43m Epoch: 467/600 | Time: 0m12s (Train 0m11s  Val 0m01s) | Train: LR 1.0000000000000004e-06  Loss 0.12  Acc 87.22% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@467\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.33898162841797_epoch_467_20240502155813.pt\n",
      "1h43m Epoch: 468/600 | Time: 0m12s (Train 0m11s  Val 0m01s) | Train: LR 1.0000000000000004e-06  Loss 0.15  Acc 84.38% | Val: Loss nan  Acc(top1) 95.34% | HA 95.34@468\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_468_20240502155826.pt\n",
      "1h43m Epoch: 469/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 1.0000000000000004e-06  Loss 0.13  Acc 87.22% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@469\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.33898162841797_epoch_469_20240502155839.pt\n",
      "1h43m Epoch: 470/600 | Time: 0m12s (Train 0m11s  Val 0m01s) | Train: LR 1.0000000000000004e-06  Loss 0.14  Acc 86.93% | Val: Loss nan  Acc(top1) 95.34% | HA 95.34@470\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_470_20240502155852.pt\n",
      "1h43m Epoch: 471/600 | Time: 0m12s (Train 0m11s  Val 0m01s) | Train: LR 1.0000000000000004e-06  Loss 0.15  Acc 86.93% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@471\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_471_20240502155905.pt\n",
      "1h44m Epoch: 472/600 | Time: 0m12s (Train 0m11s  Val 0m01s) | Train: LR 1.0000000000000004e-06  Loss 0.13  Acc 84.80% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@472\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_472_20240502155917.pt\n",
      "1h44m Epoch: 473/600 | Time: 0m12s (Train 0m11s  Val 0m01s) | Train: LR 1.0000000000000004e-06  Loss 0.13  Acc 85.80% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@473\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_473_20240502155930.pt\n",
      "1h44m Epoch: 474/600 | Time: 0m12s (Train 0m11s  Val 0m01s) | Train: LR 1.0000000000000004e-06  Loss 0.14  Acc 86.22% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@474\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_474_20240502155943.pt\n",
      "1h44m Epoch: 475/600 | Time: 0m12s (Train 0m11s  Val 0m01s) | Train: LR 1.0000000000000004e-06  Loss 0.13  Acc 89.06% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@475\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_475_20240502155955.pt\n",
      "1h44m Epoch: 476/600 | Time: 0m12s (Train 0m11s  Val 0m01s) | Train: LR 1.0000000000000004e-06  Loss 0.13  Acc 87.36% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@476\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.33898162841797_epoch_476_20240502160008.pt\n",
      "1h45m Epoch: 477/600 | Time: 0m12s (Train 0m11s  Val 0m01s) | Train: LR 1.0000000000000004e-06  Loss 0.13  Acc 87.93% | Val: Loss nan  Acc(top1) 95.34% | HA 95.34@477\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_477_20240502160021.pt\n",
      "1h45m Epoch: 478/600 | Time: 0m12s (Train 0m11s  Val 0m01s) | Train: LR 1.0000000000000004e-06  Loss 0.13  Acc 88.35% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@478\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_478_20240502160033.pt\n",
      "1h45m Epoch: 479/600 | Time: 0m12s (Train 0m11s  Val 0m01s) | Train: LR 1.0000000000000004e-06  Loss 0.13  Acc 86.65% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@479\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_479_20240502160046.pt\n",
      "1h45m Epoch: 480/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 1.0000000000000004e-06  Loss 0.13  Acc 88.21% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@480\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_480_20240502160059.pt\n",
      "1h46m Epoch: 481/600 | Time: 0m12s (Train 0m11s  Val 0m01s) | Train: LR 1.0000000000000004e-06  Loss 0.13  Acc 86.22% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@481\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_481_20240502160112.pt\n",
      "1h46m Epoch: 482/600 | Time: 0m12s (Train 0m11s  Val 0m01s) | Train: LR 1.0000000000000004e-06  Loss 0.14  Acc 87.22% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@482\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_482_20240502160125.pt\n",
      "1h46m Epoch: 483/600 | Time: 0m12s (Train 0m11s  Val 0m01s) | Train: LR 1.0000000000000004e-06  Loss 0.13  Acc 86.51% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@483\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.33898162841797_epoch_483_20240502160137.pt\n",
      "1h46m Epoch: 484/600 | Time: 0m12s (Train 0m11s  Val 0m01s) | Train: LR 1.0000000000000004e-06  Loss 0.14  Acc 86.79% | Val: Loss nan  Acc(top1) 95.34% | HA 95.34@484\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_484_20240502160150.pt\n",
      "1h46m Epoch: 485/600 | Time: 0m12s (Train 0m11s  Val 0m01s) | Train: LR 1.0000000000000004e-06  Loss 0.14  Acc 86.36% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@485\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_485_20240502160203.pt\n",
      "1h47m Epoch: 486/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 1.0000000000000004e-06  Loss 0.14  Acc 85.80% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@486\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_486_20240502160216.pt\n",
      "1h47m Epoch: 487/600 | Time: 0m12s (Train 0m11s  Val 0m01s) | Train: LR 1.0000000000000004e-06  Loss 0.14  Acc 86.51% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@487\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_487_20240502160229.pt\n",
      "1h47m Epoch: 488/600 | Time: 0m12s (Train 0m11s  Val 0m01s) | Train: LR 1.0000000000000004e-06  Loss 0.14  Acc 87.50% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@488\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_488_20240502160241.pt\n",
      "1h47m Epoch: 489/600 | Time: 0m12s (Train 0m11s  Val 0m01s) | Train: LR 1.0000000000000004e-06  Loss 0.14  Acc 86.79% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@489\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_489_20240502160254.pt\n",
      "1h47m Epoch: 490/600 | Time: 0m12s (Train 0m11s  Val 0m01s) | Train: LR 1.0000000000000004e-06  Loss 0.14  Acc 86.51% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@490\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_490_20240502160307.pt\n",
      "1h48m Epoch: 491/600 | Time: 0m12s (Train 0m11s  Val 0m01s) | Train: LR 1.0000000000000004e-06  Loss 0.12  Acc 86.65% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@491\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_491_20240502160320.pt\n",
      "1h48m Epoch: 492/600 | Time: 0m12s (Train 0m11s  Val 0m01s) | Train: LR 1.0000000000000004e-06  Loss 0.13  Acc 88.21% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@492\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc94.91525268554688_epoch_492_20240502160332.pt\n",
      "1h48m Epoch: 493/600 | Time: 0m12s (Train 0m11s  Val 0m01s) | Train: LR 1.0000000000000004e-06  Loss 0.14  Acc 86.51% | Val: Loss nan  Acc(top1) 94.92% | HA 94.92@493\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_493_20240502160345.pt\n",
      "1h48m Epoch: 494/600 | Time: 0m12s (Train 0m11s  Val 0m01s) | Train: LR 1.0000000000000004e-06  Loss 0.13  Acc 87.22% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@494\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_494_20240502160358.pt\n",
      "1h48m Epoch: 495/600 | Time: 0m12s (Train 0m11s  Val 0m01s) | Train: LR 1.0000000000000004e-06  Loss 0.13  Acc 85.23% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@495\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_495_20240502160411.pt\n",
      "1h49m Epoch: 496/600 | Time: 0m12s (Train 0m11s  Val 0m01s) | Train: LR 1.0000000000000004e-06  Loss 0.14  Acc 87.22% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@496\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_496_20240502160423.pt\n",
      "1h49m Epoch: 497/600 | Time: 0m12s (Train 0m11s  Val 0m01s) | Train: LR 1.0000000000000004e-06  Loss 0.13  Acc 87.93% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@497\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_497_20240502160436.pt\n",
      "1h49m Epoch: 498/600 | Time: 0m12s (Train 0m11s  Val 0m01s) | Train: LR 1.0000000000000004e-06  Loss 0.13  Acc 83.95% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@498\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.33898162841797_epoch_498_20240502160449.pt\n",
      "1h49m Epoch: 499/600 | Time: 0m12s (Train 0m11s  Val 0m01s) | Train: LR 1.0000000000000004e-06  Loss 0.12  Acc 87.78% | Val: Loss nan  Acc(top1) 95.34% | HA 95.34@499\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.33898162841797_epoch_499_20240502160501.pt\n",
      "1h50m Epoch: 500/600 | Time: 0m12s (Train 0m11s  Val 0m01s) | Train: LR 1.0000000000000004e-06  Loss 0.14  Acc 87.07% | Val: Loss nan  Acc(top1) 95.34% | HA 95.34@500\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_500_20240502160514.pt\n",
      "1h50m Epoch: 501/600 | Time: 0m12s (Train 0m10s  Val 0m01s) | Train: LR 1.0000000000000004e-06  Loss 0.14  Acc 89.20% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@501\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.33898162841797_epoch_501_20240502160527.pt\n",
      "1h50m Epoch: 502/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 1.0000000000000004e-06  Loss 0.13  Acc 86.93% | Val: Loss nan  Acc(top1) 95.34% | HA 95.34@502\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.33898162841797_epoch_502_20240502160540.pt\n",
      "1h50m Epoch: 503/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 1.0000000000000004e-06  Loss 0.14  Acc 86.65% | Val: Loss nan  Acc(top1) 95.34% | HA 95.34@503\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_503_20240502160553.pt\n",
      "1h50m Epoch: 504/600 | Time: 0m12s (Train 0m11s  Val 0m01s) | Train: LR 1.0000000000000004e-06  Loss 0.12  Acc 87.07% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@504\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_504_20240502160606.pt\n",
      "1h51m Epoch: 505/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 1.0000000000000004e-06  Loss 0.13  Acc 88.64% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@505\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.33898162841797_epoch_505_20240502160619.pt\n",
      "1h51m Epoch: 506/600 | Time: 0m12s (Train 0m11s  Val 0m01s) | Train: LR 1.0000000000000004e-06  Loss 0.13  Acc 86.22% | Val: Loss nan  Acc(top1) 95.34% | HA 95.34@506\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc94.91525268554688_epoch_506_20240502160632.pt\n",
      "1h51m Epoch: 507/600 | Time: 0m12s (Train 0m11s  Val 0m01s) | Train: LR 1.0000000000000004e-06  Loss 0.12  Acc 87.07% | Val: Loss nan  Acc(top1) 94.92% | HA 94.92@507\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_507_20240502160645.pt\n",
      "1h51m Epoch: 508/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 1.0000000000000004e-06  Loss 0.14  Acc 85.09% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@508\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_508_20240502160658.pt\n",
      "1h51m Epoch: 509/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 1.0000000000000004e-06  Loss 0.14  Acc 86.08% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@509\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_509_20240502160711.pt\n",
      "1h52m Epoch: 510/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 1.0000000000000004e-06  Loss 0.14  Acc 86.08% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@510\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_510_20240502160724.pt\n",
      "1h52m Epoch: 511/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 1.0000000000000004e-06  Loss 0.14  Acc 85.09% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@511\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_511_20240502160737.pt\n",
      "1h52m Epoch: 512/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 1.0000000000000004e-06  Loss 0.15  Acc 84.66% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@512\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.33898162841797_epoch_512_20240502160750.pt\n",
      "1h52m Epoch: 513/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 1.0000000000000004e-06  Loss 0.13  Acc 87.22% | Val: Loss nan  Acc(top1) 95.34% | HA 95.34@513\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_513_20240502160804.pt\n",
      "1h53m Epoch: 514/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 1.0000000000000004e-06  Loss 0.13  Acc 84.66% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@514\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_514_20240502160817.pt\n",
      "1h53m Epoch: 515/600 | Time: 0m12s (Train 0m11s  Val 0m01s) | Train: LR 1.0000000000000004e-06  Loss 0.15  Acc 87.64% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@515\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_515_20240502160830.pt\n",
      "1h53m Epoch: 516/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 1.0000000000000004e-06  Loss 0.13  Acc 86.22% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@516\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_516_20240502160844.pt\n",
      "1h53m Epoch: 517/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 1.0000000000000004e-06  Loss 0.14  Acc 85.94% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@517\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.33898162841797_epoch_517_20240502160857.pt\n",
      "1h53m Epoch: 518/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 1.0000000000000004e-06  Loss 0.13  Acc 85.80% | Val: Loss nan  Acc(top1) 95.34% | HA 95.34@518\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_518_20240502160910.pt\n",
      "1h54m Epoch: 519/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 1.0000000000000004e-06  Loss 0.14  Acc 86.79% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@519\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_519_20240502160923.pt\n",
      "1h54m Epoch: 520/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 1.0000000000000004e-06  Loss 0.13  Acc 84.94% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@520\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_520_20240502160936.pt\n",
      "1h54m Epoch: 521/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 1.0000000000000004e-06  Loss 0.14  Acc 86.51% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@521\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_521_20240502160949.pt\n",
      "1h54m Epoch: 522/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 1.0000000000000004e-06  Loss 0.14  Acc 84.52% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@522\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.33898162841797_epoch_522_20240502161002.pt\n",
      "1h55m Epoch: 523/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 1.0000000000000004e-06  Loss 0.12  Acc 88.78% | Val: Loss nan  Acc(top1) 95.34% | HA 95.34@523\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_523_20240502161016.pt\n",
      "1h55m Epoch: 524/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 1.0000000000000004e-06  Loss 0.13  Acc 85.94% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@524\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_524_20240502161029.pt\n",
      "1h55m Epoch: 525/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 1.0000000000000004e-06  Loss 0.14  Acc 86.79% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@525\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.33898162841797_epoch_525_20240502161042.pt\n",
      "1h55m Epoch: 526/600 | Time: 0m12s (Train 0m11s  Val 0m01s) | Train: LR 1.0000000000000004e-06  Loss 0.13  Acc 86.36% | Val: Loss nan  Acc(top1) 95.34% | HA 95.34@526\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc94.91525268554688_epoch_526_20240502161055.pt\n",
      "1h55m Epoch: 527/600 | Time: 0m12s (Train 0m11s  Val 0m01s) | Train: LR 1.0000000000000004e-06  Loss 0.13  Acc 89.63% | Val: Loss nan  Acc(top1) 94.92% | HA 94.92@527\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_527_20240502161108.pt\n",
      "1h56m Epoch: 528/600 | Time: 0m12s (Train 0m11s  Val 0m01s) | Train: LR 1.0000000000000004e-06  Loss 0.13  Acc 87.64% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@528\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_528_20240502161121.pt\n",
      "1h56m Epoch: 529/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 1.0000000000000004e-06  Loss 0.13  Acc 84.80% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@529\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_529_20240502161134.pt\n",
      "1h56m Epoch: 530/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 1.0000000000000004e-06  Loss 0.13  Acc 85.94% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@530\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_530_20240502161147.pt\n",
      "1h56m Epoch: 531/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 1.0000000000000004e-06  Loss 0.14  Acc 85.37% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@531\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_531_20240502161201.pt\n",
      "1h57m Epoch: 532/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 1.0000000000000004e-06  Loss 0.13  Acc 86.65% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@532\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.33898162841797_epoch_532_20240502161214.pt\n",
      "1h57m Epoch: 533/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 1.0000000000000004e-06  Loss 0.13  Acc 85.65% | Val: Loss nan  Acc(top1) 95.34% | HA 95.34@533\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_533_20240502161227.pt\n",
      "1h57m Epoch: 534/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 1.0000000000000004e-06  Loss 0.14  Acc 86.51% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@534\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_534_20240502161240.pt\n",
      "1h57m Epoch: 535/600 | Time: 0m12s (Train 0m11s  Val 0m01s) | Train: LR 1.0000000000000004e-06  Loss 0.13  Acc 86.36% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@535\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_535_20240502161253.pt\n",
      "1h57m Epoch: 536/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 1.0000000000000004e-06  Loss 0.13  Acc 88.64% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@536\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_536_20240502161306.pt\n",
      "1h58m Epoch: 537/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 1.0000000000000004e-06  Loss 0.14  Acc 86.08% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@537\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_537_20240502161319.pt\n",
      "1h58m Epoch: 538/600 | Time: 0m12s (Train 0m11s  Val 0m01s) | Train: LR 1.0000000000000004e-06  Loss 0.14  Acc 84.94% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@538\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.33898162841797_epoch_538_20240502161332.pt\n",
      "1h58m Epoch: 539/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 1.0000000000000004e-06  Loss 0.13  Acc 85.65% | Val: Loss nan  Acc(top1) 95.34% | HA 95.34@539\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_539_20240502161346.pt\n",
      "1h58m Epoch: 540/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 1.0000000000000004e-06  Loss 0.13  Acc 88.78% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@540\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_540_20240502161359.pt\n",
      "1h59m Epoch: 541/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 1.0000000000000004e-06  Loss 0.14  Acc 88.21% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@541\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_541_20240502161412.pt\n",
      "1h59m Epoch: 542/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 1.0000000000000004e-06  Loss 0.13  Acc 85.94% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@542\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc94.91525268554688_epoch_542_20240502161426.pt\n",
      "1h59m Epoch: 543/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 1.0000000000000004e-06  Loss 0.13  Acc 84.94% | Val: Loss nan  Acc(top1) 94.92% | HA 94.92@543\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_543_20240502161439.pt\n",
      "1h59m Epoch: 544/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 1.0000000000000004e-06  Loss 0.13  Acc 88.64% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@544\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_544_20240502161452.pt\n",
      "1h59m Epoch: 545/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 1.0000000000000004e-06  Loss 0.13  Acc 86.22% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@545\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_545_20240502161506.pt\n",
      "2h00m Epoch: 546/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 1.0000000000000004e-06  Loss 0.12  Acc 88.49% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@546\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.33898162841797_epoch_546_20240502161519.pt\n",
      "2h00m Epoch: 547/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 1.0000000000000004e-06  Loss 0.12  Acc 85.65% | Val: Loss nan  Acc(top1) 95.34% | HA 95.34@547\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.33898162841797_epoch_547_20240502161532.pt\n",
      "2h00m Epoch: 548/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 1.0000000000000004e-06  Loss 0.13  Acc 88.35% | Val: Loss nan  Acc(top1) 95.34% | HA 95.34@548\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.33898162841797_epoch_548_20240502161545.pt\n",
      "2h00m Epoch: 549/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 1.0000000000000004e-06  Loss 0.14  Acc 84.80% | Val: Loss nan  Acc(top1) 95.34% | HA 95.34@549\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_549_20240502161559.pt\n",
      "2h01m Epoch: 550/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 1.0000000000000004e-06  Loss 0.12  Acc 87.22% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@550\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_550_20240502161612.pt\n",
      "2h01m Epoch: 551/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 1.0000000000000004e-06  Loss 0.13  Acc 87.50% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@551\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_551_20240502161626.pt\n",
      "2h01m Epoch: 552/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 1.0000000000000004e-06  Loss 0.12  Acc 90.34% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@552\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.33898162841797_epoch_552_20240502161639.pt\n",
      "2h01m Epoch: 553/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 1.0000000000000004e-06  Loss 0.13  Acc 86.79% | Val: Loss nan  Acc(top1) 95.34% | HA 95.34@553\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.33898162841797_epoch_553_20240502161652.pt\n",
      "2h01m Epoch: 554/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 1.0000000000000004e-06  Loss 0.14  Acc 86.36% | Val: Loss nan  Acc(top1) 95.34% | HA 95.34@554\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_554_20240502161706.pt\n",
      "2h02m Epoch: 555/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 1.0000000000000004e-06  Loss 0.14  Acc 85.37% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@555\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_555_20240502161719.pt\n",
      "2h02m Epoch: 556/600 | Time: 0m12s (Train 0m11s  Val 0m01s) | Train: LR 1.0000000000000004e-06  Loss 0.13  Acc 87.93% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@556\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_556_20240502161731.pt\n",
      "2h02m Epoch: 557/600 | Time: 0m12s (Train 0m11s  Val 0m01s) | Train: LR 1.0000000000000004e-06  Loss 0.14  Acc 86.79% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@557\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_557_20240502161745.pt\n",
      "2h02m Epoch: 558/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 1.0000000000000004e-06  Loss 0.13  Acc 88.64% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@558\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_558_20240502161758.pt\n",
      "2h02m Epoch: 559/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 1.0000000000000004e-06  Loss 0.13  Acc 87.07% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@559\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.33898162841797_epoch_559_20240502161811.pt\n",
      "2h03m Epoch: 560/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 1.0000000000000004e-06  Loss 0.14  Acc 86.36% | Val: Loss nan  Acc(top1) 95.34% | HA 95.34@560\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_560_20240502161824.pt\n",
      "2h03m Epoch: 561/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 1.0000000000000004e-06  Loss 0.13  Acc 84.66% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@561\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_561_20240502161838.pt\n",
      "2h03m Epoch: 562/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 1.0000000000000004e-06  Loss 0.14  Acc 85.80% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@562\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.33898162841797_epoch_562_20240502161851.pt\n",
      "2h03m Epoch: 563/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 1.0000000000000004e-06  Loss 0.13  Acc 90.20% | Val: Loss nan  Acc(top1) 95.34% | HA 95.34@563\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_563_20240502161904.pt\n",
      "2h04m Epoch: 564/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 1.0000000000000004e-06  Loss 0.14  Acc 85.94% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@564\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.33898162841797_epoch_564_20240502161917.pt\n",
      "2h04m Epoch: 565/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 1.0000000000000004e-06  Loss 0.14  Acc 85.51% | Val: Loss nan  Acc(top1) 95.34% | HA 95.34@565\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_565_20240502161931.pt\n",
      "2h04m Epoch: 566/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 1.0000000000000004e-06  Loss 0.13  Acc 87.93% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@566\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_566_20240502161944.pt\n",
      "2h04m Epoch: 567/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 1.0000000000000004e-06  Loss 0.13  Acc 87.36% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@567\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_567_20240502161958.pt\n",
      "2h04m Epoch: 568/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 1.0000000000000004e-06  Loss 0.14  Acc 87.64% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@568\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_568_20240502162011.pt\n",
      "2h05m Epoch: 569/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 1.0000000000000004e-06  Loss 0.15  Acc 85.37% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@569\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.33898162841797_epoch_569_20240502162024.pt\n",
      "2h05m Epoch: 570/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 1.0000000000000004e-06  Loss 0.14  Acc 87.78% | Val: Loss nan  Acc(top1) 95.34% | HA 95.34@570\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_570_20240502162038.pt\n",
      "2h05m Epoch: 571/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 1.0000000000000004e-06  Loss 0.13  Acc 85.23% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@571\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_571_20240502162051.pt\n",
      "2h05m Epoch: 572/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 1.0000000000000004e-06  Loss 0.14  Acc 86.36% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@572\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_572_20240502162104.pt\n",
      "2h06m Epoch: 573/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 1.0000000000000004e-06  Loss 0.13  Acc 87.93% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@573\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_573_20240502162118.pt\n",
      "2h06m Epoch: 574/600 | Time: 0m13s (Train 0m12s  Val 0m01s) | Train: LR 1.0000000000000004e-06  Loss 0.14  Acc 85.94% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@574\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_574_20240502162132.pt\n",
      "2h06m Epoch: 575/600 | Time: 0m14s (Train 0m12s  Val 0m01s) | Train: LR 1.0000000000000004e-06  Loss 0.13  Acc 88.78% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@575\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.33898162841797_epoch_575_20240502162146.pt\n",
      "2h06m Epoch: 576/600 | Time: 0m14s (Train 0m12s  Val 0m01s) | Train: LR 1.0000000000000004e-06  Loss 0.13  Acc 86.51% | Val: Loss nan  Acc(top1) 95.34% | HA 95.34@576\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_576_20240502162201.pt\n",
      "2h07m Epoch: 577/600 | Time: 0m14s (Train 0m12s  Val 0m01s) | Train: LR 1.0000000000000004e-06  Loss 0.13  Acc 85.65% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@577\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_577_20240502162215.pt\n",
      "2h07m Epoch: 578/600 | Time: 0m14s (Train 0m12s  Val 0m01s) | Train: LR 1.0000000000000004e-06  Loss 0.13  Acc 87.50% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@578\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_578_20240502162229.pt\n",
      "2h07m Epoch: 579/600 | Time: 0m13s (Train 0m12s  Val 0m01s) | Train: LR 1.0000000000000004e-06  Loss 0.13  Acc 84.94% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@579\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_579_20240502162243.pt\n",
      "2h07m Epoch: 580/600 | Time: 0m14s (Train 0m12s  Val 0m01s) | Train: LR 1.0000000000000004e-06  Loss 0.12  Acc 86.22% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@580\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_580_20240502162256.pt\n",
      "2h07m Epoch: 581/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 1.0000000000000004e-06  Loss 0.14  Acc 85.65% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@581\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_581_20240502162309.pt\n",
      "2h08m Epoch: 582/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 1.0000000000000004e-06  Loss 0.14  Acc 87.07% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@582\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_582_20240502162323.pt\n",
      "2h08m Epoch: 583/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 1.0000000000000004e-06  Loss 0.12  Acc 87.64% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@583\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_583_20240502162336.pt\n",
      "2h08m Epoch: 584/600 | Time: 0m13s (Train 0m12s  Val 0m01s) | Train: LR 1.0000000000000004e-06  Loss 0.14  Acc 88.64% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@584\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_584_20240502162350.pt\n",
      "2h08m Epoch: 585/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 1.0000000000000004e-06  Loss 0.14  Acc 87.36% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@585\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.33898162841797_epoch_585_20240502162403.pt\n",
      "2h09m Epoch: 586/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 1.0000000000000004e-06  Loss 0.14  Acc 84.38% | Val: Loss nan  Acc(top1) 95.34% | HA 95.34@586\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc94.91525268554688_epoch_586_20240502162416.pt\n",
      "2h09m Epoch: 587/600 | Time: 0m13s (Train 0m12s  Val 0m01s) | Train: LR 1.0000000000000004e-06  Loss 0.12  Acc 88.78% | Val: Loss nan  Acc(top1) 94.92% | HA 94.92@587\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc94.49152374267578_epoch_587_20240502162430.pt\n",
      "2h09m Epoch: 588/600 | Time: 0m13s (Train 0m12s  Val 0m01s) | Train: LR 1.0000000000000004e-06  Loss 0.13  Acc 85.09% | Val: Loss nan  Acc(top1) 94.49% | HA 94.49@588\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.33898162841797_epoch_588_20240502162444.pt\n",
      "2h09m Epoch: 589/600 | Time: 0m13s (Train 0m12s  Val 0m01s) | Train: LR 1.0000000000000004e-06  Loss 0.13  Acc 89.35% | Val: Loss nan  Acc(top1) 95.34% | HA 95.34@589\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_589_20240502162457.pt\n",
      "2h09m Epoch: 590/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 1.0000000000000004e-06  Loss 0.12  Acc 87.93% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@590\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_590_20240502162511.pt\n",
      "2h10m Epoch: 591/600 | Time: 0m13s (Train 0m12s  Val 0m01s) | Train: LR 1.0000000000000004e-06  Loss 0.13  Acc 87.50% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@591\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_591_20240502162524.pt\n",
      "2h10m Epoch: 592/600 | Time: 0m13s (Train 0m12s  Val 0m01s) | Train: LR 1.0000000000000004e-06  Loss 0.14  Acc 85.80% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@592\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.33898162841797_epoch_592_20240502162537.pt\n",
      "2h10m Epoch: 593/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 1.0000000000000004e-06  Loss 0.13  Acc 87.78% | Val: Loss nan  Acc(top1) 95.34% | HA 95.34@593\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_593_20240502162551.pt\n",
      "2h10m Epoch: 594/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 1.0000000000000004e-06  Loss 0.13  Acc 86.93% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@594\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.33898162841797_epoch_594_20240502162605.pt\n",
      "2h11m Epoch: 595/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 1.0000000000000004e-06  Loss 0.12  Acc 86.51% | Val: Loss nan  Acc(top1) 95.34% | HA 95.34@595\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.33898162841797_epoch_595_20240502162618.pt\n",
      "2h11m Epoch: 596/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 1.0000000000000004e-06  Loss 0.13  Acc 88.07% | Val: Loss nan  Acc(top1) 95.34% | HA 95.34@596\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.33898162841797_epoch_596_20240502162632.pt\n",
      "2h11m Epoch: 597/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 1.0000000000000004e-06  Loss 0.12  Acc 87.50% | Val: Loss nan  Acc(top1) 95.34% | HA 95.34@597\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.33898162841797_epoch_597_20240502162645.pt\n",
      "2h11m Epoch: 598/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 1.0000000000000004e-06  Loss 0.12  Acc 89.06% | Val: Loss nan  Acc(top1) 95.34% | HA 95.34@598\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_598_20240502162658.pt\n",
      "2h11m Epoch: 599/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 1.0000000000000004e-06  Loss 0.12  Acc 88.78% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@599\n",
      "save model to ../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050214_prunratio80.0/sp_ai_model_first_stage_prun_acc95.76271057128906_epoch_599_20240502162711.pt\n",
      "2h12m Epoch: 600/600 | Time: 0m13s (Train 0m11s  Val 0m01s) | Train: LR 1.0000000000000004e-06  Loss 0.13  Acc 89.20% | Val: Loss nan  Acc(top1) 95.76% | HA 95.76@600\n",
      "Execution finished in: 2h12m\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ae31fa-cf50-449c-88b3-fdca70c66228",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfee28e6-b711-4642-8ac9-7e506be8ad4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd5acd0-ef85-4301-aedb-5cc561681ec8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
