{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28b923ec-5857-4d0b-9909-1e0236ba4583",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys;\n",
    "import os;\n",
    "import torch;\n",
    "import numpy as np;\n",
    "import torch.optim as optim;\n",
    "import torch.nn as nn;\n",
    "from operator import itemgetter;\n",
    "from heapq import nsmallest;\n",
    "import time;\n",
    "import glob;\n",
    "import math;\n",
    "import random;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a88dd74-1ca3-4b31-b50b-84b82739d4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"../../../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f540e4f9-0b63-4f73-bca1-51557fb87033",
   "metadata": {},
   "outputs": [],
   "source": [
    "import common.utils as U;\n",
    "import common.opts as opt;\n",
    "import th.resources.models as models;\n",
    "import th.resources.calculator as calc;\n",
    "# import th.resources.train_generator as train_generator;\n",
    "from th.resources.pruning_tools import filter_pruning, filter_pruner;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7215cbb7-d9ce-4b64-9f81-8abc3fada11c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import common.tlopts as tlopts\n",
    "from refine_codes.SharedLibs.datestring import genDataTimeStr, getDateStr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f74b3364-cd68-464d-9426-3a4f85ad7c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reproducibility\n",
    "seed = 42;\n",
    "random.seed(seed);\n",
    "np.random.seed(seed);\n",
    "torch.manual_seed(seed);\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(seed);\n",
    "torch.backends.cudnn.deterministic = True;\n",
    "torch.backends.cudnn.benchmark = False;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "36995275-4419-4d02-a744-3d37ef85e23f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from datetime import datetime;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "69211f9d-1d78-4eae-8540-2d1b04cd13c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def genDataTimeStr():\n",
    "#     return datetime.today().strftime('%Y-%m-%d %H:%M:%S').replace('-',\"\").replace(' ',\"\").replace(':',\"\");a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6d34d33d-7683-4dd8-ab36-9b9b9d95be12",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TLGenerator():\n",
    "    #Generates data for Keras\n",
    "    def __init__(self, samples, labels, options):\n",
    "        random.seed(42);\n",
    "        #Initialization\n",
    "        print(f\"length of samples:{len(samples)}\")\n",
    "        self.data = [(samples[i], labels[i]) for i in range (0, len(samples))];\n",
    "        self.opt = options;\n",
    "        self.batch_size = options.batchSize;\n",
    "        self.preprocess_funcs = self.preprocess_setup();\n",
    "        self.mapdict = dict([('52',1),('56',2),('99',3)])\n",
    "\n",
    "    def __len__(self):\n",
    "        #Denotes the number of batches per epoch\n",
    "        return int(np.floor(len(self.data) / self.batch_size));\n",
    "        #return len(self.samples);\n",
    "\n",
    "    def __getitem__(self, batchIndex):\n",
    "        #Generate one batch of data\n",
    "        batchX, batchY = self.generate_batch(batchIndex);\n",
    "        batchX = np.expand_dims(batchX, axis=1);\n",
    "        batchX = np.expand_dims(batchX, axis=3);\n",
    "        return batchX, batchY\n",
    "\n",
    "    def generate_batch(self, batchIndex):\n",
    "        #Generates data containing batch_size samples\n",
    "        sounds = [];\n",
    "        labels = [];\n",
    "        indexes = None;\n",
    "        for i in range(self.batch_size):\n",
    "            # Training phase of BC learning\n",
    "            # Select two training examples\n",
    "            while True:\n",
    "                sound1, label1 = self.data[random.randint(0, len(self.data) - 1)]\n",
    "                sound2, label2 = self.data[random.randint(0, len(self.data) - 1)]\n",
    "                if label1 != label2:\n",
    "                    break\n",
    "            sound1 = self.preprocess(sound1)\n",
    "            sound2 = self.preprocess(sound2)\n",
    "\n",
    "            # Mix two examples\n",
    "            r = np.array(random.random())\n",
    "            sound = U.mix(sound1, sound2, r, self.opt.sr).astype(np.float32)\n",
    "            # print(f\"sound length after U.mix is {len(sound)}\")\n",
    "            eye = np.eye(self.opt.nClasses)\n",
    "            idx1 = self.mapdict[str(label1)]- 1\n",
    "            idx2 = self.mapdict[str(label2)] - 1\n",
    "            label = (eye[idx1] * r + eye[idx2] * (1 - r)).astype(np.float32)\n",
    "            # label = (eye[label1] * r + eye[label2] * (1 - r)).astype(np.float32)\n",
    "\n",
    "            #For stronger augmentation\n",
    "            sound = U.random_gain(6)(sound).astype(np.float32)\n",
    "            # print(f\"sound length after U.random_gain is {len(sound)}\")\n",
    "            sounds.append(sound);\n",
    "            labels.append(label);\n",
    "\n",
    "        sounds = np.asarray(sounds);\n",
    "        labels = np.asarray(labels);\n",
    "        # print(f\"labels in generate_batch is:\\n{labels}\")\n",
    "\n",
    "        return sounds, labels;\n",
    "\n",
    "    def preprocess_setup(self):\n",
    "        funcs = []\n",
    "        if self.opt.strongAugment:\n",
    "            funcs += [U.random_scale(1.25)]\n",
    "\n",
    "        funcs += [U.padding(self.opt.inputLength // 2),\n",
    "                  U.random_crop(self.opt.inputLength),\n",
    "                  U.normalize(32768.0)]\n",
    "        return funcs\n",
    "\n",
    "    def preprocess(self, sound):\n",
    "        for f in self.preprocess_funcs:\n",
    "            sound = f(sound)\n",
    "\n",
    "        return sound;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1b648ed6-051a-49d7-ad2a-b051c05e88eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTrainGen(opt=None, split=None):\n",
    "    # dataset = np.load(os.path.join(opt.data, opt.dataset, 'wav{}.npz'.format(opt.sr // 1000)), allow_pickle=True);\n",
    "    # dataset = np.load(\"../datasets/fold1_test16000.npz\", allow_pickle=True);\n",
    "    dataset = np.load(opt.trainSet, allow_pickle=True);\n",
    "    train_sounds = []\n",
    "    train_labels = []\n",
    "    # print(len(dataset['x']))\n",
    "    # for i in range(1, opt.nFolds + 1):\n",
    "\n",
    "    # train_sounds = [dataset['x'][i][0] for i in range(len(dataset['x']))]\n",
    "    # train_labels = [dataset['y'][i][0] for i in range(len(dataset['y']))]\n",
    "    train_sounds = dataset['fold{}'.format(1)].item()['sounds']\n",
    "    train_labels = dataset['fold{}'.format(1)].item()['labels']\n",
    "    # print(train_sounds)\n",
    "\n",
    "    trainGen = TLGenerator(train_sounds, train_labels, opt);\n",
    "    trainGen.preprocess_setup();\n",
    "    return trainGen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f6266cad-9de1-47c0-87dc-c8ade965a7b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getOpts():\n",
    "    parser = argparse.ArgumentParser(description='Transfer Learning for ACDNet');\n",
    "    parser.add_argument('--netType', default='TLACDNet',  required=False);\n",
    "    parser.add_argument('--data', default='./datasets/forOneClassModel_alarm/train_test_npz/',  required=False);\n",
    "    parser.add_argument('--dataset', required=False, default='uec_iot', choices=['10']);\n",
    "    parser.add_argument('--BC', default=True, action='store_true', help='BC learning');\n",
    "    parser.add_argument('--strongAugment', default=True,  action='store_true', help='Add scale and gain augmentation');\n",
    "    #在ipynb中，不能使用parser.parse，要改用parser.parse_known_args()\n",
    "    opt, unknown = parser.parse_known_args()\n",
    "    return opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "086db016-0acf-4029-9634-e79d30842ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Customed_ACDNetV2(nn.Module):\n",
    "    def __init__(self, input_length, n_class, sr, ch_conf=None):\n",
    "        super(Customed_ACDNetV2, self).__init__();\n",
    "        self.input_length = input_length;\n",
    "        self.ch_config = ch_conf;\n",
    "\n",
    "        stride1 = 2;\n",
    "        stride2 = 2;\n",
    "        channels = 8;\n",
    "        k_size = (3, 3);\n",
    "        n_frames = (sr/1000)*10; #No of frames per 10ms\n",
    "\n",
    "        sfeb_pool_size = int(n_frames/(stride1*stride2));\n",
    "        # tfeb_pool_size = (2,2);\n",
    "        if self.ch_config is None:\n",
    "            self.ch_config = [channels, channels*8, channels*4, channels*8, channels*8, channels*16, channels*16, channels*32, channels*32, channels*64, channels*64, n_class];\n",
    "        # avg_pool_kernel_size = (1,4) if self.ch_config[1] < 64 else (2,4);\n",
    "        fcn_no_of_inputs =  n_class #self.ch_config[-1];\n",
    "        ch_confing_10 = 512 #8 * 64\n",
    "        ch_n_class = n_class\n",
    "        conv1, bn1 = self.make_layers(1, self.ch_config[0], (1, 9), (1, stride1));\n",
    "        conv2, bn2 = self.make_layers(self.ch_config[0], self.ch_config[1], (1, 5), (1, stride2));\n",
    "        conv3, bn3 = self.make_layers(1, self.ch_config[2], k_size, padding=1);\n",
    "        conv4, bn4 = self.make_layers(self.ch_config[2], self.ch_config[3], k_size, padding=1);\n",
    "        conv5, bn5 = self.make_layers(self.ch_config[3], self.ch_config[4], k_size, padding=1);\n",
    "        conv6, bn6 = self.make_layers(self.ch_config[4], self.ch_config[5], k_size, padding=1);\n",
    "        conv7, bn7 = self.make_layers(self.ch_config[5], self.ch_config[6], k_size, padding=1);\n",
    "        conv8, bn8 = self.make_layers(self.ch_config[6], self.ch_config[7], k_size, padding=1);\n",
    "        conv9, bn9 = self.make_layers(self.ch_config[7], self.ch_config[8], k_size, padding=1);\n",
    "        conv10, bn10 = self.make_layers(self.ch_config[8], self.ch_config[9], k_size, padding=1);\n",
    "        conv11, bn11 = self.make_layers(self.ch_config[9], self.ch_config[10], k_size, padding=1);\n",
    "        conv12, bn12 = self.make_layers(ch_confing_10, ch_n_class, (1, 1));\n",
    "        fcn = nn.Linear(fcn_no_of_inputs, ch_n_class);\n",
    "        nn.init.kaiming_normal_(fcn.weight, nonlinearity='sigmoid') # kaiming with sigoid is equivalent to lecun_normal in keras\n",
    "\n",
    "        self.sfeb = nn.Sequential(\n",
    "            #Start: Filter bank\n",
    "            conv1, bn1, nn.ReLU(),\\\n",
    "            conv2, bn2, nn.ReLU(),\\\n",
    "            nn.MaxPool2d(kernel_size=(1, sfeb_pool_size))\n",
    "        );\n",
    "\n",
    "        tfeb_modules = [];\n",
    "        self.tfeb_width = int(((self.input_length / sr)*1000)/10); # 10ms frames of audio length in seconds\n",
    "        tfeb_pool_sizes = self.get_tfeb_pool_sizes(self.ch_config[1], self.tfeb_width);\n",
    "        p_index = 0;\n",
    "        for i in [3,4,6,8,10]:\n",
    "            tfeb_modules.extend([eval('conv{}'.format(i)), eval('bn{}'.format(i)), nn.ReLU()]);\n",
    "\n",
    "            if i != 3:\n",
    "                tfeb_modules.extend([eval('conv{}'.format(i+1)), eval('bn{}'.format(i+1)), nn.ReLU()]);\n",
    "\n",
    "            h, w = tfeb_pool_sizes[p_index];\n",
    "            if h>1 or w>1:\n",
    "                tfeb_modules.append(nn.MaxPool2d(kernel_size = (h,w)));\n",
    "            p_index += 1;\n",
    "\n",
    "        tfeb_modules.append(nn.Dropout(0.2));\n",
    "        tfeb_modules.extend([conv12, bn12, nn.ReLU()]);\n",
    "        h, w = tfeb_pool_sizes[-1];\n",
    "        if h>1 or w>1:\n",
    "            tfeb_modules.append(nn.AvgPool2d(kernel_size = (2,4)));\n",
    "        tfeb_modules.extend([nn.Flatten(), fcn]);\n",
    "\n",
    "        self.tfeb = nn.Sequential(*tfeb_modules);\n",
    "\n",
    "        self.output = nn.Sequential(\n",
    "            nn.Softmax(dim=1)\n",
    "        );\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.sfeb(x);\n",
    "        #swapaxes\n",
    "        x = x.permute((0, 2, 1, 3));\n",
    "        x = self.tfeb(x);\n",
    "        y = self.output[0](x);\n",
    "        return y;\n",
    "\n",
    "    def make_layers(self, in_channels, out_channels, kernel_size, stride=(1,1), padding=0, bias=False):\n",
    "        conv = nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, stride=stride, padding=padding, bias=bias);\n",
    "        nn.init.kaiming_normal_(conv.weight, nonlinearity='relu'); # kaiming with relu is equivalent to he_normal in keras\n",
    "        bn = nn.BatchNorm2d(out_channels);\n",
    "        return conv, bn;\n",
    "\n",
    "    def get_tfeb_pool_sizes(self, con2_ch, width):\n",
    "        h = self.get_tfeb_pool_size_component(con2_ch);\n",
    "        w = self.get_tfeb_pool_size_component(width);\n",
    "        # print(w);\n",
    "        pool_size = [];\n",
    "        for  (h1, w1) in zip(h, w):\n",
    "            pool_size.append((h1, w1));\n",
    "        return pool_size;\n",
    "\n",
    "    def get_tfeb_pool_size_component(self, length):\n",
    "        # print(length);\n",
    "        c = [];\n",
    "        index = 1;\n",
    "        while index <= 6:\n",
    "            if length >= 2:\n",
    "                if index == 6:\n",
    "                    c.append(length);\n",
    "                else:\n",
    "                    c.append(2);\n",
    "                    length = length // 2;\n",
    "            else:\n",
    "               c.append(1);\n",
    "\n",
    "            index += 1;\n",
    "\n",
    "        return c;\n",
    "\n",
    "def GetCustomedACDNetModel(input_len=30225, nclass=3, sr=20000, channel_config=None):\n",
    "    net = Customed_ACDNetV2(input_len, nclass, sr, ch_conf=channel_config);\n",
    "    return net;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "56cae6f7-e8e2-438f-a003-f4b111ccae0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PruningTrainer:\n",
    "    def __init__(self, opt):\n",
    "        self.opt = opt;\n",
    "        self.opt.channels_to_prune_per_iteration = 1;\n",
    "        self.opt.finetune_epoch_per_iteration = 2;\n",
    "        self.opt.lr=0.001;\n",
    "        self.opt.schedule = [0.5, 0.8];\n",
    "        self.opt.prune_type = 2 #determine the prunning algo, 1: Magnitude Pruning ;2: tylor-pruning\n",
    "        # torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\"); #in office use \n",
    "        self.opt.device = 'cuda:0'#at home use apple m2\n",
    "        self.pruner = None;\n",
    "        self.iterations = 0;\n",
    "        self.cur_acc = 0.0;\n",
    "        self.cur_iter = 1;\n",
    "        self.cur_lr = self.opt.lr;\n",
    "        self.net = None;\n",
    "        self.criterion = torch.nn.KLDivLoss(reduction='batchmean');\n",
    "        self.trainGen = getTrainGen(opt)#train_generator.setup(self.opt, self.opt.split);\n",
    "        self.testX = None;\n",
    "        self.testY = None;\n",
    "        self.load_test_data();\n",
    "\n",
    "    def PruneAndTrain(self):\n",
    "        dir = os.getcwd();\n",
    "        self.net = GetCustomedACDNetModel();\n",
    "        trained_model = \"../../trained_models/step_2_first_stage_pruning/pruning_time_2024041717_prunratio80.0/sp_ai_model_first_stage_prun_acc96.16725158691406_epoch_86_20240417172818.pt\"\n",
    "        self.net.load_state_dict(torch.load(trained_model, map_location=\"cuda:0\")['weight']);\n",
    "        self.net = self.net.to('cuda:0');#at home use apple m2\n",
    "        self.pruner = filter_pruning.Magnitude(self.net, self.opt) if self.opt.prune_type == 1 else filter_pruning.Taylor(self.net, self.opt);\n",
    "        print(f\"pruning algorithm is {self.pruner}\");\n",
    "        self.validate();\n",
    "        calc.summary(self.net, (1, 1, self.opt.inputLength), brief=False); # shape of one sample for inferenceing\n",
    "        # exit();\n",
    "        #Make sure all the layers are trainable\n",
    "        for param in self.net.parameters():\n",
    "            param.requires_grad = True\n",
    "        self.iterations = self.estimate_pruning_iterations();\n",
    "        # exit();\n",
    "        for i in range(1, self.iterations):\n",
    "            self.cur_iter = i;\n",
    "            iter_start = time.time();\n",
    "            print(\"\\nIteration {} of {} starts..\".format(i, self.iterations-1), flush=True);\n",
    "            print(\"Ranking channels.. \", flush=True);\n",
    "            prune_targets = self.get_candidates_to_prune(self.opt.channels_to_prune_per_iteration);\n",
    "            # prune_targets = [(40,3)];\n",
    "            print(\"Pruning channels: {}\".format(prune_targets), flush=True);\n",
    "            self.net = filter_pruner.prune_layers(self.net, prune_targets, self.opt.prune_all, self.opt.device);\n",
    "            calc.summary(self.net, (1, 1, self.opt.inputLength), brief=True); # shape of one sample for inferenceing\n",
    "            self.validate();\n",
    "            print(\"Fine tuning {} epochs to recover from prunning iteration.\".format(self.opt.finetune_epoch_per_iteration), flush=True);\n",
    "\n",
    "            if self.cur_iter in list(map(int, np.array(self.iterations)*self.opt.schedule)):\n",
    "                self.cur_lr *= 0.1;\n",
    "            optimizer = optim.SGD(self.net.parameters(), lr=self.cur_lr, momentum=0.9);\n",
    "            self.train(optimizer, epoches = self.opt.finetune_epoch_per_iteration);\n",
    "            print(\"Iteration {}/{} finished in {}\".format(self.cur_iter, self.iterations+1, U.to_hms(time.time()-iter_start)), flush=True);\n",
    "            print(\"Total channels prunned so far: {}\".format(i*self.opt.channels_to_prune_per_iteration), flush=True);\n",
    "            self.__save_model(self.net);\n",
    "\n",
    "        calc.summary(self.net, (1, 1, self.opt.inputLength)); # shape of one sample for inferenceing\n",
    "        self.__save_model(self.net);\n",
    "\n",
    "    def get_candidates_to_prune(self, num_filters_to_prune):\n",
    "        self.pruner.reset();\n",
    "        if self.opt.prune_type == 1:\n",
    "            self.pruner.compute_filter_magnitude();\n",
    "        else:\n",
    "            self.train_epoch(rank_filters = True);\n",
    "            self.pruner.normalize_ranks_per_layer();\n",
    "\n",
    "        return self.pruner.get_prunning_plan(num_filters_to_prune);\n",
    "\n",
    "    def estimate_pruning_iterations(self):\n",
    "        # get total number of variables from all conv2d featuremaps\n",
    "        prunable_count = sum(self.get_channel_list(self.opt.prune_all));\n",
    "        total_count= sum(self.get_channel_list());\n",
    "        #iterations_reqired = int((prunable_count * self.opt.prune_ratio) / self.opt.channels_to_prune_per_iteration);\n",
    "        #prune_ratio works with the total number of channels, not only with the prunable channels. i.e. 80% or total will be pruned from total or from only features\n",
    "        iterations_reqired = int((total_count * self.opt.prune_ratio) / self.opt.channels_to_prune_per_iteration);\n",
    "        print('Total Channels: {}, Prunable: {}, Non-Prunable: {}'.format(total_count, prunable_count, total_count - prunable_count), flush=True);\n",
    "        print('No. of Channels to prune per iteration: {}'.format(self.opt.channels_to_prune_per_iteration), flush=True);\n",
    "        print('Total Channels to prune ({}%): {}'.format(int(self.opt.prune_ratio*100), int(total_count * self.opt.prune_ratio)-1), flush=True);\n",
    "        print('Total iterations required: {}'.format(iterations_reqired-1), flush=True);\n",
    "        return iterations_reqired;\n",
    "\n",
    "    def get_channel_list(self, prune_all=True):\n",
    "        ch_conf = [];\n",
    "        if prune_all:\n",
    "            for name, module in enumerate(self.net.sfeb):\n",
    "                if issubclass(type(module), torch.nn.Conv2d):\n",
    "                    ch_conf.append(module.out_channels);\n",
    "\n",
    "        for name, module in enumerate(self.net.tfeb):\n",
    "            if issubclass(type(module), torch.nn.Conv2d):\n",
    "                ch_conf.append(module.out_channels);\n",
    "\n",
    "        return ch_conf;\n",
    "\n",
    "    def load_test_data(self):\n",
    "        if(self.testX is None):\n",
    "            data = np.load(self.opt.valSet, allow_pickle=True);\n",
    "            dataX = np.moveaxis(data['x'], 3, 1).astype(np.float32);\n",
    "            # self.testX = torch.tensor(dataX).cuda();\n",
    "            # self.testY = torch.tensor(data['y']).cuda();\n",
    "            self.testX = torch.tensor(dataX).to(self.opt.device);\n",
    "            # self.testY = torch.tensor(data['y']).to(self.opt.device);#in office, use cuda(better) or cpu\n",
    "            self.testY = torch.FloatTensor(data['y']).to(self.opt.device);#at home use apple m2\n",
    "\n",
    "    #Calculating average prediction (10 crops) and final accuracy\n",
    "    def compute_accuracy(self, y_pred, y_target):\n",
    "        with torch.no_grad():\n",
    "            #Reshape to shape theme like each sample comtains 10 samples, calculate mean and find the indices that has highest average value for each sample\n",
    "            y_pred = (y_pred.reshape(y_pred.shape[0]//self.opt.nCrops, self.opt.nCrops, y_pred.shape[1])).mean(dim=1).argmax(dim=1);\n",
    "            y_target = (y_target.reshape(y_target.shape[0]//self.opt.nCrops, self.opt.nCrops, y_target.shape[1])).mean(dim=1).argmax(dim=1);\n",
    "            # if self.opt.device == \"mps\":\n",
    "            #     y_target = y_target.cpu() #use apple m2, in office use cuda\n",
    "            acc = (((y_pred==y_target)*1).float().mean()*100).item();\n",
    "            # valLossFunc = torch.nn.KLDivLoss();\n",
    "            loss = self.criterion(y_pred.float().log(), y_target.float()).item();\n",
    "            # loss = 0.0;\n",
    "        return acc, loss;\n",
    "\n",
    "    def train(self, optimizer = None, epoches=10):\n",
    "        for i in range(epoches):\n",
    "            # print(\"Epoch: \", i);\n",
    "            self.train_epoch(optimizer);\n",
    "            self.validate();\n",
    "        print(\"Finished fine tuning.\", flush=True);\n",
    "\n",
    "    def train_batch(self, optimizer, batch, label, rank_filters):\n",
    "        self.net.zero_grad()\n",
    "        if rank_filters:\n",
    "            output = self.pruner.forward(batch);\n",
    "            if self.opt.device == \"mps\":\n",
    "                label = label.cpu() #use apple m2, in office use cuda\n",
    "                output = output.cpu() #use apple m2, in office use cuda\n",
    "            self.criterion(output.log(), label).backward();\n",
    "        else:\n",
    "            self.criterion(self.net(batch), label).backward();\n",
    "            optimizer.step();\n",
    "\n",
    "    def train_epoch(self, optimizer = None, rank_filters = False):\n",
    "        if rank_filters is False and optimizer is None:\n",
    "            print('Please provide optimizer to train_epoch', flush=True);\n",
    "            exit();\n",
    "        n_batches = math.ceil(len(self.trainGen.data)/self.opt.batchSize);\n",
    "        for b_idx in range(n_batches):\n",
    "            x,y = self.trainGen.__getitem__(b_idx)\n",
    "            x = torch.tensor(np.moveaxis(x, 3, 1)).to(self.opt.device);\n",
    "            y = torch.tensor(y).to(self.opt.device);\n",
    "            self.train_batch(optimizer, x, y, rank_filters);\n",
    "\n",
    "    def validate(self):\n",
    "        self.net.eval();\n",
    "        with torch.no_grad():\n",
    "            y_pred = None;\n",
    "            batch_size = (self.opt.batchSize//self.opt.nCrops)*self.opt.nCrops;\n",
    "            for idx in range(math.ceil(len(self.testX)/batch_size)):\n",
    "                x = self.testX[idx*batch_size : (idx+1)*batch_size];\n",
    "                # if self.opt.device == \"mps\":\n",
    "                #     x = torch.tensor(x)\n",
    "                #     x = x.type(torch.FloatTensor) # use apple mp2\n",
    "                scores = self.net(x);\n",
    "                y_pred = scores.data if y_pred is None else torch.cat((y_pred, scores.data));\n",
    "\n",
    "            acc, loss = self.compute_accuracy(y_pred, self.testY);\n",
    "        print('Current Testing Performance - Val: Loss {:.3f}  Acc(top1) {:.3f}%'.format(loss, acc), flush=True);\n",
    "        self.cur_acc = acc;\n",
    "        self.net.train();\n",
    "        return acc, loss;\n",
    "\n",
    "    def __save_model(self, net):\n",
    "        net.ch_config = self.get_channel_list();\n",
    "        dir = os.getcwd();\n",
    "        fname = self.opt.model_name;\n",
    "        if os.path.isfile(fname):\n",
    "            os.remove(fname);\n",
    "        torch.save({'weight':net.state_dict(), 'config':net.ch_config}, fname);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d935fefb-1073-4894-aae9-9317b88dfd83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"save and record the training hyperparameters and results\\npruning algo: tylor-pruning\\npruning ration : 0.85\\nfinal accuracy : \\nepoch: \\nself.opt.LR = 0.01;\\nopt.momentum = 0.009;\\nself.opt.schedule = [0.15, 0.30, 0.45, 0.60, 0.75];\\nself.opt.warmup = 0;\\nself.opt.prune_algo = 'tylor-pruning';\\nself.opt.prune_interval = 1;\\nself.opt.nEpochs = 1000;\\n\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"save and record the training hyperparameters and results\n",
    "pruning algo: tylor-pruning\n",
    "pruning ration : 0.85\n",
    "final accuracy : \n",
    "epoch: \n",
    "self.opt.LR = 0.01;\n",
    "opt.momentum = 0.009;\n",
    "self.opt.schedule = [0.15, 0.30, 0.45, 0.60, 0.75];\n",
    "self.opt.warmup = 0;\n",
    "self.opt.prune_algo = 'tylor-pruning';\n",
    "self.opt.prune_interval = 1;\n",
    "self.opt.nEpochs = 1000;\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3888935-7f32-4d8e-bdc3-48761aa4e13c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b05ced26-21b7-4292-b531-276490ea99e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    opt = getOpts()\n",
    "    #Learning settings\n",
    "    opt.batchSize = 32;\n",
    "    # opt.LR = 0.01;\n",
    "    # opt.momentum = 0.09;\n",
    "    # opt.weightDecay = 5e-3;\n",
    "    # opt.nEpochs = 1000;#2000;\n",
    "    # opt.schedule = [0.03, 0.06, 0.09]\n",
    "    # opt.warmup = 10;\n",
    "    #set train and validation sets\n",
    "    opt.trainSet = \"../../../datasets/CurrentUse/generated_datasets/train/single_fold_train_20240416111733.npz\"\n",
    "    opt.valSet = \"../../../datasets/CurrentUse/generated_datasets/validation/final_single_val_20240416135817.npz\"\n",
    "    #Basic Net Settings\n",
    "    opt.prune_ratio = 0.85\n",
    "    opt.prune_all = True;\n",
    "    opt.nClasses = 3\n",
    "    opt.nFolds = 1;\n",
    "    opt.split = [i for i in range(1, opt.nFolds + 1)];\n",
    "    opt.inputLength = 30225;\n",
    "    #Test data\n",
    "    opt.nCrops = 2;\n",
    "    opt.sr = 20000;\n",
    "    opt.inputLength = 30225;\n",
    "    opt.trainer = None\n",
    "    \n",
    "    # import torch;\n",
    "    # opt.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\"); #in office use cuda or cpu\n",
    "    opt.device = 'cuda:0' #at home use apple m2\n",
    "    # tlopts.display_info(opt)\n",
    "    save_dir = \"../../trained_models/step_4_second_stage_pruning/pruning_time_{}_prunratio{}/\".format(getDateStr(),opt.prune_ratio*100)\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.mkdir(save_dir)\n",
    "    model_name = \"model_second_stage_prun_{}.pt\".format(genDataTimeStr());\n",
    "    opt.model_name = save_dir + model_name;\n",
    "    # valid_path = False;\n",
    "    print(\"Initializing PruneAndTrain Object.....\")\n",
    "    trainer = PruningTrainer(opt=opt)#TLTrainer(opt)\n",
    "    print(\"Start to pruning.....\")\n",
    "    trainer.PruneAndTrain();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c17937-4b7a-49f2-bb4c-cf323d891beb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing PruneAndTrain Object.....\n",
      "length of samples:727\n",
      "Start to pruning.....\n",
      "pruning algorithm is <th.resources.pruning_tools.filter_pruning.Taylor object at 0x7f3261978400>\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.167%\n",
      "+----------------------------------------------------------------------------+\n",
      "+                           Pytorch Model Summary                            +\n",
      "------------------------------------------------------------------------------\n",
      "   Layer (type)       Input Shape      Output Shape    Param #      FLOPS #\n",
      "==============================================================================\n",
      "       Conv2d-1     (1, 1, 30225)     (8, 1, 15109)         72    1,087,848\n",
      "  BatchNorm2d-2     (8, 1, 15109)     (8, 1, 15109)         16            0\n",
      "         ReLu-3     (8, 1, 15109)     (8, 1, 15109)          0      120,872\n",
      "       Conv2d-4     (8, 1, 15109)     (64, 1, 7553)      2,560   19,335,680\n",
      "  BatchNorm2d-5     (64, 1, 7553)     (64, 1, 7553)        128            0\n",
      "         ReLu-6     (64, 1, 7553)     (64, 1, 7553)          0      483,392\n",
      "    MaxPool2d-7     (64, 1, 7553)      (64, 1, 151)          0      483,200\n",
      "      Permute-8      (64, 1, 151)      (1, 64, 151)          0            0\n",
      "       Conv2d-9      (1, 64, 151)     (32, 64, 151)        288    2,783,232\n",
      " BatchNorm2d-10     (32, 64, 151)     (32, 64, 151)         64            0\n",
      "        ReLu-11     (32, 64, 151)     (32, 64, 151)          0      309,248\n",
      "   MaxPool2d-12     (32, 64, 151)      (32, 32, 75)          0      307,200\n",
      "      Conv2d-13      (32, 32, 75)      (64, 32, 75)     18,432   44,236,800\n",
      " BatchNorm2d-14      (64, 32, 75)      (64, 32, 75)        128            0\n",
      "        ReLu-15      (64, 32, 75)      (64, 32, 75)          0      153,600\n",
      "      Conv2d-16      (64, 32, 75)      (64, 32, 75)     36,864   88,473,600\n",
      " BatchNorm2d-17      (64, 32, 75)      (64, 32, 75)        128            0\n",
      "        ReLu-18      (64, 32, 75)      (64, 32, 75)          0      153,600\n",
      "   MaxPool2d-19      (64, 32, 75)      (64, 16, 37)          0      151,552\n",
      "      Conv2d-20      (64, 16, 37)     (128, 16, 37)     73,728   43,646,976\n",
      " BatchNorm2d-21     (128, 16, 37)     (128, 16, 37)        256            0\n",
      "        ReLu-22     (128, 16, 37)     (128, 16, 37)          0       75,776\n",
      "      Conv2d-23     (128, 16, 37)     (128, 16, 37)    147,456   87,293,952\n",
      " BatchNorm2d-24     (128, 16, 37)     (128, 16, 37)        256            0\n",
      "        ReLu-25     (128, 16, 37)     (128, 16, 37)          0       75,776\n",
      "   MaxPool2d-26     (128, 16, 37)      (128, 8, 18)          0       73,728\n",
      "      Conv2d-27      (128, 8, 18)      (256, 8, 18)    294,912   42,467,328\n",
      " BatchNorm2d-28      (256, 8, 18)      (256, 8, 18)        512            0\n",
      "        ReLu-29      (256, 8, 18)      (256, 8, 18)          0       36,864\n",
      "      Conv2d-30      (256, 8, 18)      (256, 8, 18)    589,824   84,934,656\n",
      " BatchNorm2d-31      (256, 8, 18)      (256, 8, 18)        512            0\n",
      "        ReLu-32      (256, 8, 18)      (256, 8, 18)          0       36,864\n",
      "   MaxPool2d-33      (256, 8, 18)       (256, 4, 9)          0       36,864\n",
      "      Conv2d-34       (256, 4, 9)       (512, 4, 9)  1,179,648   42,467,328\n",
      " BatchNorm2d-35       (512, 4, 9)       (512, 4, 9)      1,024            0\n",
      "        ReLu-36       (512, 4, 9)       (512, 4, 9)          0       18,432\n",
      "      Conv2d-37       (512, 4, 9)       (512, 4, 9)  2,359,296   84,934,656\n",
      " BatchNorm2d-38       (512, 4, 9)       (512, 4, 9)      1,024            0\n",
      "        ReLu-39       (512, 4, 9)       (512, 4, 9)          0       18,432\n",
      "   MaxPool2d-40       (512, 4, 9)       (512, 2, 4)          0       16,384\n",
      "      Conv2d-41       (512, 2, 4)         (3, 2, 4)      1,536       12,288\n",
      " BatchNorm2d-42         (3, 2, 4)         (3, 2, 4)          6            0\n",
      "        ReLu-43         (3, 2, 4)         (3, 2, 4)          0           24\n",
      "   AvgPool2d-44         (3, 2, 4)         (3, 1, 1)          0           24\n",
      "     Flatten-45         (3, 1, 1)            (1, 3)          0            0\n",
      "      Linear-46            (1, 3)            (1, 3)         12           12\n",
      "     Softmax-47            (1, 3)            (1, 3)          0            3\n",
      "==============================================================================\n",
      "Total Params: 4,708,682\n",
      "Total FLOPs : 544,226,191\n",
      "------------------------------------------------------------------------------\n",
      "Input size (MB) : 0.12\n",
      "Params size (MB): 17.96\n",
      "Total size (MB) : 18.08\n",
      "------------------------------------------------------------------------------\n",
      "\n",
      "Total Channels: 2027, Prunable: 2027, Non-Prunable: 0\n",
      "No. of Channels to prune per iteration: 1\n",
      "Total Channels to prune (85%): 1721\n",
      "Total iterations required: 1721\n",
      "\n",
      "Iteration 1 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(3, 6)]\n",
      "Input: 0.115 MB, Params: 4,708,640 (17.962 MB), Total: 18.08 MB, FLOPs: 483,664,528\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.063%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ai/miniconda3/envs/acdnetenv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Finished fine tuning.\n",
      "Iteration 1/1723 finished in 0m17s\n",
      "Total channels prunned so far: 1\n",
      "\n",
      "Iteration 2 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(3, 8)]\n",
      "Input: 0.115 MB, Params: 4,708,598 (17.962 MB), Total: 18.08 MB, FLOPs: 483,298,985\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.153%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Finished fine tuning.\n",
      "Iteration 2/1723 finished in 0m16s\n",
      "Total channels prunned so far: 2\n",
      "\n",
      "Iteration 3 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(3, 13)]\n",
      "Input: 0.115 MB, Params: 4,708,556 (17.962 MB), Total: 18.08 MB, FLOPs: 478,767,042\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.638%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Finished fine tuning.\n",
      "Iteration 3/1723 finished in 0m17s\n",
      "Total channels prunned so far: 3\n",
      "\n",
      "Iteration 4 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(3, 16)]\n",
      "Input: 0.115 MB, Params: 4,708,514 (17.962 MB), Total: 18.08 MB, FLOPs: 478,401,499\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.153%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.941%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.592%\n",
      "Finished fine tuning.\n",
      "Iteration 4/1723 finished in 0m16s\n",
      "Total channels prunned so far: 4\n",
      "\n",
      "Iteration 5 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(3, 16)]\n",
      "Input: 0.115 MB, Params: 4,708,472 (17.961 MB), Total: 18.08 MB, FLOPs: 465,666,804\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.592%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Finished fine tuning.\n",
      "Iteration 5/1723 finished in 0m16s\n",
      "Total channels prunned so far: 5\n",
      "\n",
      "Iteration 6 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(3, 21)]\n",
      "Input: 0.115 MB, Params: 4,708,430 (17.961 MB), Total: 18.08 MB, FLOPs: 465,301,261\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.547%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Finished fine tuning.\n",
      "Iteration 6/1723 finished in 0m16s\n",
      "Total channels prunned so far: 6\n",
      "\n",
      "Iteration 7 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(3, 28)]\n",
      "Input: 0.115 MB, Params: 4,708,388 (17.961 MB), Total: 18.08 MB, FLOPs: 460,769,318\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Finished fine tuning.\n",
      "Iteration 7/1723 finished in 0m17s\n",
      "Total channels prunned so far: 7\n",
      "\n",
      "Iteration 8 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(3, 28)]\n",
      "Input: 0.115 MB, Params: 4,708,346 (17.961 MB), Total: 18.08 MB, FLOPs: 460,403,775\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.289%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Finished fine tuning.\n",
      "Iteration 8/1723 finished in 0m17s\n",
      "Total channels prunned so far: 8\n",
      "\n",
      "Iteration 9 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(3, 29)]\n",
      "Input: 0.115 MB, Params: 4,708,304 (17.961 MB), Total: 18.08 MB, FLOPs: 431,725,400\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.289%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Finished fine tuning.\n",
      "Iteration 9/1723 finished in 0m17s\n",
      "Total channels prunned so far: 9\n",
      "\n",
      "Iteration 10 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(3, 40)]\n",
      "Input: 0.115 MB, Params: 4,708,262 (17.961 MB), Total: 18.08 MB, FLOPs: 431,359,857\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Finished fine tuning.\n",
      "Iteration 10/1723 finished in 0m17s\n",
      "Total channels prunned so far: 10\n",
      "\n",
      "Iteration 11 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(3, 46)]\n",
      "Input: 0.115 MB, Params: 4,708,220 (17.960 MB), Total: 18.08 MB, FLOPs: 426,827,914\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Finished fine tuning.\n",
      "Iteration 11/1723 finished in 0m16s\n",
      "Total channels prunned so far: 11\n",
      "\n",
      "Iteration 12 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(7, 26)]\n",
      "Input: 0.115 MB, Params: 4,707,633 (17.958 MB), Total: 18.07 MB, FLOPs: 425,616,884\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Finished fine tuning.\n",
      "Iteration 12/1723 finished in 0m16s\n",
      "Total channels prunned so far: 12\n",
      "\n",
      "Iteration 13 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 34)]\n",
      "Input: 0.115 MB, Params: 4,700,719 (17.932 MB), Total: 18.05 MB, FLOPs: 425,243,420\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Finished fine tuning.\n",
      "Iteration 13/1723 finished in 0m16s\n",
      "Total channels prunned so far: 13\n",
      "\n",
      "Iteration 14 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 118)]\n",
      "Input: 0.115 MB, Params: 4,696,106 (17.914 MB), Total: 18.03 MB, FLOPs: 425,118,949\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Finished fine tuning.\n",
      "Iteration 14/1723 finished in 0m16s\n",
      "Total channels prunned so far: 14\n",
      "\n",
      "Iteration 15 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 259)]\n",
      "Input: 0.115 MB, Params: 4,691,493 (17.897 MB), Total: 18.01 MB, FLOPs: 424,994,478\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Finished fine tuning.\n",
      "Iteration 15/1723 finished in 0m16s\n",
      "Total channels prunned so far: 15\n",
      "\n",
      "Iteration 16 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 280)]\n",
      "Input: 0.115 MB, Params: 4,686,880 (17.879 MB), Total: 17.99 MB, FLOPs: 424,870,007\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Finished fine tuning.\n",
      "Iteration 16/1723 finished in 0m16s\n",
      "Total channels prunned so far: 16\n",
      "\n",
      "Iteration 17 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 439)]\n",
      "Input: 0.115 MB, Params: 4,682,267 (17.861 MB), Total: 17.98 MB, FLOPs: 424,745,536\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Finished fine tuning.\n",
      "Iteration 17/1723 finished in 0m16s\n",
      "Total channels prunned so far: 17\n",
      "\n",
      "Iteration 18 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(3, 47)]\n",
      "Input: 0.115 MB, Params: 4,682,225 (17.861 MB), Total: 17.98 MB, FLOPs: 424,381,503\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Finished fine tuning.\n",
      "Iteration 18/1723 finished in 0m16s\n",
      "Total channels prunned so far: 18\n",
      "\n",
      "Iteration 19 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 43)]\n",
      "Input: 0.115 MB, Params: 4,675,356 (17.835 MB), Total: 17.95 MB, FLOPs: 424,196,067\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Finished fine tuning.\n",
      "Iteration 19/1723 finished in 0m16s\n",
      "Total channels prunned so far: 19\n",
      "\n",
      "Iteration 20 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 325)]\n",
      "Input: 0.115 MB, Params: 4,668,487 (17.809 MB), Total: 17.92 MB, FLOPs: 424,010,631\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Finished fine tuning.\n",
      "Iteration 20/1723 finished in 0m16s\n",
      "Total channels prunned so far: 20\n",
      "\n",
      "Iteration 21 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 433)]\n",
      "Input: 0.115 MB, Params: 4,663,892 (17.791 MB), Total: 17.91 MB, FLOPs: 423,886,646\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Finished fine tuning.\n",
      "Iteration 21/1723 finished in 0m16s\n",
      "Total channels prunned so far: 21\n",
      "\n",
      "Iteration 22 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 441)]\n",
      "Input: 0.115 MB, Params: 4,657,032 (17.765 MB), Total: 17.88 MB, FLOPs: 423,701,453\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Finished fine tuning.\n",
      "Iteration 22/1723 finished in 0m16s\n",
      "Total channels prunned so far: 22\n",
      "\n",
      "Iteration 23 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 279)]\n",
      "Input: 0.115 MB, Params: 4,652,446 (17.748 MB), Total: 17.86 MB, FLOPs: 423,577,711\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Finished fine tuning.\n",
      "Iteration 23/1723 finished in 0m16s\n",
      "Total channels prunned so far: 23\n",
      "\n",
      "Iteration 24 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 425)]\n",
      "Input: 0.115 MB, Params: 4,647,860 (17.730 MB), Total: 17.85 MB, FLOPs: 423,453,969\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.289%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Finished fine tuning.\n",
      "Iteration 24/1723 finished in 0m16s\n",
      "Total channels prunned so far: 24\n",
      "\n",
      "Iteration 25 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 142)]\n",
      "Input: 0.115 MB, Params: 4,641,018 (17.704 MB), Total: 17.82 MB, FLOPs: 423,269,262\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Finished fine tuning.\n",
      "Iteration 25/1723 finished in 0m16s\n",
      "Total channels prunned so far: 25\n",
      "\n",
      "Iteration 26 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 66)]\n",
      "Input: 0.115 MB, Params: 4,636,441 (17.687 MB), Total: 17.80 MB, FLOPs: 423,145,763\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Finished fine tuning.\n",
      "Iteration 26/1723 finished in 0m16s\n",
      "Total channels prunned so far: 26\n",
      "\n",
      "Iteration 27 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 370)]\n",
      "Input: 0.115 MB, Params: 4,631,864 (17.669 MB), Total: 17.78 MB, FLOPs: 423,022,264\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.774%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Finished fine tuning.\n",
      "Iteration 27/1723 finished in 0m16s\n",
      "Total channels prunned so far: 27\n",
      "\n",
      "Iteration 28 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 504)]\n",
      "Input: 0.115 MB, Params: 4,625,040 (17.643 MB), Total: 17.76 MB, FLOPs: 422,838,043\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Finished fine tuning.\n",
      "Iteration 28/1723 finished in 0m16s\n",
      "Total channels prunned so far: 28\n",
      "\n",
      "Iteration 29 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 506)]\n",
      "Input: 0.115 MB, Params: 4,618,216 (17.617 MB), Total: 17.73 MB, FLOPs: 422,653,822\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Finished fine tuning.\n",
      "Iteration 29/1723 finished in 0m16s\n",
      "Total channels prunned so far: 29\n",
      "\n",
      "Iteration 30 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 174)]\n",
      "Input: 0.115 MB, Params: 4,611,392 (17.591 MB), Total: 17.71 MB, FLOPs: 422,469,601\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Finished fine tuning.\n",
      "Iteration 30/1723 finished in 0m16s\n",
      "Total channels prunned so far: 30\n",
      "\n",
      "Iteration 31 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 484)]\n",
      "Input: 0.115 MB, Params: 4,606,842 (17.574 MB), Total: 17.69 MB, FLOPs: 422,346,831\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Finished fine tuning.\n",
      "Iteration 31/1723 finished in 0m16s\n",
      "Total channels prunned so far: 31\n",
      "\n",
      "Iteration 32 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 149)]\n",
      "Input: 0.115 MB, Params: 4,602,292 (17.556 MB), Total: 17.67 MB, FLOPs: 422,224,061\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Finished fine tuning.\n",
      "Iteration 32/1723 finished in 0m16s\n",
      "Total channels prunned so far: 32\n",
      "\n",
      "Iteration 33 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 184)]\n",
      "Input: 0.115 MB, Params: 4,597,742 (17.539 MB), Total: 17.65 MB, FLOPs: 422,101,291\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Finished fine tuning.\n",
      "Iteration 33/1723 finished in 0m16s\n",
      "Total channels prunned so far: 33\n",
      "\n",
      "Iteration 34 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 68)]\n",
      "Input: 0.115 MB, Params: 4,590,945 (17.513 MB), Total: 17.63 MB, FLOPs: 421,917,799\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Finished fine tuning.\n",
      "Iteration 34/1723 finished in 0m16s\n",
      "Total channels prunned so far: 34\n",
      "\n",
      "Iteration 35 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 259)]\n",
      "Input: 0.115 MB, Params: 4,586,404 (17.496 MB), Total: 17.61 MB, FLOPs: 421,795,272\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Finished fine tuning.\n",
      "Iteration 35/1723 finished in 0m16s\n",
      "Total channels prunned so far: 35\n",
      "\n",
      "Iteration 36 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 85)]\n",
      "Input: 0.115 MB, Params: 4,581,863 (17.478 MB), Total: 17.59 MB, FLOPs: 421,672,745\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Finished fine tuning.\n",
      "Iteration 36/1723 finished in 0m16s\n",
      "Total channels prunned so far: 36\n",
      "\n",
      "Iteration 37 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 162)]\n",
      "Input: 0.115 MB, Params: 4,578,414 (17.465 MB), Total: 17.58 MB, FLOPs: 421,300,361\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Finished fine tuning.\n",
      "Iteration 37/1723 finished in 0m16s\n",
      "Total channels prunned so far: 37\n",
      "\n",
      "Iteration 38 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 79)]\n",
      "Input: 0.115 MB, Params: 4,574,965 (17.452 MB), Total: 17.57 MB, FLOPs: 420,927,977\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Finished fine tuning.\n",
      "Iteration 38/1723 finished in 0m16s\n",
      "Total channels prunned so far: 38\n",
      "\n",
      "Iteration 39 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 416)]\n",
      "Input: 0.115 MB, Params: 4,570,424 (17.435 MB), Total: 17.55 MB, FLOPs: 420,805,450\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Finished fine tuning.\n",
      "Iteration 39/1723 finished in 0m16s\n",
      "Total channels prunned so far: 39\n",
      "\n",
      "Iteration 40 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 73)]\n",
      "Input: 0.115 MB, Params: 4,565,883 (17.417 MB), Total: 17.53 MB, FLOPs: 420,682,923\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Finished fine tuning.\n",
      "Iteration 40/1723 finished in 0m16s\n",
      "Total channels prunned so far: 40\n",
      "\n",
      "Iteration 41 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 377)]\n",
      "Input: 0.115 MB, Params: 4,559,122 (17.392 MB), Total: 17.51 MB, FLOPs: 420,500,403\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Finished fine tuning.\n",
      "Iteration 41/1723 finished in 0m16s\n",
      "Total channels prunned so far: 41\n",
      "\n",
      "Iteration 42 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 64)]\n",
      "Input: 0.115 MB, Params: 4,555,682 (17.379 MB), Total: 17.49 MB, FLOPs: 419,698,490\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Finished fine tuning.\n",
      "Iteration 42/1723 finished in 0m16s\n",
      "Total channels prunned so far: 42\n",
      "\n",
      "Iteration 43 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 346)]\n",
      "Input: 0.115 MB, Params: 4,548,921 (17.353 MB), Total: 17.47 MB, FLOPs: 419,515,970\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.774%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Finished fine tuning.\n",
      "Iteration 43/1723 finished in 0m16s\n",
      "Total channels prunned so far: 43\n",
      "\n",
      "Iteration 44 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 403)]\n",
      "Input: 0.115 MB, Params: 4,544,398 (17.336 MB), Total: 17.45 MB, FLOPs: 419,393,929\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Finished fine tuning.\n",
      "Iteration 44/1723 finished in 0m17s\n",
      "Total channels prunned so far: 44\n",
      "\n",
      "Iteration 45 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 274)]\n",
      "Input: 0.115 MB, Params: 4,539,875 (17.318 MB), Total: 17.43 MB, FLOPs: 419,271,888\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Finished fine tuning.\n",
      "Iteration 45/1723 finished in 0m16s\n",
      "Total channels prunned so far: 45\n",
      "\n",
      "Iteration 46 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(14, 9)]\n",
      "Input: 0.115 MB, Params: 4,538,145 (17.312 MB), Total: 17.43 MB, FLOPs: 417,590,702\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Finished fine tuning.\n",
      "Iteration 46/1723 finished in 0m16s\n",
      "Total channels prunned so far: 46\n",
      "\n",
      "Iteration 47 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 175)]\n",
      "Input: 0.115 MB, Params: 4,531,402 (17.286 MB), Total: 17.40 MB, FLOPs: 417,408,668\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Finished fine tuning.\n",
      "Iteration 47/1723 finished in 0m17s\n",
      "Total channels prunned so far: 47\n",
      "\n",
      "Iteration 48 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 376)]\n",
      "Input: 0.115 MB, Params: 4,526,888 (17.269 MB), Total: 17.38 MB, FLOPs: 417,286,870\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Finished fine tuning.\n",
      "Iteration 48/1723 finished in 0m16s\n",
      "Total channels prunned so far: 48\n",
      "\n",
      "Iteration 49 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 227)]\n",
      "Input: 0.115 MB, Params: 4,522,374 (17.251 MB), Total: 17.37 MB, FLOPs: 417,165,072\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.774%\n",
      "Finished fine tuning.\n",
      "Iteration 49/1723 finished in 0m16s\n",
      "Total channels prunned so far: 49\n",
      "\n",
      "Iteration 50 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 465)]\n",
      "Input: 0.115 MB, Params: 4,515,649 (17.226 MB), Total: 17.34 MB, FLOPs: 416,983,524\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.774%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Finished fine tuning.\n",
      "Iteration 50/1723 finished in 0m16s\n",
      "Total channels prunned so far: 50\n",
      "\n",
      "Iteration 51 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 148)]\n",
      "Input: 0.115 MB, Params: 4,511,144 (17.209 MB), Total: 17.32 MB, FLOPs: 416,861,969\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Finished fine tuning.\n",
      "Iteration 51/1723 finished in 0m16s\n",
      "Total channels prunned so far: 51\n",
      "\n",
      "Iteration 52 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 45)]\n",
      "Input: 0.115 MB, Params: 4,506,639 (17.191 MB), Total: 17.31 MB, FLOPs: 416,740,414\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Finished fine tuning.\n",
      "Iteration 52/1723 finished in 0m17s\n",
      "Total channels prunned so far: 52\n",
      "\n",
      "Iteration 53 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 158)]\n",
      "Input: 0.115 MB, Params: 4,502,134 (17.174 MB), Total: 17.29 MB, FLOPs: 416,618,859\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Finished fine tuning.\n",
      "Iteration 53/1723 finished in 0m16s\n",
      "Total channels prunned so far: 53\n",
      "\n",
      "Iteration 54 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 175)]\n",
      "Input: 0.115 MB, Params: 4,495,346 (17.148 MB), Total: 17.26 MB, FLOPs: 416,250,255\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.774%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Finished fine tuning.\n",
      "Iteration 54/1723 finished in 0m14s\n",
      "Total channels prunned so far: 54\n",
      "\n",
      "Iteration 55 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 10)]\n",
      "Input: 0.115 MB, Params: 4,491,906 (17.135 MB), Total: 17.25 MB, FLOPs: 415,448,342\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Finished fine tuning.\n",
      "Iteration 55/1723 finished in 0m15s\n",
      "Total channels prunned so far: 55\n",
      "\n",
      "Iteration 56 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 70)]\n",
      "Input: 0.115 MB, Params: 4,485,118 (17.109 MB), Total: 17.22 MB, FLOPs: 415,079,738\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Finished fine tuning.\n",
      "Iteration 56/1723 finished in 0m15s\n",
      "Total channels prunned so far: 56\n",
      "\n",
      "Iteration 57 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 194)]\n",
      "Input: 0.115 MB, Params: 4,478,330 (17.083 MB), Total: 17.20 MB, FLOPs: 414,711,134\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Finished fine tuning.\n",
      "Iteration 57/1723 finished in 0m15s\n",
      "Total channels prunned so far: 57\n",
      "\n",
      "Iteration 58 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 472)]\n",
      "Input: 0.115 MB, Params: 4,473,825 (17.066 MB), Total: 17.18 MB, FLOPs: 414,589,579\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Finished fine tuning.\n",
      "Iteration 58/1723 finished in 0m15s\n",
      "Total channels prunned so far: 58\n",
      "\n",
      "Iteration 59 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 187)]\n",
      "Input: 0.115 MB, Params: 4,469,320 (17.049 MB), Total: 17.16 MB, FLOPs: 414,468,024\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Finished fine tuning.\n",
      "Iteration 59/1723 finished in 0m15s\n",
      "Total channels prunned so far: 59\n",
      "\n",
      "Iteration 60 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 129)]\n",
      "Input: 0.115 MB, Params: 4,464,815 (17.032 MB), Total: 17.15 MB, FLOPs: 414,346,469\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Finished fine tuning.\n",
      "Iteration 60/1723 finished in 0m14s\n",
      "Total channels prunned so far: 60\n",
      "\n",
      "Iteration 61 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 188)]\n",
      "Input: 0.115 MB, Params: 4,460,310 (17.015 MB), Total: 17.13 MB, FLOPs: 414,224,914\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Finished fine tuning.\n",
      "Iteration 61/1723 finished in 0m14s\n",
      "Total channels prunned so far: 61\n",
      "\n",
      "Iteration 62 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 98)]\n",
      "Input: 0.115 MB, Params: 4,453,522 (16.989 MB), Total: 17.10 MB, FLOPs: 413,856,310\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Finished fine tuning.\n",
      "Iteration 62/1723 finished in 0m15s\n",
      "Total channels prunned so far: 62\n",
      "\n",
      "Iteration 63 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 218)]\n",
      "Input: 0.115 MB, Params: 4,449,017 (16.972 MB), Total: 17.09 MB, FLOPs: 413,734,755\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Finished fine tuning.\n",
      "Iteration 63/1723 finished in 0m15s\n",
      "Total channels prunned so far: 63\n",
      "\n",
      "Iteration 64 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 408)]\n",
      "Input: 0.115 MB, Params: 4,442,400 (16.946 MB), Total: 17.06 MB, FLOPs: 413,556,123\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Finished fine tuning.\n",
      "Iteration 64/1723 finished in 0m14s\n",
      "Total channels prunned so far: 64\n",
      "\n",
      "Iteration 65 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 218)]\n",
      "Input: 0.115 MB, Params: 4,437,904 (16.929 MB), Total: 17.04 MB, FLOPs: 413,434,811\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Finished fine tuning.\n",
      "Iteration 65/1723 finished in 0m14s\n",
      "Total channels prunned so far: 65\n",
      "\n",
      "Iteration 66 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 108)]\n",
      "Input: 0.115 MB, Params: 4,434,509 (16.916 MB), Total: 17.03 MB, FLOPs: 413,068,259\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Finished fine tuning.\n",
      "Iteration 66/1723 finished in 0m15s\n",
      "Total channels prunned so far: 66\n",
      "\n",
      "Iteration 67 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 73)]\n",
      "Input: 0.115 MB, Params: 4,430,013 (16.899 MB), Total: 17.01 MB, FLOPs: 412,946,947\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.774%\n",
      "Finished fine tuning.\n",
      "Iteration 67/1723 finished in 0m15s\n",
      "Total channels prunned so far: 67\n",
      "\n",
      "Iteration 68 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 201)]\n",
      "Input: 0.115 MB, Params: 4,426,618 (16.886 MB), Total: 17.00 MB, FLOPs: 412,580,395\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Finished fine tuning.\n",
      "Iteration 68/1723 finished in 0m14s\n",
      "Total channels prunned so far: 68\n",
      "\n",
      "Iteration 69 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(3, 6)]\n",
      "Input: 0.115 MB, Params: 4,426,576 (16.886 MB), Total: 17.00 MB, FLOPs: 400,062,079\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.774%\n",
      "Finished fine tuning.\n",
      "Iteration 69/1723 finished in 0m15s\n",
      "Total channels prunned so far: 69\n",
      "\n",
      "Iteration 70 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 47)]\n",
      "Input: 0.115 MB, Params: 4,419,977 (16.861 MB), Total: 16.98 MB, FLOPs: 399,883,933\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Finished fine tuning.\n",
      "Iteration 70/1723 finished in 0m16s\n",
      "Total channels prunned so far: 70\n",
      "\n",
      "Iteration 71 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 433)]\n",
      "Input: 0.115 MB, Params: 4,415,490 (16.844 MB), Total: 16.96 MB, FLOPs: 399,762,864\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Finished fine tuning.\n",
      "Iteration 71/1723 finished in 0m15s\n",
      "Total channels prunned so far: 71\n",
      "\n",
      "Iteration 72 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 266)]\n",
      "Input: 0.115 MB, Params: 4,411,003 (16.827 MB), Total: 16.94 MB, FLOPs: 399,641,795\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Finished fine tuning.\n",
      "Iteration 72/1723 finished in 0m15s\n",
      "Total channels prunned so far: 72\n",
      "\n",
      "Iteration 73 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 18)]\n",
      "Input: 0.115 MB, Params: 4,407,581 (16.814 MB), Total: 16.93 MB, FLOPs: 398,884,487\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Finished fine tuning.\n",
      "Iteration 73/1723 finished in 0m14s\n",
      "Total channels prunned so far: 73\n",
      "\n",
      "Iteration 74 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 124)]\n",
      "Input: 0.115 MB, Params: 4,401,000 (16.788 MB), Total: 16.90 MB, FLOPs: 398,706,827\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Finished fine tuning.\n",
      "Iteration 74/1723 finished in 0m14s\n",
      "Total channels prunned so far: 74\n",
      "\n",
      "Iteration 75 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 291)]\n",
      "Input: 0.115 MB, Params: 4,396,522 (16.771 MB), Total: 16.89 MB, FLOPs: 398,586,001\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Finished fine tuning.\n",
      "Iteration 75/1723 finished in 0m14s\n",
      "Total channels prunned so far: 75\n",
      "\n",
      "Iteration 76 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 135)]\n",
      "Input: 0.115 MB, Params: 4,392,044 (16.754 MB), Total: 16.87 MB, FLOPs: 398,465,175\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Finished fine tuning.\n",
      "Iteration 76/1723 finished in 0m15s\n",
      "Total channels prunned so far: 76\n",
      "\n",
      "Iteration 77 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 334)]\n",
      "Input: 0.115 MB, Params: 4,387,566 (16.737 MB), Total: 16.85 MB, FLOPs: 398,344,349\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.774%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Finished fine tuning.\n",
      "Iteration 77/1723 finished in 0m15s\n",
      "Total channels prunned so far: 77\n",
      "\n",
      "Iteration 78 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 155)]\n",
      "Input: 0.115 MB, Params: 4,384,180 (16.724 MB), Total: 16.84 MB, FLOPs: 397,978,769\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Finished fine tuning.\n",
      "Iteration 78/1723 finished in 0m15s\n",
      "Total channels prunned so far: 78\n",
      "\n",
      "Iteration 79 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 435)]\n",
      "Input: 0.115 MB, Params: 4,379,702 (16.707 MB), Total: 16.82 MB, FLOPs: 397,857,943\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Finished fine tuning.\n",
      "Iteration 79/1723 finished in 0m15s\n",
      "Total channels prunned so far: 79\n",
      "\n",
      "Iteration 80 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 133)]\n",
      "Input: 0.115 MB, Params: 4,373,157 (16.682 MB), Total: 16.80 MB, FLOPs: 397,681,255\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.122%\n",
      "Finished fine tuning.\n",
      "Iteration 80/1723 finished in 0m15s\n",
      "Total channels prunned so far: 80\n",
      "\n",
      "Iteration 81 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 478)]\n",
      "Input: 0.115 MB, Params: 4,366,612 (16.657 MB), Total: 16.77 MB, FLOPs: 397,504,567\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Finished fine tuning.\n",
      "Iteration 81/1723 finished in 0m15s\n",
      "Total channels prunned so far: 81\n",
      "\n",
      "Iteration 82 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 306)]\n",
      "Input: 0.115 MB, Params: 4,360,067 (16.632 MB), Total: 16.75 MB, FLOPs: 397,327,879\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Finished fine tuning.\n",
      "Iteration 82/1723 finished in 0m14s\n",
      "Total channels prunned so far: 82\n",
      "\n",
      "Iteration 83 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 282)]\n",
      "Input: 0.115 MB, Params: 4,353,522 (16.607 MB), Total: 16.72 MB, FLOPs: 397,151,191\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Finished fine tuning.\n",
      "Iteration 83/1723 finished in 0m15s\n",
      "Total channels prunned so far: 83\n",
      "\n",
      "Iteration 84 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 363)]\n",
      "Input: 0.115 MB, Params: 4,346,977 (16.582 MB), Total: 16.70 MB, FLOPs: 396,974,503\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Finished fine tuning.\n",
      "Iteration 84/1723 finished in 0m15s\n",
      "Total channels prunned so far: 84\n",
      "\n",
      "Iteration 85 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 160)]\n",
      "Input: 0.115 MB, Params: 4,342,544 (16.565 MB), Total: 16.68 MB, FLOPs: 396,854,892\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Finished fine tuning.\n",
      "Iteration 85/1723 finished in 0m14s\n",
      "Total channels prunned so far: 85\n",
      "\n",
      "Iteration 86 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 28)]\n",
      "Input: 0.115 MB, Params: 4,338,111 (16.549 MB), Total: 16.66 MB, FLOPs: 396,735,281\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Finished fine tuning.\n",
      "Iteration 86/1723 finished in 0m14s\n",
      "Total channels prunned so far: 86\n",
      "\n",
      "Iteration 87 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 355)]\n",
      "Input: 0.115 MB, Params: 4,333,678 (16.532 MB), Total: 16.65 MB, FLOPs: 396,615,670\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Finished fine tuning.\n",
      "Iteration 87/1723 finished in 0m15s\n",
      "Total channels prunned so far: 87\n",
      "\n",
      "Iteration 88 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 293)]\n",
      "Input: 0.115 MB, Params: 4,329,245 (16.515 MB), Total: 16.63 MB, FLOPs: 396,496,059\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.774%\n",
      "Finished fine tuning.\n",
      "Iteration 88/1723 finished in 0m14s\n",
      "Total channels prunned so far: 88\n",
      "\n",
      "Iteration 89 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 34)]\n",
      "Input: 0.115 MB, Params: 4,325,832 (16.502 MB), Total: 16.62 MB, FLOPs: 395,739,723\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.774%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.819%\n",
      "Finished fine tuning.\n",
      "Iteration 89/1723 finished in 0m15s\n",
      "Total channels prunned so far: 89\n",
      "\n",
      "Iteration 90 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 88)]\n",
      "Input: 0.115 MB, Params: 4,322,455 (16.489 MB), Total: 16.60 MB, FLOPs: 395,375,115\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.122%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Finished fine tuning.\n",
      "Iteration 90/1723 finished in 0m15s\n",
      "Total channels prunned so far: 90\n",
      "\n",
      "Iteration 91 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 375)]\n",
      "Input: 0.115 MB, Params: 4,318,022 (16.472 MB), Total: 16.59 MB, FLOPs: 395,255,504\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.774%\n",
      "Finished fine tuning.\n",
      "Iteration 91/1723 finished in 0m15s\n",
      "Total channels prunned so far: 91\n",
      "\n",
      "Iteration 92 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 292)]\n",
      "Input: 0.115 MB, Params: 4,313,589 (16.455 MB), Total: 16.57 MB, FLOPs: 395,135,893\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.774%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Finished fine tuning.\n",
      "Iteration 92/1723 finished in 0m15s\n",
      "Total channels prunned so far: 92\n",
      "\n",
      "Iteration 93 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 83)]\n",
      "Input: 0.115 MB, Params: 4,306,909 (16.430 MB), Total: 16.54 MB, FLOPs: 394,773,121\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Finished fine tuning.\n",
      "Iteration 93/1723 finished in 0m15s\n",
      "Total channels prunned so far: 93\n",
      "\n",
      "Iteration 94 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 70)]\n",
      "Input: 0.115 MB, Params: 4,305,224 (16.423 MB), Total: 16.54 MB, FLOPs: 394,025,425\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Finished fine tuning.\n",
      "Iteration 94/1723 finished in 0m15s\n",
      "Total channels prunned so far: 94\n",
      "\n",
      "Iteration 95 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 159)]\n",
      "Input: 0.115 MB, Params: 4,298,742 (16.398 MB), Total: 16.51 MB, FLOPs: 393,850,438\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Finished fine tuning.\n",
      "Iteration 95/1723 finished in 0m15s\n",
      "Total channels prunned so far: 95\n",
      "\n",
      "Iteration 96 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 452)]\n",
      "Input: 0.115 MB, Params: 4,292,260 (16.374 MB), Total: 16.49 MB, FLOPs: 393,675,451\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Finished fine tuning.\n",
      "Iteration 96/1723 finished in 0m15s\n",
      "Total channels prunned so far: 96\n",
      "\n",
      "Iteration 97 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 255)]\n",
      "Input: 0.115 MB, Params: 4,287,845 (16.357 MB), Total: 16.47 MB, FLOPs: 393,556,326\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Finished fine tuning.\n",
      "Iteration 97/1723 finished in 0m15s\n",
      "Total channels prunned so far: 97\n",
      "\n",
      "Iteration 98 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 389)]\n",
      "Input: 0.115 MB, Params: 4,281,372 (16.332 MB), Total: 16.45 MB, FLOPs: 393,381,582\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Finished fine tuning.\n",
      "Iteration 98/1723 finished in 0m14s\n",
      "Total channels prunned so far: 98\n",
      "\n",
      "Iteration 99 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(14, 35)]\n",
      "Input: 0.115 MB, Params: 4,279,651 (16.326 MB), Total: 16.44 MB, FLOPs: 391,790,439\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Finished fine tuning.\n",
      "Iteration 99/1723 finished in 0m15s\n",
      "Total channels prunned so far: 99\n",
      "\n",
      "Iteration 100 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(3, 46)]\n",
      "Input: 0.115 MB, Params: 4,279,609 (16.325 MB), Total: 16.44 MB, FLOPs: 391,426,406\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.470%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Finished fine tuning.\n",
      "Iteration 100/1723 finished in 0m15s\n",
      "Total channels prunned so far: 100\n",
      "\n",
      "Iteration 101 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 51)]\n",
      "Input: 0.115 MB, Params: 4,272,956 (16.300 MB), Total: 16.42 MB, FLOPs: 391,064,363\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Finished fine tuning.\n",
      "Iteration 101/1723 finished in 0m15s\n",
      "Total channels prunned so far: 101\n",
      "\n",
      "Iteration 102 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 45)]\n",
      "Input: 0.115 MB, Params: 4,272,117 (16.297 MB), Total: 16.41 MB, FLOPs: 389,493,113\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Finished fine tuning.\n",
      "Iteration 102/1723 finished in 0m15s\n",
      "Total channels prunned so far: 102\n",
      "\n",
      "Iteration 103 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 353)]\n",
      "Input: 0.115 MB, Params: 4,265,653 (16.272 MB), Total: 16.39 MB, FLOPs: 389,318,612\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Finished fine tuning.\n",
      "Iteration 103/1723 finished in 0m15s\n",
      "Total channels prunned so far: 103\n",
      "\n",
      "Iteration 104 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 14)]\n",
      "Input: 0.115 MB, Params: 4,261,256 (16.255 MB), Total: 16.37 MB, FLOPs: 389,199,973\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Finished fine tuning.\n",
      "Iteration 104/1723 finished in 0m15s\n",
      "Total channels prunned so far: 104\n",
      "\n",
      "Iteration 105 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 235)]\n",
      "Input: 0.115 MB, Params: 4,256,859 (16.239 MB), Total: 16.35 MB, FLOPs: 389,081,334\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Finished fine tuning.\n",
      "Iteration 105/1723 finished in 0m15s\n",
      "Total channels prunned so far: 105\n",
      "\n",
      "Iteration 106 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 81)]\n",
      "Input: 0.115 MB, Params: 4,252,462 (16.222 MB), Total: 16.34 MB, FLOPs: 388,962,695\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Finished fine tuning.\n",
      "Iteration 106/1723 finished in 0m15s\n",
      "Total channels prunned so far: 106\n",
      "\n",
      "Iteration 107 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 234)]\n",
      "Input: 0.115 MB, Params: 4,246,025 (16.197 MB), Total: 16.31 MB, FLOPs: 388,788,923\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Finished fine tuning.\n",
      "Iteration 107/1723 finished in 0m15s\n",
      "Total channels prunned so far: 107\n",
      "\n",
      "Iteration 108 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 159)]\n",
      "Input: 0.115 MB, Params: 4,239,390 (16.172 MB), Total: 16.29 MB, FLOPs: 388,427,366\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.122%\n",
      "Finished fine tuning.\n",
      "Iteration 108/1723 finished in 0m14s\n",
      "Total channels prunned so far: 108\n",
      "\n",
      "Iteration 109 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 8)]\n",
      "Input: 0.115 MB, Params: 4,237,714 (16.166 MB), Total: 16.28 MB, FLOPs: 387,683,666\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.774%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Finished fine tuning.\n",
      "Iteration 109/1723 finished in 0m14s\n",
      "Total channels prunned so far: 109\n",
      "\n",
      "Iteration 110 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 73)]\n",
      "Input: 0.115 MB, Params: 4,231,079 (16.140 MB), Total: 16.26 MB, FLOPs: 387,322,109\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.122%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Finished fine tuning.\n",
      "Iteration 110/1723 finished in 0m15s\n",
      "Total channels prunned so far: 110\n",
      "\n",
      "Iteration 111 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 332)]\n",
      "Input: 0.115 MB, Params: 4,226,691 (16.124 MB), Total: 16.24 MB, FLOPs: 387,203,713\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.122%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.122%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Finished fine tuning.\n",
      "Iteration 111/1723 finished in 0m15s\n",
      "Total channels prunned so far: 111\n",
      "\n",
      "Iteration 112 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 322)]\n",
      "Input: 0.115 MB, Params: 4,222,303 (16.107 MB), Total: 16.22 MB, FLOPs: 387,085,317\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.470%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Finished fine tuning.\n",
      "Iteration 112/1723 finished in 0m15s\n",
      "Total channels prunned so far: 112\n",
      "\n",
      "Iteration 113 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 439)]\n",
      "Input: 0.115 MB, Params: 4,215,902 (16.082 MB), Total: 16.20 MB, FLOPs: 386,912,517\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Finished fine tuning.\n",
      "Iteration 113/1723 finished in 0m15s\n",
      "Total channels prunned so far: 113\n",
      "\n",
      "Iteration 114 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 319)]\n",
      "Input: 0.115 MB, Params: 4,209,501 (16.058 MB), Total: 16.17 MB, FLOPs: 386,739,717\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.774%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Finished fine tuning.\n",
      "Iteration 114/1723 finished in 0m16s\n",
      "Total channels prunned so far: 114\n",
      "\n",
      "Iteration 115 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 229)]\n",
      "Input: 0.115 MB, Params: 4,202,884 (16.033 MB), Total: 16.15 MB, FLOPs: 386,378,646\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.774%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.122%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Finished fine tuning.\n",
      "Iteration 115/1723 finished in 0m14s\n",
      "Total channels prunned so far: 115\n",
      "\n",
      "Iteration 116 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 181)]\n",
      "Input: 0.115 MB, Params: 4,198,514 (16.016 MB), Total: 16.13 MB, FLOPs: 386,260,736\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Finished fine tuning.\n",
      "Iteration 116/1723 finished in 0m15s\n",
      "Total channels prunned so far: 116\n",
      "\n",
      "Iteration 117 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 220)]\n",
      "Input: 0.115 MB, Params: 4,192,131 (15.992 MB), Total: 16.11 MB, FLOPs: 386,088,422\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Finished fine tuning.\n",
      "Iteration 117/1723 finished in 0m15s\n",
      "Total channels prunned so far: 117\n",
      "\n",
      "Iteration 118 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 8)]\n",
      "Input: 0.115 MB, Params: 4,187,770 (15.975 MB), Total: 16.09 MB, FLOPs: 385,970,755\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Finished fine tuning.\n",
      "Iteration 118/1723 finished in 0m17s\n",
      "Total channels prunned so far: 118\n",
      "\n",
      "Iteration 119 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 124)]\n",
      "Input: 0.115 MB, Params: 4,181,162 (15.950 MB), Total: 16.07 MB, FLOPs: 385,609,927\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Finished fine tuning.\n",
      "Iteration 119/1723 finished in 0m17s\n",
      "Total channels prunned so far: 119\n",
      "\n",
      "Iteration 120 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 435)]\n",
      "Input: 0.115 MB, Params: 4,174,797 (15.926 MB), Total: 16.04 MB, FLOPs: 385,438,099\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Finished fine tuning.\n",
      "Iteration 120/1723 finished in 0m16s\n",
      "Total channels prunned so far: 120\n",
      "\n",
      "Iteration 121 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 35)]\n",
      "Input: 0.115 MB, Params: 4,171,474 (15.913 MB), Total: 16.03 MB, FLOPs: 385,079,323\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Finished fine tuning.\n",
      "Iteration 121/1723 finished in 0m16s\n",
      "Total channels prunned so far: 121\n",
      "\n",
      "Iteration 122 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 219)]\n",
      "Input: 0.115 MB, Params: 4,168,151 (15.900 MB), Total: 16.02 MB, FLOPs: 384,720,547\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Finished fine tuning.\n",
      "Iteration 122/1723 finished in 0m17s\n",
      "Total channels prunned so far: 122\n",
      "\n",
      "Iteration 123 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 1)]\n",
      "Input: 0.115 MB, Params: 4,161,786 (15.876 MB), Total: 15.99 MB, FLOPs: 384,548,719\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Finished fine tuning.\n",
      "Iteration 123/1723 finished in 0m17s\n",
      "Total channels prunned so far: 123\n",
      "\n",
      "Iteration 124 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 264)]\n",
      "Input: 0.115 MB, Params: 4,155,421 (15.852 MB), Total: 15.97 MB, FLOPs: 384,376,891\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Finished fine tuning.\n",
      "Iteration 124/1723 finished in 0m16s\n",
      "Total channels prunned so far: 124\n",
      "\n",
      "Iteration 125 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 412)]\n",
      "Input: 0.115 MB, Params: 4,149,056 (15.827 MB), Total: 15.94 MB, FLOPs: 384,205,063\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.774%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Finished fine tuning.\n",
      "Iteration 125/1723 finished in 0m17s\n",
      "Total channels prunned so far: 125\n",
      "\n",
      "Iteration 126 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 279)]\n",
      "Input: 0.115 MB, Params: 4,144,731 (15.811 MB), Total: 15.93 MB, FLOPs: 384,088,368\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Finished fine tuning.\n",
      "Iteration 126/1723 finished in 0m16s\n",
      "Total channels prunned so far: 126\n",
      "\n",
      "Iteration 127 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 22)]\n",
      "Input: 0.115 MB, Params: 4,138,375 (15.787 MB), Total: 15.90 MB, FLOPs: 383,916,783\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.819%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.167%\n",
      "Finished fine tuning.\n",
      "Iteration 127/1723 finished in 0m16s\n",
      "Total channels prunned so far: 127\n",
      "\n",
      "Iteration 128 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 10)]\n",
      "Input: 0.115 MB, Params: 4,132,019 (15.762 MB), Total: 15.88 MB, FLOPs: 383,745,198\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Finished fine tuning.\n",
      "Iteration 128/1723 finished in 0m17s\n",
      "Total channels prunned so far: 128\n",
      "\n",
      "Iteration 129 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 183)]\n",
      "Input: 0.115 MB, Params: 4,127,712 (15.746 MB), Total: 15.86 MB, FLOPs: 383,628,989\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Finished fine tuning.\n",
      "Iteration 129/1723 finished in 0m16s\n",
      "Total channels prunned so far: 129\n",
      "\n",
      "Iteration 130 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 73)]\n",
      "Input: 0.115 MB, Params: 4,121,365 (15.722 MB), Total: 15.84 MB, FLOPs: 383,457,647\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.774%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Finished fine tuning.\n",
      "Iteration 130/1723 finished in 0m17s\n",
      "Total channels prunned so far: 130\n",
      "\n",
      "Iteration 131 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 198)]\n",
      "Input: 0.115 MB, Params: 4,118,042 (15.709 MB), Total: 15.82 MB, FLOPs: 383,098,871\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.774%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.774%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Finished fine tuning.\n",
      "Iteration 131/1723 finished in 0m16s\n",
      "Total channels prunned so far: 131\n",
      "\n",
      "Iteration 132 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 184)]\n",
      "Input: 0.115 MB, Params: 4,111,695 (15.685 MB), Total: 15.80 MB, FLOPs: 382,927,529\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Finished fine tuning.\n",
      "Iteration 132/1723 finished in 0m17s\n",
      "Total channels prunned so far: 132\n",
      "\n",
      "Iteration 133 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 367)]\n",
      "Input: 0.115 MB, Params: 4,107,406 (15.669 MB), Total: 15.78 MB, FLOPs: 382,811,806\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Finished fine tuning.\n",
      "Iteration 133/1723 finished in 0m16s\n",
      "Total channels prunned so far: 133\n",
      "\n",
      "Iteration 134 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 383)]\n",
      "Input: 0.115 MB, Params: 4,103,117 (15.652 MB), Total: 15.77 MB, FLOPs: 382,696,083\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.122%\n",
      "Finished fine tuning.\n",
      "Iteration 134/1723 finished in 0m17s\n",
      "Total channels prunned so far: 134\n",
      "\n",
      "Iteration 135 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 94)]\n",
      "Input: 0.115 MB, Params: 4,099,794 (15.639 MB), Total: 15.75 MB, FLOPs: 382,337,307\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.774%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Finished fine tuning.\n",
      "Iteration 135/1723 finished in 0m16s\n",
      "Total channels prunned so far: 135\n",
      "\n",
      "Iteration 136 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 291)]\n",
      "Input: 0.115 MB, Params: 4,095,505 (15.623 MB), Total: 15.74 MB, FLOPs: 382,221,584\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Finished fine tuning.\n",
      "Iteration 136/1723 finished in 0m17s\n",
      "Total channels prunned so far: 136\n",
      "\n",
      "Iteration 137 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 310)]\n",
      "Input: 0.115 MB, Params: 4,091,216 (15.607 MB), Total: 15.72 MB, FLOPs: 382,105,861\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Finished fine tuning.\n",
      "Iteration 137/1723 finished in 0m16s\n",
      "Total channels prunned so far: 137\n",
      "\n",
      "Iteration 138 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 51)]\n",
      "Input: 0.115 MB, Params: 4,086,927 (15.590 MB), Total: 15.71 MB, FLOPs: 381,990,138\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Finished fine tuning.\n",
      "Iteration 138/1723 finished in 0m16s\n",
      "Total channels prunned so far: 138\n",
      "\n",
      "Iteration 139 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 23)]\n",
      "Input: 0.115 MB, Params: 4,083,604 (15.578 MB), Total: 15.69 MB, FLOPs: 381,631,362\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.774%\n",
      "Finished fine tuning.\n",
      "Iteration 139/1723 finished in 0m16s\n",
      "Total channels prunned so far: 139\n",
      "\n",
      "Iteration 140 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 313)]\n",
      "Input: 0.115 MB, Params: 4,079,315 (15.561 MB), Total: 15.68 MB, FLOPs: 381,515,639\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Finished fine tuning.\n",
      "Iteration 140/1723 finished in 0m16s\n",
      "Total channels prunned so far: 140\n",
      "\n",
      "Iteration 141 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 217)]\n",
      "Input: 0.115 MB, Params: 4,075,992 (15.549 MB), Total: 15.66 MB, FLOPs: 381,156,863\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.122%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.774%\n",
      "Finished fine tuning.\n",
      "Iteration 141/1723 finished in 0m17s\n",
      "Total channels prunned so far: 141\n",
      "\n",
      "Iteration 142 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 70)]\n",
      "Input: 0.115 MB, Params: 4,071,703 (15.532 MB), Total: 15.65 MB, FLOPs: 381,041,140\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.774%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Finished fine tuning.\n",
      "Iteration 142/1723 finished in 0m16s\n",
      "Total channels prunned so far: 142\n",
      "\n",
      "Iteration 143 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 474)]\n",
      "Input: 0.115 MB, Params: 4,065,419 (15.508 MB), Total: 15.62 MB, FLOPs: 380,871,499\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Finished fine tuning.\n",
      "Iteration 143/1723 finished in 0m17s\n",
      "Total channels prunned so far: 143\n",
      "\n",
      "Iteration 144 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 57)]\n",
      "Input: 0.115 MB, Params: 4,061,139 (15.492 MB), Total: 15.61 MB, FLOPs: 380,756,019\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Finished fine tuning.\n",
      "Iteration 144/1723 finished in 0m17s\n",
      "Total channels prunned so far: 144\n",
      "\n",
      "Iteration 145 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 207)]\n",
      "Input: 0.115 MB, Params: 4,056,859 (15.476 MB), Total: 15.59 MB, FLOPs: 380,640,539\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Finished fine tuning.\n",
      "Iteration 145/1723 finished in 0m17s\n",
      "Total channels prunned so far: 145\n",
      "\n",
      "Iteration 146 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 246)]\n",
      "Input: 0.115 MB, Params: 4,050,593 (15.452 MB), Total: 15.57 MB, FLOPs: 380,471,384\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Finished fine tuning.\n",
      "Iteration 146/1723 finished in 0m17s\n",
      "Total channels prunned so far: 146\n",
      "\n",
      "Iteration 147 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 128)]\n",
      "Input: 0.115 MB, Params: 4,044,129 (15.427 MB), Total: 15.54 MB, FLOPs: 380,118,818\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.774%\n",
      "Finished fine tuning.\n",
      "Iteration 147/1723 finished in 0m17s\n",
      "Total channels prunned so far: 147\n",
      "\n",
      "Iteration 148 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 42)]\n",
      "Input: 0.115 MB, Params: 4,037,665 (15.402 MB), Total: 15.52 MB, FLOPs: 379,766,252\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.774%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Finished fine tuning.\n",
      "Iteration 148/1723 finished in 0m17s\n",
      "Total channels prunned so far: 148\n",
      "\n",
      "Iteration 149 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 316)]\n",
      "Input: 0.115 MB, Params: 4,031,417 (15.379 MB), Total: 15.49 MB, FLOPs: 379,597,583\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.470%\n",
      "Finished fine tuning.\n",
      "Iteration 149/1723 finished in 0m16s\n",
      "Total channels prunned so far: 149\n",
      "\n",
      "Iteration 150 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 98)]\n",
      "Input: 0.115 MB, Params: 4,028,112 (15.366 MB), Total: 15.48 MB, FLOPs: 379,240,751\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.470%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Finished fine tuning.\n",
      "Iteration 150/1723 finished in 0m17s\n",
      "Total channels prunned so far: 150\n",
      "\n",
      "Iteration 151 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 130)]\n",
      "Input: 0.115 MB, Params: 4,023,850 (15.350 MB), Total: 15.47 MB, FLOPs: 379,125,757\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.470%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.122%\n",
      "Finished fine tuning.\n",
      "Iteration 151/1723 finished in 0m17s\n",
      "Total channels prunned so far: 151\n",
      "\n",
      "Iteration 152 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 20)]\n",
      "Input: 0.115 MB, Params: 4,019,588 (15.334 MB), Total: 15.45 MB, FLOPs: 379,010,763\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.516%\n",
      "Finished fine tuning.\n",
      "Iteration 152/1723 finished in 0m16s\n",
      "Total channels prunned so far: 152\n",
      "\n",
      "Iteration 153 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 316)]\n",
      "Input: 0.115 MB, Params: 4,015,326 (15.317 MB), Total: 15.43 MB, FLOPs: 378,895,769\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.470%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.819%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Finished fine tuning.\n",
      "Iteration 153/1723 finished in 0m16s\n",
      "Total channels prunned so far: 153\n",
      "\n",
      "Iteration 154 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 226)]\n",
      "Input: 0.115 MB, Params: 4,009,105 (15.294 MB), Total: 15.41 MB, FLOPs: 378,727,829\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Finished fine tuning.\n",
      "Iteration 154/1723 finished in 0m16s\n",
      "Total channels prunned so far: 154\n",
      "\n",
      "Iteration 155 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 214)]\n",
      "Input: 0.115 MB, Params: 4,004,852 (15.277 MB), Total: 15.39 MB, FLOPs: 378,613,078\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Finished fine tuning.\n",
      "Iteration 155/1723 finished in 0m17s\n",
      "Total channels prunned so far: 155\n",
      "\n",
      "Iteration 156 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 76)]\n",
      "Input: 0.115 MB, Params: 4,003,176 (15.271 MB), Total: 15.39 MB, FLOPs: 377,869,378\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Finished fine tuning.\n",
      "Iteration 156/1723 finished in 0m17s\n",
      "Total channels prunned so far: 156\n",
      "\n",
      "Iteration 157 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 47)]\n",
      "Input: 0.115 MB, Params: 3,996,739 (15.246 MB), Total: 15.36 MB, FLOPs: 377,518,270\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Finished fine tuning.\n",
      "Iteration 157/1723 finished in 0m17s\n",
      "Total channels prunned so far: 157\n",
      "\n",
      "Iteration 158 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 52)]\n",
      "Input: 0.115 MB, Params: 3,992,486 (15.230 MB), Total: 15.35 MB, FLOPs: 377,403,519\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.774%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Finished fine tuning.\n",
      "Iteration 158/1723 finished in 0m16s\n",
      "Total channels prunned so far: 158\n",
      "\n",
      "Iteration 159 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 218)]\n",
      "Input: 0.115 MB, Params: 3,986,292 (15.206 MB), Total: 15.32 MB, FLOPs: 377,236,308\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.774%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.774%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.122%\n",
      "Finished fine tuning.\n",
      "Iteration 159/1723 finished in 0m17s\n",
      "Total channels prunned so far: 159\n",
      "\n",
      "Iteration 160 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 120)]\n",
      "Input: 0.115 MB, Params: 3,982,048 (15.190 MB), Total: 15.31 MB, FLOPs: 377,121,800\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Finished fine tuning.\n",
      "Iteration 160/1723 finished in 0m16s\n",
      "Total channels prunned so far: 160\n",
      "\n",
      "Iteration 161 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 257)]\n",
      "Input: 0.115 MB, Params: 3,975,863 (15.167 MB), Total: 15.28 MB, FLOPs: 376,954,832\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.774%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.470%\n",
      "Finished fine tuning.\n",
      "Iteration 161/1723 finished in 0m16s\n",
      "Total channels prunned so far: 161\n",
      "\n",
      "Iteration 162 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 320)]\n",
      "Input: 0.115 MB, Params: 3,969,678 (15.143 MB), Total: 15.26 MB, FLOPs: 376,787,864\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.122%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.774%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Finished fine tuning.\n",
      "Iteration 162/1723 finished in 0m16s\n",
      "Total channels prunned so far: 162\n",
      "\n",
      "Iteration 163 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 195)]\n",
      "Input: 0.115 MB, Params: 3,963,493 (15.120 MB), Total: 15.23 MB, FLOPs: 376,620,896\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.986%\n",
      "Finished fine tuning.\n",
      "Iteration 163/1723 finished in 0m17s\n",
      "Total channels prunned so far: 163\n",
      "\n",
      "Iteration 164 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 37)]\n",
      "Input: 0.115 MB, Params: 3,957,092 (15.095 MB), Total: 15.21 MB, FLOPs: 376,270,760\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.122%\n",
      "Finished fine tuning.\n",
      "Iteration 164/1723 finished in 0m17s\n",
      "Total channels prunned so far: 164\n",
      "\n",
      "Iteration 165 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 46)]\n",
      "Input: 0.115 MB, Params: 3,953,805 (15.083 MB), Total: 15.20 MB, FLOPs: 375,915,872\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.122%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Finished fine tuning.\n",
      "Iteration 165/1723 finished in 0m17s\n",
      "Total channels prunned so far: 165\n",
      "\n",
      "Iteration 166 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 139)]\n",
      "Input: 0.115 MB, Params: 3,947,413 (15.058 MB), Total: 15.17 MB, FLOPs: 375,566,708\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.774%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Finished fine tuning.\n",
      "Iteration 166/1723 finished in 0m17s\n",
      "Total channels prunned so far: 166\n",
      "\n",
      "Iteration 167 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 174)]\n",
      "Input: 0.115 MB, Params: 3,943,196 (15.042 MB), Total: 15.16 MB, FLOPs: 375,452,929\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Finished fine tuning.\n",
      "Iteration 167/1723 finished in 0m17s\n",
      "Total channels prunned so far: 167\n",
      "\n",
      "Iteration 168 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 6)]\n",
      "Input: 0.115 MB, Params: 3,941,520 (15.036 MB), Total: 15.15 MB, FLOPs: 374,709,229\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.122%\n",
      "Finished fine tuning.\n",
      "Iteration 168/1723 finished in 0m16s\n",
      "Total channels prunned so far: 168\n",
      "\n",
      "Iteration 169 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 311)]\n",
      "Input: 0.115 MB, Params: 3,937,303 (15.020 MB), Total: 15.13 MB, FLOPs: 374,595,450\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.774%\n",
      "Finished fine tuning.\n",
      "Iteration 169/1723 finished in 0m17s\n",
      "Total channels prunned so far: 169\n",
      "\n",
      "Iteration 170 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 23)]\n",
      "Input: 0.115 MB, Params: 3,935,627 (15.013 MB), Total: 15.13 MB, FLOPs: 373,851,750\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.122%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Finished fine tuning.\n",
      "Iteration 170/1723 finished in 0m16s\n",
      "Total channels prunned so far: 170\n",
      "\n",
      "Iteration 171 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 202)]\n",
      "Input: 0.115 MB, Params: 3,932,349 (15.001 MB), Total: 15.12 MB, FLOPs: 373,497,834\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.774%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Finished fine tuning.\n",
      "Iteration 171/1723 finished in 0m16s\n",
      "Total channels prunned so far: 171\n",
      "\n",
      "Iteration 172 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 375)]\n",
      "Input: 0.115 MB, Params: 3,928,132 (14.985 MB), Total: 15.10 MB, FLOPs: 373,384,055\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Finished fine tuning.\n",
      "Iteration 172/1723 finished in 0m17s\n",
      "Total channels prunned so far: 172\n",
      "\n",
      "Iteration 173 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 88)]\n",
      "Input: 0.115 MB, Params: 3,921,992 (14.961 MB), Total: 15.08 MB, FLOPs: 373,218,302\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Finished fine tuning.\n",
      "Iteration 173/1723 finished in 0m16s\n",
      "Total channels prunned so far: 173\n",
      "\n",
      "Iteration 174 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 254)]\n",
      "Input: 0.115 MB, Params: 3,917,784 (14.945 MB), Total: 15.06 MB, FLOPs: 373,104,766\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.774%\n",
      "Finished fine tuning.\n",
      "Iteration 174/1723 finished in 0m17s\n",
      "Total channels prunned so far: 174\n",
      "\n",
      "Iteration 175 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 114)]\n",
      "Input: 0.115 MB, Params: 3,914,506 (14.933 MB), Total: 15.05 MB, FLOPs: 372,378,130\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Finished fine tuning.\n",
      "Iteration 175/1723 finished in 0m17s\n",
      "Total channels prunned so far: 175\n",
      "\n",
      "Iteration 176 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 240)]\n",
      "Input: 0.115 MB, Params: 3,911,237 (14.920 MB), Total: 15.04 MB, FLOPs: 372,025,186\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.774%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Finished fine tuning.\n",
      "Iteration 176/1723 finished in 0m16s\n",
      "Total channels prunned so far: 176\n",
      "\n",
      "Iteration 177 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 15)]\n",
      "Input: 0.115 MB, Params: 3,907,029 (14.904 MB), Total: 15.02 MB, FLOPs: 371,911,650\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.774%\n",
      "Finished fine tuning.\n",
      "Iteration 177/1723 finished in 0m17s\n",
      "Total channels prunned so far: 177\n",
      "\n",
      "Iteration 178 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 416)]\n",
      "Input: 0.115 MB, Params: 3,902,821 (14.888 MB), Total: 15.00 MB, FLOPs: 371,798,114\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.819%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Finished fine tuning.\n",
      "Iteration 178/1723 finished in 0m17s\n",
      "Total channels prunned so far: 178\n",
      "\n",
      "Iteration 179 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 67)]\n",
      "Input: 0.115 MB, Params: 3,896,456 (14.864 MB), Total: 14.98 MB, FLOPs: 371,451,137\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Finished fine tuning.\n",
      "Iteration 179/1723 finished in 0m16s\n",
      "Total channels prunned so far: 179\n",
      "\n",
      "Iteration 180 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 32)]\n",
      "Input: 0.115 MB, Params: 3,892,248 (14.848 MB), Total: 14.96 MB, FLOPs: 371,337,601\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Finished fine tuning.\n",
      "Iteration 180/1723 finished in 0m16s\n",
      "Total channels prunned so far: 180\n",
      "\n",
      "Iteration 181 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 380)]\n",
      "Input: 0.115 MB, Params: 3,888,040 (14.832 MB), Total: 14.95 MB, FLOPs: 371,224,065\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.774%\n",
      "Finished fine tuning.\n",
      "Iteration 181/1723 finished in 0m17s\n",
      "Total channels prunned so far: 181\n",
      "\n",
      "Iteration 182 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 415)]\n",
      "Input: 0.115 MB, Params: 3,881,954 (14.808 MB), Total: 14.92 MB, FLOPs: 371,059,770\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.774%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Finished fine tuning.\n",
      "Iteration 182/1723 finished in 0m16s\n",
      "Total channels prunned so far: 182\n",
      "\n",
      "Iteration 183 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 41)]\n",
      "Input: 0.115 MB, Params: 3,878,694 (14.796 MB), Total: 14.91 MB, FLOPs: 370,707,798\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.122%\n",
      "Finished fine tuning.\n",
      "Iteration 183/1723 finished in 0m17s\n",
      "Total channels prunned so far: 183\n",
      "\n",
      "Iteration 184 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 8)]\n",
      "Input: 0.115 MB, Params: 3,874,495 (14.780 MB), Total: 14.90 MB, FLOPs: 370,594,505\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.774%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.819%\n",
      "Finished fine tuning.\n",
      "Iteration 184/1723 finished in 0m17s\n",
      "Total channels prunned so far: 184\n",
      "\n",
      "Iteration 185 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 29)]\n",
      "Input: 0.115 MB, Params: 3,871,235 (14.768 MB), Total: 14.88 MB, FLOPs: 370,242,533\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.819%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Finished fine tuning.\n",
      "Iteration 185/1723 finished in 0m17s\n",
      "Total channels prunned so far: 185\n",
      "\n",
      "Iteration 186 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 190)]\n",
      "Input: 0.115 MB, Params: 3,867,036 (14.752 MB), Total: 14.87 MB, FLOPs: 370,129,240\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Finished fine tuning.\n",
      "Iteration 186/1723 finished in 0m17s\n",
      "Total channels prunned so far: 186\n",
      "\n",
      "Iteration 187 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 398)]\n",
      "Input: 0.115 MB, Params: 3,860,968 (14.728 MB), Total: 14.84 MB, FLOPs: 369,965,431\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.774%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Finished fine tuning.\n",
      "Iteration 187/1723 finished in 0m17s\n",
      "Total channels prunned so far: 187\n",
      "\n",
      "Iteration 188 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 39)]\n",
      "Input: 0.115 MB, Params: 3,854,900 (14.705 MB), Total: 14.82 MB, FLOPs: 369,801,622\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.774%\n",
      "Finished fine tuning.\n",
      "Iteration 188/1723 finished in 0m17s\n",
      "Total channels prunned so far: 188\n",
      "\n",
      "Iteration 189 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 187)]\n",
      "Input: 0.115 MB, Params: 3,848,832 (14.682 MB), Total: 14.80 MB, FLOPs: 369,637,813\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.470%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Finished fine tuning.\n",
      "Iteration 189/1723 finished in 0m17s\n",
      "Total channels prunned so far: 189\n",
      "\n",
      "Iteration 190 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 50)]\n",
      "Input: 0.115 MB, Params: 3,844,660 (14.666 MB), Total: 14.78 MB, FLOPs: 369,525,249\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.122%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.774%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Finished fine tuning.\n",
      "Iteration 190/1723 finished in 0m17s\n",
      "Total channels prunned so far: 190\n",
      "\n",
      "Iteration 191 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 52)]\n",
      "Input: 0.115 MB, Params: 3,843,821 (14.663 MB), Total: 14.78 MB, FLOPs: 367,953,999\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Finished fine tuning.\n",
      "Iteration 191/1723 finished in 0m17s\n",
      "Total channels prunned so far: 191\n",
      "\n",
      "Iteration 192 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 235)]\n",
      "Input: 0.115 MB, Params: 3,839,649 (14.647 MB), Total: 14.76 MB, FLOPs: 367,841,435\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.122%\n",
      "Finished fine tuning.\n",
      "Iteration 192/1723 finished in 0m17s\n",
      "Total channels prunned so far: 192\n",
      "\n",
      "Iteration 193 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 38)]\n",
      "Input: 0.115 MB, Params: 3,835,477 (14.631 MB), Total: 14.75 MB, FLOPs: 367,728,871\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.774%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Finished fine tuning.\n",
      "Iteration 193/1723 finished in 0m16s\n",
      "Total channels prunned so far: 193\n",
      "\n",
      "Iteration 194 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 155)]\n",
      "Input: 0.115 MB, Params: 3,829,436 (14.608 MB), Total: 14.72 MB, FLOPs: 367,565,791\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.774%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.122%\n",
      "Finished fine tuning.\n",
      "Iteration 194/1723 finished in 0m17s\n",
      "Total channels prunned so far: 194\n",
      "\n",
      "Iteration 195 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 118)]\n",
      "Input: 0.115 MB, Params: 3,826,185 (14.596 MB), Total: 14.71 MB, FLOPs: 366,842,071\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Finished fine tuning.\n",
      "Iteration 195/1723 finished in 0m16s\n",
      "Total channels prunned so far: 195\n",
      "\n",
      "Iteration 196 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 289)]\n",
      "Input: 0.115 MB, Params: 3,822,022 (14.580 MB), Total: 14.70 MB, FLOPs: 366,729,750\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Finished fine tuning.\n",
      "Iteration 196/1723 finished in 0m17s\n",
      "Total channels prunned so far: 196\n",
      "\n",
      "Iteration 197 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 427)]\n",
      "Input: 0.115 MB, Params: 3,815,990 (14.557 MB), Total: 14.67 MB, FLOPs: 366,566,913\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.941%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.592%\n",
      "Finished fine tuning.\n",
      "Iteration 197/1723 finished in 0m17s\n",
      "Total channels prunned so far: 197\n",
      "\n",
      "Iteration 198 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 182)]\n",
      "Input: 0.115 MB, Params: 3,811,836 (14.541 MB), Total: 14.66 MB, FLOPs: 366,454,835\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Finished fine tuning.\n",
      "Iteration 198/1723 finished in 0m16s\n",
      "Total channels prunned so far: 198\n",
      "\n",
      "Iteration 199 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 450)]\n",
      "Input: 0.115 MB, Params: 3,805,813 (14.518 MB), Total: 14.63 MB, FLOPs: 366,292,241\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.122%\n",
      "Finished fine tuning.\n",
      "Iteration 199/1723 finished in 0m17s\n",
      "Total channels prunned so far: 199\n",
      "\n",
      "Iteration 200 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 62)]\n",
      "Input: 0.115 MB, Params: 3,799,529 (14.494 MB), Total: 14.61 MB, FLOPs: 365,948,909\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.122%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.774%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Finished fine tuning.\n",
      "Iteration 200/1723 finished in 0m17s\n",
      "Total channels prunned so far: 200\n",
      "\n",
      "Iteration 201 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 320)]\n",
      "Input: 0.115 MB, Params: 3,795,384 (14.478 MB), Total: 14.59 MB, FLOPs: 365,837,074\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.774%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.774%\n",
      "Finished fine tuning.\n",
      "Iteration 201/1723 finished in 0m16s\n",
      "Total channels prunned so far: 201\n",
      "\n",
      "Iteration 202 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 316)]\n",
      "Input: 0.115 MB, Params: 3,789,379 (14.455 MB), Total: 14.57 MB, FLOPs: 365,674,966\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.122%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.774%\n",
      "Finished fine tuning.\n",
      "Iteration 202/1723 finished in 0m16s\n",
      "Total channels prunned so far: 202\n",
      "\n",
      "Iteration 203 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 36)]\n",
      "Input: 0.115 MB, Params: 3,783,374 (14.432 MB), Total: 14.55 MB, FLOPs: 365,512,858\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.774%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.774%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Finished fine tuning.\n",
      "Iteration 203/1723 finished in 0m16s\n",
      "Total channels prunned so far: 203\n",
      "\n",
      "Iteration 204 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 427)]\n",
      "Input: 0.115 MB, Params: 3,779,247 (14.417 MB), Total: 14.53 MB, FLOPs: 365,401,509\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.774%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.774%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Finished fine tuning.\n",
      "Iteration 204/1723 finished in 0m17s\n",
      "Total channels prunned so far: 204\n",
      "\n",
      "Iteration 205 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 358)]\n",
      "Input: 0.115 MB, Params: 3,773,251 (14.394 MB), Total: 14.51 MB, FLOPs: 365,239,644\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Finished fine tuning.\n",
      "Iteration 205/1723 finished in 0m16s\n",
      "Total channels prunned so far: 205\n",
      "\n",
      "Iteration 206 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 82)]\n",
      "Input: 0.115 MB, Params: 3,770,009 (14.381 MB), Total: 14.50 MB, FLOPs: 364,889,616\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.774%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.470%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.122%\n",
      "Finished fine tuning.\n",
      "Iteration 206/1723 finished in 0m17s\n",
      "Total channels prunned so far: 206\n",
      "\n",
      "Iteration 207 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 271)]\n",
      "Input: 0.115 MB, Params: 3,765,891 (14.366 MB), Total: 14.48 MB, FLOPs: 364,778,510\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.122%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.470%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.774%\n",
      "Finished fine tuning.\n",
      "Iteration 207/1723 finished in 0m16s\n",
      "Total channels prunned so far: 207\n",
      "\n",
      "Iteration 208 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 22)]\n",
      "Input: 0.115 MB, Params: 3,759,904 (14.343 MB), Total: 14.46 MB, FLOPs: 364,616,888\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.470%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Finished fine tuning.\n",
      "Iteration 208/1723 finished in 0m16s\n",
      "Total channels prunned so far: 208\n",
      "\n",
      "Iteration 209 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 119)]\n",
      "Input: 0.115 MB, Params: 3,756,662 (14.331 MB), Total: 14.45 MB, FLOPs: 363,894,140\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.122%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.122%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.986%\n",
      "Finished fine tuning.\n",
      "Iteration 209/1723 finished in 0m16s\n",
      "Total channels prunned so far: 209\n",
      "\n",
      "Iteration 210 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 81)]\n",
      "Input: 0.115 MB, Params: 3,752,553 (14.315 MB), Total: 14.43 MB, FLOPs: 363,783,277\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.638%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.470%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.774%\n",
      "Finished fine tuning.\n",
      "Iteration 210/1723 finished in 0m17s\n",
      "Total channels prunned so far: 210\n",
      "\n",
      "Iteration 211 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 61)]\n",
      "Input: 0.115 MB, Params: 3,750,904 (14.309 MB), Total: 14.42 MB, FLOPs: 363,051,565\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.774%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.122%\n",
      "Finished fine tuning.\n",
      "Iteration 211/1723 finished in 0m17s\n",
      "Total channels prunned so far: 211\n",
      "\n",
      "Iteration 212 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 125)]\n",
      "Input: 0.115 MB, Params: 3,746,795 (14.293 MB), Total: 14.41 MB, FLOPs: 362,940,702\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.470%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Finished fine tuning.\n",
      "Iteration 212/1723 finished in 0m17s\n",
      "Total channels prunned so far: 212\n",
      "\n",
      "Iteration 213 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 246)]\n",
      "Input: 0.115 MB, Params: 3,740,826 (14.270 MB), Total: 14.39 MB, FLOPs: 362,779,566\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.470%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.774%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.122%\n",
      "Finished fine tuning.\n",
      "Iteration 213/1723 finished in 0m17s\n",
      "Total channels prunned so far: 213\n",
      "\n",
      "Iteration 214 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 313)]\n",
      "Input: 0.115 MB, Params: 3,734,857 (14.247 MB), Total: 14.36 MB, FLOPs: 362,618,430\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.122%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Finished fine tuning.\n",
      "Iteration 214/1723 finished in 0m17s\n",
      "Total channels prunned so far: 214\n",
      "\n",
      "Iteration 215 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 181)]\n",
      "Input: 0.115 MB, Params: 3,730,766 (14.232 MB), Total: 14.35 MB, FLOPs: 362,508,053\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Finished fine tuning.\n",
      "Iteration 215/1723 finished in 0m17s\n",
      "Total channels prunned so far: 215\n",
      "\n",
      "Iteration 216 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 5)]\n",
      "Input: 0.115 MB, Params: 3,729,927 (14.229 MB), Total: 14.34 MB, FLOPs: 360,936,803\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Finished fine tuning.\n",
      "Iteration 216/1723 finished in 0m17s\n",
      "Total channels prunned so far: 216\n",
      "\n",
      "Iteration 217 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 174)]\n",
      "Input: 0.115 MB, Params: 3,725,836 (14.213 MB), Total: 14.33 MB, FLOPs: 360,826,426\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Finished fine tuning.\n",
      "Iteration 217/1723 finished in 0m17s\n",
      "Total channels prunned so far: 217\n",
      "\n",
      "Iteration 218 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 101)]\n",
      "Input: 0.115 MB, Params: 3,721,745 (14.197 MB), Total: 14.31 MB, FLOPs: 360,716,049\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Finished fine tuning.\n",
      "Iteration 218/1723 finished in 0m17s\n",
      "Total channels prunned so far: 218\n",
      "\n",
      "Iteration 219 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 110)]\n",
      "Input: 0.115 MB, Params: 3,717,654 (14.182 MB), Total: 14.30 MB, FLOPs: 360,605,672\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.774%\n",
      "Finished fine tuning.\n",
      "Iteration 219/1723 finished in 0m17s\n",
      "Total channels prunned so far: 219\n",
      "\n",
      "Iteration 220 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 366)]\n",
      "Input: 0.115 MB, Params: 3,711,721 (14.159 MB), Total: 14.27 MB, FLOPs: 360,445,508\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.774%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.774%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Finished fine tuning.\n",
      "Iteration 220/1723 finished in 0m17s\n",
      "Total channels prunned so far: 220\n",
      "\n",
      "Iteration 221 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 80)]\n",
      "Input: 0.115 MB, Params: 3,710,072 (14.153 MB), Total: 14.27 MB, FLOPs: 359,713,796\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Finished fine tuning.\n",
      "Iteration 221/1723 finished in 0m16s\n",
      "Total channels prunned so far: 221\n",
      "\n",
      "Iteration 222 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 120)]\n",
      "Input: 0.115 MB, Params: 3,705,990 (14.137 MB), Total: 14.25 MB, FLOPs: 359,603,662\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.122%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.774%\n",
      "Finished fine tuning.\n",
      "Iteration 222/1723 finished in 0m17s\n",
      "Total channels prunned so far: 222\n",
      "\n",
      "Iteration 223 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 400)]\n",
      "Input: 0.115 MB, Params: 3,700,066 (14.115 MB), Total: 14.23 MB, FLOPs: 359,443,741\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.774%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.122%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Finished fine tuning.\n",
      "Iteration 223/1723 finished in 0m16s\n",
      "Total channels prunned so far: 223\n",
      "\n",
      "Iteration 224 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 94)]\n",
      "Input: 0.115 MB, Params: 3,698,417 (14.108 MB), Total: 14.22 MB, FLOPs: 358,712,029\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.774%\n",
      "Finished fine tuning.\n",
      "Iteration 224/1723 finished in 0m17s\n",
      "Total channels prunned so far: 224\n",
      "\n",
      "Iteration 225 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 174)]\n",
      "Input: 0.115 MB, Params: 3,692,214 (14.085 MB), Total: 14.20 MB, FLOPs: 358,371,613\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.774%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Finished fine tuning.\n",
      "Iteration 225/1723 finished in 0m17s\n",
      "Total channels prunned so far: 225\n",
      "\n",
      "Iteration 226 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 19)]\n",
      "Input: 0.115 MB, Params: 3,686,299 (14.062 MB), Total: 14.18 MB, FLOPs: 358,211,935\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Finished fine tuning.\n",
      "Iteration 226/1723 finished in 0m17s\n",
      "Total channels prunned so far: 226\n",
      "\n",
      "Iteration 227 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 186)]\n",
      "Input: 0.115 MB, Params: 3,683,075 (14.050 MB), Total: 14.17 MB, FLOPs: 357,863,851\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.774%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Finished fine tuning.\n",
      "Iteration 227/1723 finished in 0m17s\n",
      "Total channels prunned so far: 227\n",
      "\n",
      "Iteration 228 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 44)]\n",
      "Input: 0.115 MB, Params: 3,682,236 (14.047 MB), Total: 14.16 MB, FLOPs: 356,292,601\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Finished fine tuning.\n",
      "Iteration 228/1723 finished in 0m17s\n",
      "Total channels prunned so far: 228\n",
      "\n",
      "Iteration 229 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 341)]\n",
      "Input: 0.115 MB, Params: 3,676,321 (14.024 MB), Total: 14.14 MB, FLOPs: 356,132,923\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Finished fine tuning.\n",
      "Iteration 229/1723 finished in 0m17s\n",
      "Total channels prunned so far: 229\n",
      "\n",
      "Iteration 230 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(7, 19)]\n",
      "Input: 0.115 MB, Params: 3,675,770 (14.022 MB), Total: 14.14 MB, FLOPs: 355,037,423\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.470%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.470%\n",
      "Finished fine tuning.\n",
      "Iteration 230/1723 finished in 0m16s\n",
      "Total channels prunned so far: 230\n",
      "\n",
      "Iteration 231 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 142)]\n",
      "Input: 0.115 MB, Params: 3,671,715 (14.006 MB), Total: 14.12 MB, FLOPs: 354,928,018\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.470%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.774%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.774%\n",
      "Finished fine tuning.\n",
      "Iteration 231/1723 finished in 0m16s\n",
      "Total channels prunned so far: 231\n",
      "\n",
      "Iteration 232 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 199)]\n",
      "Input: 0.115 MB, Params: 3,665,539 (13.983 MB), Total: 14.10 MB, FLOPs: 354,589,060\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Finished fine tuning.\n",
      "Iteration 232/1723 finished in 0m16s\n",
      "Total channels prunned so far: 232\n",
      "\n",
      "Iteration 233 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 210)]\n",
      "Input: 0.115 MB, Params: 3,659,642 (13.960 MB), Total: 14.08 MB, FLOPs: 354,429,868\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.167%\n",
      "Finished fine tuning.\n",
      "Iteration 233/1723 finished in 0m17s\n",
      "Total channels prunned so far: 233\n",
      "\n",
      "Iteration 234 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 179)]\n",
      "Input: 0.115 MB, Params: 3,656,427 (13.948 MB), Total: 14.06 MB, FLOPs: 354,082,756\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.819%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.122%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.819%\n",
      "Finished fine tuning.\n",
      "Iteration 234/1723 finished in 0m16s\n",
      "Total channels prunned so far: 234\n",
      "\n",
      "Iteration 235 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 31)]\n",
      "Input: 0.115 MB, Params: 3,653,230 (13.936 MB), Total: 14.05 MB, FLOPs: 353,373,940\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Finished fine tuning.\n",
      "Iteration 235/1723 finished in 0m17s\n",
      "Total channels prunned so far: 235\n",
      "\n",
      "Iteration 236 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 159)]\n",
      "Input: 0.115 MB, Params: 3,647,333 (13.913 MB), Total: 14.03 MB, FLOPs: 353,214,748\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Finished fine tuning.\n",
      "Iteration 236/1723 finished in 0m17s\n",
      "Total channels prunned so far: 236\n",
      "\n",
      "Iteration 237 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 17)]\n",
      "Input: 0.115 MB, Params: 3,643,296 (13.898 MB), Total: 14.01 MB, FLOPs: 353,105,829\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.774%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.122%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Finished fine tuning.\n",
      "Iteration 237/1723 finished in 0m17s\n",
      "Total channels prunned so far: 237\n",
      "\n",
      "Iteration 238 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 97)]\n",
      "Input: 0.115 MB, Params: 3,641,656 (13.892 MB), Total: 14.01 MB, FLOPs: 352,378,113\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.122%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.122%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Finished fine tuning.\n",
      "Iteration 238/1723 finished in 0m17s\n",
      "Total channels prunned so far: 238\n",
      "\n",
      "Iteration 239 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 375)]\n",
      "Input: 0.115 MB, Params: 3,637,619 (13.876 MB), Total: 13.99 MB, FLOPs: 352,269,194\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Finished fine tuning.\n",
      "Iteration 239/1723 finished in 0m17s\n",
      "Total channels prunned so far: 239\n",
      "\n",
      "Iteration 240 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 176)]\n",
      "Input: 0.115 MB, Params: 3,634,413 (13.864 MB), Total: 13.98 MB, FLOPs: 351,923,054\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Finished fine tuning.\n",
      "Iteration 240/1723 finished in 0m16s\n",
      "Total channels prunned so far: 240\n",
      "\n",
      "Iteration 241 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 412)]\n",
      "Input: 0.115 MB, Params: 3,628,534 (13.842 MB), Total: 13.96 MB, FLOPs: 351,764,348\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Finished fine tuning.\n",
      "Iteration 241/1723 finished in 0m16s\n",
      "Total channels prunned so far: 241\n",
      "\n",
      "Iteration 242 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 335)]\n",
      "Input: 0.115 MB, Params: 3,622,655 (13.819 MB), Total: 13.93 MB, FLOPs: 351,605,642\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.289%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.638%\n",
      "Finished fine tuning.\n",
      "Iteration 242/1723 finished in 0m17s\n",
      "Total channels prunned so far: 242\n",
      "\n",
      "Iteration 243 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 202)]\n",
      "Input: 0.115 MB, Params: 3,618,636 (13.804 MB), Total: 13.92 MB, FLOPs: 351,497,209\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.774%\n",
      "Finished fine tuning.\n",
      "Iteration 243/1723 finished in 0m16s\n",
      "Total channels prunned so far: 243\n",
      "\n",
      "Iteration 244 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 136)]\n",
      "Input: 0.115 MB, Params: 3,614,617 (13.789 MB), Total: 13.90 MB, FLOPs: 351,388,776\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.470%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.774%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.819%\n",
      "Finished fine tuning.\n",
      "Iteration 244/1723 finished in 0m17s\n",
      "Total channels prunned so far: 244\n",
      "\n",
      "Iteration 245 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 65)]\n",
      "Input: 0.115 MB, Params: 3,611,411 (13.776 MB), Total: 13.89 MB, FLOPs: 351,042,636\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.819%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Finished fine tuning.\n",
      "Iteration 245/1723 finished in 0m16s\n",
      "Total channels prunned so far: 245\n",
      "\n",
      "Iteration 246 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 296)]\n",
      "Input: 0.115 MB, Params: 3,607,392 (13.761 MB), Total: 13.88 MB, FLOPs: 350,934,203\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Finished fine tuning.\n",
      "Iteration 246/1723 finished in 0m16s\n",
      "Total channels prunned so far: 246\n",
      "\n",
      "Iteration 247 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 351)]\n",
      "Input: 0.115 MB, Params: 3,601,540 (13.739 MB), Total: 13.85 MB, FLOPs: 350,776,226\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.774%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Finished fine tuning.\n",
      "Iteration 247/1723 finished in 0m17s\n",
      "Total channels prunned so far: 247\n",
      "\n",
      "Iteration 248 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 231)]\n",
      "Input: 0.115 MB, Params: 3,595,436 (13.715 MB), Total: 13.83 MB, FLOPs: 350,441,399\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.819%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Finished fine tuning.\n",
      "Iteration 248/1723 finished in 0m17s\n",
      "Total channels prunned so far: 248\n",
      "\n",
      "Iteration 249 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 16)]\n",
      "Input: 0.115 MB, Params: 3,591,426 (13.700 MB), Total: 13.82 MB, FLOPs: 350,333,209\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.122%\n",
      "Finished fine tuning.\n",
      "Iteration 249/1723 finished in 0m16s\n",
      "Total channels prunned so far: 249\n",
      "\n",
      "Iteration 250 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 118)]\n",
      "Input: 0.115 MB, Params: 3,585,322 (13.677 MB), Total: 13.79 MB, FLOPs: 349,998,382\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.122%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Finished fine tuning.\n",
      "Iteration 250/1723 finished in 0m17s\n",
      "Total channels prunned so far: 250\n",
      "\n",
      "Iteration 251 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 206)]\n",
      "Input: 0.115 MB, Params: 3,579,497 (13.655 MB), Total: 13.77 MB, FLOPs: 349,841,134\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.122%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Finished fine tuning.\n",
      "Iteration 251/1723 finished in 0m17s\n",
      "Total channels prunned so far: 251\n",
      "\n",
      "Iteration 252 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 324)]\n",
      "Input: 0.115 MB, Params: 3,575,496 (13.639 MB), Total: 13.75 MB, FLOPs: 349,733,187\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Finished fine tuning.\n",
      "Iteration 252/1723 finished in 0m17s\n",
      "Total channels prunned so far: 252\n",
      "\n",
      "Iteration 253 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 412)]\n",
      "Input: 0.115 MB, Params: 3,569,680 (13.617 MB), Total: 13.73 MB, FLOPs: 349,576,182\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Finished fine tuning.\n",
      "Iteration 253/1723 finished in 0m16s\n",
      "Total channels prunned so far: 253\n",
      "\n",
      "Iteration 254 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 260)]\n",
      "Input: 0.115 MB, Params: 3,565,688 (13.602 MB), Total: 13.72 MB, FLOPs: 349,468,478\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Finished fine tuning.\n",
      "Iteration 254/1723 finished in 0m17s\n",
      "Total channels prunned so far: 254\n",
      "\n",
      "Iteration 255 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(14, 51)]\n",
      "Input: 0.115 MB, Params: 3,564,075 (13.596 MB), Total: 13.71 MB, FLOPs: 347,976,803\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Finished fine tuning.\n",
      "Iteration 255/1723 finished in 0m16s\n",
      "Total channels prunned so far: 255\n",
      "\n",
      "Iteration 256 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 43)]\n",
      "Input: 0.115 MB, Params: 3,558,268 (13.574 MB), Total: 13.69 MB, FLOPs: 347,820,041\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Finished fine tuning.\n",
      "Iteration 256/1723 finished in 0m17s\n",
      "Total channels prunned so far: 256\n",
      "\n",
      "Iteration 257 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 281)]\n",
      "Input: 0.115 MB, Params: 3,552,461 (13.552 MB), Total: 13.67 MB, FLOPs: 347,663,279\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.470%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Finished fine tuning.\n",
      "Iteration 257/1723 finished in 0m17s\n",
      "Total channels prunned so far: 257\n",
      "\n",
      "Iteration 258 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 178)]\n",
      "Input: 0.115 MB, Params: 3,546,393 (13.528 MB), Total: 13.64 MB, FLOPs: 347,329,424\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Finished fine tuning.\n",
      "Iteration 258/1723 finished in 0m17s\n",
      "Total channels prunned so far: 258\n",
      "\n",
      "Iteration 259 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 5)]\n",
      "Input: 0.115 MB, Params: 3,540,325 (13.505 MB), Total: 13.62 MB, FLOPs: 346,995,569\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.774%\n",
      "Finished fine tuning.\n",
      "Iteration 259/1723 finished in 0m17s\n",
      "Total channels prunned so far: 259\n",
      "\n",
      "Iteration 260 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 159)]\n",
      "Input: 0.115 MB, Params: 3,537,155 (13.493 MB), Total: 13.61 MB, FLOPs: 346,653,317\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Finished fine tuning.\n",
      "Iteration 260/1723 finished in 0m16s\n",
      "Total channels prunned so far: 260\n",
      "\n",
      "Iteration 261 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 230)]\n",
      "Input: 0.115 MB, Params: 3,531,366 (13.471 MB), Total: 13.59 MB, FLOPs: 346,497,041\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.122%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Finished fine tuning.\n",
      "Iteration 261/1723 finished in 0m16s\n",
      "Total channels prunned so far: 261\n",
      "\n",
      "Iteration 262 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 203)]\n",
      "Input: 0.115 MB, Params: 3,525,577 (13.449 MB), Total: 13.56 MB, FLOPs: 346,340,765\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.122%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Finished fine tuning.\n",
      "Iteration 262/1723 finished in 0m17s\n",
      "Total channels prunned so far: 262\n",
      "\n",
      "Iteration 263 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 91)]\n",
      "Input: 0.115 MB, Params: 3,523,946 (13.443 MB), Total: 13.56 MB, FLOPs: 345,617,045\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Finished fine tuning.\n",
      "Iteration 263/1723 finished in 0m16s\n",
      "Total channels prunned so far: 263\n",
      "\n",
      "Iteration 264 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 29)]\n",
      "Input: 0.115 MB, Params: 3,523,125 (13.440 MB), Total: 13.55 MB, FLOPs: 344,079,545\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Finished fine tuning.\n",
      "Iteration 264/1723 finished in 0m17s\n",
      "Total channels prunned so far: 264\n",
      "\n",
      "Iteration 265 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 138)]\n",
      "Input: 0.115 MB, Params: 3,519,955 (13.428 MB), Total: 13.54 MB, FLOPs: 343,737,293\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.122%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Finished fine tuning.\n",
      "Iteration 265/1723 finished in 0m16s\n",
      "Total channels prunned so far: 265\n",
      "\n",
      "Iteration 266 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 70)]\n",
      "Input: 0.115 MB, Params: 3,515,999 (13.412 MB), Total: 13.53 MB, FLOPs: 343,630,561\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Finished fine tuning.\n",
      "Iteration 266/1723 finished in 0m16s\n",
      "Total channels prunned so far: 266\n",
      "\n",
      "Iteration 267 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 5)]\n",
      "Input: 0.115 MB, Params: 3,514,368 (13.406 MB), Total: 13.52 MB, FLOPs: 342,906,841\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Finished fine tuning.\n",
      "Iteration 267/1723 finished in 0m17s\n",
      "Total channels prunned so far: 267\n",
      "\n",
      "Iteration 268 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 188)]\n",
      "Input: 0.115 MB, Params: 3,508,588 (13.384 MB), Total: 13.50 MB, FLOPs: 342,750,808\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Finished fine tuning.\n",
      "Iteration 268/1723 finished in 0m17s\n",
      "Total channels prunned so far: 268\n",
      "\n",
      "Iteration 269 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 125)]\n",
      "Input: 0.115 MB, Params: 3,505,418 (13.372 MB), Total: 13.49 MB, FLOPs: 342,408,556\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.774%\n",
      "Finished fine tuning.\n",
      "Iteration 269/1723 finished in 0m17s\n",
      "Total channels prunned so far: 269\n",
      "\n",
      "Iteration 270 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 193)]\n",
      "Input: 0.115 MB, Params: 3,502,248 (13.360 MB), Total: 13.48 MB, FLOPs: 342,066,304\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.774%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Finished fine tuning.\n",
      "Iteration 270/1723 finished in 0m17s\n",
      "Total channels prunned so far: 270\n",
      "\n",
      "Iteration 271 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 377)]\n",
      "Input: 0.115 MB, Params: 3,498,301 (13.345 MB), Total: 13.46 MB, FLOPs: 341,959,815\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.774%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Finished fine tuning.\n",
      "Iteration 271/1723 finished in 0m16s\n",
      "Total channels prunned so far: 271\n",
      "\n",
      "Iteration 272 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 276)]\n",
      "Input: 0.115 MB, Params: 3,492,530 (13.323 MB), Total: 13.44 MB, FLOPs: 341,804,025\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.122%\n",
      "Finished fine tuning.\n",
      "Iteration 272/1723 finished in 0m17s\n",
      "Total channels prunned so far: 272\n",
      "\n",
      "Iteration 273 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 146)]\n",
      "Input: 0.115 MB, Params: 3,486,759 (13.301 MB), Total: 13.42 MB, FLOPs: 341,648,235\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.470%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Finished fine tuning.\n",
      "Iteration 273/1723 finished in 0m16s\n",
      "Total channels prunned so far: 273\n",
      "\n",
      "Iteration 274 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 338)]\n",
      "Input: 0.115 MB, Params: 3,482,830 (13.286 MB), Total: 13.40 MB, FLOPs: 341,542,232\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.774%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.819%\n",
      "Finished fine tuning.\n",
      "Iteration 274/1723 finished in 0m17s\n",
      "Total channels prunned so far: 274\n",
      "\n",
      "Iteration 275 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 221)]\n",
      "Input: 0.115 MB, Params: 3,477,068 (13.264 MB), Total: 13.38 MB, FLOPs: 341,386,685\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.819%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.774%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.122%\n",
      "Finished fine tuning.\n",
      "Iteration 275/1723 finished in 0m17s\n",
      "Total channels prunned so far: 275\n",
      "\n",
      "Iteration 276 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 172)]\n",
      "Input: 0.115 MB, Params: 3,473,148 (13.249 MB), Total: 13.36 MB, FLOPs: 341,280,925\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.122%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.122%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Finished fine tuning.\n",
      "Iteration 276/1723 finished in 0m17s\n",
      "Total channels prunned so far: 276\n",
      "\n",
      "Iteration 277 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 315)]\n",
      "Input: 0.115 MB, Params: 3,469,228 (13.234 MB), Total: 13.35 MB, FLOPs: 341,175,165\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.774%\n",
      "Finished fine tuning.\n",
      "Iteration 277/1723 finished in 0m17s\n",
      "Total channels prunned so far: 277\n",
      "\n",
      "Iteration 278 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 96)]\n",
      "Input: 0.115 MB, Params: 3,467,597 (13.228 MB), Total: 13.34 MB, FLOPs: 340,451,445\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Finished fine tuning.\n",
      "Iteration 278/1723 finished in 0m17s\n",
      "Total channels prunned so far: 278\n",
      "\n",
      "Iteration 279 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 305)]\n",
      "Input: 0.115 MB, Params: 3,463,677 (13.213 MB), Total: 13.33 MB, FLOPs: 340,345,685\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Finished fine tuning.\n",
      "Iteration 279/1723 finished in 0m17s\n",
      "Total channels prunned so far: 279\n",
      "\n",
      "Iteration 280 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 21)]\n",
      "Input: 0.115 MB, Params: 3,460,507 (13.201 MB), Total: 13.32 MB, FLOPs: 340,003,433\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Finished fine tuning.\n",
      "Iteration 280/1723 finished in 0m17s\n",
      "Total channels prunned so far: 280\n",
      "\n",
      "Iteration 281 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 284)]\n",
      "Input: 0.115 MB, Params: 3,454,772 (13.179 MB), Total: 13.29 MB, FLOPs: 339,848,615\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Finished fine tuning.\n",
      "Iteration 281/1723 finished in 0m17s\n",
      "Total channels prunned so far: 281\n",
      "\n",
      "Iteration 282 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 83)]\n",
      "Input: 0.115 MB, Params: 3,448,812 (13.156 MB), Total: 13.27 MB, FLOPs: 339,521,321\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Finished fine tuning.\n",
      "Iteration 282/1723 finished in 0m17s\n",
      "Total channels prunned so far: 282\n",
      "\n",
      "Iteration 283 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 329)]\n",
      "Input: 0.115 MB, Params: 3,444,901 (13.141 MB), Total: 13.26 MB, FLOPs: 339,415,804\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.774%\n",
      "Finished fine tuning.\n",
      "Iteration 283/1723 finished in 0m17s\n",
      "Total channels prunned so far: 283\n",
      "\n",
      "Iteration 284 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 112)]\n",
      "Input: 0.115 MB, Params: 3,441,740 (13.129 MB), Total: 13.24 MB, FLOPs: 339,074,524\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Finished fine tuning.\n",
      "Iteration 284/1723 finished in 0m17s\n",
      "Total channels prunned so far: 284\n",
      "\n",
      "Iteration 285 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 210)]\n",
      "Input: 0.115 MB, Params: 3,436,023 (13.107 MB), Total: 13.22 MB, FLOPs: 338,920,192\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Finished fine tuning.\n",
      "Iteration 285/1723 finished in 0m17s\n",
      "Total channels prunned so far: 285\n",
      "\n",
      "Iteration 286 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 63)]\n",
      "Input: 0.115 MB, Params: 3,432,862 (13.095 MB), Total: 13.21 MB, FLOPs: 338,578,912\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Finished fine tuning.\n",
      "Iteration 286/1723 finished in 0m17s\n",
      "Total channels prunned so far: 286\n",
      "\n",
      "Iteration 287 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 50)]\n",
      "Input: 0.115 MB, Params: 3,427,145 (13.074 MB), Total: 13.19 MB, FLOPs: 338,424,580\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Finished fine tuning.\n",
      "Iteration 287/1723 finished in 0m16s\n",
      "Total channels prunned so far: 287\n",
      "\n",
      "Iteration 288 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 46)]\n",
      "Input: 0.115 MB, Params: 3,421,221 (13.051 MB), Total: 13.17 MB, FLOPs: 338,099,716\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.774%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.774%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Finished fine tuning.\n",
      "Iteration 288/1723 finished in 0m17s\n",
      "Total channels prunned so far: 288\n",
      "\n",
      "Iteration 289 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 30)]\n",
      "Input: 0.115 MB, Params: 3,415,513 (13.029 MB), Total: 13.14 MB, FLOPs: 337,945,627\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Finished fine tuning.\n",
      "Iteration 289/1723 finished in 0m17s\n",
      "Total channels prunned so far: 289\n",
      "\n",
      "Iteration 290 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 52)]\n",
      "Input: 0.115 MB, Params: 3,412,361 (13.017 MB), Total: 13.13 MB, FLOPs: 337,605,319\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Finished fine tuning.\n",
      "Iteration 290/1723 finished in 0m17s\n",
      "Total channels prunned so far: 290\n",
      "\n",
      "Iteration 291 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 291)]\n",
      "Input: 0.115 MB, Params: 3,406,653 (12.995 MB), Total: 13.11 MB, FLOPs: 337,451,230\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Finished fine tuning.\n",
      "Iteration 291/1723 finished in 0m17s\n",
      "Total channels prunned so far: 291\n",
      "\n",
      "Iteration 292 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 213)]\n",
      "Input: 0.115 MB, Params: 3,400,945 (12.974 MB), Total: 13.09 MB, FLOPs: 337,297,141\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Finished fine tuning.\n",
      "Iteration 292/1723 finished in 0m17s\n",
      "Total channels prunned so far: 292\n",
      "\n",
      "Iteration 293 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 93)]\n",
      "Input: 0.115 MB, Params: 3,397,079 (12.959 MB), Total: 13.07 MB, FLOPs: 337,192,839\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Finished fine tuning.\n",
      "Iteration 293/1723 finished in 0m16s\n",
      "Total channels prunned so far: 293\n",
      "\n",
      "Iteration 294 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 400)]\n",
      "Input: 0.115 MB, Params: 3,393,213 (12.944 MB), Total: 13.06 MB, FLOPs: 337,088,537\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.774%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Finished fine tuning.\n",
      "Iteration 294/1723 finished in 0m17s\n",
      "Total channels prunned so far: 294\n",
      "\n",
      "Iteration 295 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 63)]\n",
      "Input: 0.115 MB, Params: 3,390,142 (12.932 MB), Total: 13.05 MB, FLOPs: 336,405,425\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Finished fine tuning.\n",
      "Iteration 295/1723 finished in 0m17s\n",
      "Total channels prunned so far: 295\n",
      "\n",
      "Iteration 296 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 275)]\n",
      "Input: 0.115 MB, Params: 3,384,452 (12.911 MB), Total: 13.03 MB, FLOPs: 336,251,822\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.986%\n",
      "Finished fine tuning.\n",
      "Iteration 296/1723 finished in 0m17s\n",
      "Total channels prunned so far: 296\n",
      "\n",
      "Iteration 297 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 147)]\n",
      "Input: 0.115 MB, Params: 3,381,309 (12.899 MB), Total: 13.01 MB, FLOPs: 335,912,486\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.774%\n",
      "Finished fine tuning.\n",
      "Iteration 297/1723 finished in 0m17s\n",
      "Total channels prunned so far: 297\n",
      "\n",
      "Iteration 298 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 426)]\n",
      "Input: 0.115 MB, Params: 3,375,619 (12.877 MB), Total: 12.99 MB, FLOPs: 335,758,883\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.774%\n",
      "Finished fine tuning.\n",
      "Iteration 298/1723 finished in 0m17s\n",
      "Total channels prunned so far: 298\n",
      "\n",
      "Iteration 299 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 16)]\n",
      "Input: 0.115 MB, Params: 3,371,771 (12.862 MB), Total: 12.98 MB, FLOPs: 335,655,067\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Finished fine tuning.\n",
      "Iteration 299/1723 finished in 0m17s\n",
      "Total channels prunned so far: 299\n",
      "\n",
      "Iteration 300 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 114)]\n",
      "Input: 0.115 MB, Params: 3,370,149 (12.856 MB), Total: 12.97 MB, FLOPs: 334,935,343\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Finished fine tuning.\n",
      "Iteration 300/1723 finished in 0m16s\n",
      "Total channels prunned so far: 300\n",
      "\n",
      "Iteration 301 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 152)]\n",
      "Input: 0.115 MB, Params: 3,366,301 (12.841 MB), Total: 12.96 MB, FLOPs: 334,831,527\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.774%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Finished fine tuning.\n",
      "Iteration 301/1723 finished in 0m17s\n",
      "Total channels prunned so far: 301\n",
      "\n",
      "Iteration 302 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 311)]\n",
      "Input: 0.115 MB, Params: 3,360,629 (12.820 MB), Total: 12.94 MB, FLOPs: 334,678,410\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Finished fine tuning.\n",
      "Iteration 302/1723 finished in 0m17s\n",
      "Total channels prunned so far: 302\n",
      "\n",
      "Iteration 303 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 78)]\n",
      "Input: 0.115 MB, Params: 3,354,957 (12.798 MB), Total: 12.91 MB, FLOPs: 334,525,293\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.774%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Finished fine tuning.\n",
      "Iteration 303/1723 finished in 0m17s\n",
      "Total channels prunned so far: 303\n",
      "\n",
      "Iteration 304 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 14)]\n",
      "Input: 0.115 MB, Params: 3,351,127 (12.784 MB), Total: 12.90 MB, FLOPs: 334,421,963\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.774%\n",
      "Finished fine tuning.\n",
      "Iteration 304/1723 finished in 0m17s\n",
      "Total channels prunned so far: 304\n",
      "\n",
      "Iteration 305 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 32)]\n",
      "Input: 0.115 MB, Params: 3,348,074 (12.772 MB), Total: 12.89 MB, FLOPs: 333,743,819\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Finished fine tuning.\n",
      "Iteration 305/1723 finished in 0m16s\n",
      "Total channels prunned so far: 305\n",
      "\n",
      "Iteration 306 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 119)]\n",
      "Input: 0.115 MB, Params: 3,344,940 (12.760 MB), Total: 12.88 MB, FLOPs: 333,405,455\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Finished fine tuning.\n",
      "Iteration 306/1723 finished in 0m17s\n",
      "Total channels prunned so far: 306\n",
      "\n",
      "Iteration 307 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 181)]\n",
      "Input: 0.115 MB, Params: 3,341,110 (12.745 MB), Total: 12.86 MB, FLOPs: 333,302,125\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Finished fine tuning.\n",
      "Iteration 307/1723 finished in 0m16s\n",
      "Total channels prunned so far: 307\n",
      "\n",
      "Iteration 308 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 341)]\n",
      "Input: 0.115 MB, Params: 3,337,280 (12.731 MB), Total: 12.85 MB, FLOPs: 333,198,795\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.774%\n",
      "Finished fine tuning.\n",
      "Iteration 308/1723 finished in 0m16s\n",
      "Total channels prunned so far: 308\n",
      "\n",
      "Iteration 309 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 38)]\n",
      "Input: 0.115 MB, Params: 3,335,667 (12.725 MB), Total: 12.84 MB, FLOPs: 332,483,067\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Finished fine tuning.\n",
      "Iteration 309/1723 finished in 0m16s\n",
      "Total channels prunned so far: 309\n",
      "\n",
      "Iteration 310 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 92)]\n",
      "Input: 0.115 MB, Params: 3,331,837 (12.710 MB), Total: 12.83 MB, FLOPs: 332,379,737\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.774%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Finished fine tuning.\n",
      "Iteration 310/1723 finished in 0m17s\n",
      "Total channels prunned so far: 310\n",
      "\n",
      "Iteration 311 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 10)]\n",
      "Input: 0.115 MB, Params: 3,326,201 (12.688 MB), Total: 12.80 MB, FLOPs: 332,227,592\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.774%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Finished fine tuning.\n",
      "Iteration 311/1723 finished in 0m16s\n",
      "Total channels prunned so far: 311\n",
      "\n",
      "Iteration 312 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 3)]\n",
      "Input: 0.115 MB, Params: 3,325,380 (12.685 MB), Total: 12.80 MB, FLOPs: 330,690,092\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.774%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Finished fine tuning.\n",
      "Iteration 312/1723 finished in 0m16s\n",
      "Total channels prunned so far: 312\n",
      "\n",
      "Iteration 313 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 144)]\n",
      "Input: 0.115 MB, Params: 3,319,744 (12.664 MB), Total: 12.78 MB, FLOPs: 330,537,947\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.774%\n",
      "Finished fine tuning.\n",
      "Iteration 313/1723 finished in 0m17s\n",
      "Total channels prunned so far: 313\n",
      "\n",
      "Iteration 314 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 257)]\n",
      "Input: 0.115 MB, Params: 3,315,932 (12.649 MB), Total: 12.76 MB, FLOPs: 330,435,103\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Finished fine tuning.\n",
      "Iteration 314/1723 finished in 0m17s\n",
      "Total channels prunned so far: 314\n",
      "\n",
      "Iteration 315 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 333)]\n",
      "Input: 0.115 MB, Params: 3,310,305 (12.628 MB), Total: 12.74 MB, FLOPs: 330,283,201\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Finished fine tuning.\n",
      "Iteration 315/1723 finished in 0m17s\n",
      "Total channels prunned so far: 315\n",
      "\n",
      "Iteration 316 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 39)]\n",
      "Input: 0.115 MB, Params: 3,306,502 (12.613 MB), Total: 12.73 MB, FLOPs: 330,180,600\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Finished fine tuning.\n",
      "Iteration 316/1723 finished in 0m16s\n",
      "Total channels prunned so far: 316\n",
      "\n",
      "Iteration 317 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 111)]\n",
      "Input: 0.115 MB, Params: 3,303,467 (12.602 MB), Total: 12.72 MB, FLOPs: 329,507,424\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.986%\n",
      "Finished fine tuning.\n",
      "Iteration 317/1723 finished in 0m16s\n",
      "Total channels prunned so far: 317\n",
      "\n",
      "Iteration 318 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 78)]\n",
      "Input: 0.115 MB, Params: 3,300,342 (12.590 MB), Total: 12.71 MB, FLOPs: 329,170,032\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.638%\n",
      "Finished fine tuning.\n",
      "Iteration 318/1723 finished in 0m16s\n",
      "Total channels prunned so far: 318\n",
      "\n",
      "Iteration 319 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 291)]\n",
      "Input: 0.115 MB, Params: 3,294,724 (12.568 MB), Total: 12.68 MB, FLOPs: 329,018,373\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.986%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Finished fine tuning.\n",
      "Iteration 319/1723 finished in 0m17s\n",
      "Total channels prunned so far: 319\n",
      "\n",
      "Iteration 320 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 210)]\n",
      "Input: 0.115 MB, Params: 3,291,599 (12.556 MB), Total: 12.67 MB, FLOPs: 328,680,981\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Finished fine tuning.\n",
      "Iteration 320/1723 finished in 0m16s\n",
      "Total channels prunned so far: 320\n",
      "\n",
      "Iteration 321 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 57)]\n",
      "Input: 0.115 MB, Params: 3,289,995 (12.550 MB), Total: 12.67 MB, FLOPs: 327,969,249\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.986%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Finished fine tuning.\n",
      "Iteration 321/1723 finished in 0m17s\n",
      "Total channels prunned so far: 321\n",
      "\n",
      "Iteration 322 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 59)]\n",
      "Input: 0.115 MB, Params: 3,286,201 (12.536 MB), Total: 12.65 MB, FLOPs: 327,866,891\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Finished fine tuning.\n",
      "Iteration 322/1723 finished in 0m17s\n",
      "Total channels prunned so far: 322\n",
      "\n",
      "Iteration 323 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 94)]\n",
      "Input: 0.115 MB, Params: 3,283,193 (12.524 MB), Total: 12.64 MB, FLOPs: 327,199,655\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Finished fine tuning.\n",
      "Iteration 323/1723 finished in 0m17s\n",
      "Total channels prunned so far: 323\n",
      "\n",
      "Iteration 324 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 263)]\n",
      "Input: 0.115 MB, Params: 3,279,399 (12.510 MB), Total: 12.63 MB, FLOPs: 327,097,297\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Finished fine tuning.\n",
      "Iteration 324/1723 finished in 0m17s\n",
      "Total channels prunned so far: 324\n",
      "\n",
      "Iteration 325 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 55)]\n",
      "Input: 0.115 MB, Params: 3,275,605 (12.495 MB), Total: 12.61 MB, FLOPs: 326,994,939\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Finished fine tuning.\n",
      "Iteration 325/1723 finished in 0m17s\n",
      "Total channels prunned so far: 325\n",
      "\n",
      "Iteration 326 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 286)]\n",
      "Input: 0.115 MB, Params: 3,271,811 (12.481 MB), Total: 12.60 MB, FLOPs: 326,892,581\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Finished fine tuning.\n",
      "Iteration 326/1723 finished in 0m17s\n",
      "Total channels prunned so far: 326\n",
      "\n",
      "Iteration 327 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 399)]\n",
      "Input: 0.115 MB, Params: 3,266,229 (12.460 MB), Total: 12.57 MB, FLOPs: 326,741,894\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Finished fine tuning.\n",
      "Iteration 327/1723 finished in 0m17s\n",
      "Total channels prunned so far: 327\n",
      "\n",
      "Iteration 328 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 256)]\n",
      "Input: 0.115 MB, Params: 3,262,444 (12.445 MB), Total: 12.56 MB, FLOPs: 326,639,779\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Finished fine tuning.\n",
      "Iteration 328/1723 finished in 0m16s\n",
      "Total channels prunned so far: 328\n",
      "\n",
      "Iteration 329 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 322)]\n",
      "Input: 0.115 MB, Params: 3,258,659 (12.431 MB), Total: 12.55 MB, FLOPs: 326,537,664\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Finished fine tuning.\n",
      "Iteration 329/1723 finished in 0m16s\n",
      "Total channels prunned so far: 329\n",
      "\n",
      "Iteration 330 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 271)]\n",
      "Input: 0.115 MB, Params: 3,254,874 (12.416 MB), Total: 12.53 MB, FLOPs: 326,435,549\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Finished fine tuning.\n",
      "Iteration 330/1723 finished in 0m17s\n",
      "Total channels prunned so far: 330\n",
      "\n",
      "Iteration 331 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 373)]\n",
      "Input: 0.115 MB, Params: 3,251,089 (12.402 MB), Total: 12.52 MB, FLOPs: 326,333,434\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Finished fine tuning.\n",
      "Iteration 331/1723 finished in 0m17s\n",
      "Total channels prunned so far: 331\n",
      "\n",
      "Iteration 332 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 203)]\n",
      "Input: 0.115 MB, Params: 3,245,318 (12.380 MB), Total: 12.50 MB, FLOPs: 326,016,346\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.122%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Finished fine tuning.\n",
      "Iteration 332/1723 finished in 0m17s\n",
      "Total channels prunned so far: 332\n",
      "\n",
      "Iteration 333 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 46)]\n",
      "Input: 0.115 MB, Params: 3,239,781 (12.359 MB), Total: 12.47 MB, FLOPs: 325,866,874\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.774%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.638%\n",
      "Finished fine tuning.\n",
      "Iteration 333/1723 finished in 0m17s\n",
      "Total channels prunned so far: 333\n",
      "\n",
      "Iteration 334 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 25)]\n",
      "Input: 0.115 MB, Params: 3,238,960 (12.356 MB), Total: 12.47 MB, FLOPs: 324,329,374\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.592%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Finished fine tuning.\n",
      "Iteration 334/1723 finished in 0m17s\n",
      "Total channels prunned so far: 334\n",
      "\n",
      "Iteration 335 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 151)]\n",
      "Input: 0.115 MB, Params: 3,235,853 (12.344 MB), Total: 12.46 MB, FLOPs: 323,993,926\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Finished fine tuning.\n",
      "Iteration 335/1723 finished in 0m17s\n",
      "Total channels prunned so far: 335\n",
      "\n",
      "Iteration 336 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 379)]\n",
      "Input: 0.115 MB, Params: 3,230,316 (12.323 MB), Total: 12.44 MB, FLOPs: 323,844,454\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Finished fine tuning.\n",
      "Iteration 336/1723 finished in 0m17s\n",
      "Total channels prunned so far: 336\n",
      "\n",
      "Iteration 337 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 9)]\n",
      "Input: 0.115 MB, Params: 3,226,549 (12.308 MB), Total: 12.42 MB, FLOPs: 323,742,825\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.774%\n",
      "Finished fine tuning.\n",
      "Iteration 337/1723 finished in 0m17s\n",
      "Total channels prunned so far: 337\n",
      "\n",
      "Iteration 338 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 221)]\n",
      "Input: 0.115 MB, Params: 3,222,782 (12.294 MB), Total: 12.41 MB, FLOPs: 323,641,196\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.774%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.774%\n",
      "Finished fine tuning.\n",
      "Iteration 338/1723 finished in 0m17s\n",
      "Total channels prunned so far: 338\n",
      "\n",
      "Iteration 339 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 140)]\n",
      "Input: 0.115 MB, Params: 3,219,015 (12.280 MB), Total: 12.39 MB, FLOPs: 323,539,567\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.774%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.122%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.774%\n",
      "Finished fine tuning.\n",
      "Iteration 339/1723 finished in 0m17s\n",
      "Total channels prunned so far: 339\n",
      "\n",
      "Iteration 340 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(7, 2)]\n",
      "Input: 0.115 MB, Params: 3,218,491 (12.278 MB), Total: 12.39 MB, FLOPs: 322,494,692\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.638%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.122%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.774%\n",
      "Finished fine tuning.\n",
      "Iteration 340/1723 finished in 0m17s\n",
      "Total channels prunned so far: 340\n",
      "\n",
      "Iteration 341 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 105)]\n",
      "Input: 0.115 MB, Params: 3,215,384 (12.266 MB), Total: 12.38 MB, FLOPs: 322,159,244\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.774%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.774%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Finished fine tuning.\n",
      "Iteration 341/1723 finished in 0m17s\n",
      "Total channels prunned so far: 341\n",
      "\n",
      "Iteration 342 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 46)]\n",
      "Input: 0.115 MB, Params: 3,211,617 (12.251 MB), Total: 12.37 MB, FLOPs: 322,057,615\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.774%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.470%\n",
      "Finished fine tuning.\n",
      "Iteration 342/1723 finished in 0m16s\n",
      "Total channels prunned so far: 342\n",
      "\n",
      "Iteration 343 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 199)]\n",
      "Input: 0.115 MB, Params: 3,206,116 (12.230 MB), Total: 12.35 MB, FLOPs: 321,909,115\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.470%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Finished fine tuning.\n",
      "Iteration 343/1723 finished in 0m17s\n",
      "Total channels prunned so far: 343\n",
      "\n",
      "Iteration 344 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 89)]\n",
      "Input: 0.115 MB, Params: 3,202,358 (12.216 MB), Total: 12.33 MB, FLOPs: 321,807,729\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Finished fine tuning.\n",
      "Iteration 344/1723 finished in 0m16s\n",
      "Total channels prunned so far: 344\n",
      "\n",
      "Iteration 345 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 120)]\n",
      "Input: 0.115 MB, Params: 3,196,866 (12.195 MB), Total: 12.31 MB, FLOPs: 321,659,472\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.774%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.774%\n",
      "Finished fine tuning.\n",
      "Iteration 345/1723 finished in 0m17s\n",
      "Total channels prunned so far: 345\n",
      "\n",
      "Iteration 346 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 143)]\n",
      "Input: 0.115 MB, Params: 3,191,374 (12.174 MB), Total: 12.29 MB, FLOPs: 321,511,215\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Finished fine tuning.\n",
      "Iteration 346/1723 finished in 0m17s\n",
      "Total channels prunned so far: 346\n",
      "\n",
      "Iteration 347 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 216)]\n",
      "Input: 0.115 MB, Params: 3,187,634 (12.160 MB), Total: 12.28 MB, FLOPs: 321,410,315\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Finished fine tuning.\n",
      "Iteration 347/1723 finished in 0m16s\n",
      "Total channels prunned so far: 347\n",
      "\n",
      "Iteration 348 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 4)]\n",
      "Input: 0.115 MB, Params: 3,182,151 (12.139 MB), Total: 12.25 MB, FLOPs: 321,262,301\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Finished fine tuning.\n",
      "Iteration 348/1723 finished in 0m17s\n",
      "Total channels prunned so far: 348\n",
      "\n",
      "Iteration 349 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 306)]\n",
      "Input: 0.115 MB, Params: 3,178,420 (12.125 MB), Total: 12.24 MB, FLOPs: 321,161,644\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Finished fine tuning.\n",
      "Iteration 349/1723 finished in 0m17s\n",
      "Total channels prunned so far: 349\n",
      "\n",
      "Iteration 350 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 114)]\n",
      "Input: 0.115 MB, Params: 3,175,430 (12.113 MB), Total: 12.23 MB, FLOPs: 320,496,352\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Finished fine tuning.\n",
      "Iteration 350/1723 finished in 0m17s\n",
      "Total channels prunned so far: 350\n",
      "\n",
      "Iteration 351 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(3, 36)]\n",
      "Input: 0.115 MB, Params: 3,175,388 (12.113 MB), Total: 12.23 MB, FLOPs: 316,655,039\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Finished fine tuning.\n",
      "Iteration 351/1723 finished in 0m17s\n",
      "Total channels prunned so far: 351\n",
      "\n",
      "Iteration 352 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 255)]\n",
      "Input: 0.115 MB, Params: 3,169,914 (12.092 MB), Total: 12.21 MB, FLOPs: 316,507,268\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.470%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Finished fine tuning.\n",
      "Iteration 352/1723 finished in 0m17s\n",
      "Total channels prunned so far: 352\n",
      "\n",
      "Iteration 353 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 103)]\n",
      "Input: 0.115 MB, Params: 3,166,192 (12.078 MB), Total: 12.19 MB, FLOPs: 316,406,854\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Finished fine tuning.\n",
      "Iteration 353/1723 finished in 0m17s\n",
      "Total channels prunned so far: 353\n",
      "\n",
      "Iteration 354 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 240)]\n",
      "Input: 0.115 MB, Params: 3,160,727 (12.057 MB), Total: 12.17 MB, FLOPs: 316,259,326\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.774%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Finished fine tuning.\n",
      "Iteration 354/1723 finished in 0m17s\n",
      "Total channels prunned so far: 354\n",
      "\n",
      "Iteration 355 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 138)]\n",
      "Input: 0.115 MB, Params: 3,157,629 (12.045 MB), Total: 12.16 MB, FLOPs: 315,924,850\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.122%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Finished fine tuning.\n",
      "Iteration 355/1723 finished in 0m17s\n",
      "Total channels prunned so far: 355\n",
      "\n",
      "Iteration 356 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 176)]\n",
      "Input: 0.115 MB, Params: 3,153,916 (12.031 MB), Total: 12.15 MB, FLOPs: 315,824,679\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Finished fine tuning.\n",
      "Iteration 356/1723 finished in 0m17s\n",
      "Total channels prunned so far: 356\n",
      "\n",
      "Iteration 357 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 83)]\n",
      "Input: 0.115 MB, Params: 3,150,818 (12.019 MB), Total: 12.13 MB, FLOPs: 315,490,203\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Finished fine tuning.\n",
      "Iteration 357/1723 finished in 0m17s\n",
      "Total channels prunned so far: 357\n",
      "\n",
      "Iteration 358 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 203)]\n",
      "Input: 0.115 MB, Params: 3,145,362 (11.999 MB), Total: 12.11 MB, FLOPs: 315,342,918\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Finished fine tuning.\n",
      "Iteration 358/1723 finished in 0m17s\n",
      "Total channels prunned so far: 358\n",
      "\n",
      "Iteration 359 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 202)]\n",
      "Input: 0.115 MB, Params: 3,142,264 (11.987 MB), Total: 12.10 MB, FLOPs: 315,008,442\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Finished fine tuning.\n",
      "Iteration 359/1723 finished in 0m17s\n",
      "Total channels prunned so far: 359\n",
      "\n",
      "Iteration 360 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 81)]\n",
      "Input: 0.115 MB, Params: 3,140,678 (11.981 MB), Total: 12.10 MB, FLOPs: 314,304,702\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Finished fine tuning.\n",
      "Iteration 360/1723 finished in 0m17s\n",
      "Total channels prunned so far: 360\n",
      "\n",
      "Iteration 361 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 293)]\n",
      "Input: 0.115 MB, Params: 3,135,222 (11.960 MB), Total: 12.08 MB, FLOPs: 314,157,417\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.289%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.986%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Finished fine tuning.\n",
      "Iteration 361/1723 finished in 0m17s\n",
      "Total channels prunned so far: 361\n",
      "\n",
      "Iteration 362 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 288)]\n",
      "Input: 0.115 MB, Params: 3,131,527 (11.946 MB), Total: 12.06 MB, FLOPs: 314,057,732\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Finished fine tuning.\n",
      "Iteration 362/1723 finished in 0m17s\n",
      "Total channels prunned so far: 362\n",
      "\n",
      "Iteration 363 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 99)]\n",
      "Input: 0.115 MB, Params: 3,129,941 (11.940 MB), Total: 12.06 MB, FLOPs: 313,353,992\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Finished fine tuning.\n",
      "Iteration 363/1723 finished in 0m17s\n",
      "Total channels prunned so far: 363\n",
      "\n",
      "Iteration 364 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 191)]\n",
      "Input: 0.115 MB, Params: 3,126,843 (11.928 MB), Total: 12.04 MB, FLOPs: 313,019,516\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Finished fine tuning.\n",
      "Iteration 364/1723 finished in 0m17s\n",
      "Total channels prunned so far: 364\n",
      "\n",
      "Iteration 365 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 51)]\n",
      "Input: 0.115 MB, Params: 3,123,745 (11.916 MB), Total: 12.03 MB, FLOPs: 312,685,040\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.819%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Finished fine tuning.\n",
      "Iteration 365/1723 finished in 0m17s\n",
      "Total channels prunned so far: 365\n",
      "\n",
      "Iteration 366 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 40)]\n",
      "Input: 0.115 MB, Params: 3,118,298 (11.895 MB), Total: 12.01 MB, FLOPs: 312,537,998\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Finished fine tuning.\n",
      "Iteration 366/1723 finished in 0m17s\n",
      "Total channels prunned so far: 366\n",
      "\n",
      "Iteration 367 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 200)]\n",
      "Input: 0.115 MB, Params: 3,115,200 (11.884 MB), Total: 12.00 MB, FLOPs: 312,203,522\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.986%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Finished fine tuning.\n",
      "Iteration 367/1723 finished in 0m17s\n",
      "Total channels prunned so far: 367\n",
      "\n",
      "Iteration 368 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 96)]\n",
      "Input: 0.115 MB, Params: 3,113,614 (11.877 MB), Total: 11.99 MB, FLOPs: 311,499,782\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Finished fine tuning.\n",
      "Iteration 368/1723 finished in 0m17s\n",
      "Total channels prunned so far: 368\n",
      "\n",
      "Iteration 369 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 163)]\n",
      "Input: 0.115 MB, Params: 3,108,167 (11.857 MB), Total: 11.97 MB, FLOPs: 311,352,740\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.986%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.638%\n",
      "Finished fine tuning.\n",
      "Iteration 369/1723 finished in 0m17s\n",
      "Total channels prunned so far: 369\n",
      "\n",
      "Iteration 370 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 91)]\n",
      "Input: 0.115 MB, Params: 3,105,069 (11.845 MB), Total: 11.96 MB, FLOPs: 311,018,264\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.638%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Finished fine tuning.\n",
      "Iteration 370/1723 finished in 0m17s\n",
      "Total channels prunned so far: 370\n",
      "\n",
      "Iteration 371 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 302)]\n",
      "Input: 0.115 MB, Params: 3,101,392 (11.831 MB), Total: 11.95 MB, FLOPs: 310,919,065\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Finished fine tuning.\n",
      "Iteration 371/1723 finished in 0m17s\n",
      "Total channels prunned so far: 371\n",
      "\n",
      "Iteration 372 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 352)]\n",
      "Input: 0.115 MB, Params: 3,095,954 (11.810 MB), Total: 11.93 MB, FLOPs: 310,772,266\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Finished fine tuning.\n",
      "Iteration 372/1723 finished in 0m16s\n",
      "Total channels prunned so far: 372\n",
      "\n",
      "Iteration 373 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 89)]\n",
      "Input: 0.115 MB, Params: 3,092,856 (11.798 MB), Total: 11.91 MB, FLOPs: 310,437,790\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.774%\n",
      "Finished fine tuning.\n",
      "Iteration 373/1723 finished in 0m16s\n",
      "Total channels prunned so far: 373\n",
      "\n",
      "Iteration 374 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 276)]\n",
      "Input: 0.115 MB, Params: 3,087,418 (11.778 MB), Total: 11.89 MB, FLOPs: 310,290,991\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.774%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Finished fine tuning.\n",
      "Iteration 374/1723 finished in 0m17s\n",
      "Total channels prunned so far: 374\n",
      "\n",
      "Iteration 375 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 220)]\n",
      "Input: 0.115 MB, Params: 3,083,759 (11.764 MB), Total: 11.88 MB, FLOPs: 310,192,278\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Finished fine tuning.\n",
      "Iteration 375/1723 finished in 0m17s\n",
      "Total channels prunned so far: 375\n",
      "\n",
      "Iteration 376 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 306)]\n",
      "Input: 0.115 MB, Params: 3,078,330 (11.743 MB), Total: 11.86 MB, FLOPs: 310,045,722\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Finished fine tuning.\n",
      "Iteration 376/1723 finished in 0m16s\n",
      "Total channels prunned so far: 376\n",
      "\n",
      "Iteration 377 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 136)]\n",
      "Input: 0.115 MB, Params: 3,075,232 (11.731 MB), Total: 11.85 MB, FLOPs: 309,711,246\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Finished fine tuning.\n",
      "Iteration 377/1723 finished in 0m17s\n",
      "Total channels prunned so far: 377\n",
      "\n",
      "Iteration 378 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 46)]\n",
      "Input: 0.115 MB, Params: 3,073,646 (11.725 MB), Total: 11.84 MB, FLOPs: 309,007,506\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.774%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Finished fine tuning.\n",
      "Iteration 378/1723 finished in 0m17s\n",
      "Total channels prunned so far: 378\n",
      "\n",
      "Iteration 379 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 84)]\n",
      "Input: 0.115 MB, Params: 3,068,217 (11.704 MB), Total: 11.82 MB, FLOPs: 308,860,950\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Finished fine tuning.\n",
      "Iteration 379/1723 finished in 0m16s\n",
      "Total channels prunned so far: 379\n",
      "\n",
      "Iteration 380 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 53)]\n",
      "Input: 0.115 MB, Params: 3,065,344 (11.693 MB), Total: 11.81 MB, FLOPs: 308,220,390\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.153%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Finished fine tuning.\n",
      "Iteration 380/1723 finished in 0m17s\n",
      "Total channels prunned so far: 380\n",
      "\n",
      "Iteration 381 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 164)]\n",
      "Input: 0.115 MB, Params: 3,059,915 (11.673 MB), Total: 11.79 MB, FLOPs: 308,073,834\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.592%\n",
      "Finished fine tuning.\n",
      "Iteration 381/1723 finished in 0m17s\n",
      "Total channels prunned so far: 381\n",
      "\n",
      "Iteration 382 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 242)]\n",
      "Input: 0.115 MB, Params: 3,054,486 (11.652 MB), Total: 11.77 MB, FLOPs: 307,927,278\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.638%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.470%\n",
      "Finished fine tuning.\n",
      "Iteration 382/1723 finished in 0m17s\n",
      "Total channels prunned so far: 382\n",
      "\n",
      "Iteration 383 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 23)]\n",
      "Input: 0.115 MB, Params: 3,049,057 (11.631 MB), Total: 11.75 MB, FLOPs: 307,780,722\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.819%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Finished fine tuning.\n",
      "Iteration 383/1723 finished in 0m17s\n",
      "Total channels prunned so far: 383\n",
      "\n",
      "Iteration 384 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 107)]\n",
      "Input: 0.115 MB, Params: 3,045,968 (11.619 MB), Total: 11.73 MB, FLOPs: 307,447,218\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Finished fine tuning.\n",
      "Iteration 384/1723 finished in 0m17s\n",
      "Total channels prunned so far: 384\n",
      "\n",
      "Iteration 385 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 232)]\n",
      "Input: 0.115 MB, Params: 3,040,539 (11.599 MB), Total: 11.71 MB, FLOPs: 307,300,662\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.774%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Finished fine tuning.\n",
      "Iteration 385/1723 finished in 0m17s\n",
      "Total channels prunned so far: 385\n",
      "\n",
      "Iteration 386 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 76)]\n",
      "Input: 0.115 MB, Params: 3,035,110 (11.578 MB), Total: 11.69 MB, FLOPs: 307,154,106\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Finished fine tuning.\n",
      "Iteration 386/1723 finished in 0m17s\n",
      "Total channels prunned so far: 386\n",
      "\n",
      "Iteration 387 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 103)]\n",
      "Input: 0.115 MB, Params: 3,033,533 (11.572 MB), Total: 11.69 MB, FLOPs: 306,454,362\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.470%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Finished fine tuning.\n",
      "Iteration 387/1723 finished in 0m17s\n",
      "Total channels prunned so far: 387\n",
      "\n",
      "Iteration 388 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 176)]\n",
      "Input: 0.115 MB, Params: 3,028,104 (11.551 MB), Total: 11.67 MB, FLOPs: 306,307,806\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.122%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Finished fine tuning.\n",
      "Iteration 388/1723 finished in 0m17s\n",
      "Total channels prunned so far: 388\n",
      "\n",
      "Iteration 389 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 11)]\n",
      "Input: 0.115 MB, Params: 3,024,517 (11.538 MB), Total: 11.65 MB, FLOPs: 306,211,037\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.986%\n",
      "Finished fine tuning.\n",
      "Iteration 389/1723 finished in 0m16s\n",
      "Total channels prunned so far: 389\n",
      "\n",
      "Iteration 390 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 66)]\n",
      "Input: 0.115 MB, Params: 3,020,930 (11.524 MB), Total: 11.64 MB, FLOPs: 306,114,268\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.941%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Finished fine tuning.\n",
      "Iteration 390/1723 finished in 0m16s\n",
      "Total channels prunned so far: 390\n",
      "\n",
      "Iteration 391 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 54)]\n",
      "Input: 0.115 MB, Params: 3,017,841 (11.512 MB), Total: 11.63 MB, FLOPs: 305,780,764\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Finished fine tuning.\n",
      "Iteration 391/1723 finished in 0m17s\n",
      "Total channels prunned so far: 391\n",
      "\n",
      "Iteration 392 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 169)]\n",
      "Input: 0.115 MB, Params: 3,012,385 (11.491 MB), Total: 11.61 MB, FLOPs: 305,481,658\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Finished fine tuning.\n",
      "Iteration 392/1723 finished in 0m17s\n",
      "Total channels prunned so far: 392\n",
      "\n",
      "Iteration 393 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 22)]\n",
      "Input: 0.115 MB, Params: 3,008,798 (11.478 MB), Total: 11.59 MB, FLOPs: 305,384,889\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.774%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Finished fine tuning.\n",
      "Iteration 393/1723 finished in 0m17s\n",
      "Total channels prunned so far: 393\n",
      "\n",
      "Iteration 394 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 314)]\n",
      "Input: 0.115 MB, Params: 3,003,405 (11.457 MB), Total: 11.57 MB, FLOPs: 305,239,305\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Finished fine tuning.\n",
      "Iteration 394/1723 finished in 0m17s\n",
      "Total channels prunned so far: 394\n",
      "\n",
      "Iteration 395 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 202)]\n",
      "Input: 0.115 MB, Params: 2,998,012 (11.437 MB), Total: 11.55 MB, FLOPs: 305,093,721\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Finished fine tuning.\n",
      "Iteration 395/1723 finished in 0m16s\n",
      "Total channels prunned so far: 395\n",
      "\n",
      "Iteration 396 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 52)]\n",
      "Input: 0.115 MB, Params: 2,994,443 (11.423 MB), Total: 11.54 MB, FLOPs: 304,997,438\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.774%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Finished fine tuning.\n",
      "Iteration 396/1723 finished in 0m16s\n",
      "Total channels prunned so far: 396\n",
      "\n",
      "Iteration 397 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 5)]\n",
      "Input: 0.115 MB, Params: 2,990,874 (11.409 MB), Total: 11.52 MB, FLOPs: 304,901,155\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Finished fine tuning.\n",
      "Iteration 397/1723 finished in 0m17s\n",
      "Total channels prunned so far: 397\n",
      "\n",
      "Iteration 398 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 313)]\n",
      "Input: 0.115 MB, Params: 2,985,499 (11.389 MB), Total: 11.50 MB, FLOPs: 304,756,057\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.774%\n",
      "Finished fine tuning.\n",
      "Iteration 398/1723 finished in 0m17s\n",
      "Total channels prunned so far: 398\n",
      "\n",
      "Iteration 399 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 47)]\n",
      "Input: 0.115 MB, Params: 2,982,653 (11.378 MB), Total: 11.49 MB, FLOPs: 304,121,437\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Finished fine tuning.\n",
      "Iteration 399/1723 finished in 0m16s\n",
      "Total channels prunned so far: 399\n",
      "\n",
      "Iteration 400 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 30)]\n",
      "Input: 0.115 MB, Params: 2,977,278 (11.357 MB), Total: 11.47 MB, FLOPs: 303,976,339\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.774%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Finished fine tuning.\n",
      "Iteration 400/1723 finished in 0m17s\n",
      "Total channels prunned so far: 400\n",
      "\n",
      "Iteration 401 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 54)]\n",
      "Input: 0.115 MB, Params: 2,971,858 (11.337 MB), Total: 11.45 MB, FLOPs: 303,678,205\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.122%\n",
      "Finished fine tuning.\n",
      "Iteration 401/1723 finished in 0m17s\n",
      "Total channels prunned so far: 401\n",
      "\n",
      "Iteration 402 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 97)]\n",
      "Input: 0.115 MB, Params: 2,966,438 (11.316 MB), Total: 11.43 MB, FLOPs: 303,380,071\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.638%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.638%\n",
      "Finished fine tuning.\n",
      "Iteration 402/1723 finished in 0m17s\n",
      "Total channels prunned so far: 402\n",
      "\n",
      "Iteration 403 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 128)]\n",
      "Input: 0.115 MB, Params: 2,963,385 (11.304 MB), Total: 11.42 MB, FLOPs: 303,050,455\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.638%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Finished fine tuning.\n",
      "Iteration 403/1723 finished in 0m17s\n",
      "Total channels prunned so far: 403\n",
      "\n",
      "Iteration 404 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 224)]\n",
      "Input: 0.115 MB, Params: 2,958,028 (11.284 MB), Total: 11.40 MB, FLOPs: 302,905,843\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Finished fine tuning.\n",
      "Iteration 404/1723 finished in 0m17s\n",
      "Total channels prunned so far: 404\n",
      "\n",
      "Iteration 405 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 272)]\n",
      "Input: 0.115 MB, Params: 2,952,671 (11.264 MB), Total: 11.38 MB, FLOPs: 302,761,231\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Finished fine tuning.\n",
      "Iteration 405/1723 finished in 0m17s\n",
      "Total channels prunned so far: 405\n",
      "\n",
      "Iteration 406 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 382)]\n",
      "Input: 0.115 MB, Params: 2,947,314 (11.243 MB), Total: 11.36 MB, FLOPs: 302,616,619\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Finished fine tuning.\n",
      "Iteration 406/1723 finished in 0m17s\n",
      "Total channels prunned so far: 406\n",
      "\n",
      "Iteration 407 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 160)]\n",
      "Input: 0.115 MB, Params: 2,941,957 (11.223 MB), Total: 11.34 MB, FLOPs: 302,472,007\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Finished fine tuning.\n",
      "Iteration 407/1723 finished in 0m17s\n",
      "Total channels prunned so far: 407\n",
      "\n",
      "Iteration 408 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 351)]\n",
      "Input: 0.115 MB, Params: 2,936,600 (11.202 MB), Total: 11.32 MB, FLOPs: 302,327,395\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.774%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.774%\n",
      "Finished fine tuning.\n",
      "Iteration 408/1723 finished in 0m17s\n",
      "Total channels prunned so far: 408\n",
      "\n",
      "Iteration 409 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 5)]\n",
      "Input: 0.115 MB, Params: 2,933,547 (11.191 MB), Total: 11.31 MB, FLOPs: 301,997,779\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Finished fine tuning.\n",
      "Iteration 409/1723 finished in 0m16s\n",
      "Total channels prunned so far: 409\n",
      "\n",
      "Iteration 410 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 21)]\n",
      "Input: 0.115 MB, Params: 2,930,041 (11.177 MB), Total: 11.29 MB, FLOPs: 301,903,197\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Finished fine tuning.\n",
      "Iteration 410/1723 finished in 0m17s\n",
      "Total channels prunned so far: 410\n",
      "\n",
      "Iteration 411 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 37)]\n",
      "Input: 0.115 MB, Params: 2,924,684 (11.157 MB), Total: 11.27 MB, FLOPs: 301,608,222\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.470%\n",
      "Finished fine tuning.\n",
      "Iteration 411/1723 finished in 0m16s\n",
      "Total channels prunned so far: 411\n",
      "\n",
      "Iteration 412 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 82)]\n",
      "Input: 0.115 MB, Params: 2,919,345 (11.136 MB), Total: 11.25 MB, FLOPs: 301,464,096\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.774%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Finished fine tuning.\n",
      "Iteration 412/1723 finished in 0m17s\n",
      "Total channels prunned so far: 412\n",
      "\n",
      "Iteration 413 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(7, 2)]\n",
      "Input: 0.115 MB, Params: 2,918,821 (11.134 MB), Total: 11.25 MB, FLOPs: 300,459,506\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Finished fine tuning.\n",
      "Iteration 413/1723 finished in 0m17s\n",
      "Total channels prunned so far: 413\n",
      "\n",
      "Iteration 414 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 328)]\n",
      "Input: 0.115 MB, Params: 2,913,482 (11.114 MB), Total: 11.23 MB, FLOPs: 300,315,380\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.774%\n",
      "Finished fine tuning.\n",
      "Iteration 414/1723 finished in 0m17s\n",
      "Total channels prunned so far: 414\n",
      "\n",
      "Iteration 415 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 251)]\n",
      "Input: 0.115 MB, Params: 2,908,143 (11.094 MB), Total: 11.21 MB, FLOPs: 300,171,254\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.774%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Finished fine tuning.\n",
      "Iteration 415/1723 finished in 0m16s\n",
      "Total channels prunned so far: 415\n",
      "\n",
      "Iteration 416 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 377)]\n",
      "Input: 0.115 MB, Params: 2,902,804 (11.073 MB), Total: 11.19 MB, FLOPs: 300,027,128\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.122%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.774%\n",
      "Finished fine tuning.\n",
      "Iteration 416/1723 finished in 0m17s\n",
      "Total channels prunned so far: 416\n",
      "\n",
      "Iteration 417 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 75)]\n",
      "Input: 0.115 MB, Params: 2,897,465 (11.053 MB), Total: 11.17 MB, FLOPs: 299,883,002\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.774%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Finished fine tuning.\n",
      "Iteration 417/1723 finished in 0m17s\n",
      "Total channels prunned so far: 417\n",
      "\n",
      "Iteration 418 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 70)]\n",
      "Input: 0.115 MB, Params: 2,894,004 (11.040 MB), Total: 11.16 MB, FLOPs: 299,789,635\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Finished fine tuning.\n",
      "Iteration 418/1723 finished in 0m16s\n",
      "Total channels prunned so far: 418\n",
      "\n",
      "Iteration 419 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 156)]\n",
      "Input: 0.115 MB, Params: 2,890,543 (11.027 MB), Total: 11.14 MB, FLOPs: 299,696,268\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.774%\n",
      "Finished fine tuning.\n",
      "Iteration 419/1723 finished in 0m17s\n",
      "Total channels prunned so far: 419\n",
      "\n",
      "Iteration 420 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 234)]\n",
      "Input: 0.115 MB, Params: 2,887,082 (11.013 MB), Total: 11.13 MB, FLOPs: 299,602,901\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Finished fine tuning.\n",
      "Iteration 420/1723 finished in 0m17s\n",
      "Total channels prunned so far: 420\n",
      "\n",
      "Iteration 421 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 95)]\n",
      "Input: 0.115 MB, Params: 2,881,770 (10.993 MB), Total: 11.11 MB, FLOPs: 299,459,504\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Finished fine tuning.\n",
      "Iteration 421/1723 finished in 0m17s\n",
      "Total channels prunned so far: 421\n",
      "\n",
      "Iteration 422 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(14, 46)]\n",
      "Input: 0.115 MB, Params: 2,880,283 (10.987 MB), Total: 11.10 MB, FLOPs: 298,100,960\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Finished fine tuning.\n",
      "Iteration 422/1723 finished in 0m17s\n",
      "Total channels prunned so far: 422\n",
      "\n",
      "Iteration 423 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 73)]\n",
      "Input: 0.115 MB, Params: 2,874,980 (10.967 MB), Total: 11.08 MB, FLOPs: 297,807,443\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Finished fine tuning.\n",
      "Iteration 423/1723 finished in 0m17s\n",
      "Total channels prunned so far: 423\n",
      "\n",
      "Iteration 424 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 256)]\n",
      "Input: 0.115 MB, Params: 2,871,528 (10.954 MB), Total: 11.07 MB, FLOPs: 297,714,319\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Finished fine tuning.\n",
      "Iteration 424/1723 finished in 0m17s\n",
      "Total channels prunned so far: 424\n",
      "\n",
      "Iteration 425 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 64)]\n",
      "Input: 0.115 MB, Params: 2,868,493 (10.942 MB), Total: 11.06 MB, FLOPs: 297,386,647\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Finished fine tuning.\n",
      "Iteration 425/1723 finished in 0m17s\n",
      "Total channels prunned so far: 425\n",
      "\n",
      "Iteration 426 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 119)]\n",
      "Input: 0.115 MB, Params: 2,865,041 (10.929 MB), Total: 11.04 MB, FLOPs: 297,293,523\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Finished fine tuning.\n",
      "Iteration 426/1723 finished in 0m17s\n",
      "Total channels prunned so far: 426\n",
      "\n",
      "Iteration 427 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 124)]\n",
      "Input: 0.115 MB, Params: 2,859,756 (10.909 MB), Total: 11.02 MB, FLOPs: 297,150,855\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Finished fine tuning.\n",
      "Iteration 427/1723 finished in 0m17s\n",
      "Total channels prunned so far: 427\n",
      "\n",
      "Iteration 428 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(3, 44)]\n",
      "Input: 0.115 MB, Params: 2,859,714 (10.909 MB), Total: 11.02 MB, FLOPs: 296,791,352\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.122%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Finished fine tuning.\n",
      "Iteration 428/1723 finished in 0m17s\n",
      "Total channels prunned so far: 428\n",
      "\n",
      "Iteration 429 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 101)]\n",
      "Input: 0.115 MB, Params: 2,854,429 (10.889 MB), Total: 11.00 MB, FLOPs: 296,648,684\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Finished fine tuning.\n",
      "Iteration 429/1723 finished in 0m17s\n",
      "Total channels prunned so far: 429\n",
      "\n",
      "Iteration 430 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 172)]\n",
      "Input: 0.115 MB, Params: 2,850,995 (10.876 MB), Total: 10.99 MB, FLOPs: 296,556,046\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Finished fine tuning.\n",
      "Iteration 430/1723 finished in 0m17s\n",
      "Total channels prunned so far: 430\n",
      "\n",
      "Iteration 431 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 101)]\n",
      "Input: 0.115 MB, Params: 2,849,436 (10.870 MB), Total: 10.99 MB, FLOPs: 295,864,294\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Finished fine tuning.\n",
      "Iteration 431/1723 finished in 0m17s\n",
      "Total channels prunned so far: 431\n",
      "\n",
      "Iteration 432 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 50)]\n",
      "Input: 0.115 MB, Params: 2,844,160 (10.850 MB), Total: 10.96 MB, FLOPs: 295,721,869\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Finished fine tuning.\n",
      "Iteration 432/1723 finished in 0m17s\n",
      "Total channels prunned so far: 432\n",
      "\n",
      "Iteration 433 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 143)]\n",
      "Input: 0.115 MB, Params: 2,840,735 (10.837 MB), Total: 10.95 MB, FLOPs: 295,629,474\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Finished fine tuning.\n",
      "Iteration 433/1723 finished in 0m17s\n",
      "Total channels prunned so far: 433\n",
      "\n",
      "Iteration 434 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 151)]\n",
      "Input: 0.115 MB, Params: 2,837,310 (10.823 MB), Total: 10.94 MB, FLOPs: 295,537,079\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Finished fine tuning.\n",
      "Iteration 434/1723 finished in 0m17s\n",
      "Total channels prunned so far: 434\n",
      "\n",
      "Iteration 435 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 375)]\n",
      "Input: 0.115 MB, Params: 2,832,052 (10.803 MB), Total: 10.92 MB, FLOPs: 295,395,140\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Finished fine tuning.\n",
      "Iteration 435/1723 finished in 0m17s\n",
      "Total channels prunned so far: 435\n",
      "\n",
      "Iteration 436 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 89)]\n",
      "Input: 0.115 MB, Params: 2,828,636 (10.790 MB), Total: 10.91 MB, FLOPs: 295,302,988\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.638%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Finished fine tuning.\n",
      "Iteration 436/1723 finished in 0m17s\n",
      "Total channels prunned so far: 436\n",
      "\n",
      "Iteration 437 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 172)]\n",
      "Input: 0.115 MB, Params: 2,823,378 (10.770 MB), Total: 10.89 MB, FLOPs: 295,011,415\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Finished fine tuning.\n",
      "Iteration 437/1723 finished in 0m17s\n",
      "Total channels prunned so far: 437\n",
      "\n",
      "Iteration 438 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 232)]\n",
      "Input: 0.115 MB, Params: 2,818,138 (10.750 MB), Total: 10.87 MB, FLOPs: 294,869,962\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Finished fine tuning.\n",
      "Iteration 438/1723 finished in 0m17s\n",
      "Total channels prunned so far: 438\n",
      "\n",
      "Iteration 439 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 196)]\n",
      "Input: 0.115 MB, Params: 2,814,731 (10.737 MB), Total: 10.85 MB, FLOPs: 294,778,053\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Finished fine tuning.\n",
      "Iteration 439/1723 finished in 0m17s\n",
      "Total channels prunned so far: 439\n",
      "\n",
      "Iteration 440 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 121)]\n",
      "Input: 0.115 MB, Params: 2,811,324 (10.724 MB), Total: 10.84 MB, FLOPs: 294,686,144\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Finished fine tuning.\n",
      "Iteration 440/1723 finished in 0m17s\n",
      "Total channels prunned so far: 440\n",
      "\n",
      "Iteration 441 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 226)]\n",
      "Input: 0.115 MB, Params: 2,807,917 (10.711 MB), Total: 10.83 MB, FLOPs: 294,594,235\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.122%\n",
      "Finished fine tuning.\n",
      "Iteration 441/1723 finished in 0m16s\n",
      "Total channels prunned so far: 441\n",
      "\n",
      "Iteration 442 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 353)]\n",
      "Input: 0.115 MB, Params: 2,802,704 (10.691 MB), Total: 10.81 MB, FLOPs: 294,453,511\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Finished fine tuning.\n",
      "Iteration 442/1723 finished in 0m17s\n",
      "Total channels prunned so far: 442\n",
      "\n",
      "Iteration 443 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 7)]\n",
      "Input: 0.115 MB, Params: 2,801,910 (10.688 MB), Total: 10.80 MB, FLOPs: 293,026,111\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Finished fine tuning.\n",
      "Iteration 443/1723 finished in 0m17s\n",
      "Total channels prunned so far: 443\n",
      "\n",
      "Iteration 444 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 46)]\n",
      "Input: 0.115 MB, Params: 2,798,512 (10.675 MB), Total: 10.79 MB, FLOPs: 292,934,445\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Finished fine tuning.\n",
      "Iteration 444/1723 finished in 0m17s\n",
      "Total channels prunned so far: 444\n",
      "\n",
      "Iteration 445 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 140)]\n",
      "Input: 0.115 MB, Params: 2,793,272 (10.655 MB), Total: 10.77 MB, FLOPs: 292,643,358\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Finished fine tuning.\n",
      "Iteration 445/1723 finished in 0m16s\n",
      "Total channels prunned so far: 445\n",
      "\n",
      "Iteration 446 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 352)]\n",
      "Input: 0.115 MB, Params: 2,789,874 (10.643 MB), Total: 10.76 MB, FLOPs: 292,551,692\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Finished fine tuning.\n",
      "Iteration 446/1723 finished in 0m17s\n",
      "Total channels prunned so far: 446\n",
      "\n",
      "Iteration 447 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 54)]\n",
      "Input: 0.115 MB, Params: 2,787,064 (10.632 MB), Total: 10.75 MB, FLOPs: 291,923,984\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.470%\n",
      "Finished fine tuning.\n",
      "Iteration 447/1723 finished in 0m16s\n",
      "Total channels prunned so far: 447\n",
      "\n",
      "Iteration 448 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 70)]\n",
      "Input: 0.115 MB, Params: 2,784,254 (10.621 MB), Total: 10.74 MB, FLOPs: 291,296,276\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.470%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Finished fine tuning.\n",
      "Iteration 448/1723 finished in 0m17s\n",
      "Total channels prunned so far: 448\n",
      "\n",
      "Iteration 449 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 148)]\n",
      "Input: 0.115 MB, Params: 2,780,856 (10.608 MB), Total: 10.72 MB, FLOPs: 291,204,610\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.774%\n",
      "Finished fine tuning.\n",
      "Iteration 449/1723 finished in 0m18s\n",
      "Total channels prunned so far: 449\n",
      "\n",
      "Iteration 450 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 73)]\n",
      "Input: 0.115 MB, Params: 2,779,315 (10.602 MB), Total: 10.72 MB, FLOPs: 290,520,850\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.774%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.774%\n",
      "Finished fine tuning.\n",
      "Iteration 450/1723 finished in 0m17s\n",
      "Total channels prunned so far: 450\n",
      "\n",
      "Iteration 451 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 179)]\n",
      "Input: 0.115 MB, Params: 2,776,316 (10.591 MB), Total: 10.71 MB, FLOPs: 290,197,066\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.774%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.470%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Finished fine tuning.\n",
      "Iteration 451/1723 finished in 0m17s\n",
      "Total channels prunned so far: 451\n",
      "\n",
      "Iteration 452 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 47)]\n",
      "Input: 0.115 MB, Params: 2,772,918 (10.578 MB), Total: 10.69 MB, FLOPs: 290,105,400\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.470%\n",
      "Finished fine tuning.\n",
      "Iteration 452/1723 finished in 0m17s\n",
      "Total channels prunned so far: 452\n",
      "\n",
      "Iteration 453 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 305)]\n",
      "Input: 0.115 MB, Params: 2,769,520 (10.565 MB), Total: 10.68 MB, FLOPs: 290,013,734\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.122%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.122%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.470%\n",
      "Finished fine tuning.\n",
      "Iteration 453/1723 finished in 0m17s\n",
      "Total channels prunned so far: 453\n",
      "\n",
      "Iteration 454 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 325)]\n",
      "Input: 0.115 MB, Params: 2,764,361 (10.545 MB), Total: 10.66 MB, FLOPs: 289,874,468\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.470%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.774%\n",
      "Finished fine tuning.\n",
      "Iteration 454/1723 finished in 0m17s\n",
      "Total channels prunned so far: 454\n",
      "\n",
      "Iteration 455 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 195)]\n",
      "Input: 0.115 MB, Params: 2,759,139 (10.525 MB), Total: 10.64 MB, FLOPs: 289,584,596\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.774%\n",
      "Finished fine tuning.\n",
      "Iteration 455/1723 finished in 0m17s\n",
      "Total channels prunned so far: 455\n",
      "\n",
      "Iteration 456 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 196)]\n",
      "Input: 0.115 MB, Params: 2,756,149 (10.514 MB), Total: 10.63 MB, FLOPs: 289,261,784\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.122%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.122%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Finished fine tuning.\n",
      "Iteration 456/1723 finished in 0m16s\n",
      "Total channels prunned so far: 456\n",
      "\n",
      "Iteration 457 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 97)]\n",
      "Input: 0.115 MB, Params: 2,754,608 (10.508 MB), Total: 10.62 MB, FLOPs: 288,578,024\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.122%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.774%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Finished fine tuning.\n",
      "Iteration 457/1723 finished in 0m17s\n",
      "Total channels prunned so far: 457\n",
      "\n",
      "Iteration 458 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 267)]\n",
      "Input: 0.115 MB, Params: 2,751,219 (10.495 MB), Total: 10.61 MB, FLOPs: 288,486,601\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.774%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Finished fine tuning.\n",
      "Iteration 458/1723 finished in 0m16s\n",
      "Total channels prunned so far: 458\n",
      "\n",
      "Iteration 459 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 12)]\n",
      "Input: 0.115 MB, Params: 2,750,425 (10.492 MB), Total: 10.61 MB, FLOPs: 287,059,201\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.774%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Finished fine tuning.\n",
      "Iteration 459/1723 finished in 0m16s\n",
      "Total channels prunned so far: 459\n",
      "\n",
      "Iteration 460 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 276)]\n",
      "Input: 0.115 MB, Params: 2,745,284 (10.472 MB), Total: 10.59 MB, FLOPs: 286,920,421\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.774%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Finished fine tuning.\n",
      "Iteration 460/1723 finished in 0m17s\n",
      "Total channels prunned so far: 460\n",
      "\n",
      "Iteration 461 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 263)]\n",
      "Input: 0.115 MB, Params: 2,740,143 (10.453 MB), Total: 10.57 MB, FLOPs: 286,781,641\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Finished fine tuning.\n",
      "Iteration 461/1723 finished in 0m17s\n",
      "Total channels prunned so far: 461\n",
      "\n",
      "Iteration 462 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 153)]\n",
      "Input: 0.115 MB, Params: 2,735,002 (10.433 MB), Total: 10.55 MB, FLOPs: 286,642,861\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Finished fine tuning.\n",
      "Iteration 462/1723 finished in 0m17s\n",
      "Total channels prunned so far: 462\n",
      "\n",
      "Iteration 463 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 201)]\n",
      "Input: 0.115 MB, Params: 2,732,012 (10.422 MB), Total: 10.54 MB, FLOPs: 286,320,049\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Finished fine tuning.\n",
      "Iteration 463/1723 finished in 0m17s\n",
      "Total channels prunned so far: 463\n",
      "\n",
      "Iteration 464 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 280)]\n",
      "Input: 0.115 MB, Params: 2,726,871 (10.402 MB), Total: 10.52 MB, FLOPs: 286,181,269\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Finished fine tuning.\n",
      "Iteration 464/1723 finished in 0m17s\n",
      "Total channels prunned so far: 464\n",
      "\n",
      "Iteration 465 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 213)]\n",
      "Input: 0.115 MB, Params: 2,721,730 (10.383 MB), Total: 10.50 MB, FLOPs: 286,042,489\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Finished fine tuning.\n",
      "Iteration 465/1723 finished in 0m17s\n",
      "Total channels prunned so far: 465\n",
      "\n",
      "Iteration 466 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 240)]\n",
      "Input: 0.115 MB, Params: 2,716,589 (10.363 MB), Total: 10.48 MB, FLOPs: 285,903,709\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.289%\n",
      "Finished fine tuning.\n",
      "Iteration 466/1723 finished in 0m17s\n",
      "Total channels prunned so far: 466\n",
      "\n",
      "Iteration 467 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 22)]\n",
      "Input: 0.115 MB, Params: 2,711,439 (10.343 MB), Total: 10.46 MB, FLOPs: 285,617,239\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Finished fine tuning.\n",
      "Iteration 467/1723 finished in 0m17s\n",
      "Total channels prunned so far: 467\n",
      "\n",
      "Iteration 468 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 119)]\n",
      "Input: 0.115 MB, Params: 2,706,289 (10.324 MB), Total: 10.44 MB, FLOPs: 285,330,769\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.986%\n",
      "Finished fine tuning.\n",
      "Iteration 468/1723 finished in 0m17s\n",
      "Total channels prunned so far: 468\n",
      "\n",
      "Iteration 469 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 284)]\n",
      "Input: 0.115 MB, Params: 2,701,166 (10.304 MB), Total: 10.42 MB, FLOPs: 285,192,475\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.986%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Finished fine tuning.\n",
      "Iteration 469/1723 finished in 0m17s\n",
      "Total channels prunned so far: 469\n",
      "\n",
      "Iteration 470 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 59)]\n",
      "Input: 0.115 MB, Params: 2,699,625 (10.298 MB), Total: 10.41 MB, FLOPs: 284,508,715\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Finished fine tuning.\n",
      "Iteration 470/1723 finished in 0m17s\n",
      "Total channels prunned so far: 470\n",
      "\n",
      "Iteration 471 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 162)]\n",
      "Input: 0.115 MB, Params: 2,694,502 (10.279 MB), Total: 10.39 MB, FLOPs: 284,370,421\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Finished fine tuning.\n",
      "Iteration 471/1723 finished in 0m17s\n",
      "Total channels prunned so far: 471\n",
      "\n",
      "Iteration 472 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 140)]\n",
      "Input: 0.115 MB, Params: 2,689,379 (10.259 MB), Total: 10.37 MB, FLOPs: 284,232,127\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Finished fine tuning.\n",
      "Iteration 472/1723 finished in 0m17s\n",
      "Total channels prunned so far: 472\n",
      "\n",
      "Iteration 473 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 63)]\n",
      "Input: 0.115 MB, Params: 2,686,623 (10.249 MB), Total: 10.36 MB, FLOPs: 283,619,323\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Finished fine tuning.\n",
      "Iteration 473/1723 finished in 0m17s\n",
      "Total channels prunned so far: 473\n",
      "\n",
      "Iteration 474 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(14, 3)]\n",
      "Input: 0.115 MB, Params: 2,685,190 (10.243 MB), Total: 10.36 MB, FLOPs: 282,309,163\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Finished fine tuning.\n",
      "Iteration 474/1723 finished in 0m16s\n",
      "Total channels prunned so far: 474\n",
      "\n",
      "Iteration 475 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(3, 21)]\n",
      "Input: 0.115 MB, Params: 2,685,148 (10.243 MB), Total: 10.36 MB, FLOPs: 245,122,683\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.502%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.244%\n",
      "Finished fine tuning.\n",
      "Iteration 475/1723 finished in 0m17s\n",
      "Total channels prunned so far: 475\n",
      "\n",
      "Iteration 476 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 161)]\n",
      "Input: 0.115 MB, Params: 2,682,185 (10.232 MB), Total: 10.35 MB, FLOPs: 244,856,103\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.289%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.986%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.592%\n",
      "Finished fine tuning.\n",
      "Iteration 476/1723 finished in 0m17s\n",
      "Total channels prunned so far: 476\n",
      "\n",
      "Iteration 477 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 82)]\n",
      "Input: 0.115 MB, Params: 2,679,222 (10.220 MB), Total: 10.34 MB, FLOPs: 244,589,523\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.941%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.502%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.986%\n",
      "Finished fine tuning.\n",
      "Iteration 477/1723 finished in 0m17s\n",
      "Total channels prunned so far: 477\n",
      "\n",
      "Iteration 478 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 195)]\n",
      "Input: 0.115 MB, Params: 2,674,099 (10.201 MB), Total: 10.32 MB, FLOPs: 244,497,327\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Finished fine tuning.\n",
      "Iteration 478/1723 finished in 0m16s\n",
      "Total channels prunned so far: 478\n",
      "\n",
      "Iteration 479 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 16)]\n",
      "Input: 0.115 MB, Params: 2,669,003 (10.181 MB), Total: 10.30 MB, FLOPs: 244,275,873\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.289%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Finished fine tuning.\n",
      "Iteration 479/1723 finished in 0m17s\n",
      "Total channels prunned so far: 479\n",
      "\n",
      "Iteration 480 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(3, 43)]\n",
      "Input: 0.115 MB, Params: 2,668,961 (10.181 MB), Total: 10.30 MB, FLOPs: 243,916,370\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.986%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Finished fine tuning.\n",
      "Iteration 480/1723 finished in 0m17s\n",
      "Total channels prunned so far: 480\n",
      "\n",
      "Iteration 481 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 227)]\n",
      "Input: 0.115 MB, Params: 2,665,662 (10.169 MB), Total: 10.28 MB, FLOPs: 243,857,032\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.289%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.941%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.638%\n",
      "Finished fine tuning.\n",
      "Iteration 481/1723 finished in 0m17s\n",
      "Total channels prunned so far: 481\n",
      "\n",
      "Iteration 482 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 227)]\n",
      "Input: 0.115 MB, Params: 2,662,363 (10.156 MB), Total: 10.27 MB, FLOPs: 243,797,694\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.592%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.638%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.592%\n",
      "Finished fine tuning.\n",
      "Iteration 482/1723 finished in 0m17s\n",
      "Total channels prunned so far: 482\n",
      "\n",
      "Iteration 483 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 73)]\n",
      "Input: 0.115 MB, Params: 2,657,267 (10.137 MB), Total: 10.25 MB, FLOPs: 243,576,240\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.986%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.592%\n",
      "Finished fine tuning.\n",
      "Iteration 483/1723 finished in 0m17s\n",
      "Total channels prunned so far: 483\n",
      "\n",
      "Iteration 484 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 362)]\n",
      "Input: 0.115 MB, Params: 2,652,180 (10.117 MB), Total: 10.23 MB, FLOPs: 243,484,692\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.244%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.638%\n",
      "Finished fine tuning.\n",
      "Iteration 484/1723 finished in 0m17s\n",
      "Total channels prunned so far: 484\n",
      "\n",
      "Iteration 485 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 36)]\n",
      "Input: 0.115 MB, Params: 2,647,093 (10.098 MB), Total: 10.21 MB, FLOPs: 243,393,144\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Finished fine tuning.\n",
      "Iteration 485/1723 finished in 0m17s\n",
      "Total channels prunned so far: 485\n",
      "\n",
      "Iteration 486 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(7, 25)]\n",
      "Input: 0.115 MB, Params: 2,646,587 (10.096 MB), Total: 10.21 MB, FLOPs: 242,462,909\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Finished fine tuning.\n",
      "Iteration 486/1723 finished in 0m17s\n",
      "Total channels prunned so far: 486\n",
      "\n",
      "Iteration 487 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 296)]\n",
      "Input: 0.115 MB, Params: 2,641,500 (10.077 MB), Total: 10.19 MB, FLOPs: 242,371,361\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Finished fine tuning.\n",
      "Iteration 487/1723 finished in 0m17s\n",
      "Total channels prunned so far: 487\n",
      "\n",
      "Iteration 488 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 69)]\n",
      "Input: 0.115 MB, Params: 2,636,413 (10.057 MB), Total: 10.17 MB, FLOPs: 242,279,813\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Finished fine tuning.\n",
      "Iteration 488/1723 finished in 0m17s\n",
      "Total channels prunned so far: 488\n",
      "\n",
      "Iteration 489 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 270)]\n",
      "Input: 0.115 MB, Params: 2,631,326 (10.038 MB), Total: 10.15 MB, FLOPs: 242,188,265\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.986%\n",
      "Finished fine tuning.\n",
      "Iteration 489/1723 finished in 0m17s\n",
      "Total channels prunned so far: 489\n",
      "\n",
      "Iteration 490 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 299)]\n",
      "Input: 0.115 MB, Params: 2,628,072 (10.025 MB), Total: 10.14 MB, FLOPs: 242,129,737\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.289%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.592%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.941%\n",
      "Finished fine tuning.\n",
      "Iteration 490/1723 finished in 0m17s\n",
      "Total channels prunned so far: 490\n",
      "\n",
      "Iteration 491 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 104)]\n",
      "Input: 0.115 MB, Params: 2,622,994 (10.006 MB), Total: 10.12 MB, FLOPs: 242,038,351\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Finished fine tuning.\n",
      "Iteration 491/1723 finished in 0m17s\n",
      "Total channels prunned so far: 491\n",
      "\n",
      "Iteration 492 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 136)]\n",
      "Input: 0.115 MB, Params: 2,617,916 (9.987 MB), Total: 10.10 MB, FLOPs: 241,946,965\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Finished fine tuning.\n",
      "Iteration 492/1723 finished in 0m17s\n",
      "Total channels prunned so far: 492\n",
      "\n",
      "Iteration 493 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(7, 12)]\n",
      "Input: 0.115 MB, Params: 2,617,410 (9.985 MB), Total: 10.10 MB, FLOPs: 241,016,730\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.638%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Finished fine tuning.\n",
      "Iteration 493/1723 finished in 0m17s\n",
      "Total channels prunned so far: 493\n",
      "\n",
      "Iteration 494 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 19)]\n",
      "Input: 0.115 MB, Params: 2,614,465 (9.973 MB), Total: 10.09 MB, FLOPs: 240,751,770\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Finished fine tuning.\n",
      "Iteration 494/1723 finished in 0m17s\n",
      "Total channels prunned so far: 494\n",
      "\n",
      "Iteration 495 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 155)]\n",
      "Input: 0.115 MB, Params: 2,611,229 (9.961 MB), Total: 10.08 MB, FLOPs: 240,693,566\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.986%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Finished fine tuning.\n",
      "Iteration 495/1723 finished in 0m17s\n",
      "Total channels prunned so far: 495\n",
      "\n",
      "Iteration 496 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 277)]\n",
      "Input: 0.115 MB, Params: 2,606,160 (9.942 MB), Total: 10.06 MB, FLOPs: 240,602,342\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.986%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.986%\n",
      "Finished fine tuning.\n",
      "Iteration 496/1723 finished in 0m17s\n",
      "Total channels prunned so far: 496\n",
      "\n",
      "Iteration 497 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 24)]\n",
      "Input: 0.115 MB, Params: 2,601,145 (9.923 MB), Total: 10.04 MB, FLOPs: 240,382,994\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.638%\n",
      "Finished fine tuning.\n",
      "Iteration 497/1723 finished in 0m17s\n",
      "Total channels prunned so far: 497\n",
      "\n",
      "Iteration 498 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 47)]\n",
      "Input: 0.115 MB, Params: 2,598,209 (9.911 MB), Total: 10.03 MB, FLOPs: 240,118,844\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.638%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.638%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Finished fine tuning.\n",
      "Iteration 498/1723 finished in 0m17s\n",
      "Total channels prunned so far: 498\n",
      "\n",
      "Iteration 499 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 202)]\n",
      "Input: 0.115 MB, Params: 2,594,982 (9.899 MB), Total: 10.01 MB, FLOPs: 240,060,802\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Finished fine tuning.\n",
      "Iteration 499/1723 finished in 0m16s\n",
      "Total channels prunned so far: 499\n",
      "\n",
      "Iteration 500 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 152)]\n",
      "Input: 0.115 MB, Params: 2,591,755 (9.887 MB), Total: 10.00 MB, FLOPs: 240,002,760\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Finished fine tuning.\n",
      "Iteration 500/1723 finished in 0m17s\n",
      "Total channels prunned so far: 500\n",
      "\n",
      "Iteration 501 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 29)]\n",
      "Input: 0.115 MB, Params: 2,588,819 (9.876 MB), Total: 9.99 MB, FLOPs: 239,738,610\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Finished fine tuning.\n",
      "Iteration 501/1723 finished in 0m17s\n",
      "Total channels prunned so far: 501\n",
      "\n",
      "Iteration 502 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 3)]\n",
      "Input: 0.115 MB, Params: 2,587,296 (9.870 MB), Total: 9.99 MB, FLOPs: 239,119,156\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.774%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Finished fine tuning.\n",
      "Iteration 502/1723 finished in 0m17s\n",
      "Total channels prunned so far: 502\n",
      "\n",
      "Iteration 503 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 25)]\n",
      "Input: 0.115 MB, Params: 2,585,773 (9.864 MB), Total: 9.98 MB, FLOPs: 238,499,702\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Finished fine tuning.\n",
      "Iteration 503/1723 finished in 0m17s\n",
      "Total channels prunned so far: 503\n",
      "\n",
      "Iteration 504 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 7)]\n",
      "Input: 0.115 MB, Params: 2,583,080 (9.854 MB), Total: 9.97 MB, FLOPs: 237,965,739\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Finished fine tuning.\n",
      "Iteration 504/1723 finished in 0m16s\n",
      "Total channels prunned so far: 504\n",
      "\n",
      "Iteration 505 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 215)]\n",
      "Input: 0.115 MB, Params: 2,578,038 (9.834 MB), Total: 9.95 MB, FLOPs: 237,875,001\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Finished fine tuning.\n",
      "Iteration 505/1723 finished in 0m17s\n",
      "Total channels prunned so far: 505\n",
      "\n",
      "Iteration 506 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 30)]\n",
      "Input: 0.115 MB, Params: 2,572,996 (9.815 MB), Total: 9.93 MB, FLOPs: 237,784,263\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Finished fine tuning.\n",
      "Iteration 506/1723 finished in 0m17s\n",
      "Total channels prunned so far: 506\n",
      "\n",
      "Iteration 507 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 99)]\n",
      "Input: 0.115 MB, Params: 2,567,954 (9.796 MB), Total: 9.91 MB, FLOPs: 237,693,525\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.986%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Finished fine tuning.\n",
      "Iteration 507/1723 finished in 0m17s\n",
      "Total channels prunned so far: 507\n",
      "\n",
      "Iteration 508 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 45)]\n",
      "Input: 0.115 MB, Params: 2,562,912 (9.777 MB), Total: 9.89 MB, FLOPs: 237,602,787\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Finished fine tuning.\n",
      "Iteration 508/1723 finished in 0m17s\n",
      "Total channels prunned so far: 508\n",
      "\n",
      "Iteration 509 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 279)]\n",
      "Input: 0.115 MB, Params: 2,557,870 (9.757 MB), Total: 9.87 MB, FLOPs: 237,512,049\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Finished fine tuning.\n",
      "Iteration 509/1723 finished in 0m17s\n",
      "Total channels prunned so far: 509\n",
      "\n",
      "Iteration 510 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 123)]\n",
      "Input: 0.115 MB, Params: 2,554,688 (9.745 MB), Total: 9.86 MB, FLOPs: 237,454,817\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.986%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.289%\n",
      "Finished fine tuning.\n",
      "Iteration 510/1723 finished in 0m17s\n",
      "Total channels prunned so far: 510\n",
      "\n",
      "Iteration 511 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 6)]\n",
      "Input: 0.115 MB, Params: 2,551,506 (9.733 MB), Total: 9.85 MB, FLOPs: 237,397,585\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Finished fine tuning.\n",
      "Iteration 511/1723 finished in 0m17s\n",
      "Total channels prunned so far: 511\n",
      "\n",
      "Iteration 512 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 66)]\n",
      "Input: 0.115 MB, Params: 2,546,482 (9.714 MB), Total: 9.83 MB, FLOPs: 237,307,171\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Finished fine tuning.\n",
      "Iteration 512/1723 finished in 0m17s\n",
      "Total channels prunned so far: 512\n",
      "\n",
      "Iteration 513 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 99)]\n",
      "Input: 0.115 MB, Params: 2,543,555 (9.703 MB), Total: 9.82 MB, FLOPs: 237,043,831\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Finished fine tuning.\n",
      "Iteration 513/1723 finished in 0m17s\n",
      "Total channels prunned so far: 513\n",
      "\n",
      "Iteration 514 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 344)]\n",
      "Input: 0.115 MB, Params: 2,538,531 (9.684 MB), Total: 9.80 MB, FLOPs: 236,953,417\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Finished fine tuning.\n",
      "Iteration 514/1723 finished in 0m17s\n",
      "Total channels prunned so far: 514\n",
      "\n",
      "Iteration 515 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 190)]\n",
      "Input: 0.115 MB, Params: 2,535,367 (9.672 MB), Total: 9.79 MB, FLOPs: 236,896,509\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.986%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Finished fine tuning.\n",
      "Iteration 515/1723 finished in 0m17s\n",
      "Total channels prunned so far: 515\n",
      "\n",
      "Iteration 516 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 286)]\n",
      "Input: 0.115 MB, Params: 2,532,203 (9.660 MB), Total: 9.77 MB, FLOPs: 236,839,601\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Finished fine tuning.\n",
      "Iteration 516/1723 finished in 0m17s\n",
      "Total channels prunned so far: 516\n",
      "\n",
      "Iteration 517 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 109)]\n",
      "Input: 0.115 MB, Params: 2,527,197 (9.640 MB), Total: 9.76 MB, FLOPs: 236,749,511\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Finished fine tuning.\n",
      "Iteration 517/1723 finished in 0m17s\n",
      "Total channels prunned so far: 517\n",
      "\n",
      "Iteration 518 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 316)]\n",
      "Input: 0.115 MB, Params: 2,522,191 (9.621 MB), Total: 9.74 MB, FLOPs: 236,659,421\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Finished fine tuning.\n",
      "Iteration 518/1723 finished in 0m17s\n",
      "Total channels prunned so far: 518\n",
      "\n",
      "Iteration 519 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 135)]\n",
      "Input: 0.115 MB, Params: 2,517,185 (9.602 MB), Total: 9.72 MB, FLOPs: 236,569,331\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.774%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Finished fine tuning.\n",
      "Iteration 519/1723 finished in 0m17s\n",
      "Total channels prunned so far: 519\n",
      "\n",
      "Iteration 520 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 85)]\n",
      "Input: 0.115 MB, Params: 2,514,048 (9.590 MB), Total: 9.71 MB, FLOPs: 236,512,909\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Finished fine tuning.\n",
      "Iteration 520/1723 finished in 0m17s\n",
      "Total channels prunned so far: 520\n",
      "\n",
      "Iteration 521 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 118)]\n",
      "Input: 0.115 MB, Params: 2,509,150 (9.572 MB), Total: 9.69 MB, FLOPs: 236,297,611\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Finished fine tuning.\n",
      "Iteration 521/1723 finished in 0m17s\n",
      "Total channels prunned so far: 521\n",
      "\n",
      "Iteration 522 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 274)]\n",
      "Input: 0.115 MB, Params: 2,504,162 (9.553 MB), Total: 9.67 MB, FLOPs: 236,207,845\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Finished fine tuning.\n",
      "Iteration 522/1723 finished in 0m17s\n",
      "Total channels prunned so far: 522\n",
      "\n",
      "Iteration 523 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 212)]\n",
      "Input: 0.115 MB, Params: 2,501,034 (9.541 MB), Total: 9.66 MB, FLOPs: 236,151,585\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.941%\n",
      "Finished fine tuning.\n",
      "Iteration 523/1723 finished in 0m17s\n",
      "Total channels prunned so far: 523\n",
      "\n",
      "Iteration 524 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 235)]\n",
      "Input: 0.115 MB, Params: 2,496,055 (9.522 MB), Total: 9.64 MB, FLOPs: 236,061,981\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.986%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Finished fine tuning.\n",
      "Iteration 524/1723 finished in 0m17s\n",
      "Total channels prunned so far: 524\n",
      "\n",
      "Iteration 525 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 92)]\n",
      "Input: 0.115 MB, Params: 2,492,936 (9.510 MB), Total: 9.63 MB, FLOPs: 236,005,883\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.122%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.470%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Finished fine tuning.\n",
      "Iteration 525/1723 finished in 0m17s\n",
      "Total channels prunned so far: 525\n",
      "\n",
      "Iteration 526 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 135)]\n",
      "Input: 0.115 MB, Params: 2,489,817 (9.498 MB), Total: 9.61 MB, FLOPs: 235,949,785\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Finished fine tuning.\n",
      "Iteration 526/1723 finished in 0m17s\n",
      "Total channels prunned so far: 526\n",
      "\n",
      "Iteration 527 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 152)]\n",
      "Input: 0.115 MB, Params: 2,486,698 (9.486 MB), Total: 9.60 MB, FLOPs: 235,893,687\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.774%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Finished fine tuning.\n",
      "Iteration 527/1723 finished in 0m17s\n",
      "Total channels prunned so far: 527\n",
      "\n",
      "Iteration 528 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 5)]\n",
      "Input: 0.115 MB, Params: 2,481,746 (9.467 MB), Total: 9.58 MB, FLOPs: 235,804,569\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Finished fine tuning.\n",
      "Iteration 528/1723 finished in 0m17s\n",
      "Total channels prunned so far: 528\n",
      "\n",
      "Iteration 529 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 223)]\n",
      "Input: 0.115 MB, Params: 2,478,636 (9.455 MB), Total: 9.57 MB, FLOPs: 235,748,633\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Finished fine tuning.\n",
      "Iteration 529/1723 finished in 0m16s\n",
      "Total channels prunned so far: 529\n",
      "\n",
      "Iteration 530 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 18)]\n",
      "Input: 0.115 MB, Params: 2,473,765 (9.437 MB), Total: 9.55 MB, FLOPs: 235,533,821\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Finished fine tuning.\n",
      "Iteration 530/1723 finished in 0m17s\n",
      "Total channels prunned so far: 530\n",
      "\n",
      "Iteration 531 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 329)]\n",
      "Input: 0.115 MB, Params: 2,468,831 (9.418 MB), Total: 9.53 MB, FLOPs: 235,445,027\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Finished fine tuning.\n",
      "Iteration 531/1723 finished in 0m17s\n",
      "Total channels prunned so far: 531\n",
      "\n",
      "Iteration 532 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 172)]\n",
      "Input: 0.115 MB, Params: 2,465,922 (9.407 MB), Total: 9.52 MB, FLOPs: 235,183,307\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.986%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Finished fine tuning.\n",
      "Iteration 532/1723 finished in 0m17s\n",
      "Total channels prunned so far: 532\n",
      "\n",
      "Iteration 533 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 123)]\n",
      "Input: 0.115 MB, Params: 2,462,821 (9.395 MB), Total: 9.51 MB, FLOPs: 235,127,533\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.986%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.638%\n",
      "Finished fine tuning.\n",
      "Iteration 533/1723 finished in 0m17s\n",
      "Total channels prunned so far: 533\n",
      "\n",
      "Iteration 534 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 110)]\n",
      "Input: 0.115 MB, Params: 2,457,968 (9.376 MB), Total: 9.49 MB, FLOPs: 234,913,693\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.638%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Finished fine tuning.\n",
      "Iteration 534/1723 finished in 0m17s\n",
      "Total channels prunned so far: 534\n",
      "\n",
      "Iteration 535 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(0, 5)]\n",
      "Input: 0.115 MB, Params: 2,457,727 (9.375 MB), Total: 9.49 MB, FLOPs: 233,025,413\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.502%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.986%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Finished fine tuning.\n",
      "Iteration 535/1723 finished in 0m17s\n",
      "Total channels prunned so far: 535\n",
      "\n",
      "Iteration 536 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 117)]\n",
      "Input: 0.115 MB, Params: 2,454,626 (9.364 MB), Total: 9.48 MB, FLOPs: 232,969,639\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Finished fine tuning.\n",
      "Iteration 536/1723 finished in 0m17s\n",
      "Total channels prunned so far: 536\n",
      "\n",
      "Iteration 537 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 178)]\n",
      "Input: 0.115 MB, Params: 2,449,719 (9.345 MB), Total: 9.46 MB, FLOPs: 232,881,331\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.244%\n",
      "Finished fine tuning.\n",
      "Iteration 537/1723 finished in 0m17s\n",
      "Total channels prunned so far: 537\n",
      "\n",
      "Iteration 538 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 83)]\n",
      "Input: 0.115 MB, Params: 2,446,819 (9.334 MB), Total: 9.45 MB, FLOPs: 232,620,421\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.941%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Finished fine tuning.\n",
      "Iteration 538/1723 finished in 0m17s\n",
      "Total channels prunned so far: 538\n",
      "\n",
      "Iteration 539 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 180)]\n",
      "Input: 0.115 MB, Params: 2,443,727 (9.322 MB), Total: 9.44 MB, FLOPs: 232,564,809\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Finished fine tuning.\n",
      "Iteration 539/1723 finished in 0m17s\n",
      "Total channels prunned so far: 539\n",
      "\n",
      "Iteration 540 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 311)]\n",
      "Input: 0.115 MB, Params: 2,438,829 (9.303 MB), Total: 9.42 MB, FLOPs: 232,476,663\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.289%\n",
      "Finished fine tuning.\n",
      "Iteration 540/1723 finished in 0m17s\n",
      "Total channels prunned so far: 540\n",
      "\n",
      "Iteration 541 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 170)]\n",
      "Input: 0.115 MB, Params: 2,435,746 (9.292 MB), Total: 9.41 MB, FLOPs: 232,421,213\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.986%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Finished fine tuning.\n",
      "Iteration 541/1723 finished in 0m17s\n",
      "Total channels prunned so far: 541\n",
      "\n",
      "Iteration 542 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 256)]\n",
      "Input: 0.115 MB, Params: 2,432,663 (9.280 MB), Total: 9.40 MB, FLOPs: 232,365,763\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.941%\n",
      "Finished fine tuning.\n",
      "Iteration 542/1723 finished in 0m17s\n",
      "Total channels prunned so far: 542\n",
      "\n",
      "Iteration 543 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 169)]\n",
      "Input: 0.115 MB, Params: 2,427,783 (9.261 MB), Total: 9.38 MB, FLOPs: 232,277,941\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.244%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.774%\n",
      "Finished fine tuning.\n",
      "Iteration 543/1723 finished in 0m17s\n",
      "Total channels prunned so far: 543\n",
      "\n",
      "Iteration 544 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 105)]\n",
      "Input: 0.115 MB, Params: 2,424,709 (9.250 MB), Total: 9.36 MB, FLOPs: 232,222,653\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.122%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.470%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Finished fine tuning.\n",
      "Iteration 544/1723 finished in 0m17s\n",
      "Total channels prunned so far: 544\n",
      "\n",
      "Iteration 545 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 51)]\n",
      "Input: 0.115 MB, Params: 2,419,892 (9.231 MB), Total: 9.35 MB, FLOPs: 232,010,109\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.819%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Finished fine tuning.\n",
      "Iteration 545/1723 finished in 0m17s\n",
      "Total channels prunned so far: 545\n",
      "\n",
      "Iteration 546 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 176)]\n",
      "Input: 0.115 MB, Params: 2,417,001 (9.220 MB), Total: 9.34 MB, FLOPs: 231,750,009\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Finished fine tuning.\n",
      "Iteration 546/1723 finished in 0m17s\n",
      "Total channels prunned so far: 546\n",
      "\n",
      "Iteration 547 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 113)]\n",
      "Input: 0.115 MB, Params: 2,414,110 (9.209 MB), Total: 9.32 MB, FLOPs: 231,489,909\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.774%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Finished fine tuning.\n",
      "Iteration 547/1723 finished in 0m16s\n",
      "Total channels prunned so far: 547\n",
      "\n",
      "Iteration 548 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 1)]\n",
      "Input: 0.115 MB, Params: 2,413,343 (9.206 MB), Total: 9.32 MB, FLOPs: 230,168,559\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.986%\n",
      "Finished fine tuning.\n",
      "Iteration 548/1723 finished in 0m16s\n",
      "Total channels prunned so far: 548\n",
      "\n",
      "Iteration 549 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 231)]\n",
      "Input: 0.115 MB, Params: 2,408,481 (9.188 MB), Total: 9.30 MB, FLOPs: 230,081,061\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.638%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.638%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Finished fine tuning.\n",
      "Iteration 549/1723 finished in 0m17s\n",
      "Total channels prunned so far: 549\n",
      "\n",
      "Iteration 550 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 224)]\n",
      "Input: 0.115 MB, Params: 2,405,416 (9.176 MB), Total: 9.29 MB, FLOPs: 230,025,935\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.986%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Finished fine tuning.\n",
      "Iteration 550/1723 finished in 0m17s\n",
      "Total channels prunned so far: 550\n",
      "\n",
      "Iteration 551 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 112)]\n",
      "Input: 0.115 MB, Params: 2,402,351 (9.164 MB), Total: 9.28 MB, FLOPs: 229,970,809\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Finished fine tuning.\n",
      "Iteration 551/1723 finished in 0m17s\n",
      "Total channels prunned so far: 551\n",
      "\n",
      "Iteration 552 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 101)]\n",
      "Input: 0.115 MB, Params: 2,397,507 (9.146 MB), Total: 9.26 MB, FLOPs: 229,883,635\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Finished fine tuning.\n",
      "Iteration 552/1723 finished in 0m17s\n",
      "Total channels prunned so far: 552\n",
      "\n",
      "Iteration 553 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 283)]\n",
      "Input: 0.115 MB, Params: 2,394,451 (9.134 MB), Total: 9.25 MB, FLOPs: 229,828,671\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.986%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Finished fine tuning.\n",
      "Iteration 553/1723 finished in 0m17s\n",
      "Total channels prunned so far: 553\n",
      "\n",
      "Iteration 554 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 10)]\n",
      "Input: 0.115 MB, Params: 2,393,684 (9.131 MB), Total: 9.25 MB, FLOPs: 228,507,321\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Finished fine tuning.\n",
      "Iteration 554/1723 finished in 0m17s\n",
      "Total channels prunned so far: 554\n",
      "\n",
      "Iteration 555 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 160)]\n",
      "Input: 0.115 MB, Params: 2,390,628 (9.120 MB), Total: 9.23 MB, FLOPs: 228,452,357\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Finished fine tuning.\n",
      "Iteration 555/1723 finished in 0m16s\n",
      "Total channels prunned so far: 555\n",
      "\n",
      "Iteration 556 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 303)]\n",
      "Input: 0.115 MB, Params: 2,385,802 (9.101 MB), Total: 9.22 MB, FLOPs: 228,365,507\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.986%\n",
      "Finished fine tuning.\n",
      "Iteration 556/1723 finished in 0m17s\n",
      "Total channels prunned so far: 556\n",
      "\n",
      "Iteration 557 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 225)]\n",
      "Input: 0.115 MB, Params: 2,382,755 (9.089 MB), Total: 9.20 MB, FLOPs: 228,310,705\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.986%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.638%\n",
      "Finished fine tuning.\n",
      "Iteration 557/1723 finished in 0m17s\n",
      "Total channels prunned so far: 557\n",
      "\n",
      "Iteration 558 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 163)]\n",
      "Input: 0.115 MB, Params: 2,379,708 (9.078 MB), Total: 9.19 MB, FLOPs: 228,255,903\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.289%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.289%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.638%\n",
      "Finished fine tuning.\n",
      "Iteration 558/1723 finished in 0m17s\n",
      "Total channels prunned so far: 558\n",
      "\n",
      "Iteration 559 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 299)]\n",
      "Input: 0.115 MB, Params: 2,376,661 (9.066 MB), Total: 9.18 MB, FLOPs: 228,201,101\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.986%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Finished fine tuning.\n",
      "Iteration 559/1723 finished in 0m17s\n",
      "Total channels prunned so far: 559\n",
      "\n",
      "Iteration 560 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 46)]\n",
      "Input: 0.115 MB, Params: 2,373,770 (9.055 MB), Total: 9.17 MB, FLOPs: 227,941,001\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.638%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Finished fine tuning.\n",
      "Iteration 560/1723 finished in 0m17s\n",
      "Total channels prunned so far: 560\n",
      "\n",
      "Iteration 561 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 317)]\n",
      "Input: 0.115 MB, Params: 2,370,723 (9.044 MB), Total: 9.16 MB, FLOPs: 227,886,199\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.592%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.592%\n",
      "Finished fine tuning.\n",
      "Iteration 561/1723 finished in 0m16s\n",
      "Total channels prunned so far: 561\n",
      "\n",
      "Iteration 562 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 83)]\n",
      "Input: 0.115 MB, Params: 2,368,084 (9.034 MB), Total: 9.15 MB, FLOPs: 227,357,096\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.289%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Finished fine tuning.\n",
      "Iteration 562/1723 finished in 0m17s\n",
      "Total channels prunned so far: 562\n",
      "\n",
      "Iteration 563 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 57)]\n",
      "Input: 0.115 MB, Params: 2,365,202 (9.023 MB), Total: 9.14 MB, FLOPs: 227,097,806\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Finished fine tuning.\n",
      "Iteration 563/1723 finished in 0m17s\n",
      "Total channels prunned so far: 563\n",
      "\n",
      "Iteration 564 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 62)]\n",
      "Input: 0.115 MB, Params: 2,362,155 (9.011 MB), Total: 9.13 MB, FLOPs: 227,043,004\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.986%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Finished fine tuning.\n",
      "Iteration 564/1723 finished in 0m17s\n",
      "Total channels prunned so far: 564\n",
      "\n",
      "Iteration 565 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 189)]\n",
      "Input: 0.115 MB, Params: 2,357,401 (8.993 MB), Total: 9.11 MB, FLOPs: 226,834,186\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Finished fine tuning.\n",
      "Iteration 565/1723 finished in 0m16s\n",
      "Total channels prunned so far: 565\n",
      "\n",
      "Iteration 566 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(3, 18)]\n",
      "Input: 0.115 MB, Params: 2,357,364 (8.993 MB), Total: 9.11 MB, FLOPs: 223,458,393\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Finished fine tuning.\n",
      "Iteration 566/1723 finished in 0m17s\n",
      "Total channels prunned so far: 566\n",
      "\n",
      "Iteration 567 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 51)]\n",
      "Input: 0.115 MB, Params: 2,352,610 (8.974 MB), Total: 9.09 MB, FLOPs: 223,249,575\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.638%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.289%\n",
      "Finished fine tuning.\n",
      "Iteration 567/1723 finished in 0m17s\n",
      "Total channels prunned so far: 567\n",
      "\n",
      "Iteration 568 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 161)]\n",
      "Input: 0.115 MB, Params: 2,349,563 (8.963 MB), Total: 9.08 MB, FLOPs: 223,194,773\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.986%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.986%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Finished fine tuning.\n",
      "Iteration 568/1723 finished in 0m17s\n",
      "Total channels prunned so far: 568\n",
      "\n",
      "Iteration 569 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 172)]\n",
      "Input: 0.115 MB, Params: 2,344,809 (8.945 MB), Total: 9.06 MB, FLOPs: 222,985,955\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Finished fine tuning.\n",
      "Iteration 569/1723 finished in 0m17s\n",
      "Total channels prunned so far: 569\n",
      "\n",
      "Iteration 570 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 194)]\n",
      "Input: 0.115 MB, Params: 2,341,762 (8.933 MB), Total: 9.05 MB, FLOPs: 222,931,153\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.986%\n",
      "Finished fine tuning.\n",
      "Iteration 570/1723 finished in 0m17s\n",
      "Total channels prunned so far: 570\n",
      "\n",
      "Iteration 571 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 263)]\n",
      "Input: 0.115 MB, Params: 2,338,715 (8.921 MB), Total: 9.04 MB, FLOPs: 222,876,351\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.638%\n",
      "Finished fine tuning.\n",
      "Iteration 571/1723 finished in 0m17s\n",
      "Total channels prunned so far: 571\n",
      "\n",
      "Iteration 572 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 100)]\n",
      "Input: 0.115 MB, Params: 2,336,085 (8.911 MB), Total: 9.03 MB, FLOPs: 222,348,058\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Finished fine tuning.\n",
      "Iteration 572/1723 finished in 0m17s\n",
      "Total channels prunned so far: 572\n",
      "\n",
      "Iteration 573 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 10)]\n",
      "Input: 0.115 MB, Params: 2,335,318 (8.909 MB), Total: 9.02 MB, FLOPs: 221,084,158\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.289%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Finished fine tuning.\n",
      "Iteration 573/1723 finished in 0m17s\n",
      "Total channels prunned so far: 573\n",
      "\n",
      "Iteration 574 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 171)]\n",
      "Input: 0.115 MB, Params: 2,330,564 (8.890 MB), Total: 9.01 MB, FLOPs: 220,875,340\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.516%\n",
      "Finished fine tuning.\n",
      "Iteration 574/1723 finished in 0m17s\n",
      "Total channels prunned so far: 574\n",
      "\n",
      "Iteration 575 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 114)]\n",
      "Input: 0.115 MB, Params: 2,325,810 (8.872 MB), Total: 8.99 MB, FLOPs: 220,666,522\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.470%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.592%\n",
      "Finished fine tuning.\n",
      "Iteration 575/1723 finished in 0m17s\n",
      "Total channels prunned so far: 575\n",
      "\n",
      "Iteration 576 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(14, 10)]\n",
      "Input: 0.115 MB, Params: 2,324,422 (8.867 MB), Total: 8.98 MB, FLOPs: 219,517,418\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.941%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.638%\n",
      "Finished fine tuning.\n",
      "Iteration 576/1723 finished in 0m17s\n",
      "Total channels prunned so far: 576\n",
      "\n",
      "Iteration 577 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 157)]\n",
      "Input: 0.115 MB, Params: 2,321,594 (8.856 MB), Total: 8.97 MB, FLOPs: 219,262,988\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.986%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Finished fine tuning.\n",
      "Iteration 577/1723 finished in 0m17s\n",
      "Total channels prunned so far: 577\n",
      "\n",
      "Iteration 578 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 311)]\n",
      "Input: 0.115 MB, Params: 2,318,547 (8.845 MB), Total: 8.96 MB, FLOPs: 219,208,186\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Finished fine tuning.\n",
      "Iteration 578/1723 finished in 0m16s\n",
      "Total channels prunned so far: 578\n",
      "\n",
      "Iteration 579 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 203)]\n",
      "Input: 0.115 MB, Params: 2,313,802 (8.826 MB), Total: 8.94 MB, FLOPs: 219,000,178\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.592%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Finished fine tuning.\n",
      "Iteration 579/1723 finished in 0m17s\n",
      "Total channels prunned so far: 579\n",
      "\n",
      "Iteration 580 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 42)]\n",
      "Input: 0.115 MB, Params: 2,309,111 (8.809 MB), Total: 8.92 MB, FLOPs: 218,915,758\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Finished fine tuning.\n",
      "Iteration 580/1723 finished in 0m17s\n",
      "Total channels prunned so far: 580\n",
      "\n",
      "Iteration 581 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 51)]\n",
      "Input: 0.115 MB, Params: 2,304,375 (8.790 MB), Total: 8.91 MB, FLOPs: 218,707,912\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Finished fine tuning.\n",
      "Iteration 581/1723 finished in 0m17s\n",
      "Total channels prunned so far: 581\n",
      "\n",
      "Iteration 582 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 114)]\n",
      "Input: 0.115 MB, Params: 2,301,565 (8.780 MB), Total: 8.90 MB, FLOPs: 218,455,102\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Finished fine tuning.\n",
      "Iteration 582/1723 finished in 0m17s\n",
      "Total channels prunned so far: 582\n",
      "\n",
      "Iteration 583 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 139)]\n",
      "Input: 0.115 MB, Params: 2,296,883 (8.762 MB), Total: 8.88 MB, FLOPs: 218,370,844\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Finished fine tuning.\n",
      "Iteration 583/1723 finished in 0m17s\n",
      "Total channels prunned so far: 583\n",
      "\n",
      "Iteration 584 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 134)]\n",
      "Input: 0.115 MB, Params: 2,293,854 (8.750 MB), Total: 8.87 MB, FLOPs: 218,316,366\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Finished fine tuning.\n",
      "Iteration 584/1723 finished in 0m17s\n",
      "Total channels prunned so far: 584\n",
      "\n",
      "Iteration 585 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 32)]\n",
      "Input: 0.115 MB, Params: 2,291,044 (8.740 MB), Total: 8.85 MB, FLOPs: 218,063,556\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Finished fine tuning.\n",
      "Iteration 585/1723 finished in 0m17s\n",
      "Total channels prunned so far: 585\n",
      "\n",
      "Iteration 586 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 211)]\n",
      "Input: 0.115 MB, Params: 2,286,371 (8.722 MB), Total: 8.84 MB, FLOPs: 217,979,460\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.986%\n",
      "Finished fine tuning.\n",
      "Iteration 586/1723 finished in 0m17s\n",
      "Total channels prunned so far: 586\n",
      "\n",
      "Iteration 587 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 285)]\n",
      "Input: 0.115 MB, Params: 2,283,351 (8.710 MB), Total: 8.83 MB, FLOPs: 217,925,144\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Finished fine tuning.\n",
      "Iteration 587/1723 finished in 0m17s\n",
      "Total channels prunned so far: 587\n",
      "\n",
      "Iteration 588 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 246)]\n",
      "Input: 0.115 MB, Params: 2,280,331 (8.699 MB), Total: 8.81 MB, FLOPs: 217,870,828\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Finished fine tuning.\n",
      "Iteration 588/1723 finished in 0m17s\n",
      "Total channels prunned so far: 588\n",
      "\n",
      "Iteration 589 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 24)]\n",
      "Input: 0.115 MB, Params: 2,275,631 (8.681 MB), Total: 8.80 MB, FLOPs: 217,664,926\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Finished fine tuning.\n",
      "Iteration 589/1723 finished in 0m17s\n",
      "Total channels prunned so far: 589\n",
      "\n",
      "Iteration 590 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 291)]\n",
      "Input: 0.115 MB, Params: 2,272,611 (8.669 MB), Total: 8.78 MB, FLOPs: 217,610,610\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Finished fine tuning.\n",
      "Iteration 590/1723 finished in 0m17s\n",
      "Total channels prunned so far: 590\n",
      "\n",
      "Iteration 591 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 21)]\n",
      "Input: 0.115 MB, Params: 2,267,974 (8.652 MB), Total: 8.77 MB, FLOPs: 217,527,162\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Finished fine tuning.\n",
      "Iteration 591/1723 finished in 0m17s\n",
      "Total channels prunned so far: 591\n",
      "\n",
      "Iteration 592 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 21)]\n",
      "Input: 0.115 MB, Params: 2,264,963 (8.640 MB), Total: 8.76 MB, FLOPs: 217,473,008\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.638%\n",
      "Finished fine tuning.\n",
      "Iteration 592/1723 finished in 0m17s\n",
      "Total channels prunned so far: 592\n",
      "\n",
      "Iteration 593 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 70)]\n",
      "Input: 0.115 MB, Params: 2,263,476 (8.634 MB), Total: 8.75 MB, FLOPs: 216,868,206\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.986%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Finished fine tuning.\n",
      "Iteration 593/1723 finished in 0m17s\n",
      "Total channels prunned so far: 593\n",
      "\n",
      "Iteration 594 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 189)]\n",
      "Input: 0.115 MB, Params: 2,258,848 (8.617 MB), Total: 8.73 MB, FLOPs: 216,784,920\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Finished fine tuning.\n",
      "Iteration 594/1723 finished in 0m17s\n",
      "Total channels prunned so far: 594\n",
      "\n",
      "Iteration 595 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 108)]\n",
      "Input: 0.115 MB, Params: 2,255,846 (8.605 MB), Total: 8.72 MB, FLOPs: 216,730,928\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Finished fine tuning.\n",
      "Iteration 595/1723 finished in 0m17s\n",
      "Total channels prunned so far: 595\n",
      "\n",
      "Iteration 596 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 18)]\n",
      "Input: 0.115 MB, Params: 2,251,227 (8.588 MB), Total: 8.70 MB, FLOPs: 216,647,804\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.289%\n",
      "Finished fine tuning.\n",
      "Iteration 596/1723 finished in 0m16s\n",
      "Total channels prunned so far: 596\n",
      "\n",
      "Iteration 597 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 53)]\n",
      "Input: 0.115 MB, Params: 2,248,234 (8.576 MB), Total: 8.69 MB, FLOPs: 216,593,974\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.638%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.638%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Finished fine tuning.\n",
      "Iteration 597/1723 finished in 0m17s\n",
      "Total channels prunned so far: 597\n",
      "\n",
      "Iteration 598 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 74)]\n",
      "Input: 0.115 MB, Params: 2,243,624 (8.559 MB), Total: 8.67 MB, FLOPs: 216,511,012\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Finished fine tuning.\n",
      "Iteration 598/1723 finished in 0m17s\n",
      "Total channels prunned so far: 598\n",
      "\n",
      "Iteration 599 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 274)]\n",
      "Input: 0.115 MB, Params: 2,239,014 (8.541 MB), Total: 8.66 MB, FLOPs: 216,428,050\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Finished fine tuning.\n",
      "Iteration 599/1723 finished in 0m17s\n",
      "Total channels prunned so far: 599\n",
      "\n",
      "Iteration 600 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 233)]\n",
      "Input: 0.115 MB, Params: 2,236,039 (8.530 MB), Total: 8.65 MB, FLOPs: 216,374,544\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Finished fine tuning.\n",
      "Iteration 600/1723 finished in 0m17s\n",
      "Total channels prunned so far: 600\n",
      "\n",
      "Iteration 601 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 75)]\n",
      "Input: 0.115 MB, Params: 2,233,445 (8.520 MB), Total: 8.64 MB, FLOPs: 215,852,344\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Finished fine tuning.\n",
      "Iteration 601/1723 finished in 0m17s\n",
      "Total channels prunned so far: 601\n",
      "\n",
      "Iteration 602 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 187)]\n",
      "Input: 0.115 MB, Params: 2,228,790 (8.502 MB), Total: 8.62 MB, FLOPs: 215,647,252\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Finished fine tuning.\n",
      "Iteration 602/1723 finished in 0m17s\n",
      "Total channels prunned so far: 602\n",
      "\n",
      "Iteration 603 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 178)]\n",
      "Input: 0.115 MB, Params: 2,226,007 (8.492 MB), Total: 8.61 MB, FLOPs: 215,396,872\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Finished fine tuning.\n",
      "Iteration 603/1723 finished in 0m17s\n",
      "Total channels prunned so far: 603\n",
      "\n",
      "Iteration 604 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 259)]\n",
      "Input: 0.115 MB, Params: 2,223,032 (8.480 MB), Total: 8.60 MB, FLOPs: 215,343,366\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.122%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Finished fine tuning.\n",
      "Iteration 604/1723 finished in 0m17s\n",
      "Total channels prunned so far: 604\n",
      "\n",
      "Iteration 605 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 132)]\n",
      "Input: 0.115 MB, Params: 2,218,386 (8.462 MB), Total: 8.58 MB, FLOPs: 215,139,084\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Finished fine tuning.\n",
      "Iteration 605/1723 finished in 0m17s\n",
      "Total channels prunned so far: 605\n",
      "\n",
      "Iteration 606 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 228)]\n",
      "Input: 0.115 MB, Params: 2,215,411 (8.451 MB), Total: 8.57 MB, FLOPs: 215,085,578\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.289%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Finished fine tuning.\n",
      "Iteration 606/1723 finished in 0m17s\n",
      "Total channels prunned so far: 606\n",
      "\n",
      "Iteration 607 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 57)]\n",
      "Input: 0.115 MB, Params: 2,210,846 (8.434 MB), Total: 8.55 MB, FLOPs: 215,003,426\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.941%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Finished fine tuning.\n",
      "Iteration 607/1723 finished in 0m16s\n",
      "Total channels prunned so far: 607\n",
      "\n",
      "Iteration 608 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 16)]\n",
      "Input: 0.115 MB, Params: 2,209,368 (8.428 MB), Total: 8.54 MB, FLOPs: 214,402,287\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Finished fine tuning.\n",
      "Iteration 608/1723 finished in 0m17s\n",
      "Total channels prunned so far: 608\n",
      "\n",
      "Iteration 609 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 50)]\n",
      "Input: 0.115 MB, Params: 2,206,594 (8.417 MB), Total: 8.53 MB, FLOPs: 214,152,717\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Finished fine tuning.\n",
      "Iteration 609/1723 finished in 0m17s\n",
      "Total channels prunned so far: 609\n",
      "\n",
      "Iteration 610 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 65)]\n",
      "Input: 0.115 MB, Params: 2,201,966 (8.400 MB), Total: 8.52 MB, FLOPs: 213,949,407\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.986%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.289%\n",
      "Finished fine tuning.\n",
      "Iteration 610/1723 finished in 0m17s\n",
      "Total channels prunned so far: 610\n",
      "\n",
      "Iteration 611 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 30)]\n",
      "Input: 0.115 MB, Params: 2,199,000 (8.389 MB), Total: 8.50 MB, FLOPs: 213,896,063\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.986%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.986%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.986%\n",
      "Finished fine tuning.\n",
      "Iteration 611/1723 finished in 0m17s\n",
      "Total channels prunned so far: 611\n",
      "\n",
      "Iteration 612 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 36)]\n",
      "Input: 0.115 MB, Params: 2,194,372 (8.371 MB), Total: 8.49 MB, FLOPs: 213,692,753\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.502%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Finished fine tuning.\n",
      "Iteration 612/1723 finished in 0m17s\n",
      "Total channels prunned so far: 612\n",
      "\n",
      "Iteration 613 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 235)]\n",
      "Input: 0.115 MB, Params: 2,191,406 (8.360 MB), Total: 8.47 MB, FLOPs: 213,639,409\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.986%\n",
      "Finished fine tuning.\n",
      "Iteration 613/1723 finished in 0m17s\n",
      "Total channels prunned so far: 613\n",
      "\n",
      "Iteration 614 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 35)]\n",
      "Input: 0.115 MB, Params: 2,186,877 (8.342 MB), Total: 8.46 MB, FLOPs: 213,557,905\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Finished fine tuning.\n",
      "Iteration 614/1723 finished in 0m17s\n",
      "Total channels prunned so far: 614\n",
      "\n",
      "Iteration 615 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 45)]\n",
      "Input: 0.115 MB, Params: 2,183,920 (8.331 MB), Total: 8.45 MB, FLOPs: 213,504,723\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.986%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Finished fine tuning.\n",
      "Iteration 615/1723 finished in 0m17s\n",
      "Total channels prunned so far: 615\n",
      "\n",
      "Iteration 616 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 249)]\n",
      "Input: 0.115 MB, Params: 2,179,400 (8.314 MB), Total: 8.43 MB, FLOPs: 213,423,381\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.122%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Finished fine tuning.\n",
      "Iteration 616/1723 finished in 0m17s\n",
      "Total channels prunned so far: 616\n",
      "\n",
      "Iteration 617 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 112)]\n",
      "Input: 0.115 MB, Params: 2,176,644 (8.303 MB), Total: 8.42 MB, FLOPs: 213,175,431\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.986%\n",
      "Finished fine tuning.\n",
      "Iteration 617/1723 finished in 0m17s\n",
      "Total channels prunned so far: 617\n",
      "\n",
      "Iteration 618 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 212)]\n",
      "Input: 0.115 MB, Params: 2,172,124 (8.286 MB), Total: 8.40 MB, FLOPs: 213,094,089\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Finished fine tuning.\n",
      "Iteration 618/1723 finished in 0m17s\n",
      "Total channels prunned so far: 618\n",
      "\n",
      "Iteration 619 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 63)]\n",
      "Input: 0.115 MB, Params: 2,169,185 (8.275 MB), Total: 8.39 MB, FLOPs: 213,041,231\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.941%\n",
      "Finished fine tuning.\n",
      "Iteration 619/1723 finished in 0m16s\n",
      "Total channels prunned so far: 619\n",
      "\n",
      "Iteration 620 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 295)]\n",
      "Input: 0.115 MB, Params: 2,164,674 (8.258 MB), Total: 8.37 MB, FLOPs: 212,960,051\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.986%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Finished fine tuning.\n",
      "Iteration 620/1723 finished in 0m17s\n",
      "Total channels prunned so far: 620\n",
      "\n",
      "Iteration 621 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 47)]\n",
      "Input: 0.115 MB, Params: 2,160,163 (8.240 MB), Total: 8.36 MB, FLOPs: 212,878,871\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Finished fine tuning.\n",
      "Iteration 621/1723 finished in 0m17s\n",
      "Total channels prunned so far: 621\n",
      "\n",
      "Iteration 622 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 294)]\n",
      "Input: 0.115 MB, Params: 2,155,652 (8.223 MB), Total: 8.34 MB, FLOPs: 212,797,691\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Finished fine tuning.\n",
      "Iteration 622/1723 finished in 0m17s\n",
      "Total channels prunned so far: 622\n",
      "\n",
      "Iteration 623 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 263)]\n",
      "Input: 0.115 MB, Params: 2,152,740 (8.212 MB), Total: 8.33 MB, FLOPs: 212,745,319\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.638%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Finished fine tuning.\n",
      "Iteration 623/1723 finished in 0m17s\n",
      "Total channels prunned so far: 623\n",
      "\n",
      "Iteration 624 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 195)]\n",
      "Input: 0.115 MB, Params: 2,149,828 (8.201 MB), Total: 8.32 MB, FLOPs: 212,692,947\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Finished fine tuning.\n",
      "Iteration 624/1723 finished in 0m17s\n",
      "Total channels prunned so far: 624\n",
      "\n",
      "Iteration 625 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 243)]\n",
      "Input: 0.115 MB, Params: 2,145,335 (8.184 MB), Total: 8.30 MB, FLOPs: 212,612,091\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Finished fine tuning.\n",
      "Iteration 625/1723 finished in 0m17s\n",
      "Total channels prunned so far: 625\n",
      "\n",
      "Iteration 626 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 307)]\n",
      "Input: 0.115 MB, Params: 2,140,842 (8.167 MB), Total: 8.28 MB, FLOPs: 212,531,235\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Finished fine tuning.\n",
      "Iteration 626/1723 finished in 0m18s\n",
      "Total channels prunned so far: 626\n",
      "\n",
      "Iteration 627 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 272)]\n",
      "Input: 0.115 MB, Params: 2,137,948 (8.156 MB), Total: 8.27 MB, FLOPs: 212,479,187\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Finished fine tuning.\n",
      "Iteration 627/1723 finished in 0m17s\n",
      "Total channels prunned so far: 627\n",
      "\n",
      "Iteration 628 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 158)]\n",
      "Input: 0.115 MB, Params: 2,133,401 (8.138 MB), Total: 8.25 MB, FLOPs: 212,277,983\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Finished fine tuning.\n",
      "Iteration 628/1723 finished in 0m17s\n",
      "Total channels prunned so far: 628\n",
      "\n",
      "Iteration 629 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 99)]\n",
      "Input: 0.115 MB, Params: 2,130,843 (8.129 MB), Total: 8.24 MB, FLOPs: 211,761,876\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Finished fine tuning.\n",
      "Iteration 629/1723 finished in 0m17s\n",
      "Total channels prunned so far: 629\n",
      "\n",
      "Iteration 630 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 29)]\n",
      "Input: 0.115 MB, Params: 2,129,374 (8.123 MB), Total: 8.24 MB, FLOPs: 211,164,400\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Finished fine tuning.\n",
      "Iteration 630/1723 finished in 0m17s\n",
      "Total channels prunned so far: 630\n",
      "\n",
      "Iteration 631 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 101)]\n",
      "Input: 0.115 MB, Params: 2,126,636 (8.112 MB), Total: 8.23 MB, FLOPs: 210,918,070\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Finished fine tuning.\n",
      "Iteration 631/1723 finished in 0m17s\n",
      "Total channels prunned so far: 631\n",
      "\n",
      "Iteration 632 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 104)]\n",
      "Input: 0.115 MB, Params: 2,122,098 (8.095 MB), Total: 8.21 MB, FLOPs: 210,717,676\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Finished fine tuning.\n",
      "Iteration 632/1723 finished in 0m17s\n",
      "Total channels prunned so far: 632\n",
      "\n",
      "Iteration 633 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 118)]\n",
      "Input: 0.115 MB, Params: 2,119,204 (8.084 MB), Total: 8.20 MB, FLOPs: 210,665,628\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Finished fine tuning.\n",
      "Iteration 633/1723 finished in 0m17s\n",
      "Total channels prunned so far: 633\n",
      "\n",
      "Iteration 634 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 9)]\n",
      "Input: 0.115 MB, Params: 2,117,735 (8.079 MB), Total: 8.19 MB, FLOPs: 210,068,152\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.289%\n",
      "Finished fine tuning.\n",
      "Iteration 634/1723 finished in 0m17s\n",
      "Total channels prunned so far: 634\n",
      "\n",
      "Iteration 635 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 81)]\n",
      "Input: 0.115 MB, Params: 2,113,278 (8.062 MB), Total: 8.18 MB, FLOPs: 209,987,944\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Finished fine tuning.\n",
      "Iteration 635/1723 finished in 0m16s\n",
      "Total channels prunned so far: 635\n",
      "\n",
      "Iteration 636 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 265)]\n",
      "Input: 0.115 MB, Params: 2,110,393 (8.051 MB), Total: 8.17 MB, FLOPs: 209,936,058\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.941%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Finished fine tuning.\n",
      "Iteration 636/1723 finished in 0m15s\n",
      "Total channels prunned so far: 636\n",
      "\n",
      "Iteration 637 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 44)]\n",
      "Input: 0.115 MB, Params: 2,105,864 (8.033 MB), Total: 8.15 MB, FLOPs: 209,735,826\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.289%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.986%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Finished fine tuning.\n",
      "Iteration 637/1723 finished in 0m15s\n",
      "Total channels prunned so far: 637\n",
      "\n",
      "Iteration 638 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 54)]\n",
      "Input: 0.115 MB, Params: 2,103,144 (8.023 MB), Total: 8.14 MB, FLOPs: 209,491,116\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Finished fine tuning.\n",
      "Iteration 638/1723 finished in 0m15s\n",
      "Total channels prunned so far: 638\n",
      "\n",
      "Iteration 639 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 264)]\n",
      "Input: 0.115 MB, Params: 2,100,259 (8.012 MB), Total: 8.13 MB, FLOPs: 209,439,230\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.986%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Finished fine tuning.\n",
      "Iteration 639/1723 finished in 0m15s\n",
      "Total channels prunned so far: 639\n",
      "\n",
      "Iteration 640 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 134)]\n",
      "Input: 0.115 MB, Params: 2,095,829 (7.995 MB), Total: 8.11 MB, FLOPs: 209,359,508\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.289%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Finished fine tuning.\n",
      "Iteration 640/1723 finished in 0m15s\n",
      "Total channels prunned so far: 640\n",
      "\n",
      "Iteration 641 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 222)]\n",
      "Input: 0.115 MB, Params: 2,091,399 (7.978 MB), Total: 8.09 MB, FLOPs: 209,279,786\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Finished fine tuning.\n",
      "Iteration 641/1723 finished in 0m15s\n",
      "Total channels prunned so far: 641\n",
      "\n",
      "Iteration 642 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 126)]\n",
      "Input: 0.115 MB, Params: 2,088,679 (7.968 MB), Total: 8.08 MB, FLOPs: 209,035,076\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.986%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Finished fine tuning.\n",
      "Iteration 642/1723 finished in 0m15s\n",
      "Total channels prunned so far: 642\n",
      "\n",
      "Iteration 643 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 103)]\n",
      "Input: 0.115 MB, Params: 2,085,959 (7.957 MB), Total: 8.07 MB, FLOPs: 208,790,366\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.638%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Finished fine tuning.\n",
      "Iteration 643/1723 finished in 0m15s\n",
      "Total channels prunned so far: 643\n",
      "\n",
      "Iteration 644 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 12)]\n",
      "Input: 0.115 MB, Params: 2,084,490 (7.952 MB), Total: 8.07 MB, FLOPs: 208,192,890\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Finished fine tuning.\n",
      "Iteration 644/1723 finished in 0m15s\n",
      "Total channels prunned so far: 644\n",
      "\n",
      "Iteration 645 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 44)]\n",
      "Input: 0.115 MB, Params: 2,081,995 (7.942 MB), Total: 8.06 MB, FLOPs: 207,691,012\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.986%\n",
      "Finished fine tuning.\n",
      "Iteration 645/1723 finished in 0m15s\n",
      "Total channels prunned so far: 645\n",
      "\n",
      "Iteration 646 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 61)]\n",
      "Input: 0.115 MB, Params: 2,077,565 (7.925 MB), Total: 8.04 MB, FLOPs: 207,611,290\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.638%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.122%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Finished fine tuning.\n",
      "Iteration 646/1723 finished in 0m15s\n",
      "Total channels prunned so far: 646\n",
      "\n",
      "Iteration 647 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 260)]\n",
      "Input: 0.115 MB, Params: 2,074,707 (7.914 MB), Total: 8.03 MB, FLOPs: 207,559,890\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.470%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.774%\n",
      "Finished fine tuning.\n",
      "Iteration 647/1723 finished in 0m15s\n",
      "Total channels prunned so far: 647\n",
      "\n",
      "Iteration 648 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 198)]\n",
      "Input: 0.115 MB, Params: 2,071,849 (7.903 MB), Total: 8.02 MB, FLOPs: 207,508,490\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Finished fine tuning.\n",
      "Iteration 648/1723 finished in 0m15s\n",
      "Total channels prunned so far: 648\n",
      "\n",
      "Iteration 649 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 70)]\n",
      "Input: 0.115 MB, Params: 2,070,389 (7.898 MB), Total: 8.01 MB, FLOPs: 206,914,677\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Finished fine tuning.\n",
      "Iteration 649/1723 finished in 0m15s\n",
      "Total channels prunned so far: 649\n",
      "\n",
      "Iteration 650 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 198)]\n",
      "Input: 0.115 MB, Params: 2,067,531 (7.887 MB), Total: 8.00 MB, FLOPs: 206,863,277\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Finished fine tuning.\n",
      "Iteration 650/1723 finished in 0m15s\n",
      "Total channels prunned so far: 650\n",
      "\n",
      "Iteration 651 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 164)]\n",
      "Input: 0.115 MB, Params: 2,064,673 (7.876 MB), Total: 7.99 MB, FLOPs: 206,811,877\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Finished fine tuning.\n",
      "Iteration 651/1723 finished in 0m15s\n",
      "Total channels prunned so far: 651\n",
      "\n",
      "Iteration 652 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 302)]\n",
      "Input: 0.115 MB, Params: 2,060,279 (7.859 MB), Total: 7.97 MB, FLOPs: 206,732,803\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Finished fine tuning.\n",
      "Iteration 652/1723 finished in 0m15s\n",
      "Total channels prunned so far: 652\n",
      "\n",
      "Iteration 653 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 108)]\n",
      "Input: 0.115 MB, Params: 2,055,813 (7.842 MB), Total: 7.96 MB, FLOPs: 206,535,649\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Finished fine tuning.\n",
      "Iteration 653/1723 finished in 0m15s\n",
      "Total channels prunned so far: 653\n",
      "\n",
      "Iteration 654 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 283)]\n",
      "Input: 0.115 MB, Params: 2,052,964 (7.831 MB), Total: 7.95 MB, FLOPs: 206,484,411\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Finished fine tuning.\n",
      "Iteration 654/1723 finished in 0m15s\n",
      "Total channels prunned so far: 654\n",
      "\n",
      "Iteration 655 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 238)]\n",
      "Input: 0.115 MB, Params: 2,050,115 (7.821 MB), Total: 7.94 MB, FLOPs: 206,433,173\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Finished fine tuning.\n",
      "Iteration 655/1723 finished in 0m15s\n",
      "Total channels prunned so far: 655\n",
      "\n",
      "Iteration 656 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 158)]\n",
      "Input: 0.115 MB, Params: 2,045,748 (7.804 MB), Total: 7.92 MB, FLOPs: 206,354,585\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.986%\n",
      "Finished fine tuning.\n",
      "Iteration 656/1723 finished in 0m15s\n",
      "Total channels prunned so far: 656\n",
      "\n",
      "Iteration 657 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 179)]\n",
      "Input: 0.115 MB, Params: 2,043,046 (7.794 MB), Total: 7.91 MB, FLOPs: 206,111,495\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.638%\n",
      "Finished fine tuning.\n",
      "Iteration 657/1723 finished in 0m15s\n",
      "Total channels prunned so far: 657\n",
      "\n",
      "Iteration 658 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 20)]\n",
      "Input: 0.115 MB, Params: 2,038,679 (7.777 MB), Total: 7.89 MB, FLOPs: 206,032,907\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.986%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Finished fine tuning.\n",
      "Iteration 658/1723 finished in 0m15s\n",
      "Total channels prunned so far: 658\n",
      "\n",
      "Iteration 659 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 4)]\n",
      "Input: 0.115 MB, Params: 2,034,312 (7.760 MB), Total: 7.88 MB, FLOPs: 205,954,319\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Finished fine tuning.\n",
      "Iteration 659/1723 finished in 0m16s\n",
      "Total channels prunned so far: 659\n",
      "\n",
      "Iteration 660 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 302)]\n",
      "Input: 0.115 MB, Params: 2,029,945 (7.744 MB), Total: 7.86 MB, FLOPs: 205,875,731\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Finished fine tuning.\n",
      "Iteration 660/1723 finished in 0m17s\n",
      "Total channels prunned so far: 660\n",
      "\n",
      "Iteration 661 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(14, 14)]\n",
      "Input: 0.115 MB, Params: 2,028,611 (7.739 MB), Total: 7.85 MB, FLOPs: 204,748,605\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Finished fine tuning.\n",
      "Iteration 661/1723 finished in 0m17s\n",
      "Total channels prunned so far: 661\n",
      "\n",
      "Iteration 662 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 6)]\n",
      "Input: 0.115 MB, Params: 2,024,244 (7.722 MB), Total: 7.84 MB, FLOPs: 204,670,017\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.638%\n",
      "Finished fine tuning.\n",
      "Iteration 662/1723 finished in 0m17s\n",
      "Total channels prunned so far: 662\n",
      "\n",
      "Iteration 663 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 190)]\n",
      "Input: 0.115 MB, Params: 2,021,440 (7.711 MB), Total: 7.83 MB, FLOPs: 204,619,589\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.638%\n",
      "Finished fine tuning.\n",
      "Iteration 663/1723 finished in 0m17s\n",
      "Total channels prunned so far: 663\n",
      "\n",
      "Iteration 664 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 67)]\n",
      "Input: 0.115 MB, Params: 2,018,963 (7.702 MB), Total: 7.82 MB, FLOPs: 204,122,184\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.986%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Finished fine tuning.\n",
      "Iteration 664/1723 finished in 0m17s\n",
      "Total channels prunned so far: 664\n",
      "\n",
      "Iteration 665 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(3, 22)]\n",
      "Input: 0.115 MB, Params: 2,018,926 (7.702 MB), Total: 7.82 MB, FLOPs: 203,803,466\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Finished fine tuning.\n",
      "Iteration 665/1723 finished in 0m17s\n",
      "Total channels prunned so far: 665\n",
      "\n",
      "Iteration 666 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 231)]\n",
      "Input: 0.115 MB, Params: 2,014,568 (7.685 MB), Total: 7.80 MB, FLOPs: 203,725,040\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.774%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.470%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Finished fine tuning.\n",
      "Iteration 666/1723 finished in 0m17s\n",
      "Total channels prunned so far: 666\n",
      "\n",
      "Iteration 667 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 61)]\n",
      "Input: 0.115 MB, Params: 2,011,875 (7.675 MB), Total: 7.79 MB, FLOPs: 203,482,760\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Finished fine tuning.\n",
      "Iteration 667/1723 finished in 0m16s\n",
      "Total channels prunned so far: 667\n",
      "\n",
      "Iteration 668 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 80)]\n",
      "Input: 0.115 MB, Params: 2,009,182 (7.664 MB), Total: 7.78 MB, FLOPs: 203,240,480\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Finished fine tuning.\n",
      "Iteration 668/1723 finished in 0m17s\n",
      "Total channels prunned so far: 668\n",
      "\n",
      "Iteration 669 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 29)]\n",
      "Input: 0.115 MB, Params: 2,006,723 (7.655 MB), Total: 7.77 MB, FLOPs: 202,744,695\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.941%\n",
      "Finished fine tuning.\n",
      "Iteration 669/1723 finished in 0m17s\n",
      "Total channels prunned so far: 669\n",
      "\n",
      "Iteration 670 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 161)]\n",
      "Input: 0.115 MB, Params: 2,002,338 (7.638 MB), Total: 7.75 MB, FLOPs: 202,550,943\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.941%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Finished fine tuning.\n",
      "Iteration 670/1723 finished in 0m17s\n",
      "Total channels prunned so far: 670\n",
      "\n",
      "Iteration 671 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 184)]\n",
      "Input: 0.115 MB, Params: 1,999,543 (7.628 MB), Total: 7.74 MB, FLOPs: 202,500,677\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.592%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.289%\n",
      "Finished fine tuning.\n",
      "Iteration 671/1723 finished in 0m17s\n",
      "Total channels prunned so far: 671\n",
      "\n",
      "Iteration 672 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 32)]\n",
      "Input: 0.115 MB, Params: 1,996,868 (7.617 MB), Total: 7.73 MB, FLOPs: 202,260,017\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.289%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.941%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Finished fine tuning.\n",
      "Iteration 672/1723 finished in 0m17s\n",
      "Total channels prunned so far: 672\n",
      "\n",
      "Iteration 673 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(14, 23)]\n",
      "Input: 0.115 MB, Params: 1,995,534 (7.612 MB), Total: 7.73 MB, FLOPs: 201,132,891\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.289%\n",
      "Finished fine tuning.\n",
      "Iteration 673/1723 finished in 0m17s\n",
      "Total channels prunned so far: 673\n",
      "\n",
      "Iteration 674 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 13)]\n",
      "Input: 0.115 MB, Params: 1,994,110 (7.607 MB), Total: 7.72 MB, FLOPs: 200,553,730\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.774%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.986%\n",
      "Finished fine tuning.\n",
      "Iteration 674/1723 finished in 0m17s\n",
      "Total channels prunned so far: 674\n",
      "\n",
      "Iteration 675 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 72)]\n",
      "Input: 0.115 MB, Params: 1,989,770 (7.590 MB), Total: 7.71 MB, FLOPs: 200,475,628\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.638%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.289%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Finished fine tuning.\n",
      "Iteration 675/1723 finished in 0m17s\n",
      "Total channels prunned so far: 675\n",
      "\n",
      "Iteration 676 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 211)]\n",
      "Input: 0.115 MB, Params: 1,985,430 (7.574 MB), Total: 7.69 MB, FLOPs: 200,397,526\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Finished fine tuning.\n",
      "Iteration 676/1723 finished in 0m17s\n",
      "Total channels prunned so far: 676\n",
      "\n",
      "Iteration 677 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 127)]\n",
      "Input: 0.115 MB, Params: 1,982,755 (7.564 MB), Total: 7.68 MB, FLOPs: 200,156,866\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Finished fine tuning.\n",
      "Iteration 677/1723 finished in 0m17s\n",
      "Total channels prunned so far: 677\n",
      "\n",
      "Iteration 678 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 169)]\n",
      "Input: 0.115 MB, Params: 1,980,080 (7.553 MB), Total: 7.67 MB, FLOPs: 199,916,206\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.714%\n",
      "Finished fine tuning.\n",
      "Iteration 678/1723 finished in 0m17s\n",
      "Total channels prunned so far: 678\n",
      "\n",
      "Iteration 679 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 95)]\n",
      "Input: 0.115 MB, Params: 1,975,740 (7.537 MB), Total: 7.65 MB, FLOPs: 199,838,104\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.063%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.289%\n",
      "Finished fine tuning.\n",
      "Iteration 679/1723 finished in 0m17s\n",
      "Total channels prunned so far: 679\n",
      "\n",
      "Iteration 680 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 39)]\n",
      "Input: 0.115 MB, Params: 1,974,316 (7.531 MB), Total: 7.65 MB, FLOPs: 199,258,943\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.289%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.638%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Finished fine tuning.\n",
      "Iteration 680/1723 finished in 0m18s\n",
      "Total channels prunned so far: 680\n",
      "\n",
      "Iteration 681 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 165)]\n",
      "Input: 0.115 MB, Params: 1,971,548 (7.521 MB), Total: 7.64 MB, FLOPs: 199,209,163\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.638%\n",
      "Finished fine tuning.\n",
      "Iteration 681/1723 finished in 0m17s\n",
      "Total channels prunned so far: 681\n",
      "\n",
      "Iteration 682 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(7, 10)]\n",
      "Input: 0.115 MB, Params: 1,971,069 (7.519 MB), Total: 7.63 MB, FLOPs: 198,363,923\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.714%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.289%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Finished fine tuning.\n",
      "Iteration 682/1723 finished in 0m17s\n",
      "Total channels prunned so far: 682\n",
      "\n",
      "Iteration 683 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 25)]\n",
      "Input: 0.115 MB, Params: 1,968,301 (7.508 MB), Total: 7.62 MB, FLOPs: 198,314,143\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Finished fine tuning.\n",
      "Iteration 683/1723 finished in 0m17s\n",
      "Total channels prunned so far: 683\n",
      "\n",
      "Iteration 684 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 50)]\n",
      "Input: 0.115 MB, Params: 1,967,570 (7.506 MB), Total: 7.62 MB, FLOPs: 197,109,643\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.819%\n",
      "Finished fine tuning.\n",
      "Iteration 684/1723 finished in 0m16s\n",
      "Total channels prunned so far: 684\n",
      "\n",
      "Iteration 685 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 202)]\n",
      "Input: 0.115 MB, Params: 1,964,802 (7.495 MB), Total: 7.61 MB, FLOPs: 197,059,863\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.122%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Finished fine tuning.\n",
      "Iteration 685/1723 finished in 0m17s\n",
      "Total channels prunned so far: 685\n",
      "\n",
      "Iteration 686 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 12)]\n",
      "Input: 0.115 MB, Params: 1,962,034 (7.485 MB), Total: 7.60 MB, FLOPs: 197,010,083\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Finished fine tuning.\n",
      "Iteration 686/1723 finished in 0m17s\n",
      "Total channels prunned so far: 686\n",
      "\n",
      "Iteration 687 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 139)]\n",
      "Input: 0.115 MB, Params: 1,957,703 (7.468 MB), Total: 7.58 MB, FLOPs: 196,819,247\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.986%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.986%\n",
      "Finished fine tuning.\n",
      "Iteration 687/1723 finished in 0m17s\n",
      "Total channels prunned so far: 687\n",
      "\n",
      "Iteration 688 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 12)]\n",
      "Input: 0.115 MB, Params: 1,955,289 (7.459 MB), Total: 7.57 MB, FLOPs: 196,333,218\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.289%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Finished fine tuning.\n",
      "Iteration 688/1723 finished in 0m17s\n",
      "Total channels prunned so far: 688\n",
      "\n",
      "Iteration 689 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 149)]\n",
      "Input: 0.115 MB, Params: 1,952,521 (7.448 MB), Total: 7.56 MB, FLOPs: 196,283,438\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Finished fine tuning.\n",
      "Iteration 689/1723 finished in 0m16s\n",
      "Total channels prunned so far: 689\n",
      "\n",
      "Iteration 690 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 148)]\n",
      "Input: 0.115 MB, Params: 1,948,235 (7.432 MB), Total: 7.55 MB, FLOPs: 196,206,308\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.986%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.289%\n",
      "Finished fine tuning.\n",
      "Iteration 690/1723 finished in 0m17s\n",
      "Total channels prunned so far: 690\n",
      "\n",
      "Iteration 691 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 286)]\n",
      "Input: 0.115 MB, Params: 1,943,949 (7.416 MB), Total: 7.53 MB, FLOPs: 196,129,178\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.941%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.638%\n",
      "Finished fine tuning.\n",
      "Iteration 691/1723 finished in 0m17s\n",
      "Total channels prunned so far: 691\n",
      "\n",
      "Iteration 692 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 159)]\n",
      "Input: 0.115 MB, Params: 1,941,292 (7.405 MB), Total: 7.52 MB, FLOPs: 195,890,138\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.986%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Finished fine tuning.\n",
      "Iteration 692/1723 finished in 0m17s\n",
      "Total channels prunned so far: 692\n",
      "\n",
      "Iteration 693 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 119)]\n",
      "Input: 0.115 MB, Params: 1,937,006 (7.389 MB), Total: 7.50 MB, FLOPs: 195,813,008\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.122%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Finished fine tuning.\n",
      "Iteration 693/1723 finished in 0m17s\n",
      "Total channels prunned so far: 693\n",
      "\n",
      "Iteration 694 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(14, 34)]\n",
      "Input: 0.115 MB, Params: 1,935,699 (7.384 MB), Total: 7.50 MB, FLOPs: 194,708,058\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Finished fine tuning.\n",
      "Iteration 694/1723 finished in 0m17s\n",
      "Total channels prunned so far: 694\n",
      "\n",
      "Iteration 695 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 49)]\n",
      "Input: 0.115 MB, Params: 1,933,042 (7.374 MB), Total: 7.49 MB, FLOPs: 194,469,018\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Finished fine tuning.\n",
      "Iteration 695/1723 finished in 0m17s\n",
      "Total channels prunned so far: 695\n",
      "\n",
      "Iteration 696 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 180)]\n",
      "Input: 0.115 MB, Params: 1,928,756 (7.358 MB), Total: 7.47 MB, FLOPs: 194,280,288\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.289%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.895%\n",
      "Finished fine tuning.\n",
      "Iteration 696/1723 finished in 0m16s\n",
      "Total channels prunned so far: 696\n",
      "\n",
      "Iteration 697 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 53)]\n",
      "Input: 0.115 MB, Params: 1,924,470 (7.341 MB), Total: 7.46 MB, FLOPs: 194,091,558\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.244%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Finished fine tuning.\n",
      "Iteration 697/1723 finished in 0m16s\n",
      "Total channels prunned so far: 697\n",
      "\n",
      "Iteration 698 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 152)]\n",
      "Input: 0.115 MB, Params: 1,920,202 (7.325 MB), Total: 7.44 MB, FLOPs: 194,014,752\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.986%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.986%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Finished fine tuning.\n",
      "Iteration 698/1723 finished in 0m17s\n",
      "Total channels prunned so far: 698\n",
      "\n",
      "Iteration 699 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 8)]\n",
      "Input: 0.115 MB, Params: 1,915,925 (7.309 MB), Total: 7.42 MB, FLOPs: 193,826,184\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Finished fine tuning.\n",
      "Iteration 699/1723 finished in 0m17s\n",
      "Total channels prunned so far: 699\n",
      "\n",
      "Iteration 700 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 89)]\n",
      "Input: 0.115 MB, Params: 1,914,519 (7.303 MB), Total: 7.42 MB, FLOPs: 193,254,349\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.986%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.774%\n",
      "Finished fine tuning.\n",
      "Iteration 700/1723 finished in 0m16s\n",
      "Total channels prunned so far: 700\n",
      "\n",
      "Iteration 701 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 169)]\n",
      "Input: 0.115 MB, Params: 1,910,242 (7.287 MB), Total: 7.40 MB, FLOPs: 193,065,781\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.774%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Finished fine tuning.\n",
      "Iteration 701/1723 finished in 0m17s\n",
      "Total channels prunned so far: 701\n",
      "\n",
      "Iteration 702 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 2)]\n",
      "Input: 0.115 MB, Params: 1,908,836 (7.282 MB), Total: 7.40 MB, FLOPs: 192,493,946\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.638%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Finished fine tuning.\n",
      "Iteration 702/1723 finished in 0m17s\n",
      "Total channels prunned so far: 702\n",
      "\n",
      "Iteration 703 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 48)]\n",
      "Input: 0.115 MB, Params: 1,904,559 (7.265 MB), Total: 7.38 MB, FLOPs: 192,305,378\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.638%\n",
      "Finished fine tuning.\n",
      "Iteration 703/1723 finished in 0m17s\n",
      "Total channels prunned so far: 703\n",
      "\n",
      "Iteration 704 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 147)]\n",
      "Input: 0.115 MB, Params: 1,901,947 (7.255 MB), Total: 7.37 MB, FLOPs: 192,070,388\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Finished fine tuning.\n",
      "Iteration 704/1723 finished in 0m17s\n",
      "Total channels prunned so far: 704\n",
      "\n",
      "Iteration 705 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 59)]\n",
      "Input: 0.115 MB, Params: 1,899,215 (7.245 MB), Total: 7.36 MB, FLOPs: 192,021,256\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.941%\n",
      "Finished fine tuning.\n",
      "Iteration 705/1723 finished in 0m17s\n",
      "Total channels prunned so far: 705\n",
      "\n",
      "Iteration 706 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 153)]\n",
      "Input: 0.115 MB, Params: 1,896,483 (7.235 MB), Total: 7.35 MB, FLOPs: 191,972,124\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.986%\n",
      "Finished fine tuning.\n",
      "Iteration 706/1723 finished in 0m17s\n",
      "Total channels prunned so far: 706\n",
      "\n",
      "Iteration 707 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 102)]\n",
      "Input: 0.115 MB, Params: 1,893,871 (7.225 MB), Total: 7.34 MB, FLOPs: 191,737,134\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Finished fine tuning.\n",
      "Iteration 707/1723 finished in 0m17s\n",
      "Total channels prunned so far: 707\n",
      "\n",
      "Iteration 708 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 146)]\n",
      "Input: 0.115 MB, Params: 1,889,648 (7.208 MB), Total: 7.32 MB, FLOPs: 191,661,138\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Finished fine tuning.\n",
      "Iteration 708/1723 finished in 0m17s\n",
      "Total channels prunned so far: 708\n",
      "\n",
      "Iteration 709 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 10)]\n",
      "Input: 0.115 MB, Params: 1,887,036 (7.198 MB), Total: 7.31 MB, FLOPs: 191,426,148\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.502%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.895%\n",
      "Finished fine tuning.\n",
      "Iteration 709/1723 finished in 0m17s\n",
      "Total channels prunned so far: 709\n",
      "\n",
      "Iteration 710 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 54)]\n",
      "Input: 0.115 MB, Params: 1,885,630 (7.193 MB), Total: 7.31 MB, FLOPs: 190,854,313\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.547%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.638%\n",
      "Finished fine tuning.\n",
      "Iteration 710/1723 finished in 0m17s\n",
      "Total channels prunned so far: 710\n",
      "\n",
      "Iteration 711 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 43)]\n",
      "Input: 0.115 MB, Params: 1,883,288 (7.184 MB), Total: 7.30 MB, FLOPs: 190,383,323\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.592%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.638%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Finished fine tuning.\n",
      "Iteration 711/1723 finished in 0m17s\n",
      "Total channels prunned so far: 711\n",
      "\n",
      "Iteration 712 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 94)]\n",
      "Input: 0.115 MB, Params: 1,879,047 (7.168 MB), Total: 7.28 MB, FLOPs: 190,197,347\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Finished fine tuning.\n",
      "Iteration 712/1723 finished in 0m17s\n",
      "Total channels prunned so far: 712\n",
      "\n",
      "Iteration 713 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 141)]\n",
      "Input: 0.115 MB, Params: 1,874,833 (7.152 MB), Total: 7.27 MB, FLOPs: 190,121,513\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.895%\n",
      "Finished fine tuning.\n",
      "Iteration 713/1723 finished in 0m17s\n",
      "Total channels prunned so far: 713\n",
      "\n",
      "Iteration 714 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 38)]\n",
      "Input: 0.115 MB, Params: 1,870,619 (7.136 MB), Total: 7.25 MB, FLOPs: 190,045,679\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Finished fine tuning.\n",
      "Iteration 714/1723 finished in 0m16s\n",
      "Total channels prunned so far: 714\n",
      "\n",
      "Iteration 715 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 87)]\n",
      "Input: 0.115 MB, Params: 1,867,914 (7.126 MB), Total: 7.24 MB, FLOPs: 189,997,033\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.289%\n",
      "Finished fine tuning.\n",
      "Iteration 715/1723 finished in 0m17s\n",
      "Total channels prunned so far: 715\n",
      "\n",
      "Iteration 716 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 76)]\n",
      "Input: 0.115 MB, Params: 1,865,320 (7.116 MB), Total: 7.23 MB, FLOPs: 189,763,663\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.986%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.638%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Finished fine tuning.\n",
      "Iteration 716/1723 finished in 0m17s\n",
      "Total channels prunned so far: 716\n",
      "\n",
      "Iteration 717 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 21)]\n",
      "Input: 0.115 MB, Params: 1,861,115 (7.100 MB), Total: 7.21 MB, FLOPs: 189,687,991\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.986%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Finished fine tuning.\n",
      "Iteration 717/1723 finished in 0m17s\n",
      "Total channels prunned so far: 717\n",
      "\n",
      "Iteration 718 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 148)]\n",
      "Input: 0.115 MB, Params: 1,858,419 (7.089 MB), Total: 7.20 MB, FLOPs: 189,639,507\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Finished fine tuning.\n",
      "Iteration 718/1723 finished in 0m18s\n",
      "Total channels prunned so far: 718\n",
      "\n",
      "Iteration 719 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 37)]\n",
      "Input: 0.115 MB, Params: 1,855,825 (7.079 MB), Total: 7.19 MB, FLOPs: 189,406,137\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.638%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Finished fine tuning.\n",
      "Iteration 719/1723 finished in 0m17s\n",
      "Total channels prunned so far: 719\n",
      "\n",
      "Iteration 720 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 76)]\n",
      "Input: 0.115 MB, Params: 1,853,129 (7.069 MB), Total: 7.18 MB, FLOPs: 189,357,653\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Finished fine tuning.\n",
      "Iteration 720/1723 finished in 0m17s\n",
      "Total channels prunned so far: 720\n",
      "\n",
      "Iteration 721 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 13)]\n",
      "Input: 0.115 MB, Params: 1,850,433 (7.059 MB), Total: 7.17 MB, FLOPs: 189,309,169\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.470%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Finished fine tuning.\n",
      "Iteration 721/1723 finished in 0m17s\n",
      "Total channels prunned so far: 721\n",
      "\n",
      "Iteration 722 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 209)]\n",
      "Input: 0.115 MB, Params: 1,847,737 (7.049 MB), Total: 7.16 MB, FLOPs: 189,260,685\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.774%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.122%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.547%\n",
      "Finished fine tuning.\n",
      "Iteration 722/1723 finished in 0m17s\n",
      "Total channels prunned so far: 722\n",
      "\n",
      "Iteration 723 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 277)]\n",
      "Input: 0.115 MB, Params: 1,843,568 (7.033 MB), Total: 7.15 MB, FLOPs: 189,185,661\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.638%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.986%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.638%\n",
      "Finished fine tuning.\n",
      "Iteration 723/1723 finished in 0m16s\n",
      "Total channels prunned so far: 723\n",
      "\n",
      "Iteration 724 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(7, 22)]\n",
      "Input: 0.115 MB, Params: 1,843,098 (7.031 MB), Total: 7.15 MB, FLOPs: 188,355,271\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.986%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Finished fine tuning.\n",
      "Iteration 724/1723 finished in 0m17s\n",
      "Total channels prunned so far: 724\n",
      "\n",
      "Iteration 725 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 151)]\n",
      "Input: 0.115 MB, Params: 1,838,929 (7.015 MB), Total: 7.13 MB, FLOPs: 188,280,247\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.638%\n",
      "Finished fine tuning.\n",
      "Iteration 725/1723 finished in 0m17s\n",
      "Total channels prunned so far: 725\n",
      "\n",
      "Iteration 726 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 225)]\n",
      "Input: 0.115 MB, Params: 1,834,760 (6.999 MB), Total: 7.11 MB, FLOPs: 188,205,223\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Finished fine tuning.\n",
      "Iteration 726/1723 finished in 0m17s\n",
      "Total channels prunned so far: 726\n",
      "\n",
      "Iteration 727 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(14, 1)]\n",
      "Input: 0.115 MB, Params: 1,833,480 (6.994 MB), Total: 7.11 MB, FLOPs: 187,111,262\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.774%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Finished fine tuning.\n",
      "Iteration 727/1723 finished in 0m16s\n",
      "Total channels prunned so far: 727\n",
      "\n",
      "Iteration 728 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 214)]\n",
      "Input: 0.115 MB, Params: 1,830,811 (6.984 MB), Total: 7.10 MB, FLOPs: 187,063,264\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Finished fine tuning.\n",
      "Iteration 728/1723 finished in 0m17s\n",
      "Total channels prunned so far: 728\n",
      "\n",
      "Iteration 729 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 38)]\n",
      "Input: 0.115 MB, Params: 1,829,423 (6.979 MB), Total: 7.09 MB, FLOPs: 186,498,755\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Finished fine tuning.\n",
      "Iteration 729/1723 finished in 0m16s\n",
      "Total channels prunned so far: 729\n",
      "\n",
      "Iteration 730 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 56)]\n",
      "Input: 0.115 MB, Params: 1,825,254 (6.963 MB), Total: 7.08 MB, FLOPs: 186,315,371\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Finished fine tuning.\n",
      "Iteration 730/1723 finished in 0m17s\n",
      "Total channels prunned so far: 730\n",
      "\n",
      "Iteration 731 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 178)]\n",
      "Input: 0.115 MB, Params: 1,822,585 (6.953 MB), Total: 7.07 MB, FLOPs: 186,267,373\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.470%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Finished fine tuning.\n",
      "Iteration 731/1723 finished in 0m17s\n",
      "Total channels prunned so far: 731\n",
      "\n",
      "Iteration 732 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 123)]\n",
      "Input: 0.115 MB, Params: 1,818,443 (6.937 MB), Total: 7.05 MB, FLOPs: 186,192,835\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Finished fine tuning.\n",
      "Iteration 732/1723 finished in 0m17s\n",
      "Total channels prunned so far: 732\n",
      "\n",
      "Iteration 733 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 66)]\n",
      "Input: 0.115 MB, Params: 1,815,783 (6.927 MB), Total: 7.04 MB, FLOPs: 186,144,999\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Finished fine tuning.\n",
      "Iteration 733/1723 finished in 0m17s\n",
      "Total channels prunned so far: 733\n",
      "\n",
      "Iteration 734 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 39)]\n",
      "Input: 0.115 MB, Params: 1,813,468 (6.918 MB), Total: 7.03 MB, FLOPs: 185,679,292\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Finished fine tuning.\n",
      "Iteration 734/1723 finished in 0m17s\n",
      "Total channels prunned so far: 734\n",
      "\n",
      "Iteration 735 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 121)]\n",
      "Input: 0.115 MB, Params: 1,810,808 (6.908 MB), Total: 7.02 MB, FLOPs: 185,631,456\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.638%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.986%\n",
      "Finished fine tuning.\n",
      "Iteration 735/1723 finished in 0m17s\n",
      "Total channels prunned so far: 735\n",
      "\n",
      "Iteration 736 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 127)]\n",
      "Input: 0.115 MB, Params: 1,808,148 (6.898 MB), Total: 7.01 MB, FLOPs: 185,583,620\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.638%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Finished fine tuning.\n",
      "Iteration 736/1723 finished in 0m16s\n",
      "Total channels prunned so far: 736\n",
      "\n",
      "Iteration 737 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 103)]\n",
      "Input: 0.115 MB, Params: 1,804,033 (6.882 MB), Total: 7.00 MB, FLOPs: 185,509,568\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Finished fine tuning.\n",
      "Iteration 737/1723 finished in 0m16s\n",
      "Total channels prunned so far: 737\n",
      "\n",
      "Iteration 738 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 74)]\n",
      "Input: 0.115 MB, Params: 1,801,718 (6.873 MB), Total: 6.99 MB, FLOPs: 185,043,861\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.638%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.289%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Finished fine tuning.\n",
      "Iteration 738/1723 finished in 0m17s\n",
      "Total channels prunned so far: 738\n",
      "\n",
      "Iteration 739 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 185)]\n",
      "Input: 0.115 MB, Params: 1,797,567 (6.857 MB), Total: 6.97 MB, FLOPs: 184,860,801\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.986%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.986%\n",
      "Finished fine tuning.\n",
      "Iteration 739/1723 finished in 0m17s\n",
      "Total channels prunned so far: 739\n",
      "\n",
      "Iteration 740 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 175)]\n",
      "Input: 0.115 MB, Params: 1,793,461 (6.842 MB), Total: 6.96 MB, FLOPs: 184,786,911\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Finished fine tuning.\n",
      "Iteration 740/1723 finished in 0m17s\n",
      "Total channels prunned so far: 740\n",
      "\n",
      "Iteration 741 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 23)]\n",
      "Input: 0.115 MB, Params: 1,791,146 (6.833 MB), Total: 6.95 MB, FLOPs: 184,321,204\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Finished fine tuning.\n",
      "Iteration 741/1723 finished in 0m16s\n",
      "Total channels prunned so far: 741\n",
      "\n",
      "Iteration 742 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 93)]\n",
      "Input: 0.115 MB, Params: 1,787,040 (6.817 MB), Total: 6.93 MB, FLOPs: 184,247,314\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Finished fine tuning.\n",
      "Iteration 742/1723 finished in 0m16s\n",
      "Total channels prunned so far: 742\n",
      "\n",
      "Iteration 743 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 8)]\n",
      "Input: 0.115 MB, Params: 1,784,407 (6.807 MB), Total: 6.92 MB, FLOPs: 184,199,964\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.638%\n",
      "Finished fine tuning.\n",
      "Iteration 743/1723 finished in 0m17s\n",
      "Total channels prunned so far: 743\n",
      "\n",
      "Iteration 744 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 41)]\n",
      "Input: 0.115 MB, Params: 1,780,274 (6.791 MB), Total: 6.91 MB, FLOPs: 184,017,228\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.122%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Finished fine tuning.\n",
      "Iteration 744/1723 finished in 0m16s\n",
      "Total channels prunned so far: 744\n",
      "\n",
      "Iteration 745 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(3, 27)]\n",
      "Input: 0.115 MB, Params: 1,780,237 (6.791 MB), Total: 6.91 MB, FLOPs: 176,460,924\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Finished fine tuning.\n",
      "Iteration 745/1723 finished in 0m17s\n",
      "Total channels prunned so far: 745\n",
      "\n",
      "Iteration 746 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 59)]\n",
      "Input: 0.115 MB, Params: 1,777,604 (6.781 MB), Total: 6.90 MB, FLOPs: 176,413,574\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Finished fine tuning.\n",
      "Iteration 746/1723 finished in 0m17s\n",
      "Total channels prunned so far: 746\n",
      "\n",
      "Iteration 747 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 55)]\n",
      "Input: 0.115 MB, Params: 1,775,064 (6.771 MB), Total: 6.89 MB, FLOPs: 176,185,064\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Finished fine tuning.\n",
      "Iteration 747/1723 finished in 0m16s\n",
      "Total channels prunned so far: 747\n",
      "\n",
      "Iteration 748 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 128)]\n",
      "Input: 0.115 MB, Params: 1,772,524 (6.762 MB), Total: 6.88 MB, FLOPs: 175,956,554\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Finished fine tuning.\n",
      "Iteration 748/1723 finished in 0m17s\n",
      "Total channels prunned so far: 748\n",
      "\n",
      "Iteration 749 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 75)]\n",
      "Input: 0.115 MB, Params: 1,770,227 (6.753 MB), Total: 6.87 MB, FLOPs: 175,522,474\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Finished fine tuning.\n",
      "Iteration 749/1723 finished in 0m17s\n",
      "Total channels prunned so far: 749\n",
      "\n",
      "Iteration 750 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 114)]\n",
      "Input: 0.115 MB, Params: 1,766,148 (6.737 MB), Total: 6.85 MB, FLOPs: 175,449,070\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.122%\n",
      "Finished fine tuning.\n",
      "Iteration 750/1723 finished in 0m17s\n",
      "Total channels prunned so far: 750\n",
      "\n",
      "Iteration 751 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 202)]\n",
      "Input: 0.115 MB, Params: 1,763,524 (6.727 MB), Total: 6.84 MB, FLOPs: 175,401,882\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.122%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Finished fine tuning.\n",
      "Iteration 751/1723 finished in 0m17s\n",
      "Total channels prunned so far: 751\n",
      "\n",
      "Iteration 752 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 245)]\n",
      "Input: 0.115 MB, Params: 1,759,454 (6.712 MB), Total: 6.83 MB, FLOPs: 175,328,640\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Finished fine tuning.\n",
      "Iteration 752/1723 finished in 0m16s\n",
      "Total channels prunned so far: 752\n",
      "\n",
      "Iteration 753 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 12)]\n",
      "Input: 0.115 MB, Params: 1,757,157 (6.703 MB), Total: 6.82 MB, FLOPs: 174,894,560\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Finished fine tuning.\n",
      "Iteration 753/1723 finished in 0m17s\n",
      "Total channels prunned so far: 753\n",
      "\n",
      "Iteration 754 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 143)]\n",
      "Input: 0.115 MB, Params: 1,753,060 (6.687 MB), Total: 6.80 MB, FLOPs: 174,713,768\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.289%\n",
      "Finished fine tuning.\n",
      "Iteration 754/1723 finished in 0m17s\n",
      "Total channels prunned so far: 754\n",
      "\n",
      "Iteration 755 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 114)]\n",
      "Input: 0.115 MB, Params: 1,748,999 (6.672 MB), Total: 6.79 MB, FLOPs: 174,640,688\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.638%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.638%\n",
      "Finished fine tuning.\n",
      "Iteration 755/1723 finished in 0m17s\n",
      "Total channels prunned so far: 755\n",
      "\n",
      "Iteration 756 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(14, 6)]\n",
      "Input: 0.115 MB, Params: 1,747,728 (6.667 MB), Total: 6.78 MB, FLOPs: 173,615,008\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.941%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.289%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.289%\n",
      "Finished fine tuning.\n",
      "Iteration 756/1723 finished in 0m17s\n",
      "Total channels prunned so far: 756\n",
      "\n",
      "Iteration 757 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 190)]\n",
      "Input: 0.115 MB, Params: 1,743,667 (6.652 MB), Total: 6.77 MB, FLOPs: 173,541,928\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.986%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.289%\n",
      "Finished fine tuning.\n",
      "Iteration 757/1723 finished in 0m17s\n",
      "Total channels prunned so far: 757\n",
      "\n",
      "Iteration 758 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 228)]\n",
      "Input: 0.115 MB, Params: 1,739,606 (6.636 MB), Total: 6.75 MB, FLOPs: 173,468,848\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.470%\n",
      "Finished fine tuning.\n",
      "Iteration 758/1723 finished in 0m17s\n",
      "Total channels prunned so far: 758\n",
      "\n",
      "Iteration 759 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 251)]\n",
      "Input: 0.115 MB, Params: 1,737,018 (6.626 MB), Total: 6.74 MB, FLOPs: 173,422,308\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.470%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Finished fine tuning.\n",
      "Iteration 759/1723 finished in 0m17s\n",
      "Total channels prunned so far: 759\n",
      "\n",
      "Iteration 760 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 16)]\n",
      "Input: 0.115 MB, Params: 1,732,966 (6.611 MB), Total: 6.73 MB, FLOPs: 173,349,390\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Finished fine tuning.\n",
      "Iteration 760/1723 finished in 0m17s\n",
      "Total channels prunned so far: 760\n",
      "\n",
      "Iteration 761 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 250)]\n",
      "Input: 0.115 MB, Params: 1,728,914 (6.595 MB), Total: 6.71 MB, FLOPs: 173,276,472\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.986%\n",
      "Finished fine tuning.\n",
      "Iteration 761/1723 finished in 0m17s\n",
      "Total channels prunned so far: 761\n",
      "\n",
      "Iteration 762 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 11)]\n",
      "Input: 0.115 MB, Params: 1,726,401 (6.586 MB), Total: 6.70 MB, FLOPs: 173,050,392\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.986%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.941%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Finished fine tuning.\n",
      "Iteration 762/1723 finished in 0m17s\n",
      "Total channels prunned so far: 762\n",
      "\n",
      "Iteration 763 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 137)]\n",
      "Input: 0.115 MB, Params: 1,722,349 (6.570 MB), Total: 6.69 MB, FLOPs: 172,977,474\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.638%\n",
      "Finished fine tuning.\n",
      "Iteration 763/1723 finished in 0m17s\n",
      "Total channels prunned so far: 763\n",
      "\n",
      "Iteration 764 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 115)]\n",
      "Input: 0.115 MB, Params: 1,718,315 (6.555 MB), Total: 6.67 MB, FLOPs: 172,798,464\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.592%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Finished fine tuning.\n",
      "Iteration 764/1723 finished in 0m17s\n",
      "Total channels prunned so far: 764\n",
      "\n",
      "Iteration 765 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 215)]\n",
      "Input: 0.115 MB, Params: 1,714,272 (6.539 MB), Total: 6.65 MB, FLOPs: 172,725,708\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.638%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.986%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.941%\n",
      "Finished fine tuning.\n",
      "Iteration 765/1723 finished in 0m17s\n",
      "Total channels prunned so far: 765\n",
      "\n",
      "Iteration 766 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 256)]\n",
      "Input: 0.115 MB, Params: 1,710,229 (6.524 MB), Total: 6.64 MB, FLOPs: 172,652,952\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.289%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.986%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Finished fine tuning.\n",
      "Iteration 766/1723 finished in 0m17s\n",
      "Total channels prunned so far: 766\n",
      "\n",
      "Iteration 767 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 85)]\n",
      "Input: 0.115 MB, Params: 1,707,941 (6.515 MB), Total: 6.63 MB, FLOPs: 172,219,682\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Finished fine tuning.\n",
      "Iteration 767/1723 finished in 0m17s\n",
      "Total channels prunned so far: 767\n",
      "\n",
      "Iteration 768 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 67)]\n",
      "Input: 0.115 MB, Params: 1,703,898 (6.500 MB), Total: 6.62 MB, FLOPs: 172,146,926\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.774%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.638%\n",
      "Finished fine tuning.\n",
      "Iteration 768/1723 finished in 0m17s\n",
      "Total channels prunned so far: 768\n",
      "\n",
      "Iteration 769 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 63)]\n",
      "Input: 0.115 MB, Params: 1,701,610 (6.491 MB), Total: 6.61 MB, FLOPs: 171,713,656\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Finished fine tuning.\n",
      "Iteration 769/1723 finished in 0m17s\n",
      "Total channels prunned so far: 769\n",
      "\n",
      "Iteration 770 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 39)]\n",
      "Input: 0.115 MB, Params: 1,699,076 (6.481 MB), Total: 6.60 MB, FLOPs: 171,668,088\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.774%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Finished fine tuning.\n",
      "Iteration 770/1723 finished in 0m17s\n",
      "Total channels prunned so far: 770\n",
      "\n",
      "Iteration 771 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 78)]\n",
      "Input: 0.115 MB, Params: 1,696,542 (6.472 MB), Total: 6.59 MB, FLOPs: 171,622,520\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Finished fine tuning.\n",
      "Iteration 771/1723 finished in 0m16s\n",
      "Total channels prunned so far: 771\n",
      "\n",
      "Iteration 772 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 134)]\n",
      "Input: 0.115 MB, Params: 1,694,008 (6.462 MB), Total: 6.58 MB, FLOPs: 171,576,952\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Finished fine tuning.\n",
      "Iteration 772/1723 finished in 0m17s\n",
      "Total channels prunned so far: 772\n",
      "\n",
      "Iteration 773 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 121)]\n",
      "Input: 0.115 MB, Params: 1,691,474 (6.452 MB), Total: 6.57 MB, FLOPs: 171,531,384\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Finished fine tuning.\n",
      "Iteration 773/1723 finished in 0m17s\n",
      "Total channels prunned so far: 773\n",
      "\n",
      "Iteration 774 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 122)]\n",
      "Input: 0.115 MB, Params: 1,688,940 (6.443 MB), Total: 6.56 MB, FLOPs: 171,485,816\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.986%\n",
      "Finished fine tuning.\n",
      "Iteration 774/1723 finished in 0m17s\n",
      "Total channels prunned so far: 774\n",
      "\n",
      "Iteration 775 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 3)]\n",
      "Input: 0.115 MB, Params: 1,688,245 (6.440 MB), Total: 6.56 MB, FLOPs: 170,392,766\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Finished fine tuning.\n",
      "Iteration 775/1723 finished in 0m16s\n",
      "Total channels prunned so far: 775\n",
      "\n",
      "Iteration 776 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 153)]\n",
      "Input: 0.115 MB, Params: 1,685,759 (6.431 MB), Total: 6.55 MB, FLOPs: 170,169,116\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Finished fine tuning.\n",
      "Iteration 776/1723 finished in 0m16s\n",
      "Total channels prunned so far: 776\n",
      "\n",
      "Iteration 777 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 137)]\n",
      "Input: 0.115 MB, Params: 1,681,761 (6.415 MB), Total: 6.53 MB, FLOPs: 170,097,170\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.122%\n",
      "Finished fine tuning.\n",
      "Iteration 777/1723 finished in 0m17s\n",
      "Total channels prunned so far: 777\n",
      "\n",
      "Iteration 778 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 32)]\n",
      "Input: 0.115 MB, Params: 1,679,236 (6.406 MB), Total: 6.52 MB, FLOPs: 170,051,764\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.470%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.774%\n",
      "Finished fine tuning.\n",
      "Iteration 778/1723 finished in 0m17s\n",
      "Total channels prunned so far: 778\n",
      "\n",
      "Iteration 779 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 87)]\n",
      "Input: 0.115 MB, Params: 1,675,247 (6.391 MB), Total: 6.51 MB, FLOPs: 169,874,212\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Finished fine tuning.\n",
      "Iteration 779/1723 finished in 0m16s\n",
      "Total channels prunned so far: 779\n",
      "\n",
      "Iteration 780 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(3, 24)]\n",
      "Input: 0.115 MB, Params: 1,675,210 (6.390 MB), Total: 6.51 MB, FLOPs: 169,558,514\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Finished fine tuning.\n",
      "Iteration 780/1723 finished in 0m17s\n",
      "Total channels prunned so far: 780\n",
      "\n",
      "Iteration 781 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 118)]\n",
      "Input: 0.115 MB, Params: 1,672,685 (6.381 MB), Total: 6.50 MB, FLOPs: 169,513,108\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Finished fine tuning.\n",
      "Iteration 781/1723 finished in 0m17s\n",
      "Total channels prunned so far: 781\n",
      "\n",
      "Iteration 782 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 62)]\n",
      "Input: 0.115 MB, Params: 1,670,406 (6.372 MB), Total: 6.49 MB, FLOPs: 169,080,648\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Finished fine tuning.\n",
      "Iteration 782/1723 finished in 0m17s\n",
      "Total channels prunned so far: 782\n",
      "\n",
      "Iteration 783 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 141)]\n",
      "Input: 0.115 MB, Params: 1,667,938 (6.363 MB), Total: 6.48 MB, FLOPs: 168,858,618\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.774%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Finished fine tuning.\n",
      "Iteration 783/1723 finished in 0m16s\n",
      "Total channels prunned so far: 783\n",
      "\n",
      "Iteration 784 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 149)]\n",
      "Input: 0.115 MB, Params: 1,665,413 (6.353 MB), Total: 6.47 MB, FLOPs: 168,813,212\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.774%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.289%\n",
      "Finished fine tuning.\n",
      "Iteration 784/1723 finished in 0m17s\n",
      "Total channels prunned so far: 784\n",
      "\n",
      "Iteration 785 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(3, 28)]\n",
      "Input: 0.115 MB, Params: 1,665,376 (6.353 MB), Total: 6.47 MB, FLOPs: 165,883,839\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.592%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.289%\n",
      "Finished fine tuning.\n",
      "Iteration 785/1723 finished in 0m17s\n",
      "Total channels prunned so far: 785\n",
      "\n",
      "Iteration 786 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 47)]\n",
      "Input: 0.115 MB, Params: 1,661,414 (6.338 MB), Total: 6.45 MB, FLOPs: 165,812,541\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.592%\n",
      "Finished fine tuning.\n",
      "Iteration 786/1723 finished in 0m17s\n",
      "Total channels prunned so far: 786\n",
      "\n",
      "Iteration 787 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 91)]\n",
      "Input: 0.115 MB, Params: 1,657,452 (6.323 MB), Total: 6.44 MB, FLOPs: 165,741,243\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.941%\n",
      "Finished fine tuning.\n",
      "Iteration 787/1723 finished in 0m16s\n",
      "Total channels prunned so far: 787\n",
      "\n",
      "Iteration 788 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 113)]\n",
      "Input: 0.115 MB, Params: 1,653,490 (6.308 MB), Total: 6.42 MB, FLOPs: 165,564,825\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.638%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Finished fine tuning.\n",
      "Iteration 788/1723 finished in 0m16s\n",
      "Total channels prunned so far: 788\n",
      "\n",
      "Iteration 789 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 147)]\n",
      "Input: 0.115 MB, Params: 1,651,031 (6.298 MB), Total: 6.41 MB, FLOPs: 165,343,605\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Finished fine tuning.\n",
      "Iteration 789/1723 finished in 0m17s\n",
      "Total channels prunned so far: 789\n",
      "\n",
      "Iteration 790 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(7, 16)]\n",
      "Input: 0.115 MB, Params: 1,650,570 (6.296 MB), Total: 6.41 MB, FLOPs: 164,600,695\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.289%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Finished fine tuning.\n",
      "Iteration 790/1723 finished in 0m17s\n",
      "Total channels prunned so far: 790\n",
      "\n",
      "Iteration 791 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 25)]\n",
      "Input: 0.115 MB, Params: 1,648,309 (6.288 MB), Total: 6.40 MB, FLOPs: 164,169,855\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.986%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.638%\n",
      "Finished fine tuning.\n",
      "Iteration 791/1723 finished in 0m17s\n",
      "Total channels prunned so far: 791\n",
      "\n",
      "Iteration 792 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 63)]\n",
      "Input: 0.115 MB, Params: 1,645,802 (6.278 MB), Total: 6.39 MB, FLOPs: 164,124,773\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.986%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Finished fine tuning.\n",
      "Iteration 792/1723 finished in 0m17s\n",
      "Total channels prunned so far: 792\n",
      "\n",
      "Iteration 793 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 274)]\n",
      "Input: 0.115 MB, Params: 1,641,858 (6.263 MB), Total: 6.38 MB, FLOPs: 164,053,799\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.941%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.941%\n",
      "Finished fine tuning.\n",
      "Iteration 793/1723 finished in 0m17s\n",
      "Total channels prunned so far: 793\n",
      "\n",
      "Iteration 794 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 145)]\n",
      "Input: 0.115 MB, Params: 1,637,914 (6.248 MB), Total: 6.36 MB, FLOPs: 163,982,825\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.244%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.774%\n",
      "Finished fine tuning.\n",
      "Iteration 794/1723 finished in 0m17s\n",
      "Total channels prunned so far: 794\n",
      "\n",
      "Iteration 795 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 138)]\n",
      "Input: 0.115 MB, Params: 1,635,464 (6.239 MB), Total: 6.35 MB, FLOPs: 163,762,415\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Finished fine tuning.\n",
      "Iteration 795/1723 finished in 0m17s\n",
      "Total channels prunned so far: 795\n",
      "\n",
      "Iteration 796 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 104)]\n",
      "Input: 0.115 MB, Params: 1,632,975 (6.229 MB), Total: 6.34 MB, FLOPs: 163,717,657\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Finished fine tuning.\n",
      "Iteration 796/1723 finished in 0m17s\n",
      "Total channels prunned so far: 796\n",
      "\n",
      "Iteration 797 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 77)]\n",
      "Input: 0.115 MB, Params: 1,629,040 (6.214 MB), Total: 6.33 MB, FLOPs: 163,646,845\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.289%\n",
      "Finished fine tuning.\n",
      "Iteration 797/1723 finished in 0m17s\n",
      "Total channels prunned so far: 797\n",
      "\n",
      "Iteration 798 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 109)]\n",
      "Input: 0.115 MB, Params: 1,626,590 (6.205 MB), Total: 6.32 MB, FLOPs: 163,426,435\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.986%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.244%\n",
      "Finished fine tuning.\n",
      "Iteration 798/1723 finished in 0m16s\n",
      "Total channels prunned so far: 798\n",
      "\n",
      "Iteration 799 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 19)]\n",
      "Input: 0.115 MB, Params: 1,624,140 (6.196 MB), Total: 6.31 MB, FLOPs: 163,206,025\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.289%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Finished fine tuning.\n",
      "Iteration 799/1723 finished in 0m17s\n",
      "Total channels prunned so far: 799\n",
      "\n",
      "Iteration 800 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 115)]\n",
      "Input: 0.115 MB, Params: 1,621,660 (6.186 MB), Total: 6.30 MB, FLOPs: 163,161,429\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.774%\n",
      "Finished fine tuning.\n",
      "Iteration 800/1723 finished in 0m16s\n",
      "Total channels prunned so far: 800\n",
      "\n",
      "Iteration 801 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 58)]\n",
      "Input: 0.115 MB, Params: 1,620,362 (6.181 MB), Total: 6.30 MB, FLOPs: 162,681,539\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Finished fine tuning.\n",
      "Iteration 801/1723 finished in 0m17s\n",
      "Total channels prunned so far: 801\n",
      "\n",
      "Iteration 802 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 8)]\n",
      "Input: 0.115 MB, Params: 1,619,064 (6.176 MB), Total: 6.29 MB, FLOPs: 162,201,649\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Finished fine tuning.\n",
      "Iteration 802/1723 finished in 0m16s\n",
      "Total channels prunned so far: 802\n",
      "\n",
      "Iteration 803 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(3, 21)]\n",
      "Input: 0.115 MB, Params: 1,619,027 (6.176 MB), Total: 6.29 MB, FLOPs: 161,887,461\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.986%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Finished fine tuning.\n",
      "Iteration 803/1723 finished in 0m17s\n",
      "Total channels prunned so far: 803\n",
      "\n",
      "Iteration 804 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 180)]\n",
      "Input: 0.115 MB, Params: 1,615,101 (6.161 MB), Total: 6.28 MB, FLOPs: 161,816,811\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Finished fine tuning.\n",
      "Iteration 804/1723 finished in 0m17s\n",
      "Total channels prunned so far: 804\n",
      "\n",
      "Iteration 805 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 143)]\n",
      "Input: 0.115 MB, Params: 1,612,651 (6.152 MB), Total: 6.27 MB, FLOPs: 161,596,401\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Finished fine tuning.\n",
      "Iteration 805/1723 finished in 0m17s\n",
      "Total channels prunned so far: 805\n",
      "\n",
      "Iteration 806 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 257)]\n",
      "Input: 0.115 MB, Params: 1,608,725 (6.137 MB), Total: 6.25 MB, FLOPs: 161,525,751\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Finished fine tuning.\n",
      "Iteration 806/1723 finished in 0m16s\n",
      "Total channels prunned so far: 806\n",
      "\n",
      "Iteration 807 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 5)]\n",
      "Input: 0.115 MB, Params: 1,606,263 (6.127 MB), Total: 6.24 MB, FLOPs: 161,481,479\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.986%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Finished fine tuning.\n",
      "Iteration 807/1723 finished in 0m17s\n",
      "Total channels prunned so far: 807\n",
      "\n",
      "Iteration 808 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 46)]\n",
      "Input: 0.115 MB, Params: 1,604,965 (6.122 MB), Total: 6.24 MB, FLOPs: 161,001,589\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Finished fine tuning.\n",
      "Iteration 808/1723 finished in 0m17s\n",
      "Total channels prunned so far: 808\n",
      "\n",
      "Iteration 809 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 87)]\n",
      "Input: 0.115 MB, Params: 1,602,503 (6.113 MB), Total: 6.23 MB, FLOPs: 160,957,317\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Finished fine tuning.\n",
      "Iteration 809/1723 finished in 0m17s\n",
      "Total channels prunned so far: 809\n",
      "\n",
      "Iteration 810 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 0)]\n",
      "Input: 0.115 MB, Params: 1,600,041 (6.104 MB), Total: 6.22 MB, FLOPs: 160,913,045\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Finished fine tuning.\n",
      "Iteration 810/1723 finished in 0m17s\n",
      "Total channels prunned so far: 810\n",
      "\n",
      "Iteration 811 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 151)]\n",
      "Input: 0.115 MB, Params: 1,596,169 (6.089 MB), Total: 6.20 MB, FLOPs: 160,741,487\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Finished fine tuning.\n",
      "Iteration 811/1723 finished in 0m16s\n",
      "Total channels prunned so far: 811\n",
      "\n",
      "Iteration 812 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 121)]\n",
      "Input: 0.115 MB, Params: 1,592,279 (6.074 MB), Total: 6.19 MB, FLOPs: 160,671,485\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.986%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.895%\n",
      "Finished fine tuning.\n",
      "Iteration 812/1723 finished in 0m17s\n",
      "Total channels prunned so far: 812\n",
      "\n",
      "Iteration 813 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 220)]\n",
      "Input: 0.115 MB, Params: 1,589,826 (6.065 MB), Total: 6.18 MB, FLOPs: 160,627,375\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.941%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Finished fine tuning.\n",
      "Iteration 813/1723 finished in 0m17s\n",
      "Total channels prunned so far: 813\n",
      "\n",
      "Iteration 814 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 146)]\n",
      "Input: 0.115 MB, Params: 1,587,385 (6.055 MB), Total: 6.17 MB, FLOPs: 160,407,775\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Finished fine tuning.\n",
      "Iteration 814/1723 finished in 0m17s\n",
      "Total channels prunned so far: 814\n",
      "\n",
      "Iteration 815 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 89)]\n",
      "Input: 0.115 MB, Params: 1,584,932 (6.046 MB), Total: 6.16 MB, FLOPs: 160,363,665\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Finished fine tuning.\n",
      "Iteration 815/1723 finished in 0m16s\n",
      "Total channels prunned so far: 815\n",
      "\n",
      "Iteration 816 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 122)]\n",
      "Input: 0.115 MB, Params: 1,582,479 (6.037 MB), Total: 6.15 MB, FLOPs: 160,319,555\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.638%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Finished fine tuning.\n",
      "Iteration 816/1723 finished in 0m17s\n",
      "Total channels prunned so far: 816\n",
      "\n",
      "Iteration 817 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 233)]\n",
      "Input: 0.115 MB, Params: 1,580,026 (6.027 MB), Total: 6.14 MB, FLOPs: 160,275,445\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.638%\n",
      "Finished fine tuning.\n",
      "Iteration 817/1723 finished in 0m17s\n",
      "Total channels prunned so far: 817\n",
      "\n",
      "Iteration 818 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 28)]\n",
      "Input: 0.115 MB, Params: 1,577,585 (6.018 MB), Total: 6.13 MB, FLOPs: 160,055,845\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Finished fine tuning.\n",
      "Iteration 818/1723 finished in 0m16s\n",
      "Total channels prunned so far: 818\n",
      "\n",
      "Iteration 819 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 53)]\n",
      "Input: 0.115 MB, Params: 1,576,287 (6.013 MB), Total: 6.13 MB, FLOPs: 159,575,955\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Finished fine tuning.\n",
      "Iteration 819/1723 finished in 0m17s\n",
      "Total channels prunned so far: 819\n",
      "\n",
      "Iteration 820 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 56)]\n",
      "Input: 0.115 MB, Params: 1,573,846 (6.004 MB), Total: 6.12 MB, FLOPs: 159,356,355\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Finished fine tuning.\n",
      "Iteration 820/1723 finished in 0m17s\n",
      "Total channels prunned so far: 820\n",
      "\n",
      "Iteration 821 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(14, 22)]\n",
      "Input: 0.115 MB, Params: 1,572,620 (5.999 MB), Total: 6.11 MB, FLOPs: 158,391,995\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.122%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Finished fine tuning.\n",
      "Iteration 821/1723 finished in 0m17s\n",
      "Total channels prunned so far: 821\n",
      "\n",
      "Iteration 822 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 73)]\n",
      "Input: 0.115 MB, Params: 1,570,167 (5.990 MB), Total: 6.11 MB, FLOPs: 158,347,885\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Finished fine tuning.\n",
      "Iteration 822/1723 finished in 0m16s\n",
      "Total channels prunned so far: 822\n",
      "\n",
      "Iteration 823 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 62)]\n",
      "Input: 0.115 MB, Params: 1,568,005 (5.981 MB), Total: 6.10 MB, FLOPs: 157,936,035\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Finished fine tuning.\n",
      "Iteration 823/1723 finished in 0m17s\n",
      "Total channels prunned so far: 823\n",
      "\n",
      "Iteration 824 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 194)]\n",
      "Input: 0.115 MB, Params: 1,564,160 (5.967 MB), Total: 6.08 MB, FLOPs: 157,866,843\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.774%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Finished fine tuning.\n",
      "Iteration 824/1723 finished in 0m16s\n",
      "Total channels prunned so far: 824\n",
      "\n",
      "Iteration 825 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 195)]\n",
      "Input: 0.115 MB, Params: 1,560,315 (5.952 MB), Total: 6.07 MB, FLOPs: 157,797,651\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.470%\n",
      "Finished fine tuning.\n",
      "Iteration 825/1723 finished in 0m17s\n",
      "Total channels prunned so far: 825\n",
      "\n",
      "Iteration 826 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 160)]\n",
      "Input: 0.115 MB, Params: 1,556,470 (5.937 MB), Total: 6.05 MB, FLOPs: 157,728,459\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.122%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.774%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Finished fine tuning.\n",
      "Iteration 826/1723 finished in 0m17s\n",
      "Total channels prunned so far: 826\n",
      "\n",
      "Iteration 827 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 150)]\n",
      "Input: 0.115 MB, Params: 1,554,038 (5.928 MB), Total: 6.04 MB, FLOPs: 157,509,669\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.638%\n",
      "Finished fine tuning.\n",
      "Iteration 827/1723 finished in 0m17s\n",
      "Total channels prunned so far: 827\n",
      "\n",
      "Iteration 828 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 77)]\n",
      "Input: 0.115 MB, Params: 1,552,758 (5.923 MB), Total: 6.04 MB, FLOPs: 157,036,439\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.638%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.986%\n",
      "Finished fine tuning.\n",
      "Iteration 828/1723 finished in 0m17s\n",
      "Total channels prunned so far: 828\n",
      "\n",
      "Iteration 829 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 185)]\n",
      "Input: 0.115 MB, Params: 1,548,913 (5.909 MB), Total: 6.02 MB, FLOPs: 156,967,247\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Finished fine tuning.\n",
      "Iteration 829/1723 finished in 0m17s\n",
      "Total channels prunned so far: 829\n",
      "\n",
      "Iteration 830 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 129)]\n",
      "Input: 0.115 MB, Params: 1,546,496 (5.899 MB), Total: 6.01 MB, FLOPs: 156,923,785\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Finished fine tuning.\n",
      "Iteration 830/1723 finished in 0m17s\n",
      "Total channels prunned so far: 830\n",
      "\n",
      "Iteration 831 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 159)]\n",
      "Input: 0.115 MB, Params: 1,542,660 (5.885 MB), Total: 6.00 MB, FLOPs: 156,854,755\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Finished fine tuning.\n",
      "Iteration 831/1723 finished in 0m16s\n",
      "Total channels prunned so far: 831\n",
      "\n",
      "Iteration 832 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 124)]\n",
      "Input: 0.115 MB, Params: 1,538,824 (5.870 MB), Total: 5.99 MB, FLOPs: 156,785,725\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Finished fine tuning.\n",
      "Iteration 832/1723 finished in 0m17s\n",
      "Total channels prunned so far: 832\n",
      "\n",
      "Iteration 833 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 55)]\n",
      "Input: 0.115 MB, Params: 1,536,392 (5.861 MB), Total: 5.98 MB, FLOPs: 156,566,935\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.638%\n",
      "Finished fine tuning.\n",
      "Iteration 833/1723 finished in 0m17s\n",
      "Total channels prunned so far: 833\n",
      "\n",
      "Iteration 834 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 193)]\n",
      "Input: 0.115 MB, Params: 1,532,556 (5.846 MB), Total: 5.96 MB, FLOPs: 156,497,905\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.638%\n",
      "Finished fine tuning.\n",
      "Iteration 834/1723 finished in 0m17s\n",
      "Total channels prunned so far: 834\n",
      "\n",
      "Iteration 835 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(7, 15)]\n",
      "Input: 0.115 MB, Params: 1,532,095 (5.844 MB), Total: 5.96 MB, FLOPs: 155,756,505\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.638%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Finished fine tuning.\n",
      "Iteration 835/1723 finished in 0m16s\n",
      "Total channels prunned so far: 835\n",
      "\n",
      "Iteration 836 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 177)]\n",
      "Input: 0.115 MB, Params: 1,528,340 (5.830 MB), Total: 5.95 MB, FLOPs: 155,590,293\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Finished fine tuning.\n",
      "Iteration 836/1723 finished in 0m17s\n",
      "Total channels prunned so far: 836\n",
      "\n",
      "Iteration 837 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 53)]\n",
      "Input: 0.115 MB, Params: 1,525,917 (5.821 MB), Total: 5.94 MB, FLOPs: 155,372,313\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.592%\n",
      "Finished fine tuning.\n",
      "Iteration 837/1723 finished in 0m16s\n",
      "Total channels prunned so far: 837\n",
      "\n",
      "Iteration 838 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 193)]\n",
      "Input: 0.115 MB, Params: 1,522,090 (5.806 MB), Total: 5.92 MB, FLOPs: 155,303,445\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.199%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Finished fine tuning.\n",
      "Iteration 838/1723 finished in 0m17s\n",
      "Total channels prunned so far: 838\n",
      "\n",
      "Iteration 839 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 194)]\n",
      "Input: 0.115 MB, Params: 1,518,263 (5.792 MB), Total: 5.91 MB, FLOPs: 155,234,577\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.638%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Finished fine tuning.\n",
      "Iteration 839/1723 finished in 0m17s\n",
      "Total channels prunned so far: 839\n",
      "\n",
      "Iteration 840 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 245)]\n",
      "Input: 0.115 MB, Params: 1,514,436 (5.777 MB), Total: 5.89 MB, FLOPs: 155,165,709\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Finished fine tuning.\n",
      "Iteration 840/1723 finished in 0m17s\n",
      "Total channels prunned so far: 840\n",
      "\n",
      "Iteration 841 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 25)]\n",
      "Input: 0.115 MB, Params: 1,513,156 (5.772 MB), Total: 5.89 MB, FLOPs: 154,692,479\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Finished fine tuning.\n",
      "Iteration 841/1723 finished in 0m16s\n",
      "Total channels prunned so far: 841\n",
      "\n",
      "Iteration 842 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 108)]\n",
      "Input: 0.115 MB, Params: 1,509,329 (5.758 MB), Total: 5.87 MB, FLOPs: 154,623,611\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Finished fine tuning.\n",
      "Iteration 842/1723 finished in 0m16s\n",
      "Total channels prunned so far: 842\n",
      "\n",
      "Iteration 843 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 253)]\n",
      "Input: 0.115 MB, Params: 1,505,502 (5.743 MB), Total: 5.86 MB, FLOPs: 154,554,743\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Finished fine tuning.\n",
      "Iteration 843/1723 finished in 0m17s\n",
      "Total channels prunned so far: 843\n",
      "\n",
      "Iteration 844 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 139)]\n",
      "Input: 0.115 MB, Params: 1,501,801 (5.729 MB), Total: 5.84 MB, FLOPs: 154,390,151\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Finished fine tuning.\n",
      "Iteration 844/1723 finished in 0m17s\n",
      "Total channels prunned so far: 844\n",
      "\n",
      "Iteration 845 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 24)]\n",
      "Input: 0.115 MB, Params: 1,501,133 (5.726 MB), Total: 5.84 MB, FLOPs: 153,389,651\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.774%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Finished fine tuning.\n",
      "Iteration 845/1723 finished in 0m17s\n",
      "Total channels prunned so far: 845\n",
      "\n",
      "Iteration 846 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 15)]\n",
      "Input: 0.115 MB, Params: 1,498,719 (5.717 MB), Total: 5.83 MB, FLOPs: 153,172,481\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.774%\n",
      "Finished fine tuning.\n",
      "Iteration 846/1723 finished in 0m17s\n",
      "Total channels prunned so far: 846\n",
      "\n",
      "Iteration 847 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(3, 11)]\n",
      "Input: 0.115 MB, Params: 1,498,682 (5.717 MB), Total: 5.83 MB, FLOPs: 139,887,136\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.986%\n",
      "Finished fine tuning.\n",
      "Iteration 847/1723 finished in 0m16s\n",
      "Total channels prunned so far: 847\n",
      "\n",
      "Iteration 848 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 137)]\n",
      "Input: 0.115 MB, Params: 1,496,268 (5.708 MB), Total: 5.82 MB, FLOPs: 139,713,400\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.986%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.638%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Finished fine tuning.\n",
      "Iteration 848/1723 finished in 0m17s\n",
      "Total channels prunned so far: 848\n",
      "\n",
      "Iteration 849 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 36)]\n",
      "Input: 0.115 MB, Params: 1,492,450 (5.693 MB), Total: 5.81 MB, FLOPs: 139,644,694\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.289%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.805%\n",
      "Finished fine tuning.\n",
      "Iteration 849/1723 finished in 0m17s\n",
      "Total channels prunned so far: 849\n",
      "\n",
      "Iteration 850 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 55)]\n",
      "Input: 0.115 MB, Params: 1,491,170 (5.688 MB), Total: 5.80 MB, FLOPs: 139,218,787\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.986%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.289%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Finished fine tuning.\n",
      "Iteration 850/1723 finished in 0m17s\n",
      "Total channels prunned so far: 850\n",
      "\n",
      "Iteration 851 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 70)]\n",
      "Input: 0.115 MB, Params: 1,487,352 (5.674 MB), Total: 5.79 MB, FLOPs: 139,150,081\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.760%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.592%\n",
      "Finished fine tuning.\n",
      "Iteration 851/1723 finished in 0m17s\n",
      "Total channels prunned so far: 851\n",
      "\n",
      "Iteration 852 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 120)]\n",
      "Input: 0.115 MB, Params: 1,485,025 (5.665 MB), Total: 5.78 MB, FLOPs: 139,108,239\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.289%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.986%\n",
      "Finished fine tuning.\n",
      "Iteration 852/1723 finished in 0m17s\n",
      "Total channels prunned so far: 852\n",
      "\n",
      "Iteration 853 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 59)]\n",
      "Input: 0.115 MB, Params: 1,481,360 (5.651 MB), Total: 5.77 MB, FLOPs: 138,969,747\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.941%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Finished fine tuning.\n",
      "Iteration 853/1723 finished in 0m17s\n",
      "Total channels prunned so far: 853\n",
      "\n",
      "Iteration 854 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 218)]\n",
      "Input: 0.115 MB, Params: 1,477,560 (5.636 MB), Total: 5.75 MB, FLOPs: 138,901,365\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.986%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Finished fine tuning.\n",
      "Iteration 854/1723 finished in 0m17s\n",
      "Total channels prunned so far: 854\n",
      "\n",
      "Iteration 855 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 167)]\n",
      "Input: 0.115 MB, Params: 1,473,760 (5.622 MB), Total: 5.74 MB, FLOPs: 138,832,983\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.774%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.986%\n",
      "Finished fine tuning.\n",
      "Iteration 855/1723 finished in 0m16s\n",
      "Total channels prunned so far: 855\n",
      "\n",
      "Iteration 856 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 37)]\n",
      "Input: 0.115 MB, Params: 1,471,670 (5.614 MB), Total: 5.73 MB, FLOPs: 138,487,059\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.986%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.941%\n",
      "Finished fine tuning.\n",
      "Iteration 856/1723 finished in 0m17s\n",
      "Total channels prunned so far: 856\n",
      "\n",
      "Iteration 857 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 142)]\n",
      "Input: 0.115 MB, Params: 1,469,274 (5.605 MB), Total: 5.72 MB, FLOPs: 138,314,619\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.289%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Finished fine tuning.\n",
      "Iteration 857/1723 finished in 0m17s\n",
      "Total channels prunned so far: 857\n",
      "\n",
      "Iteration 858 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 85)]\n",
      "Input: 0.115 MB, Params: 1,466,965 (5.596 MB), Total: 5.71 MB, FLOPs: 138,273,101\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.986%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Finished fine tuning.\n",
      "Iteration 858/1723 finished in 0m17s\n",
      "Total channels prunned so far: 858\n",
      "\n",
      "Iteration 859 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 86)]\n",
      "Input: 0.115 MB, Params: 1,464,569 (5.587 MB), Total: 5.70 MB, FLOPs: 138,100,661\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.986%\n",
      "Finished fine tuning.\n",
      "Iteration 859/1723 finished in 0m17s\n",
      "Total channels prunned so far: 859\n",
      "\n",
      "Iteration 860 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 30)]\n",
      "Input: 0.115 MB, Params: 1,463,298 (5.582 MB), Total: 5.70 MB, FLOPs: 137,677,751\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.244%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Finished fine tuning.\n",
      "Iteration 860/1723 finished in 0m17s\n",
      "Total channels prunned so far: 860\n",
      "\n",
      "Iteration 861 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 29)]\n",
      "Input: 0.115 MB, Params: 1,460,989 (5.573 MB), Total: 5.69 MB, FLOPs: 137,636,233\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Finished fine tuning.\n",
      "Iteration 861/1723 finished in 0m17s\n",
      "Total channels prunned so far: 861\n",
      "\n",
      "Iteration 862 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 42)]\n",
      "Input: 0.115 MB, Params: 1,457,207 (5.559 MB), Total: 5.67 MB, FLOPs: 137,568,175\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Finished fine tuning.\n",
      "Iteration 862/1723 finished in 0m16s\n",
      "Total channels prunned so far: 862\n",
      "\n",
      "Iteration 863 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 101)]\n",
      "Input: 0.115 MB, Params: 1,454,811 (5.550 MB), Total: 5.66 MB, FLOPs: 137,395,735\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Finished fine tuning.\n",
      "Iteration 863/1723 finished in 0m17s\n",
      "Total channels prunned so far: 863\n",
      "\n",
      "Iteration 864 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 61)]\n",
      "Input: 0.115 MB, Params: 1,451,200 (5.536 MB), Total: 5.65 MB, FLOPs: 137,259,673\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Finished fine tuning.\n",
      "Iteration 864/1723 finished in 0m17s\n",
      "Total channels prunned so far: 864\n",
      "\n",
      "Iteration 865 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 10)]\n",
      "Input: 0.115 MB, Params: 1,449,146 (5.528 MB), Total: 5.64 MB, FLOPs: 136,918,690\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Finished fine tuning.\n",
      "Iteration 865/1723 finished in 0m17s\n",
      "Total channels prunned so far: 865\n",
      "\n",
      "Iteration 866 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 0)]\n",
      "Input: 0.115 MB, Params: 1,447,092 (5.520 MB), Total: 5.64 MB, FLOPs: 136,577,707\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Finished fine tuning.\n",
      "Iteration 866/1723 finished in 0m17s\n",
      "Total channels prunned so far: 866\n",
      "\n",
      "Iteration 867 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 41)]\n",
      "Input: 0.115 MB, Params: 1,445,839 (5.515 MB), Total: 5.63 MB, FLOPs: 136,160,791\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Finished fine tuning.\n",
      "Iteration 867/1723 finished in 0m17s\n",
      "Total channels prunned so far: 867\n",
      "\n",
      "Iteration 868 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(7, 11)]\n",
      "Input: 0.115 MB, Params: 1,445,387 (5.514 MB), Total: 5.63 MB, FLOPs: 135,467,776\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.927%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Finished fine tuning.\n",
      "Iteration 868/1723 finished in 0m17s\n",
      "Total channels prunned so far: 868\n",
      "\n",
      "Iteration 869 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(3, 11)]\n",
      "Input: 0.115 MB, Params: 1,445,350 (5.514 MB), Total: 5.63 MB, FLOPs: 135,156,608\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.289%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Finished fine tuning.\n",
      "Iteration 869/1723 finished in 0m16s\n",
      "Total channels prunned so far: 869\n",
      "\n",
      "Iteration 870 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 196)]\n",
      "Input: 0.115 MB, Params: 1,443,050 (5.505 MB), Total: 5.62 MB, FLOPs: 135,115,252\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Finished fine tuning.\n",
      "Iteration 870/1723 finished in 0m17s\n",
      "Total channels prunned so far: 870\n",
      "\n",
      "Iteration 871 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 55)]\n",
      "Input: 0.115 MB, Params: 1,440,681 (5.496 MB), Total: 5.61 MB, FLOPs: 134,944,756\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Finished fine tuning.\n",
      "Iteration 871/1723 finished in 0m16s\n",
      "Total channels prunned so far: 871\n",
      "\n",
      "Iteration 872 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 145)]\n",
      "Input: 0.115 MB, Params: 1,436,917 (5.481 MB), Total: 5.60 MB, FLOPs: 134,877,022\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.986%\n",
      "Finished fine tuning.\n",
      "Iteration 872/1723 finished in 0m17s\n",
      "Total channels prunned so far: 872\n",
      "\n",
      "Iteration 873 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 147)]\n",
      "Input: 0.115 MB, Params: 1,434,626 (5.473 MB), Total: 5.59 MB, FLOPs: 134,835,828\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Finished fine tuning.\n",
      "Iteration 873/1723 finished in 0m17s\n",
      "Total channels prunned so far: 873\n",
      "\n",
      "Iteration 874 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 121)]\n",
      "Input: 0.115 MB, Params: 1,430,871 (5.458 MB), Total: 5.57 MB, FLOPs: 134,768,256\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Finished fine tuning.\n",
      "Iteration 874/1723 finished in 0m16s\n",
      "Total channels prunned so far: 874\n",
      "\n",
      "Iteration 875 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 116)]\n",
      "Input: 0.115 MB, Params: 1,428,589 (5.450 MB), Total: 5.56 MB, FLOPs: 134,727,224\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Finished fine tuning.\n",
      "Iteration 875/1723 finished in 0m16s\n",
      "Total channels prunned so far: 875\n",
      "\n",
      "Iteration 876 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 77)]\n",
      "Input: 0.115 MB, Params: 1,426,553 (5.442 MB), Total: 5.56 MB, FLOPs: 134,389,886\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Finished fine tuning.\n",
      "Iteration 876/1723 finished in 0m17s\n",
      "Total channels prunned so far: 876\n",
      "\n",
      "Iteration 877 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 74)]\n",
      "Input: 0.115 MB, Params: 1,425,309 (5.437 MB), Total: 5.55 MB, FLOPs: 133,975,967\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.986%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Finished fine tuning.\n",
      "Iteration 877/1723 finished in 0m16s\n",
      "Total channels prunned so far: 877\n",
      "\n",
      "Iteration 878 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 125)]\n",
      "Input: 0.115 MB, Params: 1,423,027 (5.428 MB), Total: 5.54 MB, FLOPs: 133,934,935\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.638%\n",
      "Finished fine tuning.\n",
      "Iteration 878/1723 finished in 0m16s\n",
      "Total channels prunned so far: 878\n",
      "\n",
      "Iteration 879 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 59)]\n",
      "Input: 0.115 MB, Params: 1,421,000 (5.421 MB), Total: 5.54 MB, FLOPs: 133,600,594\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Finished fine tuning.\n",
      "Iteration 879/1723 finished in 0m17s\n",
      "Total channels prunned so far: 879\n",
      "\n",
      "Iteration 880 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 50)]\n",
      "Input: 0.115 MB, Params: 1,419,765 (5.416 MB), Total: 5.53 MB, FLOPs: 133,189,672\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Finished fine tuning.\n",
      "Iteration 880/1723 finished in 0m17s\n",
      "Total channels prunned so far: 880\n",
      "\n",
      "Iteration 881 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 60)]\n",
      "Input: 0.115 MB, Params: 1,416,181 (5.402 MB), Total: 5.52 MB, FLOPs: 133,054,582\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Finished fine tuning.\n",
      "Iteration 881/1723 finished in 0m17s\n",
      "Total channels prunned so far: 881\n",
      "\n",
      "Iteration 882 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(14, 24)]\n",
      "Input: 0.115 MB, Params: 1,415,027 (5.398 MB), Total: 5.51 MB, FLOPs: 132,186,637\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Finished fine tuning.\n",
      "Iteration 882/1723 finished in 0m17s\n",
      "Total channels prunned so far: 882\n",
      "\n",
      "Iteration 883 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 106)]\n",
      "Input: 0.115 MB, Params: 1,411,299 (5.384 MB), Total: 5.50 MB, FLOPs: 132,119,551\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Finished fine tuning.\n",
      "Iteration 883/1723 finished in 0m16s\n",
      "Total channels prunned so far: 883\n",
      "\n",
      "Iteration 884 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 134)]\n",
      "Input: 0.115 MB, Params: 1,409,026 (5.375 MB), Total: 5.49 MB, FLOPs: 132,078,681\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Finished fine tuning.\n",
      "Iteration 884/1723 finished in 0m17s\n",
      "Total channels prunned so far: 884\n",
      "\n",
      "Iteration 885 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 87)]\n",
      "Input: 0.115 MB, Params: 1,405,451 (5.361 MB), Total: 5.48 MB, FLOPs: 131,943,753\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Finished fine tuning.\n",
      "Iteration 885/1723 finished in 0m17s\n",
      "Total channels prunned so far: 885\n",
      "\n",
      "Iteration 886 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 20)]\n",
      "Input: 0.115 MB, Params: 1,401,876 (5.348 MB), Total: 5.46 MB, FLOPs: 131,808,825\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Finished fine tuning.\n",
      "Iteration 886/1723 finished in 0m17s\n",
      "Total channels prunned so far: 886\n",
      "\n",
      "Iteration 887 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 115)]\n",
      "Input: 0.115 MB, Params: 1,399,603 (5.339 MB), Total: 5.45 MB, FLOPs: 131,767,955\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Finished fine tuning.\n",
      "Iteration 887/1723 finished in 0m16s\n",
      "Total channels prunned so far: 887\n",
      "\n",
      "Iteration 888 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 46)]\n",
      "Input: 0.115 MB, Params: 1,398,377 (5.334 MB), Total: 5.45 MB, FLOPs: 131,360,030\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Finished fine tuning.\n",
      "Iteration 888/1723 finished in 0m17s\n",
      "Total channels prunned so far: 888\n",
      "\n",
      "Iteration 889 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 16)]\n",
      "Input: 0.115 MB, Params: 1,397,727 (5.332 MB), Total: 5.45 MB, FLOPs: 130,435,205\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Finished fine tuning.\n",
      "Iteration 889/1723 finished in 0m16s\n",
      "Total channels prunned so far: 889\n",
      "\n",
      "Iteration 890 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 94)]\n",
      "Input: 0.115 MB, Params: 1,395,454 (5.323 MB), Total: 5.44 MB, FLOPs: 130,394,335\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Finished fine tuning.\n",
      "Iteration 890/1723 finished in 0m17s\n",
      "Total channels prunned so far: 890\n",
      "\n",
      "Iteration 891 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 210)]\n",
      "Input: 0.115 MB, Params: 1,391,771 (5.309 MB), Total: 5.42 MB, FLOPs: 130,328,059\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Finished fine tuning.\n",
      "Iteration 891/1723 finished in 0m17s\n",
      "Total channels prunned so far: 891\n",
      "\n",
      "Iteration 892 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 120)]\n",
      "Input: 0.115 MB, Params: 1,388,088 (5.295 MB), Total: 5.41 MB, FLOPs: 130,261,783\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Finished fine tuning.\n",
      "Iteration 892/1723 finished in 0m17s\n",
      "Total channels prunned so far: 892\n",
      "\n",
      "Iteration 893 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 154)]\n",
      "Input: 0.115 MB, Params: 1,384,531 (5.282 MB), Total: 5.40 MB, FLOPs: 130,127,179\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Finished fine tuning.\n",
      "Iteration 893/1723 finished in 0m17s\n",
      "Total channels prunned so far: 893\n",
      "\n",
      "Iteration 894 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 211)]\n",
      "Input: 0.115 MB, Params: 1,380,857 (5.268 MB), Total: 5.38 MB, FLOPs: 130,061,065\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Finished fine tuning.\n",
      "Iteration 894/1723 finished in 0m17s\n",
      "Total channels prunned so far: 894\n",
      "\n",
      "Iteration 895 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 90)]\n",
      "Input: 0.115 MB, Params: 1,378,611 (5.259 MB), Total: 5.37 MB, FLOPs: 130,020,681\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Finished fine tuning.\n",
      "Iteration 895/1723 finished in 0m17s\n",
      "Total channels prunned so far: 895\n",
      "\n",
      "Iteration 896 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 36)]\n",
      "Input: 0.115 MB, Params: 1,376,365 (5.250 MB), Total: 5.37 MB, FLOPs: 129,980,297\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Finished fine tuning.\n",
      "Iteration 896/1723 finished in 0m17s\n",
      "Total channels prunned so far: 896\n",
      "\n",
      "Iteration 897 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(3, 13)]\n",
      "Input: 0.115 MB, Params: 1,376,328 (5.250 MB), Total: 5.37 MB, FLOPs: 127,322,604\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Finished fine tuning.\n",
      "Iteration 897/1723 finished in 0m17s\n",
      "Total channels prunned so far: 897\n",
      "\n",
      "Iteration 898 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 211)]\n",
      "Input: 0.115 MB, Params: 1,372,672 (5.236 MB), Total: 5.35 MB, FLOPs: 127,256,814\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Finished fine tuning.\n",
      "Iteration 898/1723 finished in 0m17s\n",
      "Total channels prunned so far: 898\n",
      "\n",
      "Iteration 899 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 38)]\n",
      "Input: 0.115 MB, Params: 1,372,022 (5.234 MB), Total: 5.35 MB, FLOPs: 126,380,664\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Finished fine tuning.\n",
      "Iteration 899/1723 finished in 0m16s\n",
      "Total channels prunned so far: 899\n",
      "\n",
      "Iteration 900 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 135)]\n",
      "Input: 0.115 MB, Params: 1,368,483 (5.220 MB), Total: 5.34 MB, FLOPs: 126,246,384\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Finished fine tuning.\n",
      "Iteration 900/1723 finished in 0m16s\n",
      "Total channels prunned so far: 900\n",
      "\n",
      "Iteration 901 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 235)]\n",
      "Input: 0.115 MB, Params: 1,364,836 (5.206 MB), Total: 5.32 MB, FLOPs: 126,180,756\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Finished fine tuning.\n",
      "Iteration 901/1723 finished in 0m17s\n",
      "Total channels prunned so far: 901\n",
      "\n",
      "Iteration 902 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 233)]\n",
      "Input: 0.115 MB, Params: 1,362,608 (5.198 MB), Total: 5.31 MB, FLOPs: 126,140,696\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.986%\n",
      "Finished fine tuning.\n",
      "Iteration 902/1723 finished in 0m17s\n",
      "Total channels prunned so far: 902\n",
      "\n",
      "Iteration 903 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 121)]\n",
      "Input: 0.115 MB, Params: 1,360,302 (5.189 MB), Total: 5.30 MB, FLOPs: 125,974,736\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Finished fine tuning.\n",
      "Iteration 903/1723 finished in 0m17s\n",
      "Total channels prunned so far: 903\n",
      "\n",
      "Iteration 904 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(7, 2)]\n",
      "Input: 0.115 MB, Params: 1,359,868 (5.187 MB), Total: 5.30 MB, FLOPs: 125,342,416\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Finished fine tuning.\n",
      "Iteration 904/1723 finished in 0m16s\n",
      "Total channels prunned so far: 904\n",
      "\n",
      "Iteration 905 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 246)]\n",
      "Input: 0.115 MB, Params: 1,356,230 (5.174 MB), Total: 5.29 MB, FLOPs: 125,276,950\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Finished fine tuning.\n",
      "Iteration 905/1723 finished in 0m17s\n",
      "Total channels prunned so far: 905\n",
      "\n",
      "Iteration 906 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(3, 13)]\n",
      "Input: 0.115 MB, Params: 1,356,193 (5.173 MB), Total: 5.29 MB, FLOPs: 124,967,292\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Finished fine tuning.\n",
      "Iteration 906/1723 finished in 0m17s\n",
      "Total channels prunned so far: 906\n",
      "\n",
      "Iteration 907 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 71)]\n",
      "Input: 0.115 MB, Params: 1,354,967 (5.169 MB), Total: 5.28 MB, FLOPs: 124,559,367\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Finished fine tuning.\n",
      "Iteration 907/1723 finished in 0m17s\n",
      "Total channels prunned so far: 907\n",
      "\n",
      "Iteration 908 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(7, 11)]\n",
      "Input: 0.115 MB, Params: 1,354,533 (5.167 MB), Total: 5.28 MB, FLOPs: 123,928,557\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Finished fine tuning.\n",
      "Iteration 908/1723 finished in 0m16s\n",
      "Total channels prunned so far: 908\n",
      "\n",
      "Iteration 909 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 44)]\n",
      "Input: 0.115 MB, Params: 1,352,227 (5.158 MB), Total: 5.27 MB, FLOPs: 123,762,597\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Finished fine tuning.\n",
      "Iteration 909/1723 finished in 0m16s\n",
      "Total channels prunned so far: 909\n",
      "\n",
      "Iteration 910 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 34)]\n",
      "Input: 0.115 MB, Params: 1,349,921 (5.150 MB), Total: 5.26 MB, FLOPs: 123,596,637\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Finished fine tuning.\n",
      "Iteration 910/1723 finished in 0m17s\n",
      "Total channels prunned so far: 910\n",
      "\n",
      "Iteration 911 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 218)]\n",
      "Input: 0.115 MB, Params: 1,346,283 (5.136 MB), Total: 5.25 MB, FLOPs: 123,531,171\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.986%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.986%\n",
      "Finished fine tuning.\n",
      "Iteration 911/1723 finished in 0m16s\n",
      "Total channels prunned so far: 911\n",
      "\n",
      "Iteration 912 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 31)]\n",
      "Input: 0.115 MB, Params: 1,343,977 (5.127 MB), Total: 5.24 MB, FLOPs: 123,365,211\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.638%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.986%\n",
      "Finished fine tuning.\n",
      "Iteration 912/1723 finished in 0m17s\n",
      "Total channels prunned so far: 912\n",
      "\n",
      "Iteration 913 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(14, 29)]\n",
      "Input: 0.115 MB, Params: 1,342,859 (5.123 MB), Total: 5.24 MB, FLOPs: 122,560,710\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Finished fine tuning.\n",
      "Iteration 913/1723 finished in 0m17s\n",
      "Total channels prunned so far: 913\n",
      "\n",
      "Iteration 914 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 59)]\n",
      "Input: 0.115 MB, Params: 1,340,553 (5.114 MB), Total: 5.23 MB, FLOPs: 122,394,750\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.986%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Finished fine tuning.\n",
      "Iteration 914/1723 finished in 0m16s\n",
      "Total channels prunned so far: 914\n",
      "\n",
      "Iteration 915 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 122)]\n",
      "Input: 0.115 MB, Params: 1,336,915 (5.100 MB), Total: 5.22 MB, FLOPs: 122,329,284\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.986%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.638%\n",
      "Finished fine tuning.\n",
      "Iteration 915/1723 finished in 0m17s\n",
      "Total channels prunned so far: 915\n",
      "\n",
      "Iteration 916 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 146)]\n",
      "Input: 0.115 MB, Params: 1,333,457 (5.087 MB), Total: 5.20 MB, FLOPs: 122,198,892\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.986%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.986%\n",
      "Finished fine tuning.\n",
      "Iteration 916/1723 finished in 0m17s\n",
      "Total channels prunned so far: 916\n",
      "\n",
      "Iteration 917 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 13)]\n",
      "Input: 0.115 MB, Params: 1,329,999 (5.074 MB), Total: 5.19 MB, FLOPs: 122,068,500\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.986%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Finished fine tuning.\n",
      "Iteration 917/1723 finished in 0m17s\n",
      "Total channels prunned so far: 917\n",
      "\n",
      "Iteration 918 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 83)]\n",
      "Input: 0.115 MB, Params: 1,328,044 (5.066 MB), Total: 5.18 MB, FLOPs: 121,746,390\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.638%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.638%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Finished fine tuning.\n",
      "Iteration 918/1723 finished in 0m17s\n",
      "Total channels prunned so far: 918\n",
      "\n",
      "Iteration 919 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 28)]\n",
      "Input: 0.115 MB, Params: 1,324,586 (5.053 MB), Total: 5.17 MB, FLOPs: 121,615,998\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Finished fine tuning.\n",
      "Iteration 919/1723 finished in 0m17s\n",
      "Total channels prunned so far: 919\n",
      "\n",
      "Iteration 920 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 168)]\n",
      "Input: 0.115 MB, Params: 1,322,385 (5.044 MB), Total: 5.16 MB, FLOPs: 121,576,424\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.986%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Finished fine tuning.\n",
      "Iteration 920/1723 finished in 0m17s\n",
      "Total channels prunned so far: 920\n",
      "\n",
      "Iteration 921 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 206)]\n",
      "Input: 0.115 MB, Params: 1,320,184 (5.036 MB), Total: 5.15 MB, FLOPs: 121,536,850\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Finished fine tuning.\n",
      "Iteration 921/1723 finished in 0m17s\n",
      "Total channels prunned so far: 921\n",
      "\n",
      "Iteration 922 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 82)]\n",
      "Input: 0.115 MB, Params: 1,316,726 (5.023 MB), Total: 5.14 MB, FLOPs: 121,406,458\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Finished fine tuning.\n",
      "Iteration 922/1723 finished in 0m17s\n",
      "Total channels prunned so far: 922\n",
      "\n",
      "Iteration 923 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 109)]\n",
      "Input: 0.115 MB, Params: 1,314,525 (5.015 MB), Total: 5.13 MB, FLOPs: 121,366,884\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Finished fine tuning.\n",
      "Iteration 923/1723 finished in 0m17s\n",
      "Total channels prunned so far: 923\n",
      "\n",
      "Iteration 924 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(7, 11)]\n",
      "Input: 0.115 MB, Params: 1,314,091 (5.013 MB), Total: 5.13 MB, FLOPs: 120,736,074\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.986%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.986%\n",
      "Finished fine tuning.\n",
      "Iteration 924/1723 finished in 0m17s\n",
      "Total channels prunned so far: 924\n",
      "\n",
      "Iteration 925 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 40)]\n",
      "Input: 0.115 MB, Params: 1,310,633 (5.000 MB), Total: 5.11 MB, FLOPs: 120,605,682\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.986%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Finished fine tuning.\n",
      "Iteration 925/1723 finished in 0m17s\n",
      "Total channels prunned so far: 925\n",
      "\n",
      "Iteration 926 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 53)]\n",
      "Input: 0.115 MB, Params: 1,309,425 (4.995 MB), Total: 5.11 MB, FLOPs: 120,203,751\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Finished fine tuning.\n",
      "Iteration 926/1723 finished in 0m17s\n",
      "Total channels prunned so far: 926\n",
      "\n",
      "Iteration 927 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 80)]\n",
      "Input: 0.115 MB, Params: 1,307,224 (4.987 MB), Total: 5.10 MB, FLOPs: 120,164,177\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Finished fine tuning.\n",
      "Iteration 927/1723 finished in 0m16s\n",
      "Total channels prunned so far: 927\n",
      "\n",
      "Iteration 928 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 52)]\n",
      "Input: 0.115 MB, Params: 1,303,667 (4.973 MB), Total: 5.09 MB, FLOPs: 120,100,169\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Finished fine tuning.\n",
      "Iteration 928/1723 finished in 0m17s\n",
      "Total channels prunned so far: 928\n",
      "\n",
      "Iteration 929 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 159)]\n",
      "Input: 0.115 MB, Params: 1,301,475 (4.965 MB), Total: 5.08 MB, FLOPs: 120,060,757\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Finished fine tuning.\n",
      "Iteration 929/1723 finished in 0m17s\n",
      "Total channels prunned so far: 929\n",
      "\n",
      "Iteration 930 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 1)]\n",
      "Input: 0.115 MB, Params: 1,297,927 (4.951 MB), Total: 5.07 MB, FLOPs: 119,996,911\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.986%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Finished fine tuning.\n",
      "Iteration 930/1723 finished in 0m16s\n",
      "Total channels prunned so far: 930\n",
      "\n",
      "Iteration 931 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(14, 39)]\n",
      "Input: 0.115 MB, Params: 1,296,818 (4.947 MB), Total: 5.06 MB, FLOPs: 119,195,407\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Finished fine tuning.\n",
      "Iteration 931/1723 finished in 0m17s\n",
      "Total channels prunned so far: 931\n",
      "\n",
      "Iteration 932 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 179)]\n",
      "Input: 0.115 MB, Params: 1,294,635 (4.939 MB), Total: 5.05 MB, FLOPs: 119,156,157\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Finished fine tuning.\n",
      "Iteration 932/1723 finished in 0m17s\n",
      "Total channels prunned so far: 932\n",
      "\n",
      "Iteration 933 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 25)]\n",
      "Input: 0.115 MB, Params: 1,292,689 (4.931 MB), Total: 5.05 MB, FLOPs: 118,837,044\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Finished fine tuning.\n",
      "Iteration 933/1723 finished in 0m17s\n",
      "Total channels prunned so far: 933\n",
      "\n",
      "Iteration 934 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 216)]\n",
      "Input: 0.115 MB, Params: 1,289,150 (4.918 MB), Total: 5.03 MB, FLOPs: 118,773,360\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Finished fine tuning.\n",
      "Iteration 934/1723 finished in 0m17s\n",
      "Total channels prunned so far: 934\n",
      "\n",
      "Iteration 935 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 65)]\n",
      "Input: 0.115 MB, Params: 1,285,611 (4.904 MB), Total: 5.02 MB, FLOPs: 118,709,676\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Finished fine tuning.\n",
      "Iteration 935/1723 finished in 0m16s\n",
      "Total channels prunned so far: 935\n",
      "\n",
      "Iteration 936 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 124)]\n",
      "Input: 0.115 MB, Params: 1,282,072 (4.891 MB), Total: 5.01 MB, FLOPs: 118,645,992\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Finished fine tuning.\n",
      "Iteration 936/1723 finished in 0m16s\n",
      "Total channels prunned so far: 936\n",
      "\n",
      "Iteration 937 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 77)]\n",
      "Input: 0.115 MB, Params: 1,279,829 (4.882 MB), Total: 5.00 MB, FLOPs: 118,484,568\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Finished fine tuning.\n",
      "Iteration 937/1723 finished in 0m17s\n",
      "Total channels prunned so far: 937\n",
      "\n",
      "Iteration 938 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 58)]\n",
      "Input: 0.115 MB, Params: 1,277,586 (4.874 MB), Total: 4.99 MB, FLOPs: 118,323,144\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.986%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Finished fine tuning.\n",
      "Iteration 938/1723 finished in 0m17s\n",
      "Total channels prunned so far: 938\n",
      "\n",
      "Iteration 939 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 104)]\n",
      "Input: 0.115 MB, Params: 1,274,191 (4.861 MB), Total: 4.98 MB, FLOPs: 118,194,858\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Finished fine tuning.\n",
      "Iteration 939/1723 finished in 0m17s\n",
      "Total channels prunned so far: 939\n",
      "\n",
      "Iteration 940 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 172)]\n",
      "Input: 0.115 MB, Params: 1,270,661 (4.847 MB), Total: 4.96 MB, FLOPs: 118,131,336\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.986%\n",
      "Finished fine tuning.\n",
      "Iteration 940/1723 finished in 0m17s\n",
      "Total channels prunned so far: 940\n",
      "\n",
      "Iteration 941 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 52)]\n",
      "Input: 0.115 MB, Params: 1,267,275 (4.834 MB), Total: 4.95 MB, FLOPs: 118,003,212\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.986%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Finished fine tuning.\n",
      "Iteration 941/1723 finished in 0m16s\n",
      "Total channels prunned so far: 941\n",
      "\n",
      "Iteration 942 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 41)]\n",
      "Input: 0.115 MB, Params: 1,265,347 (4.827 MB), Total: 4.94 MB, FLOPs: 117,685,395\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Finished fine tuning.\n",
      "Iteration 942/1723 finished in 0m17s\n",
      "Total channels prunned so far: 942\n",
      "\n",
      "Iteration 943 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 150)]\n",
      "Input: 0.115 MB, Params: 1,261,961 (4.814 MB), Total: 4.93 MB, FLOPs: 117,557,271\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.986%\n",
      "Finished fine tuning.\n",
      "Iteration 943/1723 finished in 0m17s\n",
      "Total channels prunned so far: 943\n",
      "\n",
      "Iteration 944 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(7, 6)]\n",
      "Input: 0.115 MB, Params: 1,261,527 (4.812 MB), Total: 4.93 MB, FLOPs: 116,926,461\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.986%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.638%\n",
      "Finished fine tuning.\n",
      "Iteration 944/1723 finished in 0m17s\n",
      "Total channels prunned so far: 944\n",
      "\n",
      "Iteration 945 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 173)]\n",
      "Input: 0.115 MB, Params: 1,258,015 (4.799 MB), Total: 4.91 MB, FLOPs: 116,863,263\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.289%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.986%\n",
      "Finished fine tuning.\n",
      "Iteration 945/1723 finished in 0m16s\n",
      "Total channels prunned so far: 945\n",
      "\n",
      "Iteration 946 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 13)]\n",
      "Input: 0.115 MB, Params: 1,255,877 (4.791 MB), Total: 4.91 MB, FLOPs: 116,824,823\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.986%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.289%\n",
      "Finished fine tuning.\n",
      "Iteration 946/1723 finished in 0m17s\n",
      "Total channels prunned so far: 946\n",
      "\n",
      "Iteration 947 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 86)]\n",
      "Input: 0.115 MB, Params: 1,252,374 (4.777 MB), Total: 4.89 MB, FLOPs: 116,761,787\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.986%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Finished fine tuning.\n",
      "Iteration 947/1723 finished in 0m17s\n",
      "Total channels prunned so far: 947\n",
      "\n",
      "Iteration 948 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 223)]\n",
      "Input: 0.115 MB, Params: 1,248,871 (4.764 MB), Total: 4.88 MB, FLOPs: 116,698,751\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Finished fine tuning.\n",
      "Iteration 948/1723 finished in 0m17s\n",
      "Total channels prunned so far: 948\n",
      "\n",
      "Iteration 949 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 23)]\n",
      "Input: 0.115 MB, Params: 1,245,512 (4.751 MB), Total: 4.87 MB, FLOPs: 116,571,113\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.289%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.941%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.638%\n",
      "Finished fine tuning.\n",
      "Iteration 949/1723 finished in 0m17s\n",
      "Total channels prunned so far: 949\n",
      "\n",
      "Iteration 950 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 192)]\n",
      "Input: 0.115 MB, Params: 1,242,018 (4.738 MB), Total: 4.85 MB, FLOPs: 116,508,239\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.592%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.289%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.638%\n",
      "Finished fine tuning.\n",
      "Iteration 950/1723 finished in 0m16s\n",
      "Total channels prunned so far: 950\n",
      "\n",
      "Iteration 951 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 124)]\n",
      "Input: 0.115 MB, Params: 1,239,907 (4.730 MB), Total: 4.85 MB, FLOPs: 116,470,285\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.986%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Finished fine tuning.\n",
      "Iteration 951/1723 finished in 0m16s\n",
      "Total channels prunned so far: 951\n",
      "\n",
      "Iteration 952 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 15)]\n",
      "Input: 0.115 MB, Params: 1,237,796 (4.722 MB), Total: 4.84 MB, FLOPs: 116,432,331\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.638%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.289%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.941%\n",
      "Finished fine tuning.\n",
      "Iteration 952/1723 finished in 0m17s\n",
      "Total channels prunned so far: 952\n",
      "\n",
      "Iteration 953 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 39)]\n",
      "Input: 0.115 MB, Params: 1,235,685 (4.714 MB), Total: 4.83 MB, FLOPs: 116,394,377\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.289%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.638%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.638%\n",
      "Finished fine tuning.\n",
      "Iteration 953/1723 finished in 0m17s\n",
      "Total channels prunned so far: 953\n",
      "\n",
      "Iteration 954 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 119)]\n",
      "Input: 0.115 MB, Params: 1,233,487 (4.705 MB), Total: 4.82 MB, FLOPs: 116,236,193\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.986%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.638%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.244%\n",
      "Finished fine tuning.\n",
      "Iteration 954/1723 finished in 0m16s\n",
      "Total channels prunned so far: 954\n",
      "\n",
      "Iteration 955 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 90)]\n",
      "Input: 0.115 MB, Params: 1,231,289 (4.697 MB), Total: 4.81 MB, FLOPs: 116,078,009\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.941%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.638%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.638%\n",
      "Finished fine tuning.\n",
      "Iteration 955/1723 finished in 0m17s\n",
      "Total channels prunned so far: 955\n",
      "\n",
      "Iteration 956 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 61)]\n",
      "Input: 0.115 MB, Params: 1,227,822 (4.684 MB), Total: 4.80 MB, FLOPs: 116,015,621\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Finished fine tuning.\n",
      "Iteration 956/1723 finished in 0m17s\n",
      "Total channels prunned so far: 956\n",
      "\n",
      "Iteration 957 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 59)]\n",
      "Input: 0.115 MB, Params: 1,225,624 (4.675 MB), Total: 4.79 MB, FLOPs: 115,857,437\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.638%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Finished fine tuning.\n",
      "Iteration 957/1723 finished in 0m17s\n",
      "Total channels prunned so far: 957\n",
      "\n",
      "Iteration 958 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(14, 30)]\n",
      "Input: 0.115 MB, Params: 1,224,515 (4.671 MB), Total: 4.79 MB, FLOPs: 115,055,933\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.638%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Finished fine tuning.\n",
      "Iteration 958/1723 finished in 0m17s\n",
      "Total channels prunned so far: 958\n",
      "\n",
      "Iteration 959 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 99)]\n",
      "Input: 0.115 MB, Params: 1,222,317 (4.663 MB), Total: 4.78 MB, FLOPs: 114,897,749\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Finished fine tuning.\n",
      "Iteration 959/1723 finished in 0m16s\n",
      "Total channels prunned so far: 959\n",
      "\n",
      "Iteration 960 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 137)]\n",
      "Input: 0.115 MB, Params: 1,219,012 (4.650 MB), Total: 4.77 MB, FLOPs: 114,773,027\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Finished fine tuning.\n",
      "Iteration 960/1723 finished in 0m17s\n",
      "Total channels prunned so far: 960\n",
      "\n",
      "Iteration 961 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 40)]\n",
      "Input: 0.115 MB, Params: 1,218,425 (4.648 MB), Total: 4.76 MB, FLOPs: 113,981,927\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Finished fine tuning.\n",
      "Iteration 961/1723 finished in 0m17s\n",
      "Total channels prunned so far: 961\n",
      "\n",
      "Iteration 962 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 212)]\n",
      "Input: 0.115 MB, Params: 1,214,967 (4.635 MB), Total: 4.75 MB, FLOPs: 113,919,701\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Finished fine tuning.\n",
      "Iteration 962/1723 finished in 0m17s\n",
      "Total channels prunned so far: 962\n",
      "\n",
      "Iteration 963 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 107)]\n",
      "Input: 0.115 MB, Params: 1,212,874 (4.627 MB), Total: 4.74 MB, FLOPs: 113,882,071\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Finished fine tuning.\n",
      "Iteration 963/1723 finished in 0m17s\n",
      "Total channels prunned so far: 963\n",
      "\n",
      "Iteration 964 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 198)]\n",
      "Input: 0.115 MB, Params: 1,209,425 (4.614 MB), Total: 4.73 MB, FLOPs: 113,820,007\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.986%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Finished fine tuning.\n",
      "Iteration 964/1723 finished in 0m17s\n",
      "Total channels prunned so far: 964\n",
      "\n",
      "Iteration 965 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 20)]\n",
      "Input: 0.115 MB, Params: 1,207,533 (4.606 MB), Total: 4.72 MB, FLOPs: 113,504,782\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.638%\n",
      "Finished fine tuning.\n",
      "Iteration 965/1723 finished in 0m17s\n",
      "Total channels prunned so far: 965\n",
      "\n",
      "Iteration 966 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 106)]\n",
      "Input: 0.115 MB, Params: 1,205,449 (4.598 MB), Total: 4.71 MB, FLOPs: 113,467,314\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Finished fine tuning.\n",
      "Iteration 966/1723 finished in 0m17s\n",
      "Total channels prunned so far: 966\n",
      "\n",
      "Iteration 967 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(14, 7)]\n",
      "Input: 0.115 MB, Params: 1,204,349 (4.594 MB), Total: 4.71 MB, FLOPs: 112,677,960\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.986%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Finished fine tuning.\n",
      "Iteration 967/1723 finished in 0m17s\n",
      "Total channels prunned so far: 967\n",
      "\n",
      "Iteration 968 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 71)]\n",
      "Input: 0.115 MB, Params: 1,202,457 (4.587 MB), Total: 4.70 MB, FLOPs: 112,362,735\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.986%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Finished fine tuning.\n",
      "Iteration 968/1723 finished in 0m17s\n",
      "Total channels prunned so far: 968\n",
      "\n",
      "Iteration 969 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 69)]\n",
      "Input: 0.115 MB, Params: 1,199,017 (4.574 MB), Total: 4.69 MB, FLOPs: 112,300,833\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.986%\n",
      "Finished fine tuning.\n",
      "Iteration 969/1723 finished in 0m17s\n",
      "Total channels prunned so far: 969\n",
      "\n",
      "Iteration 970 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 148)]\n",
      "Input: 0.115 MB, Params: 1,196,942 (4.566 MB), Total: 4.68 MB, FLOPs: 112,263,527\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.986%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.289%\n",
      "Finished fine tuning.\n",
      "Iteration 970/1723 finished in 0m16s\n",
      "Total channels prunned so far: 970\n",
      "\n",
      "Iteration 971 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 6)]\n",
      "Input: 0.115 MB, Params: 1,194,771 (4.558 MB), Total: 4.67 MB, FLOPs: 112,107,287\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Finished fine tuning.\n",
      "Iteration 971/1723 finished in 0m17s\n",
      "Total channels prunned so far: 971\n",
      "\n",
      "Iteration 972 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 27)]\n",
      "Input: 0.115 MB, Params: 1,192,696 (4.550 MB), Total: 4.67 MB, FLOPs: 112,069,981\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.638%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Finished fine tuning.\n",
      "Iteration 972/1723 finished in 0m17s\n",
      "Total channels prunned so far: 972\n",
      "\n",
      "Iteration 973 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 151)]\n",
      "Input: 0.115 MB, Params: 1,189,427 (4.537 MB), Total: 4.65 MB, FLOPs: 111,946,393\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.986%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Finished fine tuning.\n",
      "Iteration 973/1723 finished in 0m17s\n",
      "Total channels prunned so far: 973\n",
      "\n",
      "Iteration 974 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 106)]\n",
      "Input: 0.115 MB, Params: 1,187,352 (4.529 MB), Total: 4.64 MB, FLOPs: 111,909,087\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Finished fine tuning.\n",
      "Iteration 974/1723 finished in 0m17s\n",
      "Total channels prunned so far: 974\n",
      "\n",
      "Iteration 975 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 35)]\n",
      "Input: 0.115 MB, Params: 1,185,277 (4.521 MB), Total: 4.64 MB, FLOPs: 111,871,781\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Finished fine tuning.\n",
      "Iteration 975/1723 finished in 0m17s\n",
      "Total channels prunned so far: 975\n",
      "\n",
      "Iteration 976 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 4)]\n",
      "Input: 0.115 MB, Params: 1,184,132 (4.517 MB), Total: 4.63 MB, FLOPs: 111,490,829\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Finished fine tuning.\n",
      "Iteration 976/1723 finished in 0m16s\n",
      "Total channels prunned so far: 976\n",
      "\n",
      "Iteration 977 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 72)]\n",
      "Input: 0.115 MB, Params: 1,182,258 (4.510 MB), Total: 4.63 MB, FLOPs: 111,179,249\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.289%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Finished fine tuning.\n",
      "Iteration 977/1723 finished in 0m17s\n",
      "Total channels prunned so far: 977\n",
      "\n",
      "Iteration 978 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 66)]\n",
      "Input: 0.115 MB, Params: 1,180,384 (4.503 MB), Total: 4.62 MB, FLOPs: 110,867,669\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Finished fine tuning.\n",
      "Iteration 978/1723 finished in 0m16s\n",
      "Total channels prunned so far: 978\n",
      "\n",
      "Iteration 979 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 6)]\n",
      "Input: 0.115 MB, Params: 1,178,510 (4.496 MB), Total: 4.61 MB, FLOPs: 110,556,089\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Finished fine tuning.\n",
      "Iteration 979/1723 finished in 0m17s\n",
      "Total channels prunned so far: 979\n",
      "\n",
      "Iteration 980 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 206)]\n",
      "Input: 0.115 MB, Params: 1,176,435 (4.488 MB), Total: 4.60 MB, FLOPs: 110,518,783\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Finished fine tuning.\n",
      "Iteration 980/1723 finished in 0m17s\n",
      "Total channels prunned so far: 980\n",
      "\n",
      "Iteration 981 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 74)]\n",
      "Input: 0.115 MB, Params: 1,174,561 (4.481 MB), Total: 4.60 MB, FLOPs: 110,207,203\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.638%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.986%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Finished fine tuning.\n",
      "Iteration 981/1723 finished in 0m17s\n",
      "Total channels prunned so far: 981\n",
      "\n",
      "Iteration 982 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 13)]\n",
      "Input: 0.115 MB, Params: 1,172,687 (4.473 MB), Total: 4.59 MB, FLOPs: 109,895,623\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Finished fine tuning.\n",
      "Iteration 982/1723 finished in 0m17s\n",
      "Total channels prunned so far: 982\n",
      "\n",
      "Iteration 983 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 173)]\n",
      "Input: 0.115 MB, Params: 1,169,301 (4.461 MB), Total: 4.58 MB, FLOPs: 109,834,693\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Finished fine tuning.\n",
      "Iteration 983/1723 finished in 0m16s\n",
      "Total channels prunned so far: 983\n",
      "\n",
      "Iteration 984 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(14, 24)]\n",
      "Input: 0.115 MB, Params: 1,168,210 (4.456 MB), Total: 4.57 MB, FLOPs: 109,048,336\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Finished fine tuning.\n",
      "Iteration 984/1723 finished in 0m17s\n",
      "Total channels prunned so far: 984\n",
      "\n",
      "Iteration 985 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 20)]\n",
      "Input: 0.115 MB, Params: 1,167,641 (4.454 MB), Total: 4.57 MB, FLOPs: 108,281,536\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Finished fine tuning.\n",
      "Iteration 985/1723 finished in 0m17s\n",
      "Total channels prunned so far: 985\n",
      "\n",
      "Iteration 986 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 21)]\n",
      "Input: 0.115 MB, Params: 1,164,255 (4.441 MB), Total: 4.56 MB, FLOPs: 108,220,606\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Finished fine tuning.\n",
      "Iteration 986/1723 finished in 0m16s\n",
      "Total channels prunned so far: 986\n",
      "\n",
      "Iteration 987 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 198)]\n",
      "Input: 0.115 MB, Params: 1,160,869 (4.428 MB), Total: 4.54 MB, FLOPs: 108,159,676\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Finished fine tuning.\n",
      "Iteration 987/1723 finished in 0m16s\n",
      "Total channels prunned so far: 987\n",
      "\n",
      "Iteration 988 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 5)]\n",
      "Input: 0.115 MB, Params: 1,158,752 (4.420 MB), Total: 4.54 MB, FLOPs: 108,007,324\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Finished fine tuning.\n",
      "Iteration 988/1723 finished in 0m17s\n",
      "Total channels prunned so far: 988\n",
      "\n",
      "Iteration 989 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(14, 30)]\n",
      "Input: 0.115 MB, Params: 1,157,670 (4.416 MB), Total: 4.53 MB, FLOPs: 107,233,117\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.986%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Finished fine tuning.\n",
      "Iteration 989/1723 finished in 0m17s\n",
      "Total channels prunned so far: 989\n",
      "\n",
      "Iteration 990 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 92)]\n",
      "Input: 0.115 MB, Params: 1,155,553 (4.408 MB), Total: 4.52 MB, FLOPs: 107,080,765\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Finished fine tuning.\n",
      "Iteration 990/1723 finished in 0m17s\n",
      "Total channels prunned so far: 990\n",
      "\n",
      "Iteration 991 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 22)]\n",
      "Input: 0.115 MB, Params: 1,152,167 (4.395 MB), Total: 4.51 MB, FLOPs: 107,019,835\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Finished fine tuning.\n",
      "Iteration 991/1723 finished in 0m17s\n",
      "Total channels prunned so far: 991\n",
      "\n",
      "Iteration 992 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 57)]\n",
      "Input: 0.115 MB, Params: 1,148,781 (4.382 MB), Total: 4.50 MB, FLOPs: 106,958,905\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Finished fine tuning.\n",
      "Iteration 992/1723 finished in 0m17s\n",
      "Total channels prunned so far: 992\n",
      "\n",
      "Iteration 993 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 124)]\n",
      "Input: 0.115 MB, Params: 1,146,664 (4.374 MB), Total: 4.49 MB, FLOPs: 106,806,553\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Finished fine tuning.\n",
      "Iteration 993/1723 finished in 0m16s\n",
      "Total channels prunned so far: 993\n",
      "\n",
      "Iteration 994 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 18)]\n",
      "Input: 0.115 MB, Params: 1,144,547 (4.366 MB), Total: 4.48 MB, FLOPs: 106,654,201\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Finished fine tuning.\n",
      "Iteration 994/1723 finished in 0m17s\n",
      "Total channels prunned so far: 994\n",
      "\n",
      "Iteration 995 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 172)]\n",
      "Input: 0.115 MB, Params: 1,141,161 (4.353 MB), Total: 4.47 MB, FLOPs: 106,593,271\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Finished fine tuning.\n",
      "Iteration 995/1723 finished in 0m17s\n",
      "Total channels prunned so far: 995\n",
      "\n",
      "Iteration 996 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 48)]\n",
      "Input: 0.115 MB, Params: 1,139,323 (4.346 MB), Total: 4.46 MB, FLOPs: 106,284,283\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Finished fine tuning.\n",
      "Iteration 996/1723 finished in 0m17s\n",
      "Total channels prunned so far: 996\n",
      "\n",
      "Iteration 997 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 16)]\n",
      "Input: 0.115 MB, Params: 1,137,485 (4.339 MB), Total: 4.45 MB, FLOPs: 105,975,295\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Finished fine tuning.\n",
      "Iteration 997/1723 finished in 0m17s\n",
      "Total channels prunned so far: 997\n",
      "\n",
      "Iteration 998 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 26)]\n",
      "Input: 0.115 MB, Params: 1,135,647 (4.332 MB), Total: 4.45 MB, FLOPs: 105,666,307\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Finished fine tuning.\n",
      "Iteration 998/1723 finished in 0m17s\n",
      "Total channels prunned so far: 998\n",
      "\n",
      "Iteration 999 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 215)]\n",
      "Input: 0.115 MB, Params: 1,132,261 (4.319 MB), Total: 4.43 MB, FLOPs: 105,605,377\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Finished fine tuning.\n",
      "Iteration 999/1723 finished in 0m16s\n",
      "Total channels prunned so far: 999\n",
      "\n",
      "Iteration 1000 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(3, 31)]\n",
      "Input: 0.115 MB, Params: 1,132,224 (4.319 MB), Total: 4.43 MB, FLOPs: 100,470,975\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Finished fine tuning.\n",
      "Iteration 1000/1723 finished in 0m17s\n",
      "Total channels prunned so far: 1000\n",
      "\n",
      "Iteration 1001 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 165)]\n",
      "Input: 0.115 MB, Params: 1,130,212 (4.311 MB), Total: 4.43 MB, FLOPs: 100,434,803\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Finished fine tuning.\n",
      "Iteration 1001/1723 finished in 0m17s\n",
      "Total channels prunned so far: 1001\n",
      "\n",
      "Iteration 1002 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 147)]\n",
      "Input: 0.115 MB, Params: 1,127,042 (4.299 MB), Total: 4.41 MB, FLOPs: 100,314,941\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Finished fine tuning.\n",
      "Iteration 1002/1723 finished in 0m17s\n",
      "Total channels prunned so far: 1002\n",
      "\n",
      "Iteration 1003 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 79)]\n",
      "Input: 0.115 MB, Params: 1,123,872 (4.287 MB), Total: 4.40 MB, FLOPs: 100,195,079\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Finished fine tuning.\n",
      "Iteration 1003/1723 finished in 0m17s\n",
      "Total channels prunned so far: 1003\n",
      "\n",
      "Iteration 1004 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 128)]\n",
      "Input: 0.115 MB, Params: 1,121,860 (4.280 MB), Total: 4.39 MB, FLOPs: 100,158,907\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Finished fine tuning.\n",
      "Iteration 1004/1723 finished in 0m17s\n",
      "Total channels prunned so far: 1004\n",
      "\n",
      "Iteration 1005 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 117)]\n",
      "Input: 0.115 MB, Params: 1,118,510 (4.267 MB), Total: 4.38 MB, FLOPs: 100,098,625\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Finished fine tuning.\n",
      "Iteration 1005/1723 finished in 0m17s\n",
      "Total channels prunned so far: 1005\n",
      "\n",
      "Iteration 1006 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 38)]\n",
      "Input: 0.115 MB, Params: 1,115,349 (4.255 MB), Total: 4.37 MB, FLOPs: 99,978,925\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Finished fine tuning.\n",
      "Iteration 1006/1723 finished in 0m17s\n",
      "Total channels prunned so far: 1006\n",
      "\n",
      "Iteration 1007 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 43)]\n",
      "Input: 0.115 MB, Params: 1,112,008 (4.242 MB), Total: 4.36 MB, FLOPs: 99,918,805\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.638%\n",
      "Finished fine tuning.\n",
      "Iteration 1007/1723 finished in 0m17s\n",
      "Total channels prunned so far: 1007\n",
      "\n",
      "Iteration 1008 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 159)]\n",
      "Input: 0.115 MB, Params: 1,110,014 (4.234 MB), Total: 4.35 MB, FLOPs: 99,882,957\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Finished fine tuning.\n",
      "Iteration 1008/1723 finished in 0m16s\n",
      "Total channels prunned so far: 1008\n",
      "\n",
      "Iteration 1009 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 86)]\n",
      "Input: 0.115 MB, Params: 1,106,682 (4.222 MB), Total: 4.34 MB, FLOPs: 99,822,999\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Finished fine tuning.\n",
      "Iteration 1009/1723 finished in 0m17s\n",
      "Total channels prunned so far: 1009\n",
      "\n",
      "Iteration 1010 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 149)]\n",
      "Input: 0.115 MB, Params: 1,104,697 (4.214 MB), Total: 4.33 MB, FLOPs: 99,787,313\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Finished fine tuning.\n",
      "Iteration 1010/1723 finished in 0m17s\n",
      "Total channels prunned so far: 1010\n",
      "\n",
      "Iteration 1011 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 94)]\n",
      "Input: 0.115 MB, Params: 1,102,634 (4.206 MB), Total: 4.32 MB, FLOPs: 99,638,849\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Finished fine tuning.\n",
      "Iteration 1011/1723 finished in 0m17s\n",
      "Total channels prunned so far: 1011\n",
      "\n",
      "Iteration 1012 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 32)]\n",
      "Input: 0.115 MB, Params: 1,100,805 (4.199 MB), Total: 4.31 MB, FLOPs: 99,355,521\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Finished fine tuning.\n",
      "Iteration 1012/1723 finished in 0m17s\n",
      "Total channels prunned so far: 1012\n",
      "\n",
      "Iteration 1013 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 169)]\n",
      "Input: 0.115 MB, Params: 1,097,482 (4.187 MB), Total: 4.30 MB, FLOPs: 99,295,725\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Finished fine tuning.\n",
      "Iteration 1013/1723 finished in 0m17s\n",
      "Total channels prunned so far: 1013\n",
      "\n",
      "Iteration 1014 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 61)]\n",
      "Input: 0.115 MB, Params: 1,095,653 (4.180 MB), Total: 4.29 MB, FLOPs: 99,012,397\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Finished fine tuning.\n",
      "Iteration 1014/1723 finished in 0m17s\n",
      "Total channels prunned so far: 1014\n",
      "\n",
      "Iteration 1015 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 37)]\n",
      "Input: 0.115 MB, Params: 1,093,608 (4.172 MB), Total: 4.29 MB, FLOPs: 98,865,229\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.986%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.986%\n",
      "Finished fine tuning.\n",
      "Iteration 1015/1723 finished in 0m16s\n",
      "Total channels prunned so far: 1015\n",
      "\n",
      "Iteration 1016 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 140)]\n",
      "Input: 0.115 MB, Params: 1,091,632 (4.164 MB), Total: 4.28 MB, FLOPs: 98,829,705\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Finished fine tuning.\n",
      "Iteration 1016/1723 finished in 0m17s\n",
      "Total channels prunned so far: 1016\n",
      "\n",
      "Iteration 1017 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 112)]\n",
      "Input: 0.115 MB, Params: 1,088,318 (4.152 MB), Total: 4.27 MB, FLOPs: 98,770,071\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.986%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Finished fine tuning.\n",
      "Iteration 1017/1723 finished in 0m17s\n",
      "Total channels prunned so far: 1017\n",
      "\n",
      "Iteration 1018 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 138)]\n",
      "Input: 0.115 MB, Params: 1,085,004 (4.139 MB), Total: 4.25 MB, FLOPs: 98,710,437\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Finished fine tuning.\n",
      "Iteration 1018/1723 finished in 0m17s\n",
      "Total channels prunned so far: 1018\n",
      "\n",
      "Iteration 1019 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 47)]\n",
      "Input: 0.115 MB, Params: 1,083,046 (4.131 MB), Total: 4.25 MB, FLOPs: 98,675,237\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.986%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Finished fine tuning.\n",
      "Iteration 1019/1723 finished in 0m17s\n",
      "Total channels prunned so far: 1019\n",
      "\n",
      "Iteration 1020 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 32)]\n",
      "Input: 0.115 MB, Params: 1,079,741 (4.119 MB), Total: 4.23 MB, FLOPs: 98,615,765\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Finished fine tuning.\n",
      "Iteration 1020/1723 finished in 0m16s\n",
      "Total channels prunned so far: 1020\n",
      "\n",
      "Iteration 1021 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 137)]\n",
      "Input: 0.115 MB, Params: 1,077,792 (4.111 MB), Total: 4.23 MB, FLOPs: 98,580,727\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.986%\n",
      "Finished fine tuning.\n",
      "Iteration 1021/1723 finished in 0m17s\n",
      "Total channels prunned so far: 1021\n",
      "\n",
      "Iteration 1022 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 54)]\n",
      "Input: 0.115 MB, Params: 1,076,755 (4.107 MB), Total: 4.22 MB, FLOPs: 98,274,071\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Finished fine tuning.\n",
      "Iteration 1022/1723 finished in 0m17s\n",
      "Total channels prunned so far: 1022\n",
      "\n",
      "Iteration 1023 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 178)]\n",
      "Input: 0.115 MB, Params: 1,073,459 (4.095 MB), Total: 4.21 MB, FLOPs: 98,214,761\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Finished fine tuning.\n",
      "Iteration 1023/1723 finished in 0m17s\n",
      "Total channels prunned so far: 1023\n",
      "\n",
      "Iteration 1024 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 165)]\n",
      "Input: 0.115 MB, Params: 1,071,519 (4.088 MB), Total: 4.20 MB, FLOPs: 98,179,885\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Finished fine tuning.\n",
      "Iteration 1024/1723 finished in 0m17s\n",
      "Total channels prunned so far: 1024\n",
      "\n",
      "Iteration 1025 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 47)]\n",
      "Input: 0.115 MB, Params: 1,069,474 (4.080 MB), Total: 4.20 MB, FLOPs: 98,032,717\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Finished fine tuning.\n",
      "Iteration 1025/1723 finished in 0m17s\n",
      "Total channels prunned so far: 1025\n",
      "\n",
      "Iteration 1026 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 79)]\n",
      "Input: 0.115 MB, Params: 1,066,403 (4.068 MB), Total: 4.18 MB, FLOPs: 97,916,095\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Finished fine tuning.\n",
      "Iteration 1026/1723 finished in 0m18s\n",
      "Total channels prunned so far: 1026\n",
      "\n",
      "Iteration 1027 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 129)]\n",
      "Input: 0.115 MB, Params: 1,063,125 (4.056 MB), Total: 4.17 MB, FLOPs: 97,857,109\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Finished fine tuning.\n",
      "Iteration 1027/1723 finished in 0m17s\n",
      "Total channels prunned so far: 1027\n",
      "\n",
      "Iteration 1028 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 43)]\n",
      "Input: 0.115 MB, Params: 1,061,089 (4.048 MB), Total: 4.16 MB, FLOPs: 97,710,589\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.986%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Finished fine tuning.\n",
      "Iteration 1028/1723 finished in 0m18s\n",
      "Total channels prunned so far: 1028\n",
      "\n",
      "Iteration 1029 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 60)]\n",
      "Input: 0.115 MB, Params: 1,060,052 (4.044 MB), Total: 4.16 MB, FLOPs: 97,403,933\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Finished fine tuning.\n",
      "Iteration 1029/1723 finished in 0m16s\n",
      "Total channels prunned so far: 1029\n",
      "\n",
      "Iteration 1030 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 58)]\n",
      "Input: 0.115 MB, Params: 1,058,121 (4.036 MB), Total: 4.15 MB, FLOPs: 97,369,219\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Finished fine tuning.\n",
      "Iteration 1030/1723 finished in 0m17s\n",
      "Total channels prunned so far: 1030\n",
      "\n",
      "Iteration 1031 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 33)]\n",
      "Input: 0.115 MB, Params: 1,055,068 (4.025 MB), Total: 4.14 MB, FLOPs: 97,253,407\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Finished fine tuning.\n",
      "Iteration 1031/1723 finished in 0m17s\n",
      "Total channels prunned so far: 1031\n",
      "\n",
      "Iteration 1032 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(3, 24)]\n",
      "Input: 0.115 MB, Params: 1,055,031 (4.025 MB), Total: 4.14 MB, FLOPs: 96,948,279\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Finished fine tuning.\n",
      "Iteration 1032/1723 finished in 0m16s\n",
      "Total channels prunned so far: 1032\n",
      "\n",
      "Iteration 1033 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 28)]\n",
      "Input: 0.115 MB, Params: 1,053,100 (4.017 MB), Total: 4.13 MB, FLOPs: 96,913,565\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.986%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Finished fine tuning.\n",
      "Iteration 1033/1723 finished in 0m16s\n",
      "Total channels prunned so far: 1033\n",
      "\n",
      "Iteration 1034 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 119)]\n",
      "Input: 0.115 MB, Params: 1,049,849 (4.005 MB), Total: 4.12 MB, FLOPs: 96,855,065\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.986%\n",
      "Finished fine tuning.\n",
      "Iteration 1034/1723 finished in 0m17s\n",
      "Total channels prunned so far: 1034\n",
      "\n",
      "Iteration 1035 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 13)]\n",
      "Input: 0.115 MB, Params: 1,047,927 (3.998 MB), Total: 4.11 MB, FLOPs: 96,820,513\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.638%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.638%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Finished fine tuning.\n",
      "Iteration 1035/1723 finished in 0m17s\n",
      "Total channels prunned so far: 1035\n",
      "\n",
      "Iteration 1036 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 168)]\n",
      "Input: 0.115 MB, Params: 1,046,005 (3.990 MB), Total: 4.11 MB, FLOPs: 96,785,961\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.986%\n",
      "Finished fine tuning.\n",
      "Iteration 1036/1723 finished in 0m17s\n",
      "Total channels prunned so far: 1036\n",
      "\n",
      "Iteration 1037 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 32)]\n",
      "Input: 0.115 MB, Params: 1,045,445 (3.988 MB), Total: 4.10 MB, FLOPs: 96,073,236\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Finished fine tuning.\n",
      "Iteration 1037/1723 finished in 0m17s\n",
      "Total channels prunned so far: 1037\n",
      "\n",
      "Iteration 1038 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 110)]\n",
      "Input: 0.115 MB, Params: 1,042,401 (3.976 MB), Total: 4.09 MB, FLOPs: 95,957,586\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.986%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Finished fine tuning.\n",
      "Iteration 1038/1723 finished in 0m17s\n",
      "Total channels prunned so far: 1038\n",
      "\n",
      "Iteration 1039 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(14, 26)]\n",
      "Input: 0.115 MB, Params: 1,041,346 (3.972 MB), Total: 4.09 MB, FLOPs: 95,255,755\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.986%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Finished fine tuning.\n",
      "Iteration 1039/1723 finished in 0m17s\n",
      "Total channels prunned so far: 1039\n",
      "\n",
      "Iteration 1040 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 109)]\n",
      "Input: 0.115 MB, Params: 1,039,328 (3.965 MB), Total: 4.08 MB, FLOPs: 95,110,531\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Finished fine tuning.\n",
      "Iteration 1040/1723 finished in 0m17s\n",
      "Total channels prunned so far: 1040\n",
      "\n",
      "Iteration 1041 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 121)]\n",
      "Input: 0.115 MB, Params: 1,037,310 (3.957 MB), Total: 4.07 MB, FLOPs: 94,965,307\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Finished fine tuning.\n",
      "Iteration 1041/1723 finished in 0m17s\n",
      "Total channels prunned so far: 1041\n",
      "\n",
      "Iteration 1042 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 36)]\n",
      "Input: 0.115 MB, Params: 1,034,086 (3.945 MB), Total: 4.06 MB, FLOPs: 94,907,293\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Finished fine tuning.\n",
      "Iteration 1042/1723 finished in 0m17s\n",
      "Total channels prunned so far: 1042\n",
      "\n",
      "Iteration 1043 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 15)]\n",
      "Input: 0.115 MB, Params: 1,032,173 (3.937 MB), Total: 4.05 MB, FLOPs: 94,872,903\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Finished fine tuning.\n",
      "Iteration 1043/1723 finished in 0m17s\n",
      "Total channels prunned so far: 1043\n",
      "\n",
      "Iteration 1044 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 11)]\n",
      "Input: 0.115 MB, Params: 1,028,958 (3.925 MB), Total: 4.04 MB, FLOPs: 94,815,051\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Finished fine tuning.\n",
      "Iteration 1044/1723 finished in 0m16s\n",
      "Total channels prunned so far: 1044\n",
      "\n",
      "Iteration 1045 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 28)]\n",
      "Input: 0.115 MB, Params: 1,025,743 (3.913 MB), Total: 4.03 MB, FLOPs: 94,757,199\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.986%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Finished fine tuning.\n",
      "Iteration 1045/1723 finished in 0m17s\n",
      "Total channels prunned so far: 1045\n",
      "\n",
      "Iteration 1046 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 129)]\n",
      "Input: 0.115 MB, Params: 1,022,744 (3.901 MB), Total: 4.02 MB, FLOPs: 94,643,331\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.986%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Finished fine tuning.\n",
      "Iteration 1046/1723 finished in 0m17s\n",
      "Total channels prunned so far: 1046\n",
      "\n",
      "Iteration 1047 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 94)]\n",
      "Input: 0.115 MB, Params: 1,020,849 (3.894 MB), Total: 4.01 MB, FLOPs: 94,609,265\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Finished fine tuning.\n",
      "Iteration 1047/1723 finished in 0m17s\n",
      "Total channels prunned so far: 1047\n",
      "\n",
      "Iteration 1048 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 80)]\n",
      "Input: 0.115 MB, Params: 1,018,840 (3.887 MB), Total: 4.00 MB, FLOPs: 94,464,689\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.986%\n",
      "Finished fine tuning.\n",
      "Iteration 1048/1723 finished in 0m17s\n",
      "Total channels prunned so far: 1048\n",
      "\n",
      "Iteration 1049 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 39)]\n",
      "Input: 0.115 MB, Params: 1,015,850 (3.875 MB), Total: 3.99 MB, FLOPs: 94,351,469\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Finished fine tuning.\n",
      "Iteration 1049/1723 finished in 0m17s\n",
      "Total channels prunned so far: 1049\n",
      "\n",
      "Iteration 1050 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 157)]\n",
      "Input: 0.115 MB, Params: 1,012,662 (3.863 MB), Total: 3.98 MB, FLOPs: 94,294,103\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Finished fine tuning.\n",
      "Iteration 1050/1723 finished in 0m17s\n",
      "Total channels prunned so far: 1050\n",
      "\n",
      "Iteration 1051 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 115)]\n",
      "Input: 0.115 MB, Params: 1,009,474 (3.851 MB), Total: 3.97 MB, FLOPs: 94,236,737\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Finished fine tuning.\n",
      "Iteration 1051/1723 finished in 0m17s\n",
      "Total channels prunned so far: 1051\n",
      "\n",
      "Iteration 1052 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 148)]\n",
      "Input: 0.115 MB, Params: 1,007,597 (3.844 MB), Total: 3.96 MB, FLOPs: 94,202,995\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Finished fine tuning.\n",
      "Iteration 1052/1723 finished in 0m17s\n",
      "Total channels prunned so far: 1052\n",
      "\n",
      "Iteration 1053 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(14, 7)]\n",
      "Input: 0.115 MB, Params: 1,006,542 (3.840 MB), Total: 3.95 MB, FLOPs: 93,501,164\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Finished fine tuning.\n",
      "Iteration 1053/1723 finished in 0m16s\n",
      "Total channels prunned so far: 1053\n",
      "\n",
      "Iteration 1054 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 19)]\n",
      "Input: 0.115 MB, Params: 1,003,570 (3.828 MB), Total: 3.94 MB, FLOPs: 93,388,268\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Finished fine tuning.\n",
      "Iteration 1054/1723 finished in 0m17s\n",
      "Total channels prunned so far: 1054\n",
      "\n",
      "Iteration 1055 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 54)]\n",
      "Input: 0.115 MB, Params: 1,002,551 (3.824 MB), Total: 3.94 MB, FLOPs: 93,086,940\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Finished fine tuning.\n",
      "Iteration 1055/1723 finished in 0m17s\n",
      "Total channels prunned so far: 1055\n",
      "\n",
      "Iteration 1056 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 28)]\n",
      "Input: 0.115 MB, Params: 1,000,674 (3.817 MB), Total: 3.93 MB, FLOPs: 93,053,198\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Finished fine tuning.\n",
      "Iteration 1056/1723 finished in 0m17s\n",
      "Total channels prunned so far: 1056\n",
      "\n",
      "Iteration 1057 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(14, 32)]\n",
      "Input: 0.115 MB, Params: 999,628 (3.813 MB), Total: 3.93 MB, FLOPs: 92,354,031\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Finished fine tuning.\n",
      "Iteration 1057/1723 finished in 0m17s\n",
      "Total channels prunned so far: 1057\n",
      "\n",
      "Iteration 1058 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 65)]\n",
      "Input: 0.115 MB, Params: 997,880 (3.807 MB), Total: 3.92 MB, FLOPs: 92,082,583\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Finished fine tuning.\n",
      "Iteration 1058/1723 finished in 0m17s\n",
      "Total channels prunned so far: 1058\n",
      "\n",
      "Iteration 1059 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 43)]\n",
      "Input: 0.115 MB, Params: 994,719 (3.795 MB), Total: 3.91 MB, FLOPs: 92,025,703\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Finished fine tuning.\n",
      "Iteration 1059/1723 finished in 0m16s\n",
      "Total channels prunned so far: 1059\n",
      "\n",
      "Iteration 1060 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 79)]\n",
      "Input: 0.115 MB, Params: 991,558 (3.782 MB), Total: 3.90 MB, FLOPs: 91,968,823\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Finished fine tuning.\n",
      "Iteration 1060/1723 finished in 0m16s\n",
      "Total channels prunned so far: 1060\n",
      "\n",
      "Iteration 1061 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 116)]\n",
      "Input: 0.115 MB, Params: 988,604 (3.771 MB), Total: 3.89 MB, FLOPs: 91,856,251\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Finished fine tuning.\n",
      "Iteration 1061/1723 finished in 0m17s\n",
      "Total channels prunned so far: 1061\n",
      "\n",
      "Iteration 1062 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 117)]\n",
      "Input: 0.115 MB, Params: 985,650 (3.760 MB), Total: 3.88 MB, FLOPs: 91,743,679\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Finished fine tuning.\n",
      "Iteration 1062/1723 finished in 0m17s\n",
      "Total channels prunned so far: 1062\n",
      "\n",
      "Iteration 1063 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 167)]\n",
      "Input: 0.115 MB, Params: 982,507 (3.748 MB), Total: 3.86 MB, FLOPs: 91,687,123\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Finished fine tuning.\n",
      "Iteration 1063/1723 finished in 0m16s\n",
      "Total channels prunned so far: 1063\n",
      "\n",
      "Iteration 1064 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 6)]\n",
      "Input: 0.115 MB, Params: 979,562 (3.737 MB), Total: 3.85 MB, FLOPs: 91,574,713\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Finished fine tuning.\n",
      "Iteration 1064/1723 finished in 0m17s\n",
      "Total channels prunned so far: 1064\n",
      "\n",
      "Iteration 1065 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 119)]\n",
      "Input: 0.115 MB, Params: 976,617 (3.725 MB), Total: 3.84 MB, FLOPs: 91,462,303\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Finished fine tuning.\n",
      "Iteration 1065/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1065\n",
      "\n",
      "Iteration 1066 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 62)]\n",
      "Input: 0.115 MB, Params: 974,671 (3.718 MB), Total: 3.83 MB, FLOPs: 91,322,263\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Finished fine tuning.\n",
      "Iteration 1066/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1066\n",
      "\n",
      "Iteration 1067 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 8)]\n",
      "Input: 0.115 MB, Params: 971,546 (3.706 MB), Total: 3.82 MB, FLOPs: 91,266,031\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Finished fine tuning.\n",
      "Iteration 1067/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1067\n",
      "\n",
      "Iteration 1068 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 3)]\n",
      "Input: 0.115 MB, Params: 969,705 (3.699 MB), Total: 3.81 MB, FLOPs: 91,232,937\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Finished fine tuning.\n",
      "Iteration 1068/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1068\n",
      "\n",
      "Iteration 1069 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 104)]\n",
      "Input: 0.115 MB, Params: 967,759 (3.692 MB), Total: 3.81 MB, FLOPs: 91,092,897\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Finished fine tuning.\n",
      "Iteration 1069/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1069\n",
      "\n",
      "Iteration 1070 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 192)]\n",
      "Input: 0.115 MB, Params: 964,643 (3.680 MB), Total: 3.80 MB, FLOPs: 91,036,827\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Finished fine tuning.\n",
      "Iteration 1070/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1070\n",
      "\n",
      "Iteration 1071 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 47)]\n",
      "Input: 0.115 MB, Params: 961,527 (3.668 MB), Total: 3.78 MB, FLOPs: 90,980,757\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Finished fine tuning.\n",
      "Iteration 1071/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1071\n",
      "\n",
      "Iteration 1072 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 34)]\n",
      "Input: 0.115 MB, Params: 958,411 (3.656 MB), Total: 3.77 MB, FLOPs: 90,924,687\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Finished fine tuning.\n",
      "Iteration 1072/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1072\n",
      "\n",
      "Iteration 1073 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 53)]\n",
      "Input: 0.115 MB, Params: 955,295 (3.644 MB), Total: 3.76 MB, FLOPs: 90,868,617\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Finished fine tuning.\n",
      "Iteration 1073/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1073\n",
      "\n",
      "Iteration 1074 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 21)]\n",
      "Input: 0.115 MB, Params: 954,294 (3.640 MB), Total: 3.76 MB, FLOPs: 90,572,617\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Finished fine tuning.\n",
      "Iteration 1074/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1074\n",
      "\n",
      "Iteration 1075 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 29)]\n",
      "Input: 0.115 MB, Params: 952,348 (3.633 MB), Total: 3.75 MB, FLOPs: 90,432,577\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Finished fine tuning.\n",
      "Iteration 1075/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1075\n",
      "\n",
      "Iteration 1076 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 24)]\n",
      "Input: 0.115 MB, Params: 950,636 (3.626 MB), Total: 3.74 MB, FLOPs: 90,165,737\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Finished fine tuning.\n",
      "Iteration 1076/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1076\n",
      "\n",
      "Iteration 1077 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 25)]\n",
      "Input: 0.115 MB, Params: 949,644 (3.623 MB), Total: 3.74 MB, FLOPs: 89,872,401\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.774%\n",
      "Finished fine tuning.\n",
      "Iteration 1077/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1077\n",
      "\n",
      "Iteration 1078 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 176)]\n",
      "Input: 0.115 MB, Params: 946,528 (3.611 MB), Total: 3.73 MB, FLOPs: 89,816,331\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Finished fine tuning.\n",
      "Iteration 1078/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1078\n",
      "\n",
      "Iteration 1079 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 7)]\n",
      "Input: 0.115 MB, Params: 944,591 (3.603 MB), Total: 3.72 MB, FLOPs: 89,676,939\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Finished fine tuning.\n",
      "Iteration 1079/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1079\n",
      "\n",
      "Iteration 1080 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(14, 29)]\n",
      "Input: 0.115 MB, Params: 943,563 (3.599 MB), Total: 3.71 MB, FLOPs: 88,983,100\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.122%\n",
      "Finished fine tuning.\n",
      "Iteration 1080/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1080\n",
      "\n",
      "Iteration 1081 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 9)]\n",
      "Input: 0.115 MB, Params: 942,580 (3.596 MB), Total: 3.71 MB, FLOPs: 88,692,428\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.774%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Finished fine tuning.\n",
      "Iteration 1081/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1081\n",
      "\n",
      "Iteration 1082 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 2)]\n",
      "Input: 0.115 MB, Params: 939,725 (3.585 MB), Total: 3.70 MB, FLOPs: 88,583,582\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.774%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Finished fine tuning.\n",
      "Iteration 1082/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1082\n",
      "\n",
      "Iteration 1083 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 22)]\n",
      "Input: 0.115 MB, Params: 936,870 (3.574 MB), Total: 3.69 MB, FLOPs: 88,474,736\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.774%\n",
      "Finished fine tuning.\n",
      "Iteration 1083/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1083\n",
      "\n",
      "Iteration 1084 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 138)]\n",
      "Input: 0.115 MB, Params: 935,074 (3.567 MB), Total: 3.68 MB, FLOPs: 88,442,452\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.774%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.774%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Finished fine tuning.\n",
      "Iteration 1084/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1084\n",
      "\n",
      "Iteration 1085 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 41)]\n",
      "Input: 0.115 MB, Params: 931,985 (3.555 MB), Total: 3.67 MB, FLOPs: 88,386,868\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.774%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.774%\n",
      "Finished fine tuning.\n",
      "Iteration 1085/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1085\n",
      "\n",
      "Iteration 1086 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 168)]\n",
      "Input: 0.115 MB, Params: 930,198 (3.548 MB), Total: 3.66 MB, FLOPs: 88,354,746\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.122%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Finished fine tuning.\n",
      "Iteration 1086/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1086\n",
      "\n",
      "Iteration 1087 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 7)]\n",
      "Input: 0.115 MB, Params: 927,118 (3.537 MB), Total: 3.65 MB, FLOPs: 88,299,324\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.122%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Finished fine tuning.\n",
      "Iteration 1087/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1087\n",
      "\n",
      "Iteration 1088 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 164)]\n",
      "Input: 0.115 MB, Params: 925,340 (3.530 MB), Total: 3.65 MB, FLOPs: 88,267,364\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Finished fine tuning.\n",
      "Iteration 1088/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1088\n",
      "\n",
      "Iteration 1089 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 73)]\n",
      "Input: 0.115 MB, Params: 922,269 (3.518 MB), Total: 3.63 MB, FLOPs: 88,212,104\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.774%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Finished fine tuning.\n",
      "Iteration 1089/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1089\n",
      "\n",
      "Iteration 1090 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 131)]\n",
      "Input: 0.115 MB, Params: 919,198 (3.506 MB), Total: 3.62 MB, FLOPs: 88,156,844\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Finished fine tuning.\n",
      "Iteration 1090/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1090\n",
      "\n",
      "Iteration 1091 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 135)]\n",
      "Input: 0.115 MB, Params: 917,438 (3.500 MB), Total: 3.62 MB, FLOPs: 88,125,208\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Finished fine tuning.\n",
      "Iteration 1091/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1091\n",
      "\n",
      "Iteration 1092 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 75)]\n",
      "Input: 0.115 MB, Params: 915,678 (3.493 MB), Total: 3.61 MB, FLOPs: 88,093,572\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Finished fine tuning.\n",
      "Iteration 1092/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1092\n",
      "\n",
      "Iteration 1093 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 190)]\n",
      "Input: 0.115 MB, Params: 912,625 (3.481 MB), Total: 3.60 MB, FLOPs: 88,038,636\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.638%\n",
      "Finished fine tuning.\n",
      "Iteration 1093/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1093\n",
      "\n",
      "Iteration 1094 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 139)]\n",
      "Input: 0.115 MB, Params: 909,572 (3.470 MB), Total: 3.59 MB, FLOPs: 87,983,700\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Finished fine tuning.\n",
      "Iteration 1094/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1094\n",
      "\n",
      "Iteration 1095 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 34)]\n",
      "Input: 0.115 MB, Params: 906,519 (3.458 MB), Total: 3.57 MB, FLOPs: 87,928,764\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.941%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.289%\n",
      "Finished fine tuning.\n",
      "Iteration 1095/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1095\n",
      "\n",
      "Iteration 1096 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 156)]\n",
      "Input: 0.115 MB, Params: 904,786 (3.451 MB), Total: 3.57 MB, FLOPs: 87,897,614\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.638%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Finished fine tuning.\n",
      "Iteration 1096/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1096\n",
      "\n",
      "Iteration 1097 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 149)]\n",
      "Input: 0.115 MB, Params: 903,053 (3.445 MB), Total: 3.56 MB, FLOPs: 87,866,464\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Finished fine tuning.\n",
      "Iteration 1097/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1097\n",
      "\n",
      "Iteration 1098 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 132)]\n",
      "Input: 0.115 MB, Params: 900,018 (3.433 MB), Total: 3.55 MB, FLOPs: 87,811,852\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Finished fine tuning.\n",
      "Iteration 1098/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1098\n",
      "\n",
      "Iteration 1099 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(3, 3)]\n",
      "Input: 0.115 MB, Params: 899,981 (3.433 MB), Total: 3.55 MB, FLOPs: 85,772,649\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.986%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Finished fine tuning.\n",
      "Iteration 1099/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1099\n",
      "\n",
      "Iteration 1100 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(3, 18)]\n",
      "Input: 0.115 MB, Params: 899,944 (3.433 MB), Total: 3.55 MB, FLOPs: 85,467,521\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.986%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Finished fine tuning.\n",
      "Iteration 1100/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1100\n",
      "\n",
      "Iteration 1101 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 62)]\n",
      "Input: 0.115 MB, Params: 898,259 (3.427 MB), Total: 3.54 MB, FLOPs: 85,206,657\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Finished fine tuning.\n",
      "Iteration 1101/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1101\n",
      "\n",
      "Iteration 1102 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 47)]\n",
      "Input: 0.115 MB, Params: 896,574 (3.420 MB), Total: 3.54 MB, FLOPs: 84,945,793\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Finished fine tuning.\n",
      "Iteration 1102/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1102\n",
      "\n",
      "Iteration 1103 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 21)]\n",
      "Input: 0.115 MB, Params: 896,050 (3.418 MB), Total: 3.53 MB, FLOPs: 84,318,193\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Finished fine tuning.\n",
      "Iteration 1103/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1103\n",
      "\n",
      "Iteration 1104 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 171)]\n",
      "Input: 0.115 MB, Params: 893,015 (3.407 MB), Total: 3.52 MB, FLOPs: 84,263,581\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Finished fine tuning.\n",
      "Iteration 1104/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1104\n",
      "\n",
      "Iteration 1105 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 150)]\n",
      "Input: 0.115 MB, Params: 889,980 (3.395 MB), Total: 3.51 MB, FLOPs: 84,208,969\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Finished fine tuning.\n",
      "Iteration 1105/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1105\n",
      "\n",
      "Iteration 1106 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 18)]\n",
      "Input: 0.115 MB, Params: 886,945 (3.383 MB), Total: 3.50 MB, FLOPs: 84,154,357\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Finished fine tuning.\n",
      "Iteration 1106/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1106\n",
      "\n",
      "Iteration 1107 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 52)]\n",
      "Input: 0.115 MB, Params: 885,248 (3.377 MB), Total: 3.49 MB, FLOPs: 84,123,855\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Finished fine tuning.\n",
      "Iteration 1107/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1107\n",
      "\n",
      "Iteration 1108 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 22)]\n",
      "Input: 0.115 MB, Params: 882,222 (3.365 MB), Total: 3.48 MB, FLOPs: 84,069,405\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.425%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Finished fine tuning.\n",
      "Iteration 1108/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1108\n",
      "\n",
      "Iteration 1109 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 55)]\n",
      "Input: 0.115 MB, Params: 879,475 (3.355 MB), Total: 3.47 MB, FLOPs: 83,962,503\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Finished fine tuning.\n",
      "Iteration 1109/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1109\n",
      "\n",
      "Iteration 1110 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 2)]\n",
      "Input: 0.115 MB, Params: 877,787 (3.348 MB), Total: 3.46 MB, FLOPs: 83,932,163\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Finished fine tuning.\n",
      "Iteration 1110/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1110\n",
      "\n",
      "Iteration 1111 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 115)]\n",
      "Input: 0.115 MB, Params: 875,040 (3.338 MB), Total: 3.45 MB, FLOPs: 83,825,261\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Finished fine tuning.\n",
      "Iteration 1111/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1111\n",
      "\n",
      "Iteration 1112 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 36)]\n",
      "Input: 0.115 MB, Params: 872,293 (3.328 MB), Total: 3.44 MB, FLOPs: 83,718,359\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Finished fine tuning.\n",
      "Iteration 1112/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1112\n",
      "\n",
      "Iteration 1113 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 8)]\n",
      "Input: 0.115 MB, Params: 870,608 (3.321 MB), Total: 3.44 MB, FLOPs: 83,457,495\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Finished fine tuning.\n",
      "Iteration 1113/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1113\n",
      "\n",
      "Iteration 1114 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 164)]\n",
      "Input: 0.115 MB, Params: 868,920 (3.315 MB), Total: 3.43 MB, FLOPs: 83,427,155\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Finished fine tuning.\n",
      "Iteration 1114/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1114\n",
      "\n",
      "Iteration 1115 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 18)]\n",
      "Input: 0.115 MB, Params: 867,964 (3.311 MB), Total: 3.43 MB, FLOPs: 83,144,475\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Finished fine tuning.\n",
      "Iteration 1115/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1115\n",
      "\n",
      "Iteration 1116 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 45)]\n",
      "Input: 0.115 MB, Params: 864,983 (3.300 MB), Total: 3.41 MB, FLOPs: 83,090,835\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Finished fine tuning.\n",
      "Iteration 1116/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1116\n",
      "\n",
      "Iteration 1117 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 158)]\n",
      "Input: 0.115 MB, Params: 862,002 (3.288 MB), Total: 3.40 MB, FLOPs: 83,037,195\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Finished fine tuning.\n",
      "Iteration 1117/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1117\n",
      "\n",
      "Iteration 1118 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 37)]\n",
      "Input: 0.115 MB, Params: 861,046 (3.285 MB), Total: 3.40 MB, FLOPs: 82,754,515\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Finished fine tuning.\n",
      "Iteration 1118/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1118\n",
      "\n",
      "Iteration 1119 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 50)]\n",
      "Input: 0.115 MB, Params: 858,065 (3.273 MB), Total: 3.39 MB, FLOPs: 82,700,875\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.077%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Finished fine tuning.\n",
      "Iteration 1119/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1119\n",
      "\n",
      "Iteration 1120 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 14)]\n",
      "Input: 0.115 MB, Params: 856,200 (3.266 MB), Total: 3.38 MB, FLOPs: 82,566,667\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Finished fine tuning.\n",
      "Iteration 1120/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1120\n",
      "\n",
      "Iteration 1121 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 53)]\n",
      "Input: 0.115 MB, Params: 854,542 (3.260 MB), Total: 3.38 MB, FLOPs: 82,311,779\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Finished fine tuning.\n",
      "Iteration 1121/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1121\n",
      "\n",
      "Iteration 1122 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 128)]\n",
      "Input: 0.115 MB, Params: 851,831 (3.249 MB), Total: 3.36 MB, FLOPs: 82,206,011\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Finished fine tuning.\n",
      "Iteration 1122/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1122\n",
      "\n",
      "Iteration 1123 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 69)]\n",
      "Input: 0.115 MB, Params: 850,170 (3.243 MB), Total: 3.36 MB, FLOPs: 82,176,157\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Finished fine tuning.\n",
      "Iteration 1123/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1123\n",
      "\n",
      "Iteration 1124 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 37)]\n",
      "Input: 0.115 MB, Params: 849,646 (3.241 MB), Total: 3.36 MB, FLOPs: 81,548,557\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Finished fine tuning.\n",
      "Iteration 1124/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1124\n",
      "\n",
      "Iteration 1125 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 73)]\n",
      "Input: 0.115 MB, Params: 847,985 (3.235 MB), Total: 3.35 MB, FLOPs: 81,518,703\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.986%\n",
      "Finished fine tuning.\n",
      "Iteration 1125/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1125\n",
      "\n",
      "Iteration 1126 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 103)]\n",
      "Input: 0.115 MB, Params: 846,324 (3.228 MB), Total: 3.34 MB, FLOPs: 81,488,849\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Finished fine tuning.\n",
      "Iteration 1126/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1126\n",
      "\n",
      "Iteration 1127 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 68)]\n",
      "Input: 0.115 MB, Params: 843,613 (3.218 MB), Total: 3.33 MB, FLOPs: 81,383,081\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Finished fine tuning.\n",
      "Iteration 1127/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1127\n",
      "\n",
      "Iteration 1128 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 69)]\n",
      "Input: 0.115 MB, Params: 840,902 (3.208 MB), Total: 3.32 MB, FLOPs: 81,277,313\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Finished fine tuning.\n",
      "Iteration 1128/1723 finished in 0m17s\n",
      "Total channels prunned so far: 1128\n",
      "\n",
      "Iteration 1129 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(14, 32)]\n",
      "Input: 0.115 MB, Params: 839,919 (3.204 MB), Total: 3.32 MB, FLOPs: 80,642,841\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Finished fine tuning.\n",
      "Iteration 1129/1723 finished in 0m17s\n",
      "Total channels prunned so far: 1129\n",
      "\n",
      "Iteration 1130 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 4)]\n",
      "Input: 0.115 MB, Params: 838,090 (3.197 MB), Total: 3.31 MB, FLOPs: 80,511,225\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Finished fine tuning.\n",
      "Iteration 1130/1723 finished in 0m17s\n",
      "Total channels prunned so far: 1130\n",
      "\n",
      "Iteration 1131 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 1)]\n",
      "Input: 0.115 MB, Params: 836,261 (3.190 MB), Total: 3.31 MB, FLOPs: 80,379,609\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Finished fine tuning.\n",
      "Iteration 1131/1723 finished in 0m17s\n",
      "Total channels prunned so far: 1131\n",
      "\n",
      "Iteration 1132 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 126)]\n",
      "Input: 0.115 MB, Params: 834,600 (3.184 MB), Total: 3.30 MB, FLOPs: 80,349,755\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Finished fine tuning.\n",
      "Iteration 1132/1723 finished in 0m17s\n",
      "Total channels prunned so far: 1132\n",
      "\n",
      "Iteration 1133 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 70)]\n",
      "Input: 0.115 MB, Params: 831,907 (3.173 MB), Total: 3.29 MB, FLOPs: 80,245,283\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Finished fine tuning.\n",
      "Iteration 1133/1723 finished in 0m17s\n",
      "Total channels prunned so far: 1133\n",
      "\n",
      "Iteration 1134 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 18)]\n",
      "Input: 0.115 MB, Params: 828,998 (3.162 MB), Total: 3.28 MB, FLOPs: 80,192,939\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Finished fine tuning.\n",
      "Iteration 1134/1723 finished in 0m17s\n",
      "Total channels prunned so far: 1134\n",
      "\n",
      "Iteration 1135 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 82)]\n",
      "Input: 0.115 MB, Params: 827,178 (3.155 MB), Total: 3.27 MB, FLOPs: 80,061,971\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Finished fine tuning.\n",
      "Iteration 1135/1723 finished in 0m17s\n",
      "Total channels prunned so far: 1135\n",
      "\n",
      "Iteration 1136 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 13)]\n",
      "Input: 0.115 MB, Params: 824,269 (3.144 MB), Total: 3.26 MB, FLOPs: 80,009,627\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Finished fine tuning.\n",
      "Iteration 1136/1723 finished in 0m17s\n",
      "Total channels prunned so far: 1136\n",
      "\n",
      "Iteration 1137 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 57)]\n",
      "Input: 0.115 MB, Params: 822,449 (3.137 MB), Total: 3.25 MB, FLOPs: 79,878,659\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Finished fine tuning.\n",
      "Iteration 1137/1723 finished in 0m17s\n",
      "Total channels prunned so far: 1137\n",
      "\n",
      "Iteration 1138 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 137)]\n",
      "Input: 0.115 MB, Params: 819,792 (3.127 MB), Total: 3.24 MB, FLOPs: 79,775,807\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Finished fine tuning.\n",
      "Iteration 1138/1723 finished in 0m17s\n",
      "Total channels prunned so far: 1138\n",
      "\n",
      "Iteration 1139 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 124)]\n",
      "Input: 0.115 MB, Params: 817,135 (3.117 MB), Total: 3.23 MB, FLOPs: 79,672,955\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Finished fine tuning.\n",
      "Iteration 1139/1723 finished in 0m17s\n",
      "Total channels prunned so far: 1139\n",
      "\n",
      "Iteration 1140 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 137)]\n",
      "Input: 0.115 MB, Params: 815,492 (3.111 MB), Total: 3.23 MB, FLOPs: 79,643,425\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Finished fine tuning.\n",
      "Iteration 1140/1723 finished in 0m17s\n",
      "Total channels prunned so far: 1140\n",
      "\n",
      "Iteration 1141 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 107)]\n",
      "Input: 0.115 MB, Params: 813,690 (3.104 MB), Total: 3.22 MB, FLOPs: 79,513,753\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Finished fine tuning.\n",
      "Iteration 1141/1723 finished in 0m17s\n",
      "Total channels prunned so far: 1141\n",
      "\n",
      "Iteration 1142 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 87)]\n",
      "Input: 0.115 MB, Params: 811,042 (3.094 MB), Total: 3.21 MB, FLOPs: 79,411,549\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Finished fine tuning.\n",
      "Iteration 1142/1723 finished in 0m17s\n",
      "Total channels prunned so far: 1142\n",
      "\n",
      "Iteration 1143 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 74)]\n",
      "Input: 0.115 MB, Params: 808,169 (3.083 MB), Total: 3.20 MB, FLOPs: 79,359,853\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Finished fine tuning.\n",
      "Iteration 1143/1723 finished in 0m17s\n",
      "Total channels prunned so far: 1143\n",
      "\n",
      "Iteration 1144 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 75)]\n",
      "Input: 0.115 MB, Params: 805,296 (3.072 MB), Total: 3.19 MB, FLOPs: 79,308,157\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Finished fine tuning.\n",
      "Iteration 1144/1723 finished in 0m16s\n",
      "Total channels prunned so far: 1144\n",
      "\n",
      "Iteration 1145 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 98)]\n",
      "Input: 0.115 MB, Params: 803,671 (3.066 MB), Total: 3.18 MB, FLOPs: 79,278,951\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Finished fine tuning.\n",
      "Iteration 1145/1723 finished in 0m17s\n",
      "Total channels prunned so far: 1145\n",
      "\n",
      "Iteration 1146 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 83)]\n",
      "Input: 0.115 MB, Params: 800,807 (3.055 MB), Total: 3.17 MB, FLOPs: 79,227,417\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Finished fine tuning.\n",
      "Iteration 1146/1723 finished in 0m16s\n",
      "Total channels prunned so far: 1146\n",
      "\n",
      "Iteration 1147 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 100)]\n",
      "Input: 0.115 MB, Params: 799,191 (3.049 MB), Total: 3.16 MB, FLOPs: 79,198,373\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.986%\n",
      "Finished fine tuning.\n",
      "Iteration 1147/1723 finished in 0m17s\n",
      "Total channels prunned so far: 1147\n",
      "\n",
      "Iteration 1148 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 15)]\n",
      "Input: 0.115 MB, Params: 797,575 (3.043 MB), Total: 3.16 MB, FLOPs: 79,169,329\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.638%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.986%\n",
      "Finished fine tuning.\n",
      "Iteration 1148/1723 finished in 0m18s\n",
      "Total channels prunned so far: 1148\n",
      "\n",
      "Iteration 1149 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 54)]\n",
      "Input: 0.115 MB, Params: 794,954 (3.033 MB), Total: 3.15 MB, FLOPs: 79,067,611\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.638%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Finished fine tuning.\n",
      "Iteration 1149/1723 finished in 0m17s\n",
      "Total channels prunned so far: 1149\n",
      "\n",
      "Iteration 1150 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(14, 30)]\n",
      "Input: 0.115 MB, Params: 793,971 (3.029 MB), Total: 3.14 MB, FLOPs: 78,433,139\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Finished fine tuning.\n",
      "Iteration 1150/1723 finished in 0m17s\n",
      "Total channels prunned so far: 1150\n",
      "\n",
      "Iteration 1151 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 70)]\n",
      "Input: 0.115 MB, Params: 791,350 (3.019 MB), Total: 3.13 MB, FLOPs: 78,331,421\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.638%\n",
      "Finished fine tuning.\n",
      "Iteration 1151/1723 finished in 0m17s\n",
      "Total channels prunned so far: 1151\n",
      "\n",
      "Iteration 1152 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 0)]\n",
      "Input: 0.115 MB, Params: 789,575 (3.012 MB), Total: 3.13 MB, FLOPs: 78,203,693\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.986%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.986%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Finished fine tuning.\n",
      "Iteration 1152/1723 finished in 0m17s\n",
      "Total channels prunned so far: 1152\n",
      "\n",
      "Iteration 1153 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 74)]\n",
      "Input: 0.115 MB, Params: 787,800 (3.005 MB), Total: 3.12 MB, FLOPs: 78,075,965\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Finished fine tuning.\n",
      "Iteration 1153/1723 finished in 0m17s\n",
      "Total channels prunned so far: 1153\n",
      "\n",
      "Iteration 1154 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 164)]\n",
      "Input: 0.115 MB, Params: 784,972 (2.994 MB), Total: 3.11 MB, FLOPs: 78,025,079\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.638%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Finished fine tuning.\n",
      "Iteration 1154/1723 finished in 0m17s\n",
      "Total channels prunned so far: 1154\n",
      "\n",
      "Iteration 1155 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 78)]\n",
      "Input: 0.115 MB, Params: 782,144 (2.984 MB), Total: 3.10 MB, FLOPs: 77,974,193\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Finished fine tuning.\n",
      "Iteration 1155/1723 finished in 0m17s\n",
      "Total channels prunned so far: 1155\n",
      "\n",
      "Iteration 1156 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 9)]\n",
      "Input: 0.115 MB, Params: 780,369 (2.977 MB), Total: 3.09 MB, FLOPs: 77,846,465\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.638%\n",
      "Finished fine tuning.\n",
      "Iteration 1156/1723 finished in 0m17s\n",
      "Total channels prunned so far: 1156\n",
      "\n",
      "Iteration 1157 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 11)]\n",
      "Input: 0.115 MB, Params: 777,793 (2.967 MB), Total: 3.08 MB, FLOPs: 77,747,015\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.986%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Finished fine tuning.\n",
      "Iteration 1157/1723 finished in 0m17s\n",
      "Total channels prunned so far: 1157\n",
      "\n",
      "Iteration 1158 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 0)]\n",
      "Input: 0.115 MB, Params: 776,027 (2.960 MB), Total: 3.08 MB, FLOPs: 77,619,935\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.289%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.986%\n",
      "Finished fine tuning.\n",
      "Iteration 1158/1723 finished in 0m16s\n",
      "Total channels prunned so far: 1158\n",
      "\n",
      "Iteration 1159 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 10)]\n",
      "Input: 0.115 MB, Params: 773,208 (2.950 MB), Total: 3.06 MB, FLOPs: 77,569,211\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.289%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.638%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.986%\n",
      "Finished fine tuning.\n",
      "Iteration 1159/1723 finished in 0m17s\n",
      "Total channels prunned so far: 1159\n",
      "\n",
      "Iteration 1160 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 45)]\n",
      "Input: 0.115 MB, Params: 772,279 (2.946 MB), Total: 3.06 MB, FLOPs: 77,294,523\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.638%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Finished fine tuning.\n",
      "Iteration 1160/1723 finished in 0m17s\n",
      "Total channels prunned so far: 1160\n",
      "\n",
      "Iteration 1161 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 139)]\n",
      "Input: 0.115 MB, Params: 769,460 (2.935 MB), Total: 3.05 MB, FLOPs: 77,243,799\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.986%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.986%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Finished fine tuning.\n",
      "Iteration 1161/1723 finished in 0m17s\n",
      "Total channels prunned so far: 1161\n",
      "\n",
      "Iteration 1162 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 113)]\n",
      "Input: 0.115 MB, Params: 766,911 (2.926 MB), Total: 3.04 MB, FLOPs: 77,145,321\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.986%\n",
      "Finished fine tuning.\n",
      "Iteration 1162/1723 finished in 0m17s\n",
      "Total channels prunned so far: 1162\n",
      "\n",
      "Iteration 1163 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 31)]\n",
      "Input: 0.115 MB, Params: 764,101 (2.915 MB), Total: 3.03 MB, FLOPs: 77,094,759\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.638%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.986%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Finished fine tuning.\n",
      "Iteration 1163/1723 finished in 0m17s\n",
      "Total channels prunned so far: 1163\n",
      "\n",
      "Iteration 1164 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 102)]\n",
      "Input: 0.115 MB, Params: 762,530 (2.909 MB), Total: 3.02 MB, FLOPs: 77,066,525\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Finished fine tuning.\n",
      "Iteration 1164/1723 finished in 0m17s\n",
      "Total channels prunned so far: 1164\n",
      "\n",
      "Iteration 1165 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 25)]\n",
      "Input: 0.115 MB, Params: 762,024 (2.907 MB), Total: 3.02 MB, FLOPs: 76,460,525\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Finished fine tuning.\n",
      "Iteration 1165/1723 finished in 0m17s\n",
      "Total channels prunned so far: 1165\n",
      "\n",
      "Iteration 1166 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(14, 19)]\n",
      "Input: 0.115 MB, Params: 761,059 (2.903 MB), Total: 3.02 MB, FLOPs: 75,839,517\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.638%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Finished fine tuning.\n",
      "Iteration 1166/1723 finished in 0m17s\n",
      "Total channels prunned so far: 1166\n",
      "\n",
      "Iteration 1167 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 105)]\n",
      "Input: 0.115 MB, Params: 759,302 (2.897 MB), Total: 3.01 MB, FLOPs: 75,713,085\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Finished fine tuning.\n",
      "Iteration 1167/1723 finished in 0m17s\n",
      "Total channels prunned so far: 1167\n",
      "\n",
      "Iteration 1168 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 43)]\n",
      "Input: 0.115 MB, Params: 758,382 (2.893 MB), Total: 3.01 MB, FLOPs: 75,441,061\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Finished fine tuning.\n",
      "Iteration 1168/1723 finished in 0m17s\n",
      "Total channels prunned so far: 1168\n",
      "\n",
      "Iteration 1169 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 38)]\n",
      "Input: 0.115 MB, Params: 756,811 (2.887 MB), Total: 3.00 MB, FLOPs: 75,412,827\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Finished fine tuning.\n",
      "Iteration 1169/1723 finished in 0m17s\n",
      "Total channels prunned so far: 1169\n",
      "\n",
      "Iteration 1170 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 170)]\n",
      "Input: 0.115 MB, Params: 755,240 (2.881 MB), Total: 3.00 MB, FLOPs: 75,384,593\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.986%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Finished fine tuning.\n",
      "Iteration 1170/1723 finished in 0m17s\n",
      "Total channels prunned so far: 1170\n",
      "\n",
      "Iteration 1171 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 76)]\n",
      "Input: 0.115 MB, Params: 753,669 (2.875 MB), Total: 2.99 MB, FLOPs: 75,356,359\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.638%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Finished fine tuning.\n",
      "Iteration 1171/1723 finished in 0m17s\n",
      "Total channels prunned so far: 1171\n",
      "\n",
      "Iteration 1172 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 124)]\n",
      "Input: 0.115 MB, Params: 752,098 (2.869 MB), Total: 2.98 MB, FLOPs: 75,328,125\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.986%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Finished fine tuning.\n",
      "Iteration 1172/1723 finished in 0m17s\n",
      "Total channels prunned so far: 1172\n",
      "\n",
      "Iteration 1173 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 107)]\n",
      "Input: 0.115 MB, Params: 749,567 (2.859 MB), Total: 2.97 MB, FLOPs: 75,230,457\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Finished fine tuning.\n",
      "Iteration 1173/1723 finished in 0m17s\n",
      "Total channels prunned so far: 1173\n",
      "\n",
      "Iteration 1174 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 45)]\n",
      "Input: 0.115 MB, Params: 748,017 (2.853 MB), Total: 2.97 MB, FLOPs: 74,987,377\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.638%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Finished fine tuning.\n",
      "Iteration 1174/1723 finished in 0m17s\n",
      "Total channels prunned so far: 1174\n",
      "\n",
      "Iteration 1175 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 2)]\n",
      "Input: 0.115 MB, Params: 745,486 (2.844 MB), Total: 2.96 MB, FLOPs: 74,889,709\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Finished fine tuning.\n",
      "Iteration 1175/1723 finished in 0m17s\n",
      "Total channels prunned so far: 1175\n",
      "\n",
      "Iteration 1176 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 110)]\n",
      "Input: 0.115 MB, Params: 743,915 (2.838 MB), Total: 2.95 MB, FLOPs: 74,861,475\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.728%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Finished fine tuning.\n",
      "Iteration 1176/1723 finished in 0m17s\n",
      "Total channels prunned so far: 1176\n",
      "\n",
      "Iteration 1177 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 82)]\n",
      "Input: 0.115 MB, Params: 741,177 (2.827 MB), Total: 2.94 MB, FLOPs: 74,812,209\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.986%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Finished fine tuning.\n",
      "Iteration 1177/1723 finished in 0m17s\n",
      "Total channels prunned so far: 1177\n",
      "\n",
      "Iteration 1178 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 62)]\n",
      "Input: 0.115 MB, Params: 739,447 (2.821 MB), Total: 2.94 MB, FLOPs: 74,687,721\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Finished fine tuning.\n",
      "Iteration 1178/1723 finished in 0m18s\n",
      "Total channels prunned so far: 1178\n",
      "\n",
      "Iteration 1179 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 146)]\n",
      "Input: 0.115 MB, Params: 737,885 (2.815 MB), Total: 2.93 MB, FLOPs: 74,659,649\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.638%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.380%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.986%\n",
      "Finished fine tuning.\n",
      "Iteration 1179/1723 finished in 0m17s\n",
      "Total channels prunned so far: 1179\n",
      "\n",
      "Iteration 1180 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 14)]\n",
      "Input: 0.115 MB, Params: 736,344 (2.809 MB), Total: 2.92 MB, FLOPs: 74,417,217\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.986%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Finished fine tuning.\n",
      "Iteration 1180/1723 finished in 0m17s\n",
      "Total channels prunned so far: 1180\n",
      "\n",
      "Iteration 1181 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 72)]\n",
      "Input: 0.115 MB, Params: 734,623 (2.802 MB), Total: 2.92 MB, FLOPs: 74,293,377\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.986%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Finished fine tuning.\n",
      "Iteration 1181/1723 finished in 0m17s\n",
      "Total channels prunned so far: 1181\n",
      "\n",
      "Iteration 1182 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 52)]\n",
      "Input: 0.115 MB, Params: 733,091 (2.797 MB), Total: 2.91 MB, FLOPs: 74,051,593\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Finished fine tuning.\n",
      "Iteration 1182/1723 finished in 0m17s\n",
      "Total channels prunned so far: 1182\n",
      "\n",
      "Iteration 1183 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 39)]\n",
      "Input: 0.115 MB, Params: 730,362 (2.786 MB), Total: 2.90 MB, FLOPs: 74,002,489\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.031%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Finished fine tuning.\n",
      "Iteration 1183/1723 finished in 0m17s\n",
      "Total channels prunned so far: 1183\n",
      "\n",
      "Iteration 1184 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 58)]\n",
      "Input: 0.115 MB, Params: 727,633 (2.776 MB), Total: 2.89 MB, FLOPs: 73,953,385\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.683%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.334%\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12cbe351-bc11-4e98-89ce-6c0531393ed9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c660e0-e1c1-4f30-be4f-d8d322c93eeb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
