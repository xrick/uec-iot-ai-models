{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28b923ec-5857-4d0b-9909-1e0236ba4583",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys;\n",
    "import os;\n",
    "import torch;\n",
    "import numpy as np;\n",
    "import torch.optim as optim;\n",
    "import torch.nn as nn;\n",
    "from operator import itemgetter;\n",
    "from heapq import nsmallest;\n",
    "import time;\n",
    "import glob;\n",
    "import math;\n",
    "import random;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a88dd74-1ca3-4b31-b50b-84b82739d4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"../../../src/\")\n",
    "sys.path.append(\"../../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f540e4f9-0b63-4f73-bca1-51557fb87033",
   "metadata": {},
   "outputs": [],
   "source": [
    "import common.utils as U;\n",
    "import common.opts as opt;\n",
    "import th.resources.models as models;\n",
    "import th.resources.calculator as calc;\n",
    "# import th.resources.train_generator as train_generator;\n",
    "from th.resources.pruning_tools import filter_pruning, filter_pruner;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7215cbb7-d9ce-4b64-9f81-8abc3fada11c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import common.tlopts as tlopts\n",
    "from SharedLibs.datestring import genDataTimeStr, getDateStr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f74b3364-cd68-464d-9426-3a4f85ad7c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reproducibility\n",
    "seed = 42;\n",
    "random.seed(seed);\n",
    "np.random.seed(seed);\n",
    "torch.manual_seed(seed);\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(seed);\n",
    "torch.backends.cudnn.deterministic = True;\n",
    "torch.backends.cudnn.benchmark = False;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69211f9d-1d78-4eae-8540-2d1b04cd13c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6d34d33d-7683-4dd8-ab36-9b9b9d95be12",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TLGenerator():\n",
    "    #Generates data for Keras\n",
    "    def __init__(self, samples, labels, options):\n",
    "        random.seed(42);\n",
    "        #Initialization\n",
    "        print(f\"length of samples:{len(samples)}\")\n",
    "        self.data = [(samples[i], labels[i]) for i in range (0, len(samples))];\n",
    "        self.opt = options;\n",
    "        self.batch_size = options.batchSize;\n",
    "        self.preprocess_funcs = self.preprocess_setup();\n",
    "        self.mapdict = dict([('52',1),('56',2),('99',3)])\n",
    "\n",
    "    def __len__(self):\n",
    "        #Denotes the number of batches per epoch\n",
    "        return int(np.floor(len(self.data) / self.batch_size));\n",
    "        #return len(self.samples);\n",
    "\n",
    "    def __getitem__(self, batchIndex):\n",
    "        #Generate one batch of data\n",
    "        batchX, batchY = self.generate_batch(batchIndex);\n",
    "        batchX = np.expand_dims(batchX, axis=1);\n",
    "        batchX = np.expand_dims(batchX, axis=3);\n",
    "        return batchX, batchY\n",
    "\n",
    "    def generate_batch(self, batchIndex):\n",
    "        #Generates data containing batch_size samples\n",
    "        sounds = [];\n",
    "        labels = [];\n",
    "        indexes = None;\n",
    "        for i in range(self.batch_size):\n",
    "            # Training phase of BC learning\n",
    "            # Select two training examples\n",
    "            while True:\n",
    "                sound1, label1 = self.data[random.randint(0, len(self.data) - 1)]\n",
    "                sound2, label2 = self.data[random.randint(0, len(self.data) - 1)]\n",
    "                if label1 != label2:\n",
    "                    break\n",
    "            sound1 = self.preprocess(sound1)\n",
    "            sound2 = self.preprocess(sound2)\n",
    "\n",
    "            # Mix two examples\n",
    "            r = np.array(random.random())\n",
    "            sound = U.mix(sound1, sound2, r, self.opt.sr).astype(np.float32)\n",
    "            # print(f\"sound length after U.mix is {len(sound)}\")\n",
    "            eye = np.eye(self.opt.nClasses)\n",
    "            idx1 = self.mapdict[str(label1)]- 1\n",
    "            idx2 = self.mapdict[str(label2)] - 1\n",
    "            label = (eye[idx1] * r + eye[idx2] * (1 - r)).astype(np.float32)\n",
    "            # label = (eye[label1] * r + eye[label2] * (1 - r)).astype(np.float32)\n",
    "\n",
    "            #For stronger augmentation\n",
    "            sound = U.random_gain(6)(sound).astype(np.float32)\n",
    "            # print(f\"sound length after U.random_gain is {len(sound)}\")\n",
    "            sounds.append(sound);\n",
    "            labels.append(label);\n",
    "\n",
    "        sounds = np.asarray(sounds);\n",
    "        labels = np.asarray(labels);\n",
    "        # print(f\"labels in generate_batch is:\\n{labels}\")\n",
    "\n",
    "        return sounds, labels;\n",
    "\n",
    "    def preprocess_setup(self):\n",
    "        funcs = []\n",
    "        if self.opt.strongAugment:\n",
    "            funcs += [U.random_scale(1.25)]\n",
    "\n",
    "        funcs += [U.padding(self.opt.inputLength // 2),\n",
    "                  U.random_crop(self.opt.inputLength),\n",
    "                  U.normalize(32768.0)]\n",
    "        return funcs\n",
    "\n",
    "    def preprocess_setup_withoutt_normalize(self):\n",
    "        funcs = []\n",
    "        if self.opt.strongAugment:\n",
    "            funcs += [U.random_scale(1.25)]\n",
    "\n",
    "        funcs += [U.padding(self.opt.inputLength // 2),\n",
    "                  U.random_crop(self.opt.inputLength)\n",
    "                 ]\n",
    "        return funcs\n",
    "\n",
    "    def preprocess(self, sound):\n",
    "        for f in self.preprocess_funcs:\n",
    "            sound = f(sound)\n",
    "\n",
    "        return sound;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1b648ed6-051a-49d7-ad2a-b051c05e88eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTrainGen(opt=None, split=None):\n",
    "    dataset = np.load(opt.trainSet, allow_pickle=True);\n",
    "    train_sounds = []\n",
    "    train_labels = []\n",
    "    # train_sounds = [dataset['x'][i][0] for i in range(len(dataset['x']))]\n",
    "    # train_labels = [dataset['y'][i][0] for i in range(len(dataset['y']))]\n",
    "    train_sounds = dataset['fold{}'.format(1)].item()['sounds']\n",
    "    train_labels = dataset['fold{}'.format(1)].item()['labels']\n",
    "    # print(train_sounds)\n",
    "\n",
    "    trainGen = TLGenerator(train_sounds, train_labels, opt);\n",
    "    trainGen.preprocess_setup();\n",
    "    return trainGen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f6266cad-9de1-47c0-87dc-c8ade965a7b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getOpts():\n",
    "    parser = argparse.ArgumentParser(description='Transfer Learning for ACDNet');\n",
    "    parser.add_argument('--netType', default='TLACDNet',  required=False);\n",
    "    parser.add_argument('--data', default='./datasets/forOneClassModel_alarm/train_test_npz/',  required=False);\n",
    "    parser.add_argument('--dataset', required=False, default='uec_iot', choices=['10']);\n",
    "    parser.add_argument('--BC', default=True, action='store_true', help='BC learning');\n",
    "    parser.add_argument('--strongAugment', default=True,  action='store_true', help='Add scale and gain augmentation');\n",
    "    #在ipynb中，不能使用parser.parse，要改用parser.parse_known_args()\n",
    "    opt, unknown = parser.parse_known_args()\n",
    "    return opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "086db016-0acf-4029-9634-e79d30842ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Customed_ACDNetV2(nn.Module):\n",
    "    def __init__(self, input_length, n_class, sr, ch_conf=None):\n",
    "        super(Customed_ACDNetV2, self).__init__();\n",
    "        self.input_length = input_length;\n",
    "        self.ch_config = ch_conf;\n",
    "\n",
    "        stride1 = 2;\n",
    "        stride2 = 2;\n",
    "        channels = 8;\n",
    "        k_size = (3, 3);\n",
    "        n_frames = (sr/1000)*10; #No of frames per 10ms\n",
    "\n",
    "        sfeb_pool_size = int(n_frames/(stride1*stride2));\n",
    "        # tfeb_pool_size = (2,2);\n",
    "        if self.ch_config is None:\n",
    "            self.ch_config = [channels, channels*8, channels*4, channels*8, channels*8, channels*16, channels*16, channels*32, channels*32, channels*64, channels*64, n_class];\n",
    "        # avg_pool_kernel_size = (1,4) if self.ch_config[1] < 64 else (2,4);\n",
    "        fcn_no_of_inputs =  n_class #self.ch_config[-1];\n",
    "        ch_confing_10 = 512 #8 * 64\n",
    "        ch_n_class = n_class\n",
    "        conv1, bn1 = self.make_layers(1, self.ch_config[0], (1, 9), (1, stride1));\n",
    "        conv2, bn2 = self.make_layers(self.ch_config[0], self.ch_config[1], (1, 5), (1, stride2));\n",
    "        conv3, bn3 = self.make_layers(1, self.ch_config[2], k_size, padding=1);\n",
    "        conv4, bn4 = self.make_layers(self.ch_config[2], self.ch_config[3], k_size, padding=1);\n",
    "        conv5, bn5 = self.make_layers(self.ch_config[3], self.ch_config[4], k_size, padding=1);\n",
    "        conv6, bn6 = self.make_layers(self.ch_config[4], self.ch_config[5], k_size, padding=1);\n",
    "        conv7, bn7 = self.make_layers(self.ch_config[5], self.ch_config[6], k_size, padding=1);\n",
    "        conv8, bn8 = self.make_layers(self.ch_config[6], self.ch_config[7], k_size, padding=1);\n",
    "        conv9, bn9 = self.make_layers(self.ch_config[7], self.ch_config[8], k_size, padding=1);\n",
    "        conv10, bn10 = self.make_layers(self.ch_config[8], self.ch_config[9], k_size, padding=1);\n",
    "        conv11, bn11 = self.make_layers(self.ch_config[9], self.ch_config[10], k_size, padding=1);\n",
    "        conv12, bn12 = self.make_layers(ch_confing_10, ch_n_class, (1, 1));\n",
    "        fcn = nn.Linear(fcn_no_of_inputs, ch_n_class);\n",
    "        nn.init.kaiming_normal_(fcn.weight, nonlinearity='sigmoid') # kaiming with sigoid is equivalent to lecun_normal in keras\n",
    "\n",
    "        self.sfeb = nn.Sequential(\n",
    "            #Start: Filter bank\n",
    "            conv1, bn1, nn.ReLU(),\\\n",
    "            conv2, bn2, nn.ReLU(),\\\n",
    "            nn.MaxPool2d(kernel_size=(1, sfeb_pool_size))\n",
    "        );\n",
    "\n",
    "        tfeb_modules = [];\n",
    "        self.tfeb_width = int(((self.input_length / sr)*1000)/10); # 10ms frames of audio length in seconds\n",
    "        tfeb_pool_sizes = self.get_tfeb_pool_sizes(self.ch_config[1], self.tfeb_width);\n",
    "        p_index = 0;\n",
    "        for i in [3,4,6,8,10]:\n",
    "            tfeb_modules.extend([eval('conv{}'.format(i)), eval('bn{}'.format(i)), nn.ReLU()]);\n",
    "\n",
    "            if i != 3:\n",
    "                tfeb_modules.extend([eval('conv{}'.format(i+1)), eval('bn{}'.format(i+1)), nn.ReLU()]);\n",
    "\n",
    "            h, w = tfeb_pool_sizes[p_index];\n",
    "            if h>1 or w>1:\n",
    "                tfeb_modules.append(nn.MaxPool2d(kernel_size = (h,w)));\n",
    "            p_index += 1;\n",
    "\n",
    "        tfeb_modules.append(nn.Dropout(0.2));\n",
    "        tfeb_modules.extend([conv12, bn12, nn.ReLU()]);\n",
    "        h, w = tfeb_pool_sizes[-1];\n",
    "        if h>1 or w>1:\n",
    "            tfeb_modules.append(nn.AvgPool2d(kernel_size = (2,4)));\n",
    "        tfeb_modules.extend([nn.Flatten(), fcn]);\n",
    "\n",
    "        self.tfeb = nn.Sequential(*tfeb_modules);\n",
    "\n",
    "        self.output = nn.Sequential(\n",
    "            nn.Softmax(dim=1)\n",
    "        );\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.sfeb(x);\n",
    "        #swapaxes\n",
    "        x = x.permute((0, 2, 1, 3));\n",
    "        x = self.tfeb(x);\n",
    "        y = self.output[0](x);\n",
    "        return y;\n",
    "\n",
    "    def make_layers(self, in_channels, out_channels, kernel_size, stride=(1,1), padding=0, bias=False):\n",
    "        conv = nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, stride=stride, padding=padding, bias=bias);\n",
    "        nn.init.kaiming_normal_(conv.weight, nonlinearity='relu'); # kaiming with relu is equivalent to he_normal in keras\n",
    "        bn = nn.BatchNorm2d(out_channels);\n",
    "        return conv, bn;\n",
    "\n",
    "    def get_tfeb_pool_sizes(self, con2_ch, width):\n",
    "        h = self.get_tfeb_pool_size_component(con2_ch);\n",
    "        w = self.get_tfeb_pool_size_component(width);\n",
    "        # print(w);\n",
    "        pool_size = [];\n",
    "        for  (h1, w1) in zip(h, w):\n",
    "            pool_size.append((h1, w1));\n",
    "        return pool_size;\n",
    "\n",
    "    def get_tfeb_pool_size_component(self, length):\n",
    "        # print(length);\n",
    "        c = [];\n",
    "        index = 1;\n",
    "        while index <= 6:\n",
    "            if length >= 2:\n",
    "                if index == 6:\n",
    "                    c.append(length);\n",
    "                else:\n",
    "                    c.append(2);\n",
    "                    length = length // 2;\n",
    "            else:\n",
    "               c.append(1);\n",
    "\n",
    "            index += 1;\n",
    "\n",
    "        return c;\n",
    "\n",
    "def GetCustomedACDNetModel(input_len=30225, nclass=3, sr=20000, channel_config=None):\n",
    "    net = Customed_ACDNetV2(input_len, nclass, sr, ch_conf=channel_config);\n",
    "    return net;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "56cae6f7-e8e2-438f-a003-f4b111ccae0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PruningTrainer:\n",
    "    def __init__(self, opt):\n",
    "        self.opt = opt;\n",
    "        self.opt.channels_to_prune_per_iteration = 1;\n",
    "        self.opt.finetune_epoch_per_iteration = 2;\n",
    "        self.opt.lr=0.001;\n",
    "        self.opt.schedule = [0.5, 0.8];\n",
    "        self.opt.prune_type = 2 #determine the prunning algo, 1: Magnitude Pruning ;2: tylor-pruning\n",
    "        # torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\"); #in office use \n",
    "        self.opt.device = 'cuda:0'#at home use apple m2\n",
    "        self.pruner = None;\n",
    "        self.iterations = 0;\n",
    "        self.cur_acc = 0.0;\n",
    "        self.cur_iter = 1;\n",
    "        self.cur_lr = self.opt.lr;\n",
    "        self.net = None;\n",
    "        self.criterion = torch.nn.KLDivLoss(reduction='batchmean');\n",
    "        self.trainGen = getTrainGen(opt)#train_generator.setup(self.opt, self.opt.split);\n",
    "        self.testX = None;\n",
    "        self.testY = None;\n",
    "        self.load_test_data();\n",
    "\n",
    "    def PruneAndTrain(self):\n",
    "        dir = os.getcwd();\n",
    "        self.net = GetCustomedACDNetModel();\n",
    "        trained_model = \"../../../trained_models/step_2_first_stage_pruning/pruning_time_2024050309_prunratio80.0/sp_ai_model_first_stage_prun_haacc_95.33898162841797_valacc94.06779479980469_tracc89.3465909090909_epoch_355_20240503113438.pt\"\n",
    "        self.net.load_state_dict(torch.load(trained_model, map_location=\"cuda:0\")['weight']);\n",
    "        self.net = self.net.to('cuda:0');#at home use apple m2\n",
    "        self.pruner = filter_pruning.Magnitude(self.net, self.opt) if self.opt.prune_type == 1 else filter_pruning.Taylor(self.net, self.opt);\n",
    "        print(f\"pruning algorithm is {self.pruner}\");\n",
    "        self.validate();\n",
    "        calc.summary(self.net, (1, 1, self.opt.inputLength), brief=False); # shape of one sample for inferenceing\n",
    "        # exit();\n",
    "        #Make sure all the layers are trainable\n",
    "        for param in self.net.parameters():\n",
    "            param.requires_grad = True\n",
    "        self.iterations = self.estimate_pruning_iterations();\n",
    "        # exit();\n",
    "        for i in range(1, self.iterations):\n",
    "            self.cur_iter = i;\n",
    "            iter_start = time.time();\n",
    "            print(\"\\nIteration {} of {} starts..\".format(i, self.iterations-1), flush=True);\n",
    "            print(\"Ranking channels.. \", flush=True);\n",
    "            prune_targets = self.get_candidates_to_prune(self.opt.channels_to_prune_per_iteration);\n",
    "            # prune_targets = [(40,3)];\n",
    "            print(\"Pruning channels: {}\".format(prune_targets), flush=True);\n",
    "            self.net = filter_pruner.prune_layers(self.net, prune_targets, self.opt.prune_all, self.opt.device);\n",
    "            calc.summary(self.net, (1, 1, self.opt.inputLength), brief=True); # shape of one sample for inferenceing\n",
    "            self.validate();\n",
    "            print(\"Fine tuning {} epochs to recover from prunning iteration.\".format(self.opt.finetune_epoch_per_iteration), flush=True);\n",
    "\n",
    "            if self.cur_iter in list(map(int, np.array(self.iterations)*self.opt.schedule)):\n",
    "                self.cur_lr *= 0.1;\n",
    "            optimizer = optim.SGD(self.net.parameters(), lr=self.cur_lr, momentum=0.9);\n",
    "            self.train(optimizer, epoches = self.opt.finetune_epoch_per_iteration);\n",
    "            print(\"Iteration {}/{} finished in {}\".format(self.cur_iter, self.iterations+1, U.to_hms(time.time()-iter_start)), flush=True);\n",
    "            print(\"Total channels prunned so far: {}\".format(i*self.opt.channels_to_prune_per_iteration), flush=True);\n",
    "            self.__save_model(self.net);\n",
    "\n",
    "        calc.summary(self.net, (1, 1, self.opt.inputLength)); # shape of one sample for inferenceing\n",
    "        self.__save_model(self.net);\n",
    "\n",
    "    def get_candidates_to_prune(self, num_filters_to_prune):\n",
    "        self.pruner.reset();\n",
    "        if self.opt.prune_type == 1:\n",
    "            self.pruner.compute_filter_magnitude();\n",
    "        else:\n",
    "            self.train_epoch(rank_filters = True);\n",
    "            self.pruner.normalize_ranks_per_layer();\n",
    "\n",
    "        return self.pruner.get_prunning_plan(num_filters_to_prune);\n",
    "\n",
    "    def estimate_pruning_iterations(self):\n",
    "        # get total number of variables from all conv2d featuremaps\n",
    "        prunable_count = sum(self.get_channel_list(self.opt.prune_all));\n",
    "        total_count= sum(self.get_channel_list());\n",
    "        #iterations_reqired = int((prunable_count * self.opt.prune_ratio) / self.opt.channels_to_prune_per_iteration);\n",
    "        #prune_ratio works with the total number of channels, not only with the prunable channels. i.e. 80% or total will be pruned from total or from only features\n",
    "        iterations_reqired = int((total_count * self.opt.prune_ratio) / self.opt.channels_to_prune_per_iteration);\n",
    "        print('Total Channels: {}, Prunable: {}, Non-Prunable: {}'.format(total_count, prunable_count, total_count - prunable_count), flush=True);\n",
    "        print('No. of Channels to prune per iteration: {}'.format(self.opt.channels_to_prune_per_iteration), flush=True);\n",
    "        print('Total Channels to prune ({}%): {}'.format(int(self.opt.prune_ratio*100), int(total_count * self.opt.prune_ratio)-1), flush=True);\n",
    "        print('Total iterations required: {}'.format(iterations_reqired-1), flush=True);\n",
    "        return iterations_reqired;\n",
    "\n",
    "    def get_channel_list(self, prune_all=True):\n",
    "        ch_conf = [];\n",
    "        if prune_all:\n",
    "            for name, module in enumerate(self.net.sfeb):\n",
    "                if issubclass(type(module), torch.nn.Conv2d):\n",
    "                    ch_conf.append(module.out_channels);\n",
    "\n",
    "        for name, module in enumerate(self.net.tfeb):\n",
    "            if issubclass(type(module), torch.nn.Conv2d):\n",
    "                ch_conf.append(module.out_channels);\n",
    "\n",
    "        return ch_conf;\n",
    "\n",
    "    def load_test_data(self):\n",
    "        if(self.testX is None):\n",
    "            data = np.load(self.opt.valSet, allow_pickle=True);\n",
    "            dataX = np.moveaxis(data['x'], 3, 1).astype(np.float32);\n",
    "            # self.testX = torch.tensor(dataX).cuda();\n",
    "            # self.testY = torch.tensor(data['y']).cuda();\n",
    "            self.testX = torch.tensor(dataX).to(self.opt.device);\n",
    "            # self.testY = torch.tensor(data['y']).to(self.opt.device);#in office, use cuda(better) or cpu\n",
    "            self.testY = torch.FloatTensor(data['y']).to(self.opt.device);#at home use apple m2\n",
    "\n",
    "    #Calculating average prediction (10 crops) and final accuracy\n",
    "    def compute_accuracy(self, y_pred, y_target):\n",
    "        with torch.no_grad():\n",
    "            #Reshape to shape theme like each sample comtains 10 samples, calculate mean and find the indices that has highest average value for each sample\n",
    "            y_pred = (y_pred.reshape(y_pred.shape[0]//self.opt.nCrops, self.opt.nCrops, y_pred.shape[1])).mean(dim=1).argmax(dim=1);\n",
    "            y_target = (y_target.reshape(y_target.shape[0]//self.opt.nCrops, self.opt.nCrops, y_target.shape[1])).mean(dim=1).argmax(dim=1);\n",
    "            # if self.opt.device == \"mps\":\n",
    "            #     y_target = y_target.cpu() #use apple m2, in office use cuda\n",
    "            acc = (((y_pred==y_target)*1).float().mean()*100).item();\n",
    "            # valLossFunc = torch.nn.KLDivLoss();\n",
    "            loss = self.criterion(y_pred.float().log(), y_target.float()).item();\n",
    "            # loss = 0.0;\n",
    "        return acc, loss;\n",
    "\n",
    "    def train(self, optimizer = None, epoches=10):\n",
    "        for i in range(epoches):\n",
    "            # print(\"Epoch: \", i);\n",
    "            self.train_epoch(optimizer);\n",
    "            self.validate();\n",
    "        print(\"Finished fine tuning.\", flush=True);\n",
    "\n",
    "    def train_batch(self, optimizer, batch, label, rank_filters):\n",
    "        self.net.zero_grad()\n",
    "        if rank_filters:\n",
    "            output = self.pruner.forward(batch);\n",
    "            if self.opt.device == \"mps\":\n",
    "                label = label.cpu() #use apple m2, in office use cuda\n",
    "                output = output.cpu() #use apple m2, in office use cuda\n",
    "            self.criterion(output.log(), label).backward();\n",
    "        else:\n",
    "            self.criterion(self.net(batch), label).backward();\n",
    "            optimizer.step();\n",
    "\n",
    "    def train_epoch(self, optimizer = None, rank_filters = False):\n",
    "        if rank_filters is False and optimizer is None:\n",
    "            print('Please provide optimizer to train_epoch', flush=True);\n",
    "            exit();\n",
    "        n_batches = math.ceil(len(self.trainGen.data)/self.opt.batchSize);\n",
    "        for b_idx in range(n_batches):\n",
    "            x,y = self.trainGen.__getitem__(b_idx)\n",
    "            x = torch.tensor(np.moveaxis(x, 3, 1)).to(self.opt.device);\n",
    "            y = torch.tensor(y).to(self.opt.device);\n",
    "            self.train_batch(optimizer, x, y, rank_filters);\n",
    "\n",
    "    def validate(self):\n",
    "        self.net.eval();\n",
    "        with torch.no_grad():\n",
    "            y_pred = None;\n",
    "            batch_size = (self.opt.batchSize//self.opt.nCrops)*self.opt.nCrops;\n",
    "            for idx in range(math.ceil(len(self.testX)/batch_size)):\n",
    "                x = self.testX[idx*batch_size : (idx+1)*batch_size];\n",
    "                # if self.opt.device == \"mps\":\n",
    "                #     x = torch.tensor(x)\n",
    "                #     x = x.type(torch.FloatTensor) # use apple mp2\n",
    "                scores = self.net(x);\n",
    "                y_pred = scores.data if y_pred is None else torch.cat((y_pred, scores.data));\n",
    "\n",
    "            acc, loss = self.compute_accuracy(y_pred, self.testY);\n",
    "        print('Current Testing Performance - Val: Loss {:.3f}  Acc(top1) {:.3f}%'.format(loss, acc), flush=True);\n",
    "        self.cur_acc = acc;\n",
    "        self.net.train();\n",
    "        return acc, loss;\n",
    "\n",
    "    def __save_model(self, net):\n",
    "        net.ch_config = self.get_channel_list();\n",
    "        dir = os.getcwd();\n",
    "        fname = self.opt.model_name;\n",
    "        if os.path.isfile(fname):\n",
    "            os.remove(fname);\n",
    "        torch.save({'weight':net.state_dict(), 'config':net.ch_config}, fname);\n",
    "        \n",
    "    # def __save_model(self, acc, train_acc, epochIdx, net):\n",
    "    #     if acc > self.bestAcc:\n",
    "    #         self.bestAcc = acc;\n",
    "    #         self.bestAccEpoch = epochIdx +1;\n",
    "    #         __do_save_model(self, acc, train_acc, self.bestAccEpoch, net);\n",
    "    #     else:\n",
    "    #         if acc > 94.0 or train_acc > 85.0: \n",
    "    #             __do_save_model(self, acc, train_acc, epochIdx, net);\n",
    "    #         else:\n",
    "    #             pass\n",
    "\n",
    "    # def __do_save_model(self, acc, tr_acc, bestAccIdx, net):\n",
    "    #     save_model_name = self.opt.model_name.format(self.bestAcc, acc, train_acc, epochIdx, genDataTimeStr());\n",
    "    #     save_model_fullpath = self.opt.save_dir + save_model_name;\n",
    "    #     print(f\"save model to {save_model_fullpath}\")\n",
    "    #     torch.save({'weight':net.state_dict(), 'config':net.ch_config}, save_model_fullpath);\n",
    "    #     logObj.write(f\"save model:{model_name}, bestAcc:{self.bestAcc}@{self.}, currentAcc:{acc}@{epochIdx}\");\n",
    "    #     logObj.write(\"\\n\");\n",
    "    #     logObj.flush();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d935fefb-1073-4894-aae9-9317b88dfd83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"save and record the training hyperparameters and results\\npruning algo: tylor-pruning\\npruning ration : 0.85\\nfinal accuracy : \\nepoch: \\nself.opt.LR = 0.01;\\nopt.momentum = 0.009;\\nself.opt.schedule = [0.15, 0.30, 0.45, 0.60, 0.75];\\nself.opt.warmup = 0;\\nself.opt.prune_algo = 'tylor-pruning';\\nself.opt.prune_interval = 1;\\nself.opt.nEpochs = 1000;\\n\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"save and record the training hyperparameters and results\n",
    "pruning algo: tylor-pruning\n",
    "pruning ration : 0.85\n",
    "final accuracy : \n",
    "epoch: \n",
    "self.opt.LR = 0.01;\n",
    "opt.momentum = 0.009;\n",
    "self.opt.schedule = [0.15, 0.30, 0.45, 0.60, 0.75];\n",
    "self.opt.warmup = 0;\n",
    "self.opt.prune_algo = 'tylor-pruning';\n",
    "self.opt.prune_interval = 1;\n",
    "self.opt.nEpochs = 1000;\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3888935-7f32-4d8e-bdc3-48761aa4e13c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b05ced26-21b7-4292-b531-276490ea99e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    opt = getOpts()\n",
    "    #Learning settings\n",
    "    opt.batchSize = 32;\n",
    "    # opt.LR = 0.01;\n",
    "    # opt.momentum = 0.09;\n",
    "    # opt.weightDecay = 5e-3;\n",
    "    # opt.nEpochs = 1000;#2000;\n",
    "    # opt.schedule = [0.03, 0.06, 0.09]\n",
    "    # opt.warmup = 10;\n",
    "    #set train and validation sets\n",
    "    opt.trainSet = \"../../../datasets/CurrentUse/generated_datasets/train/version4/single_fold_train_20240502114607.npz\"\n",
    "    opt.valSet = \"../../../datasets/CurrentUse/generated_datasets/val/version4/final_single_val_20240502120516.npz\"\n",
    "    #Basic Net Settings\n",
    "    opt.prune_ratio = 0.85\n",
    "    opt.prune_all = True;\n",
    "    opt.nClasses = 3\n",
    "    opt.nFolds = 1;\n",
    "    opt.split = [i for i in range(1, opt.nFolds + 1)];\n",
    "    opt.inputLength = 30225;\n",
    "    #Test data\n",
    "    opt.nCrops = 2;\n",
    "    opt.sr = 20000;\n",
    "    opt.inputLength = 30225;\n",
    "    opt.trainer = None\n",
    "    \n",
    "    # import torch;\n",
    "    # opt.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\"); #in office use cuda or cpu\n",
    "    opt.device = 'cuda:0' #at home use apple m2\n",
    "    # tlopts.display_info(opt)\n",
    "    save_dir = \"../../../trained_models/step_4_second_stage_pruning/valacc_95.34_tracc90_pruning_time_{}_prunratio{}/\".format(getDateStr(),opt.prune_ratio*100)\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.mkdir(save_dir)\n",
    "    model_name = \"model_second_stage_prun_ratio0.85_{}.pt\".format(genDataTimeStr());\n",
    "    opt.model_name = save_dir + model_name;\n",
    "    # valid_path = False;\n",
    "    print(\"Initializing PruneAndTrain Object.....\")\n",
    "    trainer = PruningTrainer(opt=opt)#TLTrainer(opt)\n",
    "    print(\"Start to pruning.....\")\n",
    "    trainer.PruneAndTrain();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f7c17937-4b7a-49f2-bb4c-cf323d891beb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing PruneAndTrain Object.....\n",
      "length of samples:651\n",
      "Start to pruning.....\n",
      "pruning algorithm is <th.resources.pruning_tools.filter_pruning.Taylor object at 0x7f7d24c1f430>\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.339%\n",
      "+----------------------------------------------------------------------------+\n",
      "+                           Pytorch Model Summary                            +\n",
      "------------------------------------------------------------------------------\n",
      "   Layer (type)       Input Shape      Output Shape    Param #      FLOPS #\n",
      "==============================================================================\n",
      "       Conv2d-1     (1, 1, 30225)     (8, 1, 15109)         72    1,087,848\n",
      "  BatchNorm2d-2     (8, 1, 15109)     (8, 1, 15109)         16            0\n",
      "         ReLu-3     (8, 1, 15109)     (8, 1, 15109)          0      120,872\n",
      "       Conv2d-4     (8, 1, 15109)     (64, 1, 7553)      2,560   19,335,680\n",
      "  BatchNorm2d-5     (64, 1, 7553)     (64, 1, 7553)        128            0\n",
      "         ReLu-6     (64, 1, 7553)     (64, 1, 7553)          0      483,392\n",
      "    MaxPool2d-7     (64, 1, 7553)      (64, 1, 151)          0      483,200\n",
      "      Permute-8      (64, 1, 151)      (1, 64, 151)          0            0\n",
      "       Conv2d-9      (1, 64, 151)     (32, 64, 151)        288    2,783,232\n",
      " BatchNorm2d-10     (32, 64, 151)     (32, 64, 151)         64            0\n",
      "        ReLu-11     (32, 64, 151)     (32, 64, 151)          0      309,248\n",
      "   MaxPool2d-12     (32, 64, 151)      (32, 32, 75)          0      307,200\n",
      "      Conv2d-13      (32, 32, 75)      (64, 32, 75)     18,432   44,236,800\n",
      " BatchNorm2d-14      (64, 32, 75)      (64, 32, 75)        128            0\n",
      "        ReLu-15      (64, 32, 75)      (64, 32, 75)          0      153,600\n",
      "      Conv2d-16      (64, 32, 75)      (64, 32, 75)     36,864   88,473,600\n",
      " BatchNorm2d-17      (64, 32, 75)      (64, 32, 75)        128            0\n",
      "        ReLu-18      (64, 32, 75)      (64, 32, 75)          0      153,600\n",
      "   MaxPool2d-19      (64, 32, 75)      (64, 16, 37)          0      151,552\n",
      "      Conv2d-20      (64, 16, 37)     (128, 16, 37)     73,728   43,646,976\n",
      " BatchNorm2d-21     (128, 16, 37)     (128, 16, 37)        256            0\n",
      "        ReLu-22     (128, 16, 37)     (128, 16, 37)          0       75,776\n",
      "      Conv2d-23     (128, 16, 37)     (128, 16, 37)    147,456   87,293,952\n",
      " BatchNorm2d-24     (128, 16, 37)     (128, 16, 37)        256            0\n",
      "        ReLu-25     (128, 16, 37)     (128, 16, 37)          0       75,776\n",
      "   MaxPool2d-26     (128, 16, 37)      (128, 8, 18)          0       73,728\n",
      "      Conv2d-27      (128, 8, 18)      (256, 8, 18)    294,912   42,467,328\n",
      " BatchNorm2d-28      (256, 8, 18)      (256, 8, 18)        512            0\n",
      "        ReLu-29      (256, 8, 18)      (256, 8, 18)          0       36,864\n",
      "      Conv2d-30      (256, 8, 18)      (256, 8, 18)    589,824   84,934,656\n",
      " BatchNorm2d-31      (256, 8, 18)      (256, 8, 18)        512            0\n",
      "        ReLu-32      (256, 8, 18)      (256, 8, 18)          0       36,864\n",
      "   MaxPool2d-33      (256, 8, 18)       (256, 4, 9)          0       36,864\n",
      "      Conv2d-34       (256, 4, 9)       (512, 4, 9)  1,179,648   42,467,328\n",
      " BatchNorm2d-35       (512, 4, 9)       (512, 4, 9)      1,024            0\n",
      "        ReLu-36       (512, 4, 9)       (512, 4, 9)          0       18,432\n",
      "      Conv2d-37       (512, 4, 9)       (512, 4, 9)  2,359,296   84,934,656\n",
      " BatchNorm2d-38       (512, 4, 9)       (512, 4, 9)      1,024            0\n",
      "        ReLu-39       (512, 4, 9)       (512, 4, 9)          0       18,432\n",
      "   MaxPool2d-40       (512, 4, 9)       (512, 2, 4)          0       16,384\n",
      "      Conv2d-41       (512, 2, 4)         (3, 2, 4)      1,536       12,288\n",
      " BatchNorm2d-42         (3, 2, 4)         (3, 2, 4)          6            0\n",
      "        ReLu-43         (3, 2, 4)         (3, 2, 4)          0           24\n",
      "   AvgPool2d-44         (3, 2, 4)         (3, 1, 1)          0           24\n",
      "     Flatten-45         (3, 1, 1)            (1, 3)          0            0\n",
      "      Linear-46            (1, 3)            (1, 3)         12           12\n",
      "     Softmax-47            (1, 3)            (1, 3)          0            3\n",
      "==============================================================================\n",
      "Total Params: 4,708,682\n",
      "Total FLOPs : 544,226,191\n",
      "------------------------------------------------------------------------------\n",
      "Input size (MB) : 0.12\n",
      "Params size (MB): 17.96\n",
      "Total size (MB) : 18.08\n",
      "------------------------------------------------------------------------------\n",
      "\n",
      "Total Channels: 2027, Prunable: 2027, Non-Prunable: 0\n",
      "No. of Channels to prune per iteration: 1\n",
      "Total Channels to prune (85%): 1721\n",
      "Total iterations required: 1721\n",
      "\n",
      "Iteration 1 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(3, 6)]\n",
      "Input: 0.115 MB, Params: 4,708,640 (17.962 MB), Total: 18.08 MB, FLOPs: 483,664,528\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ai/miniconda3/envs/acdnetenv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Finished fine tuning.\n",
      "Iteration 1/1723 finished in 0m16s\n",
      "Total channels prunned so far: 1\n",
      "\n",
      "Iteration 2 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(3, 8)]\n",
      "Input: 0.115 MB, Params: 4,708,598 (17.962 MB), Total: 18.08 MB, FLOPs: 483,298,985\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.441%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Finished fine tuning.\n",
      "Iteration 2/1723 finished in 0m15s\n",
      "Total channels prunned so far: 2\n",
      "\n",
      "Iteration 3 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(3, 13)]\n",
      "Input: 0.115 MB, Params: 4,708,556 (17.962 MB), Total: 18.08 MB, FLOPs: 478,767,042\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Finished fine tuning.\n",
      "Iteration 3/1723 finished in 0m15s\n",
      "Total channels prunned so far: 3\n",
      "\n",
      "Iteration 4 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(3, 16)]\n",
      "Input: 0.115 MB, Params: 4,708,514 (17.962 MB), Total: 18.08 MB, FLOPs: 478,401,499\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Finished fine tuning.\n",
      "Iteration 4/1723 finished in 0m15s\n",
      "Total channels prunned so far: 4\n",
      "\n",
      "Iteration 5 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(3, 16)]\n",
      "Input: 0.115 MB, Params: 4,708,472 (17.961 MB), Total: 18.08 MB, FLOPs: 465,666,804\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Finished fine tuning.\n",
      "Iteration 5/1723 finished in 0m15s\n",
      "Total channels prunned so far: 5\n",
      "\n",
      "Iteration 6 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(3, 21)]\n",
      "Input: 0.115 MB, Params: 4,708,430 (17.961 MB), Total: 18.08 MB, FLOPs: 465,301,261\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Finished fine tuning.\n",
      "Iteration 6/1723 finished in 0m16s\n",
      "Total channels prunned so far: 6\n",
      "\n",
      "Iteration 7 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(3, 28)]\n",
      "Input: 0.115 MB, Params: 4,708,388 (17.961 MB), Total: 18.08 MB, FLOPs: 460,769,318\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Finished fine tuning.\n",
      "Iteration 7/1723 finished in 0m15s\n",
      "Total channels prunned so far: 7\n",
      "\n",
      "Iteration 8 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(3, 28)]\n",
      "Input: 0.115 MB, Params: 4,708,346 (17.961 MB), Total: 18.08 MB, FLOPs: 460,403,775\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.254%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Finished fine tuning.\n",
      "Iteration 8/1723 finished in 0m15s\n",
      "Total channels prunned so far: 8\n",
      "\n",
      "Iteration 9 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(3, 29)]\n",
      "Input: 0.115 MB, Params: 4,708,304 (17.961 MB), Total: 18.08 MB, FLOPs: 431,725,400\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Finished fine tuning.\n",
      "Iteration 9/1723 finished in 0m15s\n",
      "Total channels prunned so far: 9\n",
      "\n",
      "Iteration 10 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(3, 40)]\n",
      "Input: 0.115 MB, Params: 4,708,262 (17.961 MB), Total: 18.08 MB, FLOPs: 431,359,857\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Finished fine tuning.\n",
      "Iteration 10/1723 finished in 0m15s\n",
      "Total channels prunned so far: 10\n",
      "\n",
      "Iteration 11 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(3, 46)]\n",
      "Input: 0.115 MB, Params: 4,708,220 (17.960 MB), Total: 18.08 MB, FLOPs: 426,827,914\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Finished fine tuning.\n",
      "Iteration 11/1723 finished in 0m15s\n",
      "Total channels prunned so far: 11\n",
      "\n",
      "Iteration 12 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(7, 26)]\n",
      "Input: 0.115 MB, Params: 4,707,633 (17.958 MB), Total: 18.07 MB, FLOPs: 425,616,884\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Finished fine tuning.\n",
      "Iteration 12/1723 finished in 0m15s\n",
      "Total channels prunned so far: 12\n",
      "\n",
      "Iteration 13 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 95)]\n",
      "Input: 0.115 MB, Params: 4,704,175 (17.945 MB), Total: 18.06 MB, FLOPs: 424,813,027\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Finished fine tuning.\n",
      "Iteration 13/1723 finished in 0m15s\n",
      "Total channels prunned so far: 13\n",
      "\n",
      "Iteration 14 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 34)]\n",
      "Input: 0.115 MB, Params: 4,697,261 (17.919 MB), Total: 18.03 MB, FLOPs: 424,439,563\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Finished fine tuning.\n",
      "Iteration 14/1723 finished in 0m15s\n",
      "Total channels prunned so far: 14\n",
      "\n",
      "Iteration 15 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 361)]\n",
      "Input: 0.115 MB, Params: 4,690,356 (17.892 MB), Total: 18.01 MB, FLOPs: 424,253,155\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Finished fine tuning.\n",
      "Iteration 15/1723 finished in 0m15s\n",
      "Total channels prunned so far: 15\n",
      "\n",
      "Iteration 16 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 41)]\n",
      "Input: 0.115 MB, Params: 4,685,752 (17.875 MB), Total: 17.99 MB, FLOPs: 424,128,927\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Finished fine tuning.\n",
      "Iteration 16/1723 finished in 0m15s\n",
      "Total channels prunned so far: 16\n",
      "\n",
      "Iteration 17 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 81)]\n",
      "Input: 0.115 MB, Params: 4,681,148 (17.857 MB), Total: 17.97 MB, FLOPs: 424,004,699\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Finished fine tuning.\n",
      "Iteration 17/1723 finished in 0m15s\n",
      "Total channels prunned so far: 17\n",
      "\n",
      "Iteration 18 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 116)]\n",
      "Input: 0.115 MB, Params: 4,676,544 (17.840 MB), Total: 17.95 MB, FLOPs: 423,880,471\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.254%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Finished fine tuning.\n",
      "Iteration 18/1723 finished in 0m15s\n",
      "Total channels prunned so far: 18\n",
      "\n",
      "Iteration 19 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 143)]\n",
      "Input: 0.115 MB, Params: 4,671,940 (17.822 MB), Total: 17.94 MB, FLOPs: 423,756,243\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Finished fine tuning.\n",
      "Iteration 19/1723 finished in 0m15s\n",
      "Total channels prunned so far: 19\n",
      "\n",
      "Iteration 20 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 345)]\n",
      "Input: 0.115 MB, Params: 4,667,336 (17.804 MB), Total: 17.92 MB, FLOPs: 423,632,015\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Finished fine tuning.\n",
      "Iteration 20/1723 finished in 0m15s\n",
      "Total channels prunned so far: 20\n",
      "\n",
      "Iteration 21 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 343)]\n",
      "Input: 0.115 MB, Params: 4,662,732 (17.787 MB), Total: 17.90 MB, FLOPs: 423,507,787\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Finished fine tuning.\n",
      "Iteration 21/1723 finished in 0m15s\n",
      "Total channels prunned so far: 21\n",
      "\n",
      "Iteration 22 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 273)]\n",
      "Input: 0.115 MB, Params: 4,658,128 (17.769 MB), Total: 17.88 MB, FLOPs: 423,383,559\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Finished fine tuning.\n",
      "Iteration 22/1723 finished in 0m15s\n",
      "Total channels prunned so far: 22\n",
      "\n",
      "Iteration 23 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 321)]\n",
      "Input: 0.115 MB, Params: 4,653,524 (17.752 MB), Total: 17.87 MB, FLOPs: 423,259,331\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Finished fine tuning.\n",
      "Iteration 23/1723 finished in 0m15s\n",
      "Total channels prunned so far: 23\n",
      "\n",
      "Iteration 24 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 2)]\n",
      "Input: 0.115 MB, Params: 4,646,691 (17.726 MB), Total: 17.84 MB, FLOPs: 423,074,867\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.254%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Finished fine tuning.\n",
      "Iteration 24/1723 finished in 0m15s\n",
      "Total channels prunned so far: 24\n",
      "\n",
      "Iteration 25 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 423)]\n",
      "Input: 0.115 MB, Params: 4,642,096 (17.708 MB), Total: 17.82 MB, FLOPs: 422,950,882\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Finished fine tuning.\n",
      "Iteration 25/1723 finished in 0m15s\n",
      "Total channels prunned so far: 25\n",
      "\n",
      "Iteration 26 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 415)]\n",
      "Input: 0.115 MB, Params: 4,637,501 (17.691 MB), Total: 17.81 MB, FLOPs: 422,826,897\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Finished fine tuning.\n",
      "Iteration 26/1723 finished in 0m15s\n",
      "Total channels prunned so far: 26\n",
      "\n",
      "Iteration 27 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 468)]\n",
      "Input: 0.115 MB, Params: 4,632,906 (17.673 MB), Total: 17.79 MB, FLOPs: 422,702,912\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Finished fine tuning.\n",
      "Iteration 27/1723 finished in 0m15s\n",
      "Total channels prunned so far: 27\n",
      "\n",
      "Iteration 28 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 470)]\n",
      "Input: 0.115 MB, Params: 4,628,311 (17.656 MB), Total: 17.77 MB, FLOPs: 422,578,927\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Finished fine tuning.\n",
      "Iteration 28/1723 finished in 0m15s\n",
      "Total channels prunned so far: 28\n",
      "\n",
      "Iteration 29 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 496)]\n",
      "Input: 0.115 MB, Params: 4,623,716 (17.638 MB), Total: 17.75 MB, FLOPs: 422,454,942\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Finished fine tuning.\n",
      "Iteration 29/1723 finished in 0m15s\n",
      "Total channels prunned so far: 29\n",
      "\n",
      "Iteration 30 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 0)]\n",
      "Input: 0.115 MB, Params: 4,616,820 (17.612 MB), Total: 17.73 MB, FLOPs: 422,081,964\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Finished fine tuning.\n",
      "Iteration 30/1723 finished in 0m15s\n",
      "Total channels prunned so far: 30\n",
      "\n",
      "Iteration 31 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 119)]\n",
      "Input: 0.115 MB, Params: 4,610,041 (17.586 MB), Total: 17.70 MB, FLOPs: 421,898,958\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Finished fine tuning.\n",
      "Iteration 31/1723 finished in 0m15s\n",
      "Total channels prunned so far: 31\n",
      "\n",
      "Iteration 32 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 142)]\n",
      "Input: 0.115 MB, Params: 4,603,262 (17.560 MB), Total: 17.68 MB, FLOPs: 421,715,952\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Finished fine tuning.\n",
      "Iteration 32/1723 finished in 0m15s\n",
      "Total channels prunned so far: 32\n",
      "\n",
      "Iteration 33 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 292)]\n",
      "Input: 0.115 MB, Params: 4,598,685 (17.543 MB), Total: 17.66 MB, FLOPs: 421,592,453\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Finished fine tuning.\n",
      "Iteration 33/1723 finished in 0m15s\n",
      "Total channels prunned so far: 33\n",
      "\n",
      "Iteration 34 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(14, 50)]\n",
      "Input: 0.115 MB, Params: 4,596,955 (17.536 MB), Total: 17.65 MB, FLOPs: 419,911,267\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Finished fine tuning.\n",
      "Iteration 34/1723 finished in 0m15s\n",
      "Total channels prunned so far: 34\n",
      "\n",
      "Iteration 35 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 41)]\n",
      "Input: 0.115 MB, Params: 4,596,107 (17.533 MB), Total: 17.65 MB, FLOPs: 418,259,617\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Finished fine tuning.\n",
      "Iteration 35/1723 finished in 0m15s\n",
      "Total channels prunned so far: 35\n",
      "\n",
      "Iteration 36 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 393)]\n",
      "Input: 0.115 MB, Params: 4,589,337 (17.507 MB), Total: 17.62 MB, FLOPs: 418,076,854\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Finished fine tuning.\n",
      "Iteration 36/1723 finished in 0m15s\n",
      "Total channels prunned so far: 36\n",
      "\n",
      "Iteration 37 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 363)]\n",
      "Input: 0.115 MB, Params: 4,584,769 (17.490 MB), Total: 17.60 MB, FLOPs: 417,953,598\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Finished fine tuning.\n",
      "Iteration 37/1723 finished in 0m15s\n",
      "Total channels prunned so far: 37\n",
      "\n",
      "Iteration 38 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 183)]\n",
      "Input: 0.115 MB, Params: 4,580,201 (17.472 MB), Total: 17.59 MB, FLOPs: 417,830,342\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Finished fine tuning.\n",
      "Iteration 38/1723 finished in 0m15s\n",
      "Total channels prunned so far: 38\n",
      "\n",
      "Iteration 39 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 68)]\n",
      "Input: 0.115 MB, Params: 4,576,770 (17.459 MB), Total: 17.57 MB, FLOPs: 417,459,902\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Finished fine tuning.\n",
      "Iteration 39/1723 finished in 0m15s\n",
      "Total channels prunned so far: 39\n",
      "\n",
      "Iteration 40 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 196)]\n",
      "Input: 0.115 MB, Params: 4,573,339 (17.446 MB), Total: 17.56 MB, FLOPs: 417,089,462\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Finished fine tuning.\n",
      "Iteration 40/1723 finished in 0m15s\n",
      "Total channels prunned so far: 40\n",
      "\n",
      "Iteration 41 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 467)]\n",
      "Input: 0.115 MB, Params: 4,566,587 (17.420 MB), Total: 17.54 MB, FLOPs: 416,907,185\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Finished fine tuning.\n",
      "Iteration 41/1723 finished in 0m15s\n",
      "Total channels prunned so far: 41\n",
      "\n",
      "Iteration 42 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 93)]\n",
      "Input: 0.115 MB, Params: 4,562,028 (17.403 MB), Total: 17.52 MB, FLOPs: 416,784,172\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Finished fine tuning.\n",
      "Iteration 42/1723 finished in 0m15s\n",
      "Total channels prunned so far: 42\n",
      "\n",
      "Iteration 43 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 19)]\n",
      "Input: 0.115 MB, Params: 4,555,186 (17.377 MB), Total: 17.49 MB, FLOPs: 416,414,110\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Finished fine tuning.\n",
      "Iteration 43/1723 finished in 0m15s\n",
      "Total channels prunned so far: 43\n",
      "\n",
      "Iteration 44 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 118)]\n",
      "Input: 0.115 MB, Params: 4,550,627 (17.359 MB), Total: 17.47 MB, FLOPs: 416,291,097\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Finished fine tuning.\n",
      "Iteration 44/1723 finished in 0m15s\n",
      "Total channels prunned so far: 44\n",
      "\n",
      "Iteration 45 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 456)]\n",
      "Input: 0.115 MB, Params: 4,543,902 (17.334 MB), Total: 17.45 MB, FLOPs: 416,109,549\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Finished fine tuning.\n",
      "Iteration 45/1723 finished in 0m15s\n",
      "Total channels prunned so far: 45\n",
      "\n",
      "Iteration 46 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 402)]\n",
      "Input: 0.115 MB, Params: 4,539,352 (17.316 MB), Total: 17.43 MB, FLOPs: 415,986,779\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Finished fine tuning.\n",
      "Iteration 46/1723 finished in 0m15s\n",
      "Total channels prunned so far: 46\n",
      "\n",
      "Iteration 47 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 71)]\n",
      "Input: 0.115 MB, Params: 4,532,519 (17.290 MB), Total: 17.41 MB, FLOPs: 415,616,960\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Finished fine tuning.\n",
      "Iteration 47/1723 finished in 0m15s\n",
      "Total channels prunned so far: 47\n",
      "\n",
      "Iteration 48 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 223)]\n",
      "Input: 0.115 MB, Params: 4,525,812 (17.265 MB), Total: 17.38 MB, FLOPs: 415,435,898\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.254%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Finished fine tuning.\n",
      "Iteration 48/1723 finished in 0m15s\n",
      "Total channels prunned so far: 48\n",
      "\n",
      "Iteration 49 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 83)]\n",
      "Input: 0.115 MB, Params: 4,519,105 (17.239 MB), Total: 17.35 MB, FLOPs: 415,254,836\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Finished fine tuning.\n",
      "Iteration 49/1723 finished in 0m15s\n",
      "Total channels prunned so far: 49\n",
      "\n",
      "Iteration 50 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 248)]\n",
      "Input: 0.115 MB, Params: 4,514,573 (17.222 MB), Total: 17.34 MB, FLOPs: 415,132,552\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Finished fine tuning.\n",
      "Iteration 50/1723 finished in 0m15s\n",
      "Total channels prunned so far: 50\n",
      "\n",
      "Iteration 51 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 198)]\n",
      "Input: 0.115 MB, Params: 4,507,875 (17.196 MB), Total: 17.31 MB, FLOPs: 414,951,733\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Finished fine tuning.\n",
      "Iteration 51/1723 finished in 0m15s\n",
      "Total channels prunned so far: 51\n",
      "\n",
      "Iteration 52 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 102)]\n",
      "Input: 0.115 MB, Params: 4,503,352 (17.179 MB), Total: 17.29 MB, FLOPs: 414,829,692\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Finished fine tuning.\n",
      "Iteration 52/1723 finished in 0m15s\n",
      "Total channels prunned so far: 52\n",
      "\n",
      "Iteration 53 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 277)]\n",
      "Input: 0.115 MB, Params: 4,498,829 (17.162 MB), Total: 17.28 MB, FLOPs: 414,707,651\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Finished fine tuning.\n",
      "Iteration 53/1723 finished in 0m15s\n",
      "Total channels prunned so far: 53\n",
      "\n",
      "Iteration 54 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 102)]\n",
      "Input: 0.115 MB, Params: 4,492,149 (17.136 MB), Total: 17.25 MB, FLOPs: 414,527,318\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Finished fine tuning.\n",
      "Iteration 54/1723 finished in 0m15s\n",
      "Total channels prunned so far: 54\n",
      "\n",
      "Iteration 55 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 317)]\n",
      "Input: 0.115 MB, Params: 4,487,635 (17.119 MB), Total: 17.23 MB, FLOPs: 414,405,520\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Finished fine tuning.\n",
      "Iteration 55/1723 finished in 0m15s\n",
      "Total channels prunned so far: 55\n",
      "\n",
      "Iteration 56 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 217)]\n",
      "Input: 0.115 MB, Params: 4,480,964 (17.094 MB), Total: 17.21 MB, FLOPs: 414,225,430\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Finished fine tuning.\n",
      "Iteration 56/1723 finished in 0m15s\n",
      "Total channels prunned so far: 56\n",
      "\n",
      "Iteration 57 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 196)]\n",
      "Input: 0.115 MB, Params: 4,477,551 (17.081 MB), Total: 17.20 MB, FLOPs: 413,856,934\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Finished fine tuning.\n",
      "Iteration 57/1723 finished in 0m15s\n",
      "Total channels prunned so far: 57\n",
      "\n",
      "Iteration 58 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 86)]\n",
      "Input: 0.115 MB, Params: 4,474,138 (17.067 MB), Total: 17.18 MB, FLOPs: 413,488,438\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Finished fine tuning.\n",
      "Iteration 58/1723 finished in 0m15s\n",
      "Total channels prunned so far: 58\n",
      "\n",
      "Iteration 59 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 345)]\n",
      "Input: 0.115 MB, Params: 4,469,633 (17.050 MB), Total: 17.17 MB, FLOPs: 413,366,883\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Finished fine tuning.\n",
      "Iteration 59/1723 finished in 0m15s\n",
      "Total channels prunned so far: 59\n",
      "\n",
      "Iteration 60 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 144)]\n",
      "Input: 0.115 MB, Params: 4,465,128 (17.033 MB), Total: 17.15 MB, FLOPs: 413,245,328\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Finished fine tuning.\n",
      "Iteration 60/1723 finished in 0m15s\n",
      "Total channels prunned so far: 60\n",
      "\n",
      "Iteration 61 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 326)]\n",
      "Input: 0.115 MB, Params: 4,458,475 (17.008 MB), Total: 17.12 MB, FLOPs: 413,065,724\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.068%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.492%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Finished fine tuning.\n",
      "Iteration 61/1723 finished in 0m15s\n",
      "Total channels prunned so far: 61\n",
      "\n",
      "Iteration 62 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 160)]\n",
      "Input: 0.115 MB, Params: 4,451,714 (16.982 MB), Total: 17.10 MB, FLOPs: 412,699,307\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Finished fine tuning.\n",
      "Iteration 62/1723 finished in 0m15s\n",
      "Total channels prunned so far: 62\n",
      "\n",
      "Iteration 63 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 452)]\n",
      "Input: 0.115 MB, Params: 4,447,218 (16.965 MB), Total: 17.08 MB, FLOPs: 412,577,995\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Finished fine tuning.\n",
      "Iteration 63/1723 finished in 0m15s\n",
      "Total channels prunned so far: 63\n",
      "\n",
      "Iteration 64 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 167)]\n",
      "Input: 0.115 MB, Params: 4,443,814 (16.952 MB), Total: 17.07 MB, FLOPs: 412,210,471\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Finished fine tuning.\n",
      "Iteration 64/1723 finished in 0m15s\n",
      "Total channels prunned so far: 64\n",
      "\n",
      "Iteration 65 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 6)]\n",
      "Input: 0.115 MB, Params: 4,442,966 (16.949 MB), Total: 17.06 MB, FLOPs: 410,558,821\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Finished fine tuning.\n",
      "Iteration 65/1723 finished in 0m15s\n",
      "Total channels prunned so far: 65\n",
      "\n",
      "Iteration 66 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 401)]\n",
      "Input: 0.115 MB, Params: 4,436,331 (16.923 MB), Total: 17.04 MB, FLOPs: 410,379,703\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Finished fine tuning.\n",
      "Iteration 66/1723 finished in 0m15s\n",
      "Total channels prunned so far: 66\n",
      "\n",
      "Iteration 67 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 180)]\n",
      "Input: 0.115 MB, Params: 4,429,696 (16.898 MB), Total: 17.01 MB, FLOPs: 410,200,585\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Finished fine tuning.\n",
      "Iteration 67/1723 finished in 0m15s\n",
      "Total channels prunned so far: 67\n",
      "\n",
      "Iteration 68 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 65)]\n",
      "Input: 0.115 MB, Params: 4,423,061 (16.873 MB), Total: 16.99 MB, FLOPs: 410,021,467\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Finished fine tuning.\n",
      "Iteration 68/1723 finished in 0m15s\n",
      "Total channels prunned so far: 68\n",
      "\n",
      "Iteration 69 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 41)]\n",
      "Input: 0.115 MB, Params: 4,416,336 (16.847 MB), Total: 16.96 MB, FLOPs: 409,656,751\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Finished fine tuning.\n",
      "Iteration 69/1723 finished in 0m15s\n",
      "Total channels prunned so far: 69\n",
      "\n",
      "Iteration 70 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 328)]\n",
      "Input: 0.115 MB, Params: 4,409,710 (16.822 MB), Total: 16.94 MB, FLOPs: 409,477,876\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Finished fine tuning.\n",
      "Iteration 70/1723 finished in 0m15s\n",
      "Total channels prunned so far: 70\n",
      "\n",
      "Iteration 71 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 353)]\n",
      "Input: 0.115 MB, Params: 4,403,084 (16.796 MB), Total: 16.91 MB, FLOPs: 409,299,001\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Finished fine tuning.\n",
      "Iteration 71/1723 finished in 0m15s\n",
      "Total channels prunned so far: 71\n",
      "\n",
      "Iteration 72 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 63)]\n",
      "Input: 0.115 MB, Params: 4,396,377 (16.771 MB), Total: 16.89 MB, FLOPs: 408,934,771\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Finished fine tuning.\n",
      "Iteration 72/1723 finished in 0m15s\n",
      "Total channels prunned so far: 72\n",
      "\n",
      "Iteration 73 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 265)]\n",
      "Input: 0.115 MB, Params: 4,389,760 (16.746 MB), Total: 16.86 MB, FLOPs: 408,756,139\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Finished fine tuning.\n",
      "Iteration 73/1723 finished in 0m15s\n",
      "Total channels prunned so far: 73\n",
      "\n",
      "Iteration 74 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 310)]\n",
      "Input: 0.115 MB, Params: 4,383,143 (16.720 MB), Total: 16.84 MB, FLOPs: 408,577,507\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Finished fine tuning.\n",
      "Iteration 74/1723 finished in 0m15s\n",
      "Total channels prunned so far: 74\n",
      "\n",
      "Iteration 75 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 177)]\n",
      "Input: 0.115 MB, Params: 4,378,710 (16.703 MB), Total: 16.82 MB, FLOPs: 408,457,896\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Finished fine tuning.\n",
      "Iteration 75/1723 finished in 0m15s\n",
      "Total channels prunned so far: 75\n",
      "\n",
      "Iteration 76 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 465)]\n",
      "Input: 0.115 MB, Params: 4,372,102 (16.678 MB), Total: 16.79 MB, FLOPs: 408,279,507\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Finished fine tuning.\n",
      "Iteration 76/1723 finished in 0m15s\n",
      "Total channels prunned so far: 76\n",
      "\n",
      "Iteration 77 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 234)]\n",
      "Input: 0.115 MB, Params: 4,365,494 (16.653 MB), Total: 16.77 MB, FLOPs: 408,101,118\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Finished fine tuning.\n",
      "Iteration 77/1723 finished in 0m15s\n",
      "Total channels prunned so far: 77\n",
      "\n",
      "Iteration 78 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 107)]\n",
      "Input: 0.115 MB, Params: 4,358,823 (16.628 MB), Total: 16.74 MB, FLOPs: 407,737,860\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Finished fine tuning.\n",
      "Iteration 78/1723 finished in 0m15s\n",
      "Total channels prunned so far: 78\n",
      "\n",
      "Iteration 79 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 365)]\n",
      "Input: 0.115 MB, Params: 4,354,408 (16.611 MB), Total: 16.73 MB, FLOPs: 407,618,735\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Finished fine tuning.\n",
      "Iteration 79/1723 finished in 0m15s\n",
      "Total channels prunned so far: 79\n",
      "\n",
      "Iteration 80 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 279)]\n",
      "Input: 0.115 MB, Params: 4,349,993 (16.594 MB), Total: 16.71 MB, FLOPs: 407,499,610\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Finished fine tuning.\n",
      "Iteration 80/1723 finished in 0m15s\n",
      "Total channels prunned so far: 80\n",
      "\n",
      "Iteration 81 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 182)]\n",
      "Input: 0.115 MB, Params: 4,345,578 (16.577 MB), Total: 16.69 MB, FLOPs: 407,380,485\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Finished fine tuning.\n",
      "Iteration 81/1723 finished in 0m15s\n",
      "Total channels prunned so far: 81\n",
      "\n",
      "Iteration 82 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 342)]\n",
      "Input: 0.115 MB, Params: 4,341,163 (16.560 MB), Total: 16.68 MB, FLOPs: 407,261,360\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Finished fine tuning.\n",
      "Iteration 82/1723 finished in 0m15s\n",
      "Total channels prunned so far: 82\n",
      "\n",
      "Iteration 83 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 125)]\n",
      "Input: 0.115 MB, Params: 4,336,748 (16.543 MB), Total: 16.66 MB, FLOPs: 407,142,235\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Finished fine tuning.\n",
      "Iteration 83/1723 finished in 0m15s\n",
      "Total channels prunned so far: 83\n",
      "\n",
      "Iteration 84 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 296)]\n",
      "Input: 0.115 MB, Params: 4,332,333 (16.527 MB), Total: 16.64 MB, FLOPs: 407,023,110\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Finished fine tuning.\n",
      "Iteration 84/1723 finished in 0m15s\n",
      "Total channels prunned so far: 84\n",
      "\n",
      "Iteration 85 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 283)]\n",
      "Input: 0.115 MB, Params: 4,325,788 (16.502 MB), Total: 16.62 MB, FLOPs: 406,846,422\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Finished fine tuning.\n",
      "Iteration 85/1723 finished in 0m15s\n",
      "Total channels prunned so far: 85\n",
      "\n",
      "Iteration 86 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 207)]\n",
      "Input: 0.115 MB, Params: 4,321,382 (16.485 MB), Total: 16.60 MB, FLOPs: 406,727,540\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Finished fine tuning.\n",
      "Iteration 86/1723 finished in 0m15s\n",
      "Total channels prunned so far: 86\n",
      "\n",
      "Iteration 87 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 458)]\n",
      "Input: 0.115 MB, Params: 4,316,976 (16.468 MB), Total: 16.58 MB, FLOPs: 406,608,658\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Finished fine tuning.\n",
      "Iteration 87/1723 finished in 0m15s\n",
      "Total channels prunned so far: 87\n",
      "\n",
      "Iteration 88 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 64)]\n",
      "Input: 0.115 MB, Params: 4,310,314 (16.443 MB), Total: 16.56 MB, FLOPs: 406,245,643\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Finished fine tuning.\n",
      "Iteration 88/1723 finished in 0m15s\n",
      "Total channels prunned so far: 88\n",
      "\n",
      "Iteration 89 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 163)]\n",
      "Input: 0.115 MB, Params: 4,305,908 (16.426 MB), Total: 16.54 MB, FLOPs: 406,126,761\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Finished fine tuning.\n",
      "Iteration 89/1723 finished in 0m15s\n",
      "Total channels prunned so far: 89\n",
      "\n",
      "Iteration 90 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 152)]\n",
      "Input: 0.115 MB, Params: 4,299,399 (16.401 MB), Total: 16.52 MB, FLOPs: 405,951,045\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Finished fine tuning.\n",
      "Iteration 90/1723 finished in 0m15s\n",
      "Total channels prunned so far: 90\n",
      "\n",
      "Iteration 91 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 471)]\n",
      "Input: 0.115 MB, Params: 4,295,002 (16.384 MB), Total: 16.50 MB, FLOPs: 405,832,406\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Finished fine tuning.\n",
      "Iteration 91/1723 finished in 0m15s\n",
      "Total channels prunned so far: 91\n",
      "\n",
      "Iteration 92 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 26)]\n",
      "Input: 0.115 MB, Params: 4,288,502 (16.359 MB), Total: 16.47 MB, FLOPs: 405,656,933\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Finished fine tuning.\n",
      "Iteration 92/1723 finished in 0m15s\n",
      "Total channels prunned so far: 92\n",
      "\n",
      "Iteration 93 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 37)]\n",
      "Input: 0.115 MB, Params: 4,286,790 (16.353 MB), Total: 16.47 MB, FLOPs: 404,833,942\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Finished fine tuning.\n",
      "Iteration 93/1723 finished in 0m15s\n",
      "Total channels prunned so far: 93\n",
      "\n",
      "Iteration 94 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 198)]\n",
      "Input: 0.115 MB, Params: 4,280,290 (16.328 MB), Total: 16.44 MB, FLOPs: 404,658,469\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Finished fine tuning.\n",
      "Iteration 94/1723 finished in 0m15s\n",
      "Total channels prunned so far: 94\n",
      "\n",
      "Iteration 95 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 15)]\n",
      "Input: 0.115 MB, Params: 4,278,578 (16.321 MB), Total: 16.44 MB, FLOPs: 403,835,478\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Finished fine tuning.\n",
      "Iteration 95/1723 finished in 0m15s\n",
      "Total channels prunned so far: 95\n",
      "\n",
      "Iteration 96 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 2)]\n",
      "Input: 0.115 MB, Params: 4,277,730 (16.318 MB), Total: 16.43 MB, FLOPs: 402,183,828\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Finished fine tuning.\n",
      "Iteration 96/1723 finished in 0m15s\n",
      "Total channels prunned so far: 96\n",
      "\n",
      "Iteration 97 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 80)]\n",
      "Input: 0.115 MB, Params: 4,271,095 (16.293 MB), Total: 16.41 MB, FLOPs: 401,821,542\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Finished fine tuning.\n",
      "Iteration 97/1723 finished in 0m15s\n",
      "Total channels prunned so far: 97\n",
      "\n",
      "Iteration 98 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 102)]\n",
      "Input: 0.115 MB, Params: 4,266,716 (16.276 MB), Total: 16.39 MB, FLOPs: 401,703,389\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Finished fine tuning.\n",
      "Iteration 98/1723 finished in 0m15s\n",
      "Total channels prunned so far: 98\n",
      "\n",
      "Iteration 99 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 57)]\n",
      "Input: 0.115 MB, Params: 4,262,337 (16.260 MB), Total: 16.37 MB, FLOPs: 401,585,236\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Finished fine tuning.\n",
      "Iteration 99/1723 finished in 0m15s\n",
      "Total channels prunned so far: 99\n",
      "\n",
      "Iteration 100 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 222)]\n",
      "Input: 0.115 MB, Params: 4,255,702 (16.234 MB), Total: 16.35 MB, FLOPs: 401,222,950\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Finished fine tuning.\n",
      "Iteration 100/1723 finished in 0m15s\n",
      "Total channels prunned so far: 100\n",
      "\n",
      "Iteration 101 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 51)]\n",
      "Input: 0.115 MB, Params: 4,254,854 (16.231 MB), Total: 16.35 MB, FLOPs: 399,571,300\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Finished fine tuning.\n",
      "Iteration 101/1723 finished in 0m15s\n",
      "Total channels prunned so far: 101\n",
      "\n",
      "Iteration 102 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 456)]\n",
      "Input: 0.115 MB, Params: 4,250,475 (16.214 MB), Total: 16.33 MB, FLOPs: 399,453,147\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Finished fine tuning.\n",
      "Iteration 102/1723 finished in 0m15s\n",
      "Total channels prunned so far: 102\n",
      "\n",
      "Iteration 103 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 127)]\n",
      "Input: 0.115 MB, Params: 4,244,020 (16.190 MB), Total: 16.30 MB, FLOPs: 399,278,889\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Finished fine tuning.\n",
      "Iteration 103/1723 finished in 0m15s\n",
      "Total channels prunned so far: 103\n",
      "\n",
      "Iteration 104 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 262)]\n",
      "Input: 0.115 MB, Params: 4,239,650 (16.173 MB), Total: 16.29 MB, FLOPs: 399,160,979\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.254%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Finished fine tuning.\n",
      "Iteration 104/1723 finished in 0m15s\n",
      "Total channels prunned so far: 104\n",
      "\n",
      "Iteration 105 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 96)]\n",
      "Input: 0.115 MB, Params: 4,237,938 (16.166 MB), Total: 16.28 MB, FLOPs: 398,337,988\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.831%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Finished fine tuning.\n",
      "Iteration 105/1723 finished in 0m15s\n",
      "Total channels prunned so far: 105\n",
      "\n",
      "Iteration 106 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 295)]\n",
      "Input: 0.115 MB, Params: 4,233,568 (16.150 MB), Total: 16.27 MB, FLOPs: 398,220,078\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Finished fine tuning.\n",
      "Iteration 106/1723 finished in 0m15s\n",
      "Total channels prunned so far: 106\n",
      "\n",
      "Iteration 107 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 225)]\n",
      "Input: 0.115 MB, Params: 4,227,131 (16.125 MB), Total: 16.24 MB, FLOPs: 398,046,306\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.254%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Finished fine tuning.\n",
      "Iteration 107/1723 finished in 0m15s\n",
      "Total channels prunned so far: 107\n",
      "\n",
      "Iteration 108 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 7)]\n",
      "Input: 0.115 MB, Params: 4,223,781 (16.112 MB), Total: 16.23 MB, FLOPs: 397,684,614\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Finished fine tuning.\n",
      "Iteration 108/1723 finished in 0m15s\n",
      "Total channels prunned so far: 108\n",
      "\n",
      "Iteration 109 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 80)]\n",
      "Input: 0.115 MB, Params: 4,220,431 (16.100 MB), Total: 16.21 MB, FLOPs: 397,322,922\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Finished fine tuning.\n",
      "Iteration 109/1723 finished in 0m15s\n",
      "Total channels prunned so far: 109\n",
      "\n",
      "Iteration 110 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 194)]\n",
      "Input: 0.115 MB, Params: 4,216,070 (16.083 MB), Total: 16.20 MB, FLOPs: 397,205,255\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.254%\n",
      "Finished fine tuning.\n",
      "Iteration 110/1723 finished in 0m15s\n",
      "Total channels prunned so far: 110\n",
      "\n",
      "Iteration 111 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 206)]\n",
      "Input: 0.115 MB, Params: 4,212,720 (16.070 MB), Total: 16.19 MB, FLOPs: 396,843,563\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Finished fine tuning.\n",
      "Iteration 111/1723 finished in 0m15s\n",
      "Total channels prunned so far: 111\n",
      "\n",
      "Iteration 112 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 169)]\n",
      "Input: 0.115 MB, Params: 4,206,292 (16.046 MB), Total: 16.16 MB, FLOPs: 396,670,034\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Finished fine tuning.\n",
      "Iteration 112/1723 finished in 0m15s\n",
      "Total channels prunned so far: 112\n",
      "\n",
      "Iteration 113 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 403)]\n",
      "Input: 0.115 MB, Params: 4,199,864 (16.021 MB), Total: 16.14 MB, FLOPs: 396,496,505\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Finished fine tuning.\n",
      "Iteration 113/1723 finished in 0m15s\n",
      "Total channels prunned so far: 113\n",
      "\n",
      "Iteration 114 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 402)]\n",
      "Input: 0.115 MB, Params: 4,193,436 (15.997 MB), Total: 16.11 MB, FLOPs: 396,322,976\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Finished fine tuning.\n",
      "Iteration 114/1723 finished in 0m15s\n",
      "Total channels prunned so far: 114\n",
      "\n",
      "Iteration 115 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(14, 18)]\n",
      "Input: 0.115 MB, Params: 4,191,769 (15.990 MB), Total: 16.11 MB, FLOPs: 394,724,977\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Finished fine tuning.\n",
      "Iteration 115/1723 finished in 0m15s\n",
      "Total channels prunned so far: 115\n",
      "\n",
      "Iteration 116 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 33)]\n",
      "Input: 0.115 MB, Params: 4,185,206 (15.965 MB), Total: 16.08 MB, FLOPs: 394,366,822\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Finished fine tuning.\n",
      "Iteration 116/1723 finished in 0m15s\n",
      "Total channels prunned so far: 116\n",
      "\n",
      "Iteration 117 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 252)]\n",
      "Input: 0.115 MB, Params: 4,178,787 (15.941 MB), Total: 16.06 MB, FLOPs: 394,193,536\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Finished fine tuning.\n",
      "Iteration 117/1723 finished in 0m15s\n",
      "Total channels prunned so far: 117\n",
      "\n",
      "Iteration 118 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 27)]\n",
      "Input: 0.115 MB, Params: 4,172,368 (15.916 MB), Total: 16.03 MB, FLOPs: 394,020,250\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Finished fine tuning.\n",
      "Iteration 118/1723 finished in 0m15s\n",
      "Total channels prunned so far: 118\n",
      "\n",
      "Iteration 119 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 208)]\n",
      "Input: 0.115 MB, Params: 4,168,052 (15.900 MB), Total: 16.02 MB, FLOPs: 393,903,798\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Finished fine tuning.\n",
      "Iteration 119/1723 finished in 0m15s\n",
      "Total channels prunned so far: 119\n",
      "\n",
      "Iteration 120 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 206)]\n",
      "Input: 0.115 MB, Params: 4,164,711 (15.887 MB), Total: 16.00 MB, FLOPs: 393,543,078\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Finished fine tuning.\n",
      "Iteration 120/1723 finished in 0m15s\n",
      "Total channels prunned so far: 120\n",
      "\n",
      "Iteration 121 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 398)]\n",
      "Input: 0.115 MB, Params: 4,160,395 (15.871 MB), Total: 15.99 MB, FLOPs: 393,426,626\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Finished fine tuning.\n",
      "Iteration 121/1723 finished in 0m15s\n",
      "Total channels prunned so far: 121\n",
      "\n",
      "Iteration 122 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 324)]\n",
      "Input: 0.115 MB, Params: 4,156,079 (15.854 MB), Total: 15.97 MB, FLOPs: 393,310,174\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Finished fine tuning.\n",
      "Iteration 122/1723 finished in 0m15s\n",
      "Total channels prunned so far: 122\n",
      "\n",
      "Iteration 123 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 418)]\n",
      "Input: 0.115 MB, Params: 4,151,763 (15.838 MB), Total: 15.95 MB, FLOPs: 393,193,722\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Finished fine tuning.\n",
      "Iteration 123/1723 finished in 0m15s\n",
      "Total channels prunned so far: 123\n",
      "\n",
      "Iteration 124 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 416)]\n",
      "Input: 0.115 MB, Params: 4,147,447 (15.821 MB), Total: 15.94 MB, FLOPs: 393,077,270\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Finished fine tuning.\n",
      "Iteration 124/1723 finished in 0m15s\n",
      "Total channels prunned so far: 124\n",
      "\n",
      "Iteration 125 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 297)]\n",
      "Input: 0.115 MB, Params: 4,143,131 (15.805 MB), Total: 15.92 MB, FLOPs: 392,960,818\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Finished fine tuning.\n",
      "Iteration 125/1723 finished in 0m15s\n",
      "Total channels prunned so far: 125\n",
      "\n",
      "Iteration 126 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 363)]\n",
      "Input: 0.115 MB, Params: 4,138,815 (15.788 MB), Total: 15.90 MB, FLOPs: 392,844,366\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Finished fine tuning.\n",
      "Iteration 126/1723 finished in 0m15s\n",
      "Total channels prunned so far: 126\n",
      "\n",
      "Iteration 127 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 68)]\n",
      "Input: 0.115 MB, Params: 4,132,459 (15.764 MB), Total: 15.88 MB, FLOPs: 392,672,781\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.254%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Finished fine tuning.\n",
      "Iteration 127/1723 finished in 0m15s\n",
      "Total channels prunned so far: 127\n",
      "\n",
      "Iteration 128 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 79)]\n",
      "Input: 0.115 MB, Params: 4,126,103 (15.740 MB), Total: 15.86 MB, FLOPs: 392,501,196\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Finished fine tuning.\n",
      "Iteration 128/1723 finished in 0m15s\n",
      "Total channels prunned so far: 128\n",
      "\n",
      "Iteration 129 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 126)]\n",
      "Input: 0.115 MB, Params: 4,121,805 (15.723 MB), Total: 15.84 MB, FLOPs: 392,385,230\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Finished fine tuning.\n",
      "Iteration 129/1723 finished in 0m15s\n",
      "Total channels prunned so far: 129\n",
      "\n",
      "Iteration 130 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 205)]\n",
      "Input: 0.115 MB, Params: 4,115,287 (15.699 MB), Total: 15.81 MB, FLOPs: 392,029,019\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Finished fine tuning.\n",
      "Iteration 130/1723 finished in 0m15s\n",
      "Total channels prunned so far: 130\n",
      "\n",
      "Iteration 131 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 47)]\n",
      "Input: 0.115 MB, Params: 4,110,989 (15.682 MB), Total: 15.80 MB, FLOPs: 391,913,053\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Finished fine tuning.\n",
      "Iteration 131/1723 finished in 0m15s\n",
      "Total channels prunned so far: 131\n",
      "\n",
      "Iteration 132 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 327)]\n",
      "Input: 0.115 MB, Params: 4,106,691 (15.666 MB), Total: 15.78 MB, FLOPs: 391,797,087\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Finished fine tuning.\n",
      "Iteration 132/1723 finished in 0m15s\n",
      "Total channels prunned so far: 132\n",
      "\n",
      "Iteration 133 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 456)]\n",
      "Input: 0.115 MB, Params: 4,100,371 (15.642 MB), Total: 15.76 MB, FLOPs: 391,626,474\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Finished fine tuning.\n",
      "Iteration 133/1723 finished in 0m15s\n",
      "Total channels prunned so far: 133\n",
      "\n",
      "Iteration 134 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 90)]\n",
      "Input: 0.115 MB, Params: 4,094,051 (15.618 MB), Total: 15.73 MB, FLOPs: 391,455,861\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.254%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Finished fine tuning.\n",
      "Iteration 134/1723 finished in 0m15s\n",
      "Total channels prunned so far: 134\n",
      "\n",
      "Iteration 135 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 3)]\n",
      "Input: 0.115 MB, Params: 4,087,551 (15.593 MB), Total: 15.71 MB, FLOPs: 391,100,136\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Finished fine tuning.\n",
      "Iteration 135/1723 finished in 0m15s\n",
      "Total channels prunned so far: 135\n",
      "\n",
      "Iteration 136 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 67)]\n",
      "Input: 0.115 MB, Params: 4,081,240 (15.569 MB), Total: 15.68 MB, FLOPs: 390,929,766\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Finished fine tuning.\n",
      "Iteration 136/1723 finished in 0m15s\n",
      "Total channels prunned so far: 136\n",
      "\n",
      "Iteration 137 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 143)]\n",
      "Input: 0.115 MB, Params: 4,077,917 (15.556 MB), Total: 15.67 MB, FLOPs: 390,570,990\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Finished fine tuning.\n",
      "Iteration 137/1723 finished in 0m15s\n",
      "Total channels prunned so far: 137\n",
      "\n",
      "Iteration 138 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 111)]\n",
      "Input: 0.115 MB, Params: 4,076,214 (15.550 MB), Total: 15.66 MB, FLOPs: 389,752,328\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Finished fine tuning.\n",
      "Iteration 138/1723 finished in 0m15s\n",
      "Total channels prunned so far: 138\n",
      "\n",
      "Iteration 139 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 344)]\n",
      "Input: 0.115 MB, Params: 4,069,903 (15.525 MB), Total: 15.64 MB, FLOPs: 389,581,958\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Finished fine tuning.\n",
      "Iteration 139/1723 finished in 0m15s\n",
      "Total channels prunned so far: 139\n",
      "\n",
      "Iteration 140 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(3, 45)]\n",
      "Input: 0.115 MB, Params: 4,069,861 (15.525 MB), Total: 15.64 MB, FLOPs: 389,217,925\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Finished fine tuning.\n",
      "Iteration 140/1723 finished in 0m15s\n",
      "Total channels prunned so far: 140\n",
      "\n",
      "Iteration 141 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 4)]\n",
      "Input: 0.115 MB, Params: 4,063,388 (15.501 MB), Total: 15.62 MB, FLOPs: 388,863,658\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Finished fine tuning.\n",
      "Iteration 141/1723 finished in 0m15s\n",
      "Total channels prunned so far: 141\n",
      "\n",
      "Iteration 142 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 95)]\n",
      "Input: 0.115 MB, Params: 4,056,915 (15.476 MB), Total: 15.59 MB, FLOPs: 388,509,391\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Finished fine tuning.\n",
      "Iteration 142/1723 finished in 0m15s\n",
      "Total channels prunned so far: 142\n",
      "\n",
      "Iteration 143 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 374)]\n",
      "Input: 0.115 MB, Params: 4,050,622 (15.452 MB), Total: 15.57 MB, FLOPs: 388,339,507\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Finished fine tuning.\n",
      "Iteration 143/1723 finished in 0m15s\n",
      "Total channels prunned so far: 143\n",
      "\n",
      "Iteration 144 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 353)]\n",
      "Input: 0.115 MB, Params: 4,046,369 (15.436 MB), Total: 15.55 MB, FLOPs: 388,224,756\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Finished fine tuning.\n",
      "Iteration 144/1723 finished in 0m15s\n",
      "Total channels prunned so far: 144\n",
      "\n",
      "Iteration 145 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 142)]\n",
      "Input: 0.115 MB, Params: 4,043,064 (15.423 MB), Total: 15.54 MB, FLOPs: 387,867,924\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Finished fine tuning.\n",
      "Iteration 145/1723 finished in 0m15s\n",
      "Total channels prunned so far: 145\n",
      "\n",
      "Iteration 146 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 371)]\n",
      "Input: 0.115 MB, Params: 4,036,780 (15.399 MB), Total: 15.51 MB, FLOPs: 387,698,283\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Finished fine tuning.\n",
      "Iteration 146/1723 finished in 0m15s\n",
      "Total channels prunned so far: 146\n",
      "\n",
      "Iteration 147 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 22)]\n",
      "Input: 0.115 MB, Params: 4,033,475 (15.386 MB), Total: 15.50 MB, FLOPs: 387,341,451\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Finished fine tuning.\n",
      "Iteration 147/1723 finished in 0m15s\n",
      "Total channels prunned so far: 147\n",
      "\n",
      "Iteration 148 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 138)]\n",
      "Input: 0.115 MB, Params: 4,027,191 (15.363 MB), Total: 15.48 MB, FLOPs: 387,171,810\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Finished fine tuning.\n",
      "Iteration 148/1723 finished in 0m15s\n",
      "Total channels prunned so far: 148\n",
      "\n",
      "Iteration 149 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 95)]\n",
      "Input: 0.115 MB, Params: 4,025,488 (15.356 MB), Total: 15.47 MB, FLOPs: 386,353,148\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Finished fine tuning.\n",
      "Iteration 149/1723 finished in 0m15s\n",
      "Total channels prunned so far: 149\n",
      "\n",
      "Iteration 150 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 120)]\n",
      "Input: 0.115 MB, Params: 4,023,785 (15.350 MB), Total: 15.46 MB, FLOPs: 385,534,486\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Finished fine tuning.\n",
      "Iteration 150/1723 finished in 0m15s\n",
      "Total channels prunned so far: 150\n",
      "\n",
      "Iteration 151 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 375)]\n",
      "Input: 0.115 MB, Params: 4,017,501 (15.326 MB), Total: 15.44 MB, FLOPs: 385,364,845\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Finished fine tuning.\n",
      "Iteration 151/1723 finished in 0m15s\n",
      "Total channels prunned so far: 151\n",
      "\n",
      "Iteration 152 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 244)]\n",
      "Input: 0.115 MB, Params: 4,011,217 (15.302 MB), Total: 15.42 MB, FLOPs: 385,195,204\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Finished fine tuning.\n",
      "Iteration 152/1723 finished in 0m15s\n",
      "Total channels prunned so far: 152\n",
      "\n",
      "Iteration 153 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 115)]\n",
      "Input: 0.115 MB, Params: 4,007,000 (15.285 MB), Total: 15.40 MB, FLOPs: 385,081,425\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Finished fine tuning.\n",
      "Iteration 153/1723 finished in 0m15s\n",
      "Total channels prunned so far: 153\n",
      "\n",
      "Iteration 154 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 264)]\n",
      "Input: 0.115 MB, Params: 4,000,725 (15.262 MB), Total: 15.38 MB, FLOPs: 384,912,027\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Finished fine tuning.\n",
      "Iteration 154/1723 finished in 0m15s\n",
      "Total channels prunned so far: 154\n",
      "\n",
      "Iteration 155 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 47)]\n",
      "Input: 0.115 MB, Params: 3,996,517 (15.246 MB), Total: 15.36 MB, FLOPs: 384,798,491\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Finished fine tuning.\n",
      "Iteration 155/1723 finished in 0m15s\n",
      "Total channels prunned so far: 155\n",
      "\n",
      "Iteration 156 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 181)]\n",
      "Input: 0.115 MB, Params: 3,990,251 (15.222 MB), Total: 15.34 MB, FLOPs: 384,629,336\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Finished fine tuning.\n",
      "Iteration 156/1723 finished in 0m15s\n",
      "Total channels prunned so far: 156\n",
      "\n",
      "Iteration 157 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 63)]\n",
      "Input: 0.115 MB, Params: 3,988,548 (15.215 MB), Total: 15.33 MB, FLOPs: 383,810,674\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Finished fine tuning.\n",
      "Iteration 157/1723 finished in 0m15s\n",
      "Total channels prunned so far: 157\n",
      "\n",
      "Iteration 158 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 150)]\n",
      "Input: 0.115 MB, Params: 3,982,282 (15.191 MB), Total: 15.31 MB, FLOPs: 383,641,519\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Finished fine tuning.\n",
      "Iteration 158/1723 finished in 0m15s\n",
      "Total channels prunned so far: 158\n",
      "\n",
      "Iteration 159 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 103)]\n",
      "Input: 0.115 MB, Params: 3,976,016 (15.167 MB), Total: 15.28 MB, FLOPs: 383,472,364\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Finished fine tuning.\n",
      "Iteration 159/1723 finished in 0m15s\n",
      "Total channels prunned so far: 159\n",
      "\n",
      "Iteration 160 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 93)]\n",
      "Input: 0.115 MB, Params: 3,972,711 (15.155 MB), Total: 15.27 MB, FLOPs: 383,115,532\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Finished fine tuning.\n",
      "Iteration 160/1723 finished in 0m15s\n",
      "Total channels prunned so far: 160\n",
      "\n",
      "Iteration 161 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 219)]\n",
      "Input: 0.115 MB, Params: 3,966,346 (15.130 MB), Total: 15.25 MB, FLOPs: 382,766,368\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Finished fine tuning.\n",
      "Iteration 161/1723 finished in 0m15s\n",
      "Total channels prunned so far: 161\n",
      "\n",
      "Iteration 162 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(3, 22)]\n",
      "Input: 0.115 MB, Params: 3,966,304 (15.130 MB), Total: 15.25 MB, FLOPs: 370,983,656\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Finished fine tuning.\n",
      "Iteration 162/1723 finished in 0m15s\n",
      "Total channels prunned so far: 162\n",
      "\n",
      "Iteration 163 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 103)]\n",
      "Input: 0.115 MB, Params: 3,963,008 (15.118 MB), Total: 15.23 MB, FLOPs: 370,627,796\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Finished fine tuning.\n",
      "Iteration 163/1723 finished in 0m15s\n",
      "Total channels prunned so far: 163\n",
      "\n",
      "Iteration 164 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 146)]\n",
      "Input: 0.115 MB, Params: 3,956,751 (15.094 MB), Total: 15.21 MB, FLOPs: 370,458,884\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Finished fine tuning.\n",
      "Iteration 164/1723 finished in 0m15s\n",
      "Total channels prunned so far: 164\n",
      "\n",
      "Iteration 165 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 438)]\n",
      "Input: 0.115 MB, Params: 3,950,494 (15.070 MB), Total: 15.19 MB, FLOPs: 370,289,972\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Finished fine tuning.\n",
      "Iteration 165/1723 finished in 0m15s\n",
      "Total channels prunned so far: 165\n",
      "\n",
      "Iteration 166 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 13)]\n",
      "Input: 0.115 MB, Params: 3,944,237 (15.046 MB), Total: 15.16 MB, FLOPs: 370,121,060\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Finished fine tuning.\n",
      "Iteration 166/1723 finished in 0m15s\n",
      "Total channels prunned so far: 166\n",
      "\n",
      "Iteration 167 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 223)]\n",
      "Input: 0.115 MB, Params: 3,940,083 (15.030 MB), Total: 15.15 MB, FLOPs: 370,008,982\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.492%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Finished fine tuning.\n",
      "Iteration 167/1723 finished in 0m15s\n",
      "Total channels prunned so far: 167\n",
      "\n",
      "Iteration 168 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 153)]\n",
      "Input: 0.115 MB, Params: 3,936,787 (15.018 MB), Total: 15.13 MB, FLOPs: 369,653,122\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Finished fine tuning.\n",
      "Iteration 168/1723 finished in 0m17s\n",
      "Total channels prunned so far: 168\n",
      "\n",
      "Iteration 169 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 126)]\n",
      "Input: 0.115 MB, Params: 3,930,539 (14.994 MB), Total: 15.11 MB, FLOPs: 369,484,453\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Finished fine tuning.\n",
      "Iteration 169/1723 finished in 0m20s\n",
      "Total channels prunned so far: 169\n",
      "\n",
      "Iteration 170 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 361)]\n",
      "Input: 0.115 MB, Params: 3,924,291 (14.970 MB), Total: 15.09 MB, FLOPs: 369,315,784\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Finished fine tuning.\n",
      "Iteration 170/1723 finished in 0m20s\n",
      "Total channels prunned so far: 170\n",
      "\n",
      "Iteration 171 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 451)]\n",
      "Input: 0.115 MB, Params: 3,920,155 (14.954 MB), Total: 15.07 MB, FLOPs: 369,204,192\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Finished fine tuning.\n",
      "Iteration 171/1723 finished in 0m19s\n",
      "Total channels prunned so far: 171\n",
      "\n",
      "Iteration 172 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 207)]\n",
      "Input: 0.115 MB, Params: 3,913,916 (14.930 MB), Total: 15.05 MB, FLOPs: 369,035,766\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Finished fine tuning.\n",
      "Iteration 172/1723 finished in 0m19s\n",
      "Total channels prunned so far: 172\n",
      "\n",
      "Iteration 173 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 254)]\n",
      "Input: 0.115 MB, Params: 3,909,789 (14.915 MB), Total: 15.03 MB, FLOPs: 368,924,417\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Finished fine tuning.\n",
      "Iteration 173/1723 finished in 0m20s\n",
      "Total channels prunned so far: 173\n",
      "\n",
      "Iteration 174 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 49)]\n",
      "Input: 0.115 MB, Params: 3,908,950 (14.911 MB), Total: 15.03 MB, FLOPs: 367,353,167\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Finished fine tuning.\n",
      "Iteration 174/1723 finished in 0m20s\n",
      "Total channels prunned so far: 174\n",
      "\n",
      "Iteration 175 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(14, 26)]\n",
      "Input: 0.115 MB, Params: 3,907,328 (14.905 MB), Total: 15.02 MB, FLOPs: 365,870,375\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Finished fine tuning.\n",
      "Iteration 175/1723 finished in 0m16s\n",
      "Total channels prunned so far: 175\n",
      "\n",
      "Iteration 176 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 64)]\n",
      "Input: 0.115 MB, Params: 3,901,098 (14.882 MB), Total: 15.00 MB, FLOPs: 365,702,192\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.492%\n",
      "Finished fine tuning.\n",
      "Iteration 176/1723 finished in 0m15s\n",
      "Total channels prunned so far: 176\n",
      "\n",
      "Iteration 177 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(14, 14)]\n",
      "Input: 0.115 MB, Params: 3,899,476 (14.875 MB), Total: 14.99 MB, FLOPs: 364,219,400\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Finished fine tuning.\n",
      "Iteration 177/1723 finished in 0m15s\n",
      "Total channels prunned so far: 177\n",
      "\n",
      "Iteration 178 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 303)]\n",
      "Input: 0.115 MB, Params: 3,895,358 (14.860 MB), Total: 14.97 MB, FLOPs: 364,108,294\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Finished fine tuning.\n",
      "Iteration 178/1723 finished in 0m15s\n",
      "Total channels prunned so far: 178\n",
      "\n",
      "Iteration 179 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 72)]\n",
      "Input: 0.115 MB, Params: 3,889,074 (14.836 MB), Total: 14.95 MB, FLOPs: 363,762,775\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.068%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Finished fine tuning.\n",
      "Iteration 179/1723 finished in 0m15s\n",
      "Total channels prunned so far: 179\n",
      "\n",
      "Iteration 180 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 182)]\n",
      "Input: 0.115 MB, Params: 3,882,862 (14.812 MB), Total: 14.93 MB, FLOPs: 363,595,078\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.068%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.068%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Finished fine tuning.\n",
      "Iteration 180/1723 finished in 0m15s\n",
      "Total channels prunned so far: 180\n",
      "\n",
      "Iteration 181 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 199)]\n",
      "Input: 0.115 MB, Params: 3,876,650 (14.788 MB), Total: 14.90 MB, FLOPs: 363,427,381\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Finished fine tuning.\n",
      "Iteration 181/1723 finished in 0m15s\n",
      "Total channels prunned so far: 181\n",
      "\n",
      "Iteration 182 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 1)]\n",
      "Input: 0.115 MB, Params: 3,870,384 (14.764 MB), Total: 14.88 MB, FLOPs: 363,082,348\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Finished fine tuning.\n",
      "Iteration 182/1723 finished in 0m15s\n",
      "Total channels prunned so far: 182\n",
      "\n",
      "Iteration 183 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 420)]\n",
      "Input: 0.115 MB, Params: 3,864,181 (14.741 MB), Total: 14.86 MB, FLOPs: 362,914,894\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Finished fine tuning.\n",
      "Iteration 183/1723 finished in 0m19s\n",
      "Total channels prunned so far: 183\n",
      "\n",
      "Iteration 184 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 241)]\n",
      "Input: 0.115 MB, Params: 3,860,090 (14.725 MB), Total: 14.84 MB, FLOPs: 362,804,517\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Finished fine tuning.\n",
      "Iteration 184/1723 finished in 0m19s\n",
      "Total channels prunned so far: 184\n",
      "\n",
      "Iteration 185 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 119)]\n",
      "Input: 0.115 MB, Params: 3,853,896 (14.701 MB), Total: 14.82 MB, FLOPs: 362,637,306\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Finished fine tuning.\n",
      "Iteration 185/1723 finished in 0m20s\n",
      "Total channels prunned so far: 185\n",
      "\n",
      "Iteration 186 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 29)]\n",
      "Input: 0.115 MB, Params: 3,853,075 (14.698 MB), Total: 14.81 MB, FLOPs: 361,099,806\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Finished fine tuning.\n",
      "Iteration 186/1723 finished in 0m20s\n",
      "Total channels prunned so far: 186\n",
      "\n",
      "Iteration 187 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 193)]\n",
      "Input: 0.115 MB, Params: 3,849,797 (14.686 MB), Total: 14.80 MB, FLOPs: 360,745,890\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.068%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Finished fine tuning.\n",
      "Iteration 187/1723 finished in 0m20s\n",
      "Total channels prunned so far: 187\n",
      "\n",
      "Iteration 188 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 73)]\n",
      "Input: 0.115 MB, Params: 3,845,715 (14.670 MB), Total: 14.79 MB, FLOPs: 360,635,756\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Finished fine tuning.\n",
      "Iteration 188/1723 finished in 0m19s\n",
      "Total channels prunned so far: 188\n",
      "\n",
      "Iteration 189 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 119)]\n",
      "Input: 0.115 MB, Params: 3,841,633 (14.655 MB), Total: 14.77 MB, FLOPs: 360,525,622\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Finished fine tuning.\n",
      "Iteration 189/1723 finished in 0m18s\n",
      "Total channels prunned so far: 189\n",
      "\n",
      "Iteration 190 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 35)]\n",
      "Input: 0.115 MB, Params: 3,835,457 (14.631 MB), Total: 14.75 MB, FLOPs: 360,358,897\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.186%\n",
      "Finished fine tuning.\n",
      "Iteration 190/1723 finished in 0m16s\n",
      "Total channels prunned so far: 190\n",
      "\n",
      "Iteration 191 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 271)]\n",
      "Input: 0.115 MB, Params: 3,831,384 (14.616 MB), Total: 14.73 MB, FLOPs: 360,249,006\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.915%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.068%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Finished fine tuning.\n",
      "Iteration 191/1723 finished in 0m15s\n",
      "Total channels prunned so far: 191\n",
      "\n",
      "Iteration 192 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 286)]\n",
      "Input: 0.115 MB, Params: 3,827,311 (14.600 MB), Total: 14.72 MB, FLOPs: 360,139,115\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Finished fine tuning.\n",
      "Iteration 192/1723 finished in 0m15s\n",
      "Total channels prunned so far: 192\n",
      "\n",
      "Iteration 193 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 70)]\n",
      "Input: 0.115 MB, Params: 3,821,081 (14.576 MB), Total: 14.69 MB, FLOPs: 359,795,783\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Finished fine tuning.\n",
      "Iteration 193/1723 finished in 0m15s\n",
      "Total channels prunned so far: 193\n",
      "\n",
      "Iteration 194 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 60)]\n",
      "Input: 0.115 MB, Params: 3,814,851 (14.553 MB), Total: 14.67 MB, FLOPs: 359,452,451\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Finished fine tuning.\n",
      "Iteration 194/1723 finished in 0m15s\n",
      "Total channels prunned so far: 194\n",
      "\n",
      "Iteration 195 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 80)]\n",
      "Input: 0.115 MB, Params: 3,811,591 (14.540 MB), Total: 14.66 MB, FLOPs: 359,100,479\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Finished fine tuning.\n",
      "Iteration 195/1723 finished in 0m15s\n",
      "Total channels prunned so far: 195\n",
      "\n",
      "Iteration 196 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 5)]\n",
      "Input: 0.115 MB, Params: 3,810,770 (14.537 MB), Total: 14.65 MB, FLOPs: 357,562,979\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Finished fine tuning.\n",
      "Iteration 196/1723 finished in 0m15s\n",
      "Total channels prunned so far: 196\n",
      "\n",
      "Iteration 197 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 39)]\n",
      "Input: 0.115 MB, Params: 3,804,549 (14.513 MB), Total: 14.63 MB, FLOPs: 357,220,619\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.254%\n",
      "Finished fine tuning.\n",
      "Iteration 197/1723 finished in 0m15s\n",
      "Total channels prunned so far: 197\n",
      "\n",
      "Iteration 198 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 386)]\n",
      "Input: 0.115 MB, Params: 3,800,476 (14.498 MB), Total: 14.61 MB, FLOPs: 357,110,728\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Finished fine tuning.\n",
      "Iteration 198/1723 finished in 0m15s\n",
      "Total channels prunned so far: 198\n",
      "\n",
      "Iteration 199 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 423)]\n",
      "Input: 0.115 MB, Params: 3,794,354 (14.474 MB), Total: 14.59 MB, FLOPs: 356,945,461\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.068%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Finished fine tuning.\n",
      "Iteration 199/1723 finished in 0m15s\n",
      "Total channels prunned so far: 199\n",
      "\n",
      "Iteration 200 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 10)]\n",
      "Input: 0.115 MB, Params: 3,788,232 (14.451 MB), Total: 14.57 MB, FLOPs: 356,780,194\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Finished fine tuning.\n",
      "Iteration 200/1723 finished in 0m15s\n",
      "Total channels prunned so far: 200\n",
      "\n",
      "Iteration 201 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 178)]\n",
      "Input: 0.115 MB, Params: 3,784,981 (14.439 MB), Total: 14.55 MB, FLOPs: 356,429,194\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Finished fine tuning.\n",
      "Iteration 201/1723 finished in 0m15s\n",
      "Total channels prunned so far: 201\n",
      "\n",
      "Iteration 202 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 365)]\n",
      "Input: 0.115 MB, Params: 3,780,926 (14.423 MB), Total: 14.54 MB, FLOPs: 356,319,789\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.068%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.068%\n",
      "Finished fine tuning.\n",
      "Iteration 202/1723 finished in 0m15s\n",
      "Total channels prunned so far: 202\n",
      "\n",
      "Iteration 203 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 346)]\n",
      "Input: 0.115 MB, Params: 3,776,871 (14.408 MB), Total: 14.52 MB, FLOPs: 356,210,384\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.068%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.068%\n",
      "Finished fine tuning.\n",
      "Iteration 203/1723 finished in 0m15s\n",
      "Total channels prunned so far: 203\n",
      "\n",
      "Iteration 204 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 70)]\n",
      "Input: 0.115 MB, Params: 3,773,638 (14.395 MB), Total: 14.51 MB, FLOPs: 355,494,656\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.915%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.339%\n",
      "Finished fine tuning.\n",
      "Iteration 204/1723 finished in 0m15s\n",
      "Total channels prunned so far: 204\n",
      "\n",
      "Iteration 205 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 302)]\n",
      "Input: 0.115 MB, Params: 3,769,583 (14.380 MB), Total: 14.50 MB, FLOPs: 355,385,251\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Finished fine tuning.\n",
      "Iteration 205/1723 finished in 0m15s\n",
      "Total channels prunned so far: 205\n",
      "\n",
      "Iteration 206 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 41)]\n",
      "Input: 0.115 MB, Params: 3,763,488 (14.357 MB), Total: 14.47 MB, FLOPs: 355,220,713\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Finished fine tuning.\n",
      "Iteration 206/1723 finished in 0m15s\n",
      "Total channels prunned so far: 206\n",
      "\n",
      "Iteration 207 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 281)]\n",
      "Input: 0.115 MB, Params: 3,759,442 (14.341 MB), Total: 14.46 MB, FLOPs: 355,111,551\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Finished fine tuning.\n",
      "Iteration 207/1723 finished in 0m15s\n",
      "Total channels prunned so far: 207\n",
      "\n",
      "Iteration 208 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 13)]\n",
      "Input: 0.115 MB, Params: 3,753,356 (14.318 MB), Total: 14.43 MB, FLOPs: 354,947,256\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Finished fine tuning.\n",
      "Iteration 208/1723 finished in 0m15s\n",
      "Total channels prunned so far: 208\n",
      "\n",
      "Iteration 209 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 435)]\n",
      "Input: 0.115 MB, Params: 3,749,319 (14.303 MB), Total: 14.42 MB, FLOPs: 354,838,337\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Finished fine tuning.\n",
      "Iteration 209/1723 finished in 0m15s\n",
      "Total channels prunned so far: 209\n",
      "\n",
      "Iteration 210 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 257)]\n",
      "Input: 0.115 MB, Params: 3,745,282 (14.287 MB), Total: 14.40 MB, FLOPs: 354,729,418\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.068%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Finished fine tuning.\n",
      "Iteration 210/1723 finished in 0m15s\n",
      "Total channels prunned so far: 210\n",
      "\n",
      "Iteration 211 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 184)]\n",
      "Input: 0.115 MB, Params: 3,741,245 (14.272 MB), Total: 14.39 MB, FLOPs: 354,620,499\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Finished fine tuning.\n",
      "Iteration 211/1723 finished in 0m15s\n",
      "Total channels prunned so far: 211\n",
      "\n",
      "Iteration 212 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 13)]\n",
      "Input: 0.115 MB, Params: 3,735,069 (14.248 MB), Total: 14.36 MB, FLOPs: 354,280,083\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Finished fine tuning.\n",
      "Iteration 212/1723 finished in 0m15s\n",
      "Total channels prunned so far: 212\n",
      "\n",
      "Iteration 213 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 315)]\n",
      "Input: 0.115 MB, Params: 3,731,032 (14.233 MB), Total: 14.35 MB, FLOPs: 354,171,164\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Finished fine tuning.\n",
      "Iteration 213/1723 finished in 0m15s\n",
      "Total channels prunned so far: 213\n",
      "\n",
      "Iteration 214 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 148)]\n",
      "Input: 0.115 MB, Params: 3,724,856 (14.209 MB), Total: 14.32 MB, FLOPs: 353,830,748\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Finished fine tuning.\n",
      "Iteration 214/1723 finished in 0m15s\n",
      "Total channels prunned so far: 214\n",
      "\n",
      "Iteration 215 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 31)]\n",
      "Input: 0.115 MB, Params: 3,718,680 (14.186 MB), Total: 14.30 MB, FLOPs: 353,490,332\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.492%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Finished fine tuning.\n",
      "Iteration 215/1723 finished in 0m15s\n",
      "Total channels prunned so far: 215\n",
      "\n",
      "Iteration 216 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 349)]\n",
      "Input: 0.115 MB, Params: 3,712,657 (14.163 MB), Total: 14.28 MB, FLOPs: 353,327,738\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Finished fine tuning.\n",
      "Iteration 216/1723 finished in 0m15s\n",
      "Total channels prunned so far: 216\n",
      "\n",
      "Iteration 217 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 231)]\n",
      "Input: 0.115 MB, Params: 3,708,629 (14.147 MB), Total: 14.26 MB, FLOPs: 353,219,062\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Finished fine tuning.\n",
      "Iteration 217/1723 finished in 0m15s\n",
      "Total channels prunned so far: 217\n",
      "\n",
      "Iteration 218 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 228)]\n",
      "Input: 0.115 MB, Params: 3,702,615 (14.124 MB), Total: 14.24 MB, FLOPs: 353,056,711\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Finished fine tuning.\n",
      "Iteration 218/1723 finished in 0m15s\n",
      "Total channels prunned so far: 218\n",
      "\n",
      "Iteration 219 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 168)]\n",
      "Input: 0.115 MB, Params: 3,699,400 (14.112 MB), Total: 14.23 MB, FLOPs: 352,709,599\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Finished fine tuning.\n",
      "Iteration 219/1723 finished in 0m15s\n",
      "Total channels prunned so far: 219\n",
      "\n",
      "Iteration 220 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 24)]\n",
      "Input: 0.115 MB, Params: 3,693,386 (14.089 MB), Total: 14.20 MB, FLOPs: 352,547,248\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.068%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.068%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.492%\n",
      "Finished fine tuning.\n",
      "Iteration 220/1723 finished in 0m15s\n",
      "Total channels prunned so far: 220\n",
      "\n",
      "Iteration 221 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 121)]\n",
      "Input: 0.115 MB, Params: 3,690,171 (14.077 MB), Total: 14.19 MB, FLOPs: 352,200,136\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Finished fine tuning.\n",
      "Iteration 221/1723 finished in 0m15s\n",
      "Total channels prunned so far: 221\n",
      "\n",
      "Iteration 222 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 369)]\n",
      "Input: 0.115 MB, Params: 3,686,161 (14.062 MB), Total: 14.18 MB, FLOPs: 352,091,946\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.068%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Finished fine tuning.\n",
      "Iteration 222/1723 finished in 0m15s\n",
      "Total channels prunned so far: 222\n",
      "\n",
      "Iteration 223 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 219)]\n",
      "Input: 0.115 MB, Params: 3,682,946 (14.049 MB), Total: 14.16 MB, FLOPs: 351,744,834\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Finished fine tuning.\n",
      "Iteration 223/1723 finished in 0m15s\n",
      "Total channels prunned so far: 223\n",
      "\n",
      "Iteration 224 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 90)]\n",
      "Input: 0.115 MB, Params: 3,679,740 (14.037 MB), Total: 14.15 MB, FLOPs: 351,032,022\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.068%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.339%\n",
      "Finished fine tuning.\n",
      "Iteration 224/1723 finished in 0m15s\n",
      "Total channels prunned so far: 224\n",
      "\n",
      "Iteration 225 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 83)]\n",
      "Input: 0.115 MB, Params: 3,675,730 (14.022 MB), Total: 14.14 MB, FLOPs: 350,923,832\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.068%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.339%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.492%\n",
      "Finished fine tuning.\n",
      "Iteration 225/1723 finished in 0m15s\n",
      "Total channels prunned so far: 225\n",
      "\n",
      "Iteration 226 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 128)]\n",
      "Input: 0.115 MB, Params: 3,669,734 (13.999 MB), Total: 14.11 MB, FLOPs: 350,761,967\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.492%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.915%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.068%\n",
      "Finished fine tuning.\n",
      "Iteration 226/1723 finished in 0m15s\n",
      "Total channels prunned so far: 226\n",
      "\n",
      "Iteration 227 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 380)]\n",
      "Input: 0.115 MB, Params: 3,663,738 (13.976 MB), Total: 14.09 MB, FLOPs: 350,600,102\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.492%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.068%\n",
      "Finished fine tuning.\n",
      "Iteration 227/1723 finished in 0m15s\n",
      "Total channels prunned so far: 227\n",
      "\n",
      "Iteration 228 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 7)]\n",
      "Input: 0.115 MB, Params: 3,657,742 (13.953 MB), Total: 14.07 MB, FLOPs: 350,438,237\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.068%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.068%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.068%\n",
      "Finished fine tuning.\n",
      "Iteration 228/1723 finished in 0m20s\n",
      "Total channels prunned so far: 228\n",
      "\n",
      "Iteration 229 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 52)]\n",
      "Input: 0.115 MB, Params: 3,653,759 (13.938 MB), Total: 14.05 MB, FLOPs: 350,330,776\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.492%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.068%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.492%\n",
      "Finished fine tuning.\n",
      "Iteration 229/1723 finished in 0m19s\n",
      "Total channels prunned so far: 229\n",
      "\n",
      "Iteration 230 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 330)]\n",
      "Input: 0.115 MB, Params: 3,649,776 (13.923 MB), Total: 14.04 MB, FLOPs: 350,223,315\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.492%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.068%\n",
      "Finished fine tuning.\n",
      "Iteration 230/1723 finished in 0m20s\n",
      "Total channels prunned so far: 230\n",
      "\n",
      "Iteration 231 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 106)]\n",
      "Input: 0.115 MB, Params: 3,646,570 (13.911 MB), Total: 14.03 MB, FLOPs: 349,510,503\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.339%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.915%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.492%\n",
      "Finished fine tuning.\n",
      "Iteration 231/1723 finished in 0m20s\n",
      "Total channels prunned so far: 231\n",
      "\n",
      "Iteration 232 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 158)]\n",
      "Input: 0.115 MB, Params: 3,642,587 (13.895 MB), Total: 14.01 MB, FLOPs: 349,403,042\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.068%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.492%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.068%\n",
      "Finished fine tuning.\n",
      "Iteration 232/1723 finished in 0m20s\n",
      "Total channels prunned so far: 232\n",
      "\n",
      "Iteration 233 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 204)]\n",
      "Input: 0.115 MB, Params: 3,636,492 (13.872 MB), Total: 13.99 MB, FLOPs: 349,067,000\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.068%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.492%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Finished fine tuning.\n",
      "Iteration 233/1723 finished in 0m20s\n",
      "Total channels prunned so far: 233\n",
      "\n",
      "Iteration 234 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 11)]\n",
      "Input: 0.115 MB, Params: 3,634,834 (13.866 MB), Total: 13.98 MB, FLOPs: 348,331,292\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.068%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Finished fine tuning.\n",
      "Iteration 234/1723 finished in 0m20s\n",
      "Total channels prunned so far: 234\n",
      "\n",
      "Iteration 235 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 320)]\n",
      "Input: 0.115 MB, Params: 3,630,851 (13.851 MB), Total: 13.97 MB, FLOPs: 348,223,831\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.068%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.492%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Finished fine tuning.\n",
      "Iteration 235/1723 finished in 0m15s\n",
      "Total channels prunned so far: 235\n",
      "\n",
      "Iteration 236 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 272)]\n",
      "Input: 0.115 MB, Params: 3,624,900 (13.828 MB), Total: 13.94 MB, FLOPs: 348,063,181\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.068%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Finished fine tuning.\n",
      "Iteration 236/1723 finished in 0m15s\n",
      "Total channels prunned so far: 236\n",
      "\n",
      "Iteration 237 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 288)]\n",
      "Input: 0.115 MB, Params: 3,618,949 (13.805 MB), Total: 13.92 MB, FLOPs: 347,902,531\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.068%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Finished fine tuning.\n",
      "Iteration 237/1723 finished in 0m15s\n",
      "Total channels prunned so far: 237\n",
      "\n",
      "Iteration 238 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 189)]\n",
      "Input: 0.115 MB, Params: 3,615,761 (13.793 MB), Total: 13.91 MB, FLOPs: 347,558,335\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.068%\n",
      "Finished fine tuning.\n",
      "Iteration 238/1723 finished in 0m19s\n",
      "Total channels prunned so far: 238\n",
      "\n",
      "Iteration 239 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 145)]\n",
      "Input: 0.115 MB, Params: 3,609,810 (13.770 MB), Total: 13.89 MB, FLOPs: 347,397,685\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Finished fine tuning.\n",
      "Iteration 239/1723 finished in 0m19s\n",
      "Total channels prunned so far: 239\n",
      "\n",
      "Iteration 240 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 63)]\n",
      "Input: 0.115 MB, Params: 3,606,622 (13.758 MB), Total: 13.87 MB, FLOPs: 346,689,841\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Finished fine tuning.\n",
      "Iteration 240/1723 finished in 0m20s\n",
      "Total channels prunned so far: 240\n",
      "\n",
      "Iteration 241 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 237)]\n",
      "Input: 0.115 MB, Params: 3,600,671 (13.735 MB), Total: 13.85 MB, FLOPs: 346,529,191\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Finished fine tuning.\n",
      "Iteration 241/1723 finished in 0m19s\n",
      "Total channels prunned so far: 241\n",
      "\n",
      "Iteration 242 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 18)]\n",
      "Input: 0.115 MB, Params: 3,599,022 (13.729 MB), Total: 13.84 MB, FLOPs: 345,797,479\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Finished fine tuning.\n",
      "Iteration 242/1723 finished in 0m20s\n",
      "Total channels prunned so far: 242\n",
      "\n",
      "Iteration 243 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 248)]\n",
      "Input: 0.115 MB, Params: 3,595,075 (13.714 MB), Total: 13.83 MB, FLOPs: 345,690,990\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.068%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.915%\n",
      "Finished fine tuning.\n",
      "Iteration 243/1723 finished in 0m20s\n",
      "Total channels prunned so far: 243\n",
      "\n",
      "Iteration 244 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 165)]\n",
      "Input: 0.115 MB, Params: 3,589,025 (13.691 MB), Total: 13.81 MB, FLOPs: 345,356,892\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.492%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.492%\n",
      "Finished fine tuning.\n",
      "Iteration 244/1723 finished in 0m20s\n",
      "Total channels prunned so far: 244\n",
      "\n",
      "Iteration 245 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 408)]\n",
      "Input: 0.115 MB, Params: 3,583,092 (13.668 MB), Total: 13.78 MB, FLOPs: 345,196,728\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.068%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.915%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Finished fine tuning.\n",
      "Iteration 245/1723 finished in 0m15s\n",
      "Total channels prunned so far: 245\n",
      "\n",
      "Iteration 246 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 94)]\n",
      "Input: 0.115 MB, Params: 3,579,913 (13.656 MB), Total: 13.77 MB, FLOPs: 344,492,880\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.068%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.915%\n",
      "Finished fine tuning.\n",
      "Iteration 246/1723 finished in 0m15s\n",
      "Total channels prunned so far: 246\n",
      "\n",
      "Iteration 247 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 20)]\n",
      "Input: 0.115 MB, Params: 3,579,092 (13.653 MB), Total: 13.77 MB, FLOPs: 342,955,380\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.915%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Finished fine tuning.\n",
      "Iteration 247/1723 finished in 0m15s\n",
      "Total channels prunned so far: 247\n",
      "\n",
      "Iteration 248 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 7)]\n",
      "Input: 0.115 MB, Params: 3,575,154 (13.638 MB), Total: 13.75 MB, FLOPs: 342,849,134\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Finished fine tuning.\n",
      "Iteration 248/1723 finished in 0m15s\n",
      "Total channels prunned so far: 248\n",
      "\n",
      "Iteration 249 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 221)]\n",
      "Input: 0.115 MB, Params: 3,569,230 (13.616 MB), Total: 13.73 MB, FLOPs: 342,689,213\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Finished fine tuning.\n",
      "Iteration 249/1723 finished in 0m15s\n",
      "Total channels prunned so far: 249\n",
      "\n",
      "Iteration 250 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 101)]\n",
      "Input: 0.115 MB, Params: 3,565,301 (13.601 MB), Total: 13.72 MB, FLOPs: 342,583,210\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Finished fine tuning.\n",
      "Iteration 250/1723 finished in 0m15s\n",
      "Total channels prunned so far: 250\n",
      "\n",
      "Iteration 251 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 31)]\n",
      "Input: 0.115 MB, Params: 3,563,661 (13.594 MB), Total: 13.71 MB, FLOPs: 341,855,494\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Finished fine tuning.\n",
      "Iteration 251/1723 finished in 0m15s\n",
      "Total channels prunned so far: 251\n",
      "\n",
      "Iteration 252 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 404)]\n",
      "Input: 0.115 MB, Params: 3,559,732 (13.579 MB), Total: 13.69 MB, FLOPs: 341,749,491\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Finished fine tuning.\n",
      "Iteration 252/1723 finished in 0m15s\n",
      "Total channels prunned so far: 252\n",
      "\n",
      "Iteration 253 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 164)]\n",
      "Input: 0.115 MB, Params: 3,553,700 (13.556 MB), Total: 13.67 MB, FLOPs: 341,415,879\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Finished fine tuning.\n",
      "Iteration 253/1723 finished in 0m16s\n",
      "Total channels prunned so far: 253\n",
      "\n",
      "Iteration 254 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 316)]\n",
      "Input: 0.115 MB, Params: 3,549,771 (13.541 MB), Total: 13.66 MB, FLOPs: 341,309,876\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Finished fine tuning.\n",
      "Iteration 254/1723 finished in 0m19s\n",
      "Total channels prunned so far: 254\n",
      "\n",
      "Iteration 255 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(7, 19)]\n",
      "Input: 0.115 MB, Params: 3,549,256 (13.539 MB), Total: 13.65 MB, FLOPs: 340,280,366\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Finished fine tuning.\n",
      "Iteration 255/1723 finished in 0m20s\n",
      "Total channels prunned so far: 255\n",
      "\n",
      "Iteration 256 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 4)]\n",
      "Input: 0.115 MB, Params: 3,543,224 (13.516 MB), Total: 13.63 MB, FLOPs: 339,946,754\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Finished fine tuning.\n",
      "Iteration 256/1723 finished in 0m20s\n",
      "Total channels prunned so far: 256\n",
      "\n",
      "Iteration 257 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 351)]\n",
      "Input: 0.115 MB, Params: 3,537,345 (13.494 MB), Total: 13.61 MB, FLOPs: 339,788,048\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Finished fine tuning.\n",
      "Iteration 257/1723 finished in 0m20s\n",
      "Total channels prunned so far: 257\n",
      "\n",
      "Iteration 258 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 103)]\n",
      "Input: 0.115 MB, Params: 3,531,466 (13.471 MB), Total: 13.59 MB, FLOPs: 339,629,342\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Finished fine tuning.\n",
      "Iteration 258/1723 finished in 0m19s\n",
      "Total channels prunned so far: 258\n",
      "\n",
      "Iteration 259 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 243)]\n",
      "Input: 0.115 MB, Params: 3,525,587 (13.449 MB), Total: 13.56 MB, FLOPs: 339,470,636\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Finished fine tuning.\n",
      "Iteration 259/1723 finished in 0m19s\n",
      "Total channels prunned so far: 259\n",
      "\n",
      "Iteration 260 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 222)]\n",
      "Input: 0.115 MB, Params: 3,519,708 (13.427 MB), Total: 13.54 MB, FLOPs: 339,311,930\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Finished fine tuning.\n",
      "Iteration 260/1723 finished in 0m21s\n",
      "Total channels prunned so far: 260\n",
      "\n",
      "Iteration 261 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 85)]\n",
      "Input: 0.115 MB, Params: 3,516,565 (13.415 MB), Total: 13.53 MB, FLOPs: 338,972,594\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Finished fine tuning.\n",
      "Iteration 261/1723 finished in 0m19s\n",
      "Total channels prunned so far: 261\n",
      "\n",
      "Iteration 262 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 160)]\n",
      "Input: 0.115 MB, Params: 3,513,422 (13.403 MB), Total: 13.52 MB, FLOPs: 338,633,258\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Finished fine tuning.\n",
      "Iteration 262/1723 finished in 0m19s\n",
      "Total channels prunned so far: 262\n",
      "\n",
      "Iteration 263 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 130)]\n",
      "Input: 0.115 MB, Params: 3,507,444 (13.380 MB), Total: 13.50 MB, FLOPs: 338,302,562\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Finished fine tuning.\n",
      "Iteration 263/1723 finished in 0m20s\n",
      "Total channels prunned so far: 263\n",
      "\n",
      "Iteration 264 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 41)]\n",
      "Input: 0.115 MB, Params: 3,501,574 (13.357 MB), Total: 13.47 MB, FLOPs: 338,144,099\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.492%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.068%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Finished fine tuning.\n",
      "Iteration 264/1723 finished in 0m20s\n",
      "Total channels prunned so far: 264\n",
      "\n",
      "Iteration 265 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 30)]\n",
      "Input: 0.115 MB, Params: 3,495,605 (13.335 MB), Total: 13.45 MB, FLOPs: 337,813,646\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.068%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Finished fine tuning.\n",
      "Iteration 265/1723 finished in 0m20s\n",
      "Total channels prunned so far: 265\n",
      "\n",
      "Iteration 266 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 158)]\n",
      "Input: 0.115 MB, Params: 3,489,744 (13.312 MB), Total: 13.43 MB, FLOPs: 337,655,426\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.068%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Finished fine tuning.\n",
      "Iteration 266/1723 finished in 0m20s\n",
      "Total channels prunned so far: 266\n",
      "\n",
      "Iteration 267 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 201)]\n",
      "Input: 0.115 MB, Params: 3,486,619 (13.300 MB), Total: 13.42 MB, FLOPs: 337,318,034\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.492%\n",
      "Finished fine tuning.\n",
      "Iteration 267/1723 finished in 0m21s\n",
      "Total channels prunned so far: 267\n",
      "\n",
      "Iteration 268 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 34)]\n",
      "Input: 0.115 MB, Params: 3,485,807 (13.297 MB), Total: 13.41 MB, FLOPs: 335,797,409\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.068%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Finished fine tuning.\n",
      "Iteration 268/1723 finished in 0m20s\n",
      "Total channels prunned so far: 268\n",
      "\n",
      "Iteration 269 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 237)]\n",
      "Input: 0.115 MB, Params: 3,479,946 (13.275 MB), Total: 13.39 MB, FLOPs: 335,639,189\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Finished fine tuning.\n",
      "Iteration 269/1723 finished in 0m19s\n",
      "Total channels prunned so far: 269\n",
      "\n",
      "Iteration 270 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 102)]\n",
      "Input: 0.115 MB, Params: 3,478,306 (13.269 MB), Total: 13.38 MB, FLOPs: 334,911,473\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.254%\n",
      "Finished fine tuning.\n",
      "Iteration 270/1723 finished in 0m21s\n",
      "Total channels prunned so far: 270\n",
      "\n",
      "Iteration 271 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 321)]\n",
      "Input: 0.115 MB, Params: 3,472,445 (13.246 MB), Total: 13.36 MB, FLOPs: 334,753,253\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.254%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Finished fine tuning.\n",
      "Iteration 271/1723 finished in 0m20s\n",
      "Total channels prunned so far: 271\n",
      "\n",
      "Iteration 272 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 122)]\n",
      "Input: 0.115 MB, Params: 3,468,588 (13.232 MB), Total: 13.35 MB, FLOPs: 334,649,194\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Finished fine tuning.\n",
      "Iteration 272/1723 finished in 0m20s\n",
      "Total channels prunned so far: 272\n",
      "\n",
      "Iteration 273 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 46)]\n",
      "Input: 0.115 MB, Params: 3,462,736 (13.209 MB), Total: 13.32 MB, FLOPs: 334,491,217\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Finished fine tuning.\n",
      "Iteration 273/1723 finished in 0m19s\n",
      "Total channels prunned so far: 273\n",
      "\n",
      "Iteration 274 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 190)]\n",
      "Input: 0.115 MB, Params: 3,456,884 (13.187 MB), Total: 13.30 MB, FLOPs: 334,333,240\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Finished fine tuning.\n",
      "Iteration 274/1723 finished in 0m20s\n",
      "Total channels prunned so far: 274\n",
      "\n",
      "Iteration 275 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 38)]\n",
      "Input: 0.115 MB, Params: 3,453,045 (13.172 MB), Total: 13.29 MB, FLOPs: 334,229,667\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.068%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Finished fine tuning.\n",
      "Iteration 275/1723 finished in 0m21s\n",
      "Total channels prunned so far: 275\n",
      "\n",
      "Iteration 276 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 207)]\n",
      "Input: 0.115 MB, Params: 3,447,202 (13.150 MB), Total: 13.27 MB, FLOPs: 334,071,933\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Finished fine tuning.\n",
      "Iteration 276/1723 finished in 0m19s\n",
      "Total channels prunned so far: 276\n",
      "\n",
      "Iteration 277 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 11)]\n",
      "Input: 0.115 MB, Params: 3,443,372 (13.135 MB), Total: 13.25 MB, FLOPs: 333,968,603\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Finished fine tuning.\n",
      "Iteration 277/1723 finished in 0m20s\n",
      "Total channels prunned so far: 277\n",
      "\n",
      "Iteration 278 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 263)]\n",
      "Input: 0.115 MB, Params: 3,439,542 (13.121 MB), Total: 13.24 MB, FLOPs: 333,865,273\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Finished fine tuning.\n",
      "Iteration 278/1723 finished in 0m21s\n",
      "Total channels prunned so far: 278\n",
      "\n",
      "Iteration 279 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 56)]\n",
      "Input: 0.115 MB, Params: 3,435,712 (13.106 MB), Total: 13.22 MB, FLOPs: 333,761,943\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Finished fine tuning.\n",
      "Iteration 279/1723 finished in 0m20s\n",
      "Total channels prunned so far: 279\n",
      "\n",
      "Iteration 280 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(3, 36)]\n",
      "Input: 0.115 MB, Params: 3,435,670 (13.106 MB), Total: 13.22 MB, FLOPs: 333,399,420\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.068%\n",
      "Finished fine tuning.\n",
      "Iteration 280/1723 finished in 0m20s\n",
      "Total channels prunned so far: 280\n",
      "\n",
      "Iteration 281 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 96)]\n",
      "Input: 0.115 MB, Params: 3,434,030 (13.100 MB), Total: 13.22 MB, FLOPs: 332,671,704\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Finished fine tuning.\n",
      "Iteration 281/1723 finished in 0m20s\n",
      "Total channels prunned so far: 281\n",
      "\n",
      "Iteration 282 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 151)]\n",
      "Input: 0.115 MB, Params: 3,428,214 (13.078 MB), Total: 13.19 MB, FLOPs: 332,514,699\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.068%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.068%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.492%\n",
      "Finished fine tuning.\n",
      "Iteration 282/1723 finished in 0m21s\n",
      "Total channels prunned so far: 282\n",
      "\n",
      "Iteration 283 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 102)]\n",
      "Input: 0.115 MB, Params: 3,424,393 (13.063 MB), Total: 13.18 MB, FLOPs: 332,411,612\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.339%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.915%\n",
      "Finished fine tuning.\n",
      "Iteration 283/1723 finished in 0m20s\n",
      "Total channels prunned so far: 283\n",
      "\n",
      "Iteration 284 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 166)]\n",
      "Input: 0.115 MB, Params: 3,418,496 (13.041 MB), Total: 13.16 MB, FLOPs: 332,083,832\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.339%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.068%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Finished fine tuning.\n",
      "Iteration 284/1723 finished in 0m20s\n",
      "Total channels prunned so far: 284\n",
      "\n",
      "Iteration 285 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 168)]\n",
      "Input: 0.115 MB, Params: 3,412,599 (13.018 MB), Total: 13.13 MB, FLOPs: 331,756,052\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Finished fine tuning.\n",
      "Iteration 285/1723 finished in 0m21s\n",
      "Total channels prunned so far: 285\n",
      "\n",
      "Iteration 286 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 164)]\n",
      "Input: 0.115 MB, Params: 3,409,492 (13.006 MB), Total: 13.12 MB, FLOPs: 331,420,604\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Finished fine tuning.\n",
      "Iteration 286/1723 finished in 0m20s\n",
      "Total channels prunned so far: 286\n",
      "\n",
      "Iteration 287 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 94)]\n",
      "Input: 0.115 MB, Params: 3,405,671 (12.992 MB), Total: 13.11 MB, FLOPs: 331,317,517\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Finished fine tuning.\n",
      "Iteration 287/1723 finished in 0m20s\n",
      "Total channels prunned so far: 287\n",
      "\n",
      "Iteration 288 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 92)]\n",
      "Input: 0.115 MB, Params: 3,399,783 (12.969 MB), Total: 13.08 MB, FLOPs: 330,990,709\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Finished fine tuning.\n",
      "Iteration 288/1723 finished in 0m20s\n",
      "Total channels prunned so far: 288\n",
      "\n",
      "Iteration 289 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 36)]\n",
      "Input: 0.115 MB, Params: 3,394,012 (12.947 MB), Total: 13.06 MB, FLOPs: 330,834,919\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Finished fine tuning.\n",
      "Iteration 289/1723 finished in 0m20s\n",
      "Total channels prunned so far: 289\n",
      "\n",
      "Iteration 290 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(3, 11)]\n",
      "Input: 0.115 MB, Params: 3,393,970 (12.947 MB), Total: 13.06 MB, FLOPs: 327,113,521\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.831%\n",
      "Finished fine tuning.\n",
      "Iteration 290/1723 finished in 0m21s\n",
      "Total channels prunned so far: 290\n",
      "\n",
      "Iteration 291 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 10)]\n",
      "Input: 0.115 MB, Params: 3,392,330 (12.941 MB), Total: 13.06 MB, FLOPs: 326,385,805\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.254%\n",
      "Finished fine tuning.\n",
      "Iteration 291/1723 finished in 0m21s\n",
      "Total channels prunned so far: 291\n",
      "\n",
      "Iteration 292 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 207)]\n",
      "Input: 0.115 MB, Params: 3,389,232 (12.929 MB), Total: 13.04 MB, FLOPs: 326,051,329\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Finished fine tuning.\n",
      "Iteration 292/1723 finished in 0m19s\n",
      "Total channels prunned so far: 292\n",
      "\n",
      "Iteration 293 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 78)]\n",
      "Input: 0.115 MB, Params: 3,386,134 (12.917 MB), Total: 13.03 MB, FLOPs: 325,716,853\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Finished fine tuning.\n",
      "Iteration 293/1723 finished in 0m20s\n",
      "Total channels prunned so far: 293\n",
      "\n",
      "Iteration 294 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 105)]\n",
      "Input: 0.115 MB, Params: 3,380,273 (12.895 MB), Total: 13.01 MB, FLOPs: 325,392,232\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Finished fine tuning.\n",
      "Iteration 294/1723 finished in 0m20s\n",
      "Total channels prunned so far: 294\n",
      "\n",
      "Iteration 295 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 346)]\n",
      "Input: 0.115 MB, Params: 3,374,511 (12.873 MB), Total: 12.99 MB, FLOPs: 325,236,685\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Finished fine tuning.\n",
      "Iteration 295/1723 finished in 0m20s\n",
      "Total channels prunned so far: 295\n",
      "\n",
      "Iteration 296 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 40)]\n",
      "Input: 0.115 MB, Params: 3,368,749 (12.851 MB), Total: 12.97 MB, FLOPs: 325,081,138\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Finished fine tuning.\n",
      "Iteration 296/1723 finished in 0m20s\n",
      "Total channels prunned so far: 296\n",
      "\n",
      "Iteration 297 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 139)]\n",
      "Input: 0.115 MB, Params: 3,362,906 (12.828 MB), Total: 12.94 MB, FLOPs: 324,757,003\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Finished fine tuning.\n",
      "Iteration 297/1723 finished in 0m20s\n",
      "Total channels prunned so far: 297\n",
      "\n",
      "Iteration 298 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 83)]\n",
      "Input: 0.115 MB, Params: 3,359,112 (12.814 MB), Total: 12.93 MB, FLOPs: 324,654,645\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Finished fine tuning.\n",
      "Iteration 298/1723 finished in 0m20s\n",
      "Total channels prunned so far: 298\n",
      "\n",
      "Iteration 299 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 244)]\n",
      "Input: 0.115 MB, Params: 3,355,318 (12.800 MB), Total: 12.91 MB, FLOPs: 324,552,287\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Finished fine tuning.\n",
      "Iteration 299/1723 finished in 0m20s\n",
      "Total channels prunned so far: 299\n",
      "\n",
      "Iteration 300 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 206)]\n",
      "Input: 0.115 MB, Params: 3,349,583 (12.778 MB), Total: 12.89 MB, FLOPs: 324,397,469\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Finished fine tuning.\n",
      "Iteration 300/1723 finished in 0m19s\n",
      "Total channels prunned so far: 300\n",
      "\n",
      "Iteration 301 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 149)]\n",
      "Input: 0.115 MB, Params: 3,346,503 (12.766 MB), Total: 12.88 MB, FLOPs: 324,064,937\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Finished fine tuning.\n",
      "Iteration 301/1723 finished in 0m20s\n",
      "Total channels prunned so far: 301\n",
      "\n",
      "Iteration 302 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 194)]\n",
      "Input: 0.115 MB, Params: 3,343,423 (12.754 MB), Total: 12.87 MB, FLOPs: 323,732,405\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Finished fine tuning.\n",
      "Iteration 302/1723 finished in 0m19s\n",
      "Total channels prunned so far: 302\n",
      "\n",
      "Iteration 303 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 81)]\n",
      "Input: 0.115 MB, Params: 3,340,343 (12.742 MB), Total: 12.86 MB, FLOPs: 323,399,873\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Finished fine tuning.\n",
      "Iteration 303/1723 finished in 0m21s\n",
      "Total channels prunned so far: 303\n",
      "\n",
      "Iteration 304 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 329)]\n",
      "Input: 0.115 MB, Params: 3,336,558 (12.728 MB), Total: 12.84 MB, FLOPs: 323,297,758\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.254%\n",
      "Finished fine tuning.\n",
      "Iteration 304/1723 finished in 0m20s\n",
      "Total channels prunned so far: 304\n",
      "\n",
      "Iteration 305 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 387)]\n",
      "Input: 0.115 MB, Params: 3,332,773 (12.714 MB), Total: 12.83 MB, FLOPs: 323,195,643\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Finished fine tuning.\n",
      "Iteration 305/1723 finished in 0m20s\n",
      "Total channels prunned so far: 305\n",
      "\n",
      "Iteration 306 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 61)]\n",
      "Input: 0.115 MB, Params: 3,327,056 (12.692 MB), Total: 12.81 MB, FLOPs: 323,041,311\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Finished fine tuning.\n",
      "Iteration 306/1723 finished in 0m20s\n",
      "Total channels prunned so far: 306\n",
      "\n",
      "Iteration 307 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 241)]\n",
      "Input: 0.115 MB, Params: 3,323,280 (12.677 MB), Total: 12.79 MB, FLOPs: 322,939,439\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Finished fine tuning.\n",
      "Iteration 307/1723 finished in 0m20s\n",
      "Total channels prunned so far: 307\n",
      "\n",
      "Iteration 308 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 27)]\n",
      "Input: 0.115 MB, Params: 3,321,640 (12.671 MB), Total: 12.79 MB, FLOPs: 322,211,723\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Finished fine tuning.\n",
      "Iteration 308/1723 finished in 0m20s\n",
      "Total channels prunned so far: 308\n",
      "\n",
      "Iteration 309 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 298)]\n",
      "Input: 0.115 MB, Params: 3,315,932 (12.649 MB), Total: 12.76 MB, FLOPs: 322,057,634\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Finished fine tuning.\n",
      "Iteration 309/1723 finished in 0m21s\n",
      "Total channels prunned so far: 309\n",
      "\n",
      "Iteration 310 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 119)]\n",
      "Input: 0.115 MB, Params: 3,310,224 (12.628 MB), Total: 12.74 MB, FLOPs: 321,903,545\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Finished fine tuning.\n",
      "Iteration 310/1723 finished in 0m17s\n",
      "Total channels prunned so far: 310\n",
      "\n",
      "Iteration 311 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 210)]\n",
      "Input: 0.115 MB, Params: 3,304,516 (12.606 MB), Total: 12.72 MB, FLOPs: 321,749,456\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Finished fine tuning.\n",
      "Iteration 311/1723 finished in 0m15s\n",
      "Total channels prunned so far: 311\n",
      "\n",
      "Iteration 312 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 14)]\n",
      "Input: 0.115 MB, Params: 3,301,436 (12.594 MB), Total: 12.71 MB, FLOPs: 321,416,924\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Finished fine tuning.\n",
      "Iteration 312/1723 finished in 0m15s\n",
      "Total channels prunned so far: 312\n",
      "\n",
      "Iteration 313 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 372)]\n",
      "Input: 0.115 MB, Params: 3,297,687 (12.580 MB), Total: 12.69 MB, FLOPs: 321,315,781\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Finished fine tuning.\n",
      "Iteration 313/1723 finished in 0m15s\n",
      "Total channels prunned so far: 313\n",
      "\n",
      "Iteration 314 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 156)]\n",
      "Input: 0.115 MB, Params: 3,293,938 (12.565 MB), Total: 12.68 MB, FLOPs: 321,214,638\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Finished fine tuning.\n",
      "Iteration 314/1723 finished in 0m15s\n",
      "Total channels prunned so far: 314\n",
      "\n",
      "Iteration 315 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 153)]\n",
      "Input: 0.115 MB, Params: 3,290,858 (12.554 MB), Total: 12.67 MB, FLOPs: 320,882,106\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Finished fine tuning.\n",
      "Iteration 315/1723 finished in 0m15s\n",
      "Total channels prunned so far: 315\n",
      "\n",
      "Iteration 316 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 100)]\n",
      "Input: 0.115 MB, Params: 3,287,778 (12.542 MB), Total: 12.66 MB, FLOPs: 320,549,574\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Finished fine tuning.\n",
      "Iteration 316/1723 finished in 0m15s\n",
      "Total channels prunned so far: 316\n",
      "\n",
      "Iteration 317 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 251)]\n",
      "Input: 0.115 MB, Params: 3,282,088 (12.520 MB), Total: 12.64 MB, FLOPs: 320,395,971\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Finished fine tuning.\n",
      "Iteration 317/1723 finished in 0m15s\n",
      "Total channels prunned so far: 317\n",
      "\n",
      "Iteration 318 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 166)]\n",
      "Input: 0.115 MB, Params: 3,276,353 (12.498 MB), Total: 12.61 MB, FLOPs: 320,079,126\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.254%\n",
      "Finished fine tuning.\n",
      "Iteration 318/1723 finished in 0m15s\n",
      "Total channels prunned so far: 318\n",
      "\n",
      "Iteration 319 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 335)]\n",
      "Input: 0.115 MB, Params: 3,270,672 (12.477 MB), Total: 12.59 MB, FLOPs: 319,925,766\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Finished fine tuning.\n",
      "Iteration 319/1723 finished in 0m15s\n",
      "Total channels prunned so far: 319\n",
      "\n",
      "Iteration 320 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 69)]\n",
      "Input: 0.115 MB, Params: 3,267,601 (12.465 MB), Total: 12.58 MB, FLOPs: 319,594,206\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Finished fine tuning.\n",
      "Iteration 320/1723 finished in 0m15s\n",
      "Total channels prunned so far: 320\n",
      "\n",
      "Iteration 321 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 407)]\n",
      "Input: 0.115 MB, Params: 3,261,920 (12.443 MB), Total: 12.56 MB, FLOPs: 319,440,846\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Finished fine tuning.\n",
      "Iteration 321/1723 finished in 0m15s\n",
      "Total channels prunned so far: 321\n",
      "\n",
      "Iteration 322 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 384)]\n",
      "Input: 0.115 MB, Params: 3,258,198 (12.429 MB), Total: 12.54 MB, FLOPs: 319,340,432\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.254%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Finished fine tuning.\n",
      "Iteration 322/1723 finished in 0m15s\n",
      "Total channels prunned so far: 322\n",
      "\n",
      "Iteration 323 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 264)]\n",
      "Input: 0.115 MB, Params: 3,252,526 (12.407 MB), Total: 12.52 MB, FLOPs: 319,187,315\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Finished fine tuning.\n",
      "Iteration 323/1723 finished in 0m15s\n",
      "Total channels prunned so far: 323\n",
      "\n",
      "Iteration 324 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 240)]\n",
      "Input: 0.115 MB, Params: 3,248,813 (12.393 MB), Total: 12.51 MB, FLOPs: 319,087,144\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Finished fine tuning.\n",
      "Iteration 324/1723 finished in 0m15s\n",
      "Total channels prunned so far: 324\n",
      "\n",
      "Iteration 325 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 71)]\n",
      "Input: 0.115 MB, Params: 3,247,173 (12.387 MB), Total: 12.50 MB, FLOPs: 318,359,428\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.254%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.831%\n",
      "Finished fine tuning.\n",
      "Iteration 325/1723 finished in 0m15s\n",
      "Total channels prunned so far: 325\n",
      "\n",
      "Iteration 326 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 279)]\n",
      "Input: 0.115 MB, Params: 3,243,460 (12.373 MB), Total: 12.49 MB, FLOPs: 318,259,257\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.254%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Finished fine tuning.\n",
      "Iteration 326/1723 finished in 0m15s\n",
      "Total channels prunned so far: 326\n",
      "\n",
      "Iteration 327 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 60)]\n",
      "Input: 0.115 MB, Params: 3,241,820 (12.367 MB), Total: 12.48 MB, FLOPs: 317,531,541\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Finished fine tuning.\n",
      "Iteration 327/1723 finished in 0m15s\n",
      "Total channels prunned so far: 327\n",
      "\n",
      "Iteration 328 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 370)]\n",
      "Input: 0.115 MB, Params: 3,236,166 (12.345 MB), Total: 12.46 MB, FLOPs: 317,378,910\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Finished fine tuning.\n",
      "Iteration 328/1723 finished in 0m15s\n",
      "Total channels prunned so far: 328\n",
      "\n",
      "Iteration 329 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 136)]\n",
      "Input: 0.115 MB, Params: 3,230,512 (12.323 MB), Total: 12.44 MB, FLOPs: 317,226,279\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Finished fine tuning.\n",
      "Iteration 329/1723 finished in 0m15s\n",
      "Total channels prunned so far: 329\n",
      "\n",
      "Iteration 330 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 35)]\n",
      "Input: 0.115 MB, Params: 3,224,858 (12.302 MB), Total: 12.42 MB, FLOPs: 317,073,648\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Finished fine tuning.\n",
      "Iteration 330/1723 finished in 0m15s\n",
      "Total channels prunned so far: 330\n",
      "\n",
      "Iteration 331 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 390)]\n",
      "Input: 0.115 MB, Params: 3,219,204 (12.280 MB), Total: 12.40 MB, FLOPs: 316,921,017\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Finished fine tuning.\n",
      "Iteration 331/1723 finished in 0m15s\n",
      "Total channels prunned so far: 331\n",
      "\n",
      "Iteration 332 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 12)]\n",
      "Input: 0.115 MB, Params: 3,213,550 (12.259 MB), Total: 12.37 MB, FLOPs: 316,768,386\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Finished fine tuning.\n",
      "Iteration 332/1723 finished in 0m15s\n",
      "Total channels prunned so far: 332\n",
      "\n",
      "Iteration 333 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 125)]\n",
      "Input: 0.115 MB, Params: 3,210,479 (12.247 MB), Total: 12.36 MB, FLOPs: 316,436,826\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Finished fine tuning.\n",
      "Iteration 333/1723 finished in 0m15s\n",
      "Total channels prunned so far: 333\n",
      "\n",
      "Iteration 334 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(14, 4)]\n",
      "Input: 0.115 MB, Params: 3,208,974 (12.241 MB), Total: 12.36 MB, FLOPs: 315,094,698\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.915%\n",
      "Finished fine tuning.\n",
      "Iteration 334/1723 finished in 0m15s\n",
      "Total channels prunned so far: 334\n",
      "\n",
      "Iteration 335 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 400)]\n",
      "Input: 0.115 MB, Params: 3,205,306 (12.227 MB), Total: 12.34 MB, FLOPs: 314,995,742\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Finished fine tuning.\n",
      "Iteration 335/1723 finished in 0m15s\n",
      "Total channels prunned so far: 335\n",
      "\n",
      "Iteration 336 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 133)]\n",
      "Input: 0.115 MB, Params: 3,199,661 (12.206 MB), Total: 12.32 MB, FLOPs: 314,682,785\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Finished fine tuning.\n",
      "Iteration 336/1723 finished in 0m15s\n",
      "Total channels prunned so far: 336\n",
      "\n",
      "Iteration 337 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 90)]\n",
      "Input: 0.115 MB, Params: 3,194,016 (12.184 MB), Total: 12.30 MB, FLOPs: 314,369,828\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Finished fine tuning.\n",
      "Iteration 337/1723 finished in 0m15s\n",
      "Total channels prunned so far: 337\n",
      "\n",
      "Iteration 338 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 15)]\n",
      "Input: 0.115 MB, Params: 3,188,389 (12.163 MB), Total: 12.28 MB, FLOPs: 314,217,926\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Finished fine tuning.\n",
      "Iteration 338/1723 finished in 0m15s\n",
      "Total channels prunned so far: 338\n",
      "\n",
      "Iteration 339 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 104)]\n",
      "Input: 0.115 MB, Params: 3,185,399 (12.151 MB), Total: 12.27 MB, FLOPs: 313,555,658\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Finished fine tuning.\n",
      "Iteration 339/1723 finished in 0m15s\n",
      "Total channels prunned so far: 339\n",
      "\n",
      "Iteration 340 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 138)]\n",
      "Input: 0.115 MB, Params: 3,179,772 (12.130 MB), Total: 12.25 MB, FLOPs: 313,403,756\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.068%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Finished fine tuning.\n",
      "Iteration 340/1723 finished in 0m15s\n",
      "Total channels prunned so far: 340\n",
      "\n",
      "Iteration 341 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 235)]\n",
      "Input: 0.115 MB, Params: 3,174,145 (12.108 MB), Total: 12.22 MB, FLOPs: 313,251,854\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Finished fine tuning.\n",
      "Iteration 341/1723 finished in 0m15s\n",
      "Total channels prunned so far: 341\n",
      "\n",
      "Iteration 342 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 181)]\n",
      "Input: 0.115 MB, Params: 3,168,518 (12.087 MB), Total: 12.20 MB, FLOPs: 313,099,952\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.068%\n",
      "Finished fine tuning.\n",
      "Iteration 342/1723 finished in 0m15s\n",
      "Total channels prunned so far: 342\n",
      "\n",
      "Iteration 343 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 100)]\n",
      "Input: 0.115 MB, Params: 3,165,474 (12.075 MB), Total: 12.19 MB, FLOPs: 312,771,308\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Finished fine tuning.\n",
      "Iteration 343/1723 finished in 0m15s\n",
      "Total channels prunned so far: 343\n",
      "\n",
      "Iteration 344 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 153)]\n",
      "Input: 0.115 MB, Params: 3,162,430 (12.064 MB), Total: 12.18 MB, FLOPs: 312,442,664\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Finished fine tuning.\n",
      "Iteration 344/1723 finished in 0m15s\n",
      "Total channels prunned so far: 344\n",
      "\n",
      "Iteration 345 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 173)]\n",
      "Input: 0.115 MB, Params: 3,156,803 (12.042 MB), Total: 12.16 MB, FLOPs: 312,290,762\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Finished fine tuning.\n",
      "Iteration 345/1723 finished in 0m15s\n",
      "Total channels prunned so far: 345\n",
      "\n",
      "Iteration 346 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(3, 43)]\n",
      "Input: 0.115 MB, Params: 3,156,761 (12.042 MB), Total: 12.16 MB, FLOPs: 311,928,239\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Finished fine tuning.\n",
      "Iteration 346/1723 finished in 0m15s\n",
      "Total channels prunned so far: 346\n",
      "\n",
      "Iteration 347 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 83)]\n",
      "Input: 0.115 MB, Params: 3,151,134 (12.021 MB), Total: 12.14 MB, FLOPs: 311,776,337\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Finished fine tuning.\n",
      "Iteration 347/1723 finished in 0m15s\n",
      "Total channels prunned so far: 347\n",
      "\n",
      "Iteration 348 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 106)]\n",
      "Input: 0.115 MB, Params: 3,145,561 (11.999 MB), Total: 12.11 MB, FLOPs: 311,466,782\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Finished fine tuning.\n",
      "Iteration 348/1723 finished in 0m15s\n",
      "Total channels prunned so far: 348\n",
      "\n",
      "Iteration 349 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 130)]\n",
      "Input: 0.115 MB, Params: 3,141,947 (11.986 MB), Total: 12.10 MB, FLOPs: 311,369,284\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Finished fine tuning.\n",
      "Iteration 349/1723 finished in 0m15s\n",
      "Total channels prunned so far: 349\n",
      "\n",
      "Iteration 350 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 107)]\n",
      "Input: 0.115 MB, Params: 3,138,912 (11.974 MB), Total: 12.09 MB, FLOPs: 311,041,612\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Finished fine tuning.\n",
      "Iteration 350/1723 finished in 0m15s\n",
      "Total channels prunned so far: 350\n",
      "\n",
      "Iteration 351 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 132)]\n",
      "Input: 0.115 MB, Params: 3,133,348 (11.953 MB), Total: 12.07 MB, FLOPs: 310,733,029\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Finished fine tuning.\n",
      "Iteration 351/1723 finished in 0m15s\n",
      "Total channels prunned so far: 351\n",
      "\n",
      "Iteration 352 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 46)]\n",
      "Input: 0.115 MB, Params: 3,132,545 (11.950 MB), Total: 12.07 MB, FLOPs: 309,289,429\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Finished fine tuning.\n",
      "Iteration 352/1723 finished in 0m15s\n",
      "Total channels prunned so far: 352\n",
      "\n",
      "Iteration 353 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 115)]\n",
      "Input: 0.115 MB, Params: 3,128,931 (11.936 MB), Total: 12.05 MB, FLOPs: 309,191,931\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Finished fine tuning.\n",
      "Iteration 353/1723 finished in 0m15s\n",
      "Total channels prunned so far: 353\n",
      "\n",
      "Iteration 354 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(3, 2)]\n",
      "Input: 0.115 MB, Params: 3,128,889 (11.936 MB), Total: 12.05 MB, FLOPs: 266,823,314\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.712%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Finished fine tuning.\n",
      "Iteration 354/1723 finished in 0m15s\n",
      "Total channels prunned so far: 354\n",
      "\n",
      "Iteration 355 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 24)]\n",
      "Input: 0.115 MB, Params: 3,125,275 (11.922 MB), Total: 12.04 MB, FLOPs: 266,758,306\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Finished fine tuning.\n",
      "Iteration 355/1723 finished in 0m15s\n",
      "Total channels prunned so far: 355\n",
      "\n",
      "Iteration 356 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 349)]\n",
      "Input: 0.115 MB, Params: 3,121,661 (11.908 MB), Total: 12.02 MB, FLOPs: 266,693,298\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Finished fine tuning.\n",
      "Iteration 356/1723 finished in 0m15s\n",
      "Total channels prunned so far: 356\n",
      "\n",
      "Iteration 357 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 205)]\n",
      "Input: 0.115 MB, Params: 3,118,047 (11.894 MB), Total: 12.01 MB, FLOPs: 266,628,290\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.068%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Finished fine tuning.\n",
      "Iteration 357/1723 finished in 0m15s\n",
      "Total channels prunned so far: 357\n",
      "\n",
      "Iteration 358 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 84)]\n",
      "Input: 0.115 MB, Params: 3,114,433 (11.881 MB), Total: 12.00 MB, FLOPs: 266,563,282\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Finished fine tuning.\n",
      "Iteration 358/1723 finished in 0m15s\n",
      "Total channels prunned so far: 358\n",
      "\n",
      "Iteration 359 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 198)]\n",
      "Input: 0.115 MB, Params: 3,108,878 (11.859 MB), Total: 11.97 MB, FLOPs: 266,463,310\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Finished fine tuning.\n",
      "Iteration 359/1723 finished in 0m15s\n",
      "Total channels prunned so far: 359\n",
      "\n",
      "Iteration 360 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 89)]\n",
      "Input: 0.115 MB, Params: 3,103,323 (11.838 MB), Total: 11.95 MB, FLOPs: 266,222,578\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Finished fine tuning.\n",
      "Iteration 360/1723 finished in 0m15s\n",
      "Total channels prunned so far: 360\n",
      "\n",
      "Iteration 361 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 138)]\n",
      "Input: 0.115 MB, Params: 3,100,306 (11.827 MB), Total: 11.94 MB, FLOPs: 265,951,138\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Finished fine tuning.\n",
      "Iteration 361/1723 finished in 0m15s\n",
      "Total channels prunned so far: 361\n",
      "\n",
      "Iteration 362 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 45)]\n",
      "Input: 0.115 MB, Params: 3,094,760 (11.806 MB), Total: 11.92 MB, FLOPs: 265,851,328\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.492%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Finished fine tuning.\n",
      "Iteration 362/1723 finished in 0m15s\n",
      "Total channels prunned so far: 362\n",
      "\n",
      "Iteration 363 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 401)]\n",
      "Input: 0.115 MB, Params: 3,091,164 (11.792 MB), Total: 11.91 MB, FLOPs: 265,786,644\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.068%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Finished fine tuning.\n",
      "Iteration 363/1723 finished in 0m15s\n",
      "Total channels prunned so far: 363\n",
      "\n",
      "Iteration 364 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 227)]\n",
      "Input: 0.115 MB, Params: 3,085,627 (11.771 MB), Total: 11.89 MB, FLOPs: 265,686,996\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Finished fine tuning.\n",
      "Iteration 364/1723 finished in 0m15s\n",
      "Total channels prunned so far: 364\n",
      "\n",
      "Iteration 365 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 169)]\n",
      "Input: 0.115 MB, Params: 3,080,090 (11.750 MB), Total: 11.86 MB, FLOPs: 265,587,348\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Finished fine tuning.\n",
      "Iteration 365/1723 finished in 0m15s\n",
      "Total channels prunned so far: 365\n",
      "\n",
      "Iteration 366 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 263)]\n",
      "Input: 0.115 MB, Params: 3,076,512 (11.736 MB), Total: 11.85 MB, FLOPs: 265,522,988\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Finished fine tuning.\n",
      "Iteration 366/1723 finished in 0m15s\n",
      "Total channels prunned so far: 366\n",
      "\n",
      "Iteration 367 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 166)]\n",
      "Input: 0.115 MB, Params: 3,072,934 (11.722 MB), Total: 11.84 MB, FLOPs: 265,458,628\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Finished fine tuning.\n",
      "Iteration 367/1723 finished in 0m15s\n",
      "Total channels prunned so far: 367\n",
      "\n",
      "Iteration 368 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 46)]\n",
      "Input: 0.115 MB, Params: 3,067,415 (11.701 MB), Total: 11.82 MB, FLOPs: 265,219,192\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Finished fine tuning.\n",
      "Iteration 368/1723 finished in 0m15s\n",
      "Total channels prunned so far: 368\n",
      "\n",
      "Iteration 369 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 22)]\n",
      "Input: 0.115 MB, Params: 3,064,407 (11.690 MB), Total: 11.81 MB, FLOPs: 264,948,562\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.068%\n",
      "Finished fine tuning.\n",
      "Iteration 369/1723 finished in 0m15s\n",
      "Total channels prunned so far: 369\n",
      "\n",
      "Iteration 370 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 168)]\n",
      "Input: 0.115 MB, Params: 3,058,897 (11.669 MB), Total: 11.78 MB, FLOPs: 264,849,400\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.915%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Finished fine tuning.\n",
      "Iteration 370/1723 finished in 0m15s\n",
      "Total channels prunned so far: 370\n",
      "\n",
      "Iteration 371 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 329)]\n",
      "Input: 0.115 MB, Params: 3,053,387 (11.648 MB), Total: 11.76 MB, FLOPs: 264,750,238\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.068%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.254%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.068%\n",
      "Finished fine tuning.\n",
      "Iteration 371/1723 finished in 0m15s\n",
      "Total channels prunned so far: 371\n",
      "\n",
      "Iteration 372 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 72)]\n",
      "Input: 0.115 MB, Params: 3,050,442 (11.637 MB), Total: 11.75 MB, FLOPs: 264,165,065\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.492%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Finished fine tuning.\n",
      "Iteration 372/1723 finished in 0m15s\n",
      "Total channels prunned so far: 372\n",
      "\n",
      "Iteration 373 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 272)]\n",
      "Input: 0.115 MB, Params: 3,046,882 (11.623 MB), Total: 11.74 MB, FLOPs: 264,101,029\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Finished fine tuning.\n",
      "Iteration 373/1723 finished in 0m15s\n",
      "Total channels prunned so far: 373\n",
      "\n",
      "Iteration 374 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(7, 3)]\n",
      "Input: 0.115 MB, Params: 3,046,385 (11.621 MB), Total: 11.74 MB, FLOPs: 263,184,809\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.407%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Finished fine tuning.\n",
      "Iteration 374/1723 finished in 0m15s\n",
      "Total channels prunned so far: 374\n",
      "\n",
      "Iteration 375 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 368)]\n",
      "Input: 0.115 MB, Params: 3,040,884 (11.600 MB), Total: 11.72 MB, FLOPs: 263,085,809\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Finished fine tuning.\n",
      "Iteration 375/1723 finished in 0m15s\n",
      "Total channels prunned so far: 375\n",
      "\n",
      "Iteration 376 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 215)]\n",
      "Input: 0.115 MB, Params: 3,037,333 (11.587 MB), Total: 11.70 MB, FLOPs: 263,021,935\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Finished fine tuning.\n",
      "Iteration 376/1723 finished in 0m15s\n",
      "Total channels prunned so far: 376\n",
      "\n",
      "Iteration 377 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 349)]\n",
      "Input: 0.115 MB, Params: 3,031,841 (11.566 MB), Total: 11.68 MB, FLOPs: 262,923,097\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Finished fine tuning.\n",
      "Iteration 377/1723 finished in 0m15s\n",
      "Total channels prunned so far: 377\n",
      "\n",
      "Iteration 378 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 11)]\n",
      "Input: 0.115 MB, Params: 3,026,367 (11.545 MB), Total: 11.66 MB, FLOPs: 262,685,119\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Finished fine tuning.\n",
      "Iteration 378/1723 finished in 0m15s\n",
      "Total channels prunned so far: 378\n",
      "\n",
      "Iteration 379 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 57)]\n",
      "Input: 0.115 MB, Params: 3,020,893 (11.524 MB), Total: 11.64 MB, FLOPs: 262,447,141\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Finished fine tuning.\n",
      "Iteration 379/1723 finished in 0m15s\n",
      "Total channels prunned so far: 379\n",
      "\n",
      "Iteration 380 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 20)]\n",
      "Input: 0.115 MB, Params: 3,015,419 (11.503 MB), Total: 11.62 MB, FLOPs: 262,348,627\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Finished fine tuning.\n",
      "Iteration 380/1723 finished in 0m15s\n",
      "Total channels prunned so far: 380\n",
      "\n",
      "Iteration 381 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 35)]\n",
      "Input: 0.115 MB, Params: 3,012,438 (11.492 MB), Total: 11.61 MB, FLOPs: 262,080,427\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Finished fine tuning.\n",
      "Iteration 381/1723 finished in 0m15s\n",
      "Total channels prunned so far: 381\n",
      "\n",
      "Iteration 382 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 243)]\n",
      "Input: 0.115 MB, Params: 3,006,964 (11.471 MB), Total: 11.59 MB, FLOPs: 261,981,913\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Finished fine tuning.\n",
      "Iteration 382/1723 finished in 0m15s\n",
      "Total channels prunned so far: 382\n",
      "\n",
      "Iteration 383 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 3)]\n",
      "Input: 0.115 MB, Params: 3,001,517 (11.450 MB), Total: 11.57 MB, FLOPs: 261,745,069\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Finished fine tuning.\n",
      "Iteration 383/1723 finished in 0m15s\n",
      "Total channels prunned so far: 383\n",
      "\n",
      "Iteration 384 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 41)]\n",
      "Input: 0.115 MB, Params: 2,996,052 (11.429 MB), Total: 11.54 MB, FLOPs: 261,646,717\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Finished fine tuning.\n",
      "Iteration 384/1723 finished in 0m15s\n",
      "Total channels prunned so far: 384\n",
      "\n",
      "Iteration 385 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 6)]\n",
      "Input: 0.115 MB, Params: 2,990,614 (11.408 MB), Total: 11.52 MB, FLOPs: 261,410,035\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Finished fine tuning.\n",
      "Iteration 385/1723 finished in 0m15s\n",
      "Total channels prunned so far: 385\n",
      "\n",
      "Iteration 386 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 38)]\n",
      "Input: 0.115 MB, Params: 2,987,099 (11.395 MB), Total: 11.51 MB, FLOPs: 261,346,809\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.068%\n",
      "Finished fine tuning.\n",
      "Iteration 386/1723 finished in 0m15s\n",
      "Total channels prunned so far: 386\n",
      "\n",
      "Iteration 387 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 8)]\n",
      "Input: 0.115 MB, Params: 2,984,163 (11.384 MB), Total: 11.50 MB, FLOPs: 260,762,446\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Finished fine tuning.\n",
      "Iteration 387/1723 finished in 0m15s\n",
      "Total channels prunned so far: 387\n",
      "\n",
      "Iteration 388 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 254)]\n",
      "Input: 0.115 MB, Params: 2,978,716 (11.363 MB), Total: 11.48 MB, FLOPs: 260,664,418\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Finished fine tuning.\n",
      "Iteration 388/1723 finished in 0m15s\n",
      "Total channels prunned so far: 388\n",
      "\n",
      "Iteration 389 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 63)]\n",
      "Input: 0.115 MB, Params: 2,973,269 (11.342 MB), Total: 11.46 MB, FLOPs: 260,566,390\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Finished fine tuning.\n",
      "Iteration 389/1723 finished in 0m15s\n",
      "Total channels prunned so far: 389\n",
      "\n",
      "Iteration 390 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 325)]\n",
      "Input: 0.115 MB, Params: 2,967,822 (11.321 MB), Total: 11.44 MB, FLOPs: 260,468,362\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Finished fine tuning.\n",
      "Iteration 390/1723 finished in 0m15s\n",
      "Total channels prunned so far: 390\n",
      "\n",
      "Iteration 391 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 47)]\n",
      "Input: 0.115 MB, Params: 2,964,868 (11.310 MB), Total: 11.43 MB, FLOPs: 260,202,592\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Finished fine tuning.\n",
      "Iteration 391/1723 finished in 0m15s\n",
      "Total channels prunned so far: 391\n",
      "\n",
      "Iteration 392 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 199)]\n",
      "Input: 0.115 MB, Params: 2,959,421 (11.289 MB), Total: 11.40 MB, FLOPs: 260,104,564\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Finished fine tuning.\n",
      "Iteration 392/1723 finished in 0m15s\n",
      "Total channels prunned so far: 392\n",
      "\n",
      "Iteration 393 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 170)]\n",
      "Input: 0.115 MB, Params: 2,955,942 (11.276 MB), Total: 11.39 MB, FLOPs: 260,041,986\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Finished fine tuning.\n",
      "Iteration 393/1723 finished in 0m15s\n",
      "Total channels prunned so far: 393\n",
      "\n",
      "Iteration 394 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 133)]\n",
      "Input: 0.115 MB, Params: 2,952,988 (11.265 MB), Total: 11.38 MB, FLOPs: 259,776,216\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Finished fine tuning.\n",
      "Iteration 394/1723 finished in 0m15s\n",
      "Total channels prunned so far: 394\n",
      "\n",
      "Iteration 395 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 42)]\n",
      "Input: 0.115 MB, Params: 2,951,384 (11.259 MB), Total: 11.37 MB, FLOPs: 259,123,795\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Finished fine tuning.\n",
      "Iteration 395/1723 finished in 0m15s\n",
      "Total channels prunned so far: 395\n",
      "\n",
      "Iteration 396 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 139)]\n",
      "Input: 0.115 MB, Params: 2,946,000 (11.238 MB), Total: 11.35 MB, FLOPs: 258,889,381\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Finished fine tuning.\n",
      "Iteration 396/1723 finished in 0m15s\n",
      "Total channels prunned so far: 396\n",
      "\n",
      "Iteration 397 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 34)]\n",
      "Input: 0.115 MB, Params: 2,942,521 (11.225 MB), Total: 11.34 MB, FLOPs: 258,826,803\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Finished fine tuning.\n",
      "Iteration 397/1723 finished in 0m15s\n",
      "Total channels prunned so far: 397\n",
      "\n",
      "Iteration 398 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(7, 3)]\n",
      "Input: 0.115 MB, Params: 2,942,024 (11.223 MB), Total: 11.34 MB, FLOPs: 257,910,583\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Finished fine tuning.\n",
      "Iteration 398/1723 finished in 0m15s\n",
      "Total channels prunned so far: 398\n",
      "\n",
      "Iteration 399 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 174)]\n",
      "Input: 0.115 MB, Params: 2,936,604 (11.202 MB), Total: 11.32 MB, FLOPs: 257,813,041\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Finished fine tuning.\n",
      "Iteration 399/1723 finished in 0m15s\n",
      "Total channels prunned so far: 399\n",
      "\n",
      "Iteration 400 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 380)]\n",
      "Input: 0.115 MB, Params: 2,931,184 (11.182 MB), Total: 11.30 MB, FLOPs: 257,715,499\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.492%\n",
      "Finished fine tuning.\n",
      "Iteration 400/1723 finished in 0m15s\n",
      "Total channels prunned so far: 400\n",
      "\n",
      "Iteration 401 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 31)]\n",
      "Input: 0.115 MB, Params: 2,925,818 (11.161 MB), Total: 11.28 MB, FLOPs: 257,481,409\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.492%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.068%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Finished fine tuning.\n",
      "Iteration 401/1723 finished in 0m15s\n",
      "Total channels prunned so far: 401\n",
      "\n",
      "Iteration 402 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 77)]\n",
      "Input: 0.115 MB, Params: 2,920,452 (11.141 MB), Total: 11.26 MB, FLOPs: 257,247,319\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Finished fine tuning.\n",
      "Iteration 402/1723 finished in 0m15s\n",
      "Total channels prunned so far: 402\n",
      "\n",
      "Iteration 403 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 18)]\n",
      "Input: 0.115 MB, Params: 2,916,991 (11.127 MB), Total: 11.24 MB, FLOPs: 257,185,065\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Finished fine tuning.\n",
      "Iteration 403/1723 finished in 0m15s\n",
      "Total channels prunned so far: 403\n",
      "\n",
      "Iteration 404 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 327)]\n",
      "Input: 0.115 MB, Params: 2,913,530 (11.114 MB), Total: 11.23 MB, FLOPs: 257,122,811\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Finished fine tuning.\n",
      "Iteration 404/1723 finished in 0m15s\n",
      "Total channels prunned so far: 404\n",
      "\n",
      "Iteration 405 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 105)]\n",
      "Input: 0.115 MB, Params: 2,908,146 (11.094 MB), Total: 11.21 MB, FLOPs: 257,025,917\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Finished fine tuning.\n",
      "Iteration 405/1723 finished in 0m15s\n",
      "Total channels prunned so far: 405\n",
      "\n",
      "Iteration 406 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 211)]\n",
      "Input: 0.115 MB, Params: 2,904,694 (11.081 MB), Total: 11.20 MB, FLOPs: 256,963,825\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Finished fine tuning.\n",
      "Iteration 406/1723 finished in 0m15s\n",
      "Total channels prunned so far: 406\n",
      "\n",
      "Iteration 407 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 241)]\n",
      "Input: 0.115 MB, Params: 2,899,319 (11.060 MB), Total: 11.18 MB, FLOPs: 256,867,093\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Finished fine tuning.\n",
      "Iteration 407/1723 finished in 0m15s\n",
      "Total channels prunned so far: 407\n",
      "\n",
      "Iteration 408 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 233)]\n",
      "Input: 0.115 MB, Params: 2,895,876 (11.047 MB), Total: 11.16 MB, FLOPs: 256,805,163\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Finished fine tuning.\n",
      "Iteration 408/1723 finished in 0m15s\n",
      "Total channels prunned so far: 408\n",
      "\n",
      "Iteration 409 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 62)]\n",
      "Input: 0.115 MB, Params: 2,892,967 (11.036 MB), Total: 11.15 MB, FLOPs: 256,226,083\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Finished fine tuning.\n",
      "Iteration 409/1723 finished in 0m15s\n",
      "Total channels prunned so far: 409\n",
      "\n",
      "Iteration 410 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 189)]\n",
      "Input: 0.115 MB, Params: 2,887,601 (11.015 MB), Total: 11.13 MB, FLOPs: 256,129,513\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Finished fine tuning.\n",
      "Iteration 410/1723 finished in 0m15s\n",
      "Total channels prunned so far: 410\n",
      "\n",
      "Iteration 411 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 158)]\n",
      "Input: 0.115 MB, Params: 2,884,167 (11.002 MB), Total: 11.12 MB, FLOPs: 256,067,745\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Finished fine tuning.\n",
      "Iteration 411/1723 finished in 0m15s\n",
      "Total channels prunned so far: 411\n",
      "\n",
      "Iteration 412 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 86)]\n",
      "Input: 0.115 MB, Params: 2,878,810 (10.982 MB), Total: 11.10 MB, FLOPs: 255,971,337\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Finished fine tuning.\n",
      "Iteration 412/1723 finished in 0m15s\n",
      "Total channels prunned so far: 412\n",
      "\n",
      "Iteration 413 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 39)]\n",
      "Input: 0.115 MB, Params: 2,877,215 (10.976 MB), Total: 11.09 MB, FLOPs: 255,322,579\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Finished fine tuning.\n",
      "Iteration 413/1723 finished in 0m15s\n",
      "Total channels prunned so far: 413\n",
      "\n",
      "Iteration 414 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 286)]\n",
      "Input: 0.115 MB, Params: 2,873,790 (10.963 MB), Total: 11.08 MB, FLOPs: 255,260,973\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Finished fine tuning.\n",
      "Iteration 414/1723 finished in 0m15s\n",
      "Total channels prunned so far: 414\n",
      "\n",
      "Iteration 415 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 13)]\n",
      "Input: 0.115 MB, Params: 2,873,005 (10.960 MB), Total: 11.07 MB, FLOPs: 253,908,573\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.712%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.559%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Finished fine tuning.\n",
      "Iteration 415/1723 finished in 0m15s\n",
      "Total channels prunned so far: 415\n",
      "\n",
      "Iteration 416 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 78)]\n",
      "Input: 0.115 MB, Params: 2,867,657 (10.939 MB), Total: 11.05 MB, FLOPs: 253,812,327\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Finished fine tuning.\n",
      "Iteration 416/1723 finished in 0m15s\n",
      "Total channels prunned so far: 416\n",
      "\n",
      "Iteration 417 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 141)]\n",
      "Input: 0.115 MB, Params: 2,864,241 (10.926 MB), Total: 11.04 MB, FLOPs: 253,750,883\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Finished fine tuning.\n",
      "Iteration 417/1723 finished in 0m15s\n",
      "Total channels prunned so far: 417\n",
      "\n",
      "Iteration 418 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(14, 35)]\n",
      "Input: 0.115 MB, Params: 2,862,772 (10.921 MB), Total: 11.04 MB, FLOPs: 252,521,775\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Finished fine tuning.\n",
      "Iteration 418/1723 finished in 0m15s\n",
      "Total channels prunned so far: 418\n",
      "\n",
      "Iteration 419 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 67)]\n",
      "Input: 0.115 MB, Params: 2,857,433 (10.900 MB), Total: 11.02 MB, FLOPs: 252,425,691\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Finished fine tuning.\n",
      "Iteration 419/1723 finished in 0m15s\n",
      "Total channels prunned so far: 419\n",
      "\n",
      "Iteration 420 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 40)]\n",
      "Input: 0.115 MB, Params: 2,854,515 (10.889 MB), Total: 11.00 MB, FLOPs: 252,163,161\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Finished fine tuning.\n",
      "Iteration 420/1723 finished in 0m15s\n",
      "Total channels prunned so far: 420\n",
      "\n",
      "Iteration 421 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 262)]\n",
      "Input: 0.115 MB, Params: 2,849,176 (10.869 MB), Total: 10.98 MB, FLOPs: 252,067,077\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Finished fine tuning.\n",
      "Iteration 421/1723 finished in 0m15s\n",
      "Total channels prunned so far: 421\n",
      "\n",
      "Iteration 422 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(7, 14)]\n",
      "Input: 0.115 MB, Params: 2,848,688 (10.867 MB), Total: 10.98 MB, FLOPs: 251,166,382\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 68.644%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Finished fine tuning.\n",
      "Iteration 422/1723 finished in 0m15s\n",
      "Total channels prunned so far: 422\n",
      "\n",
      "Iteration 423 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 1)]\n",
      "Input: 0.115 MB, Params: 2,845,290 (10.854 MB), Total: 10.97 MB, FLOPs: 251,105,262\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Finished fine tuning.\n",
      "Iteration 423/1723 finished in 0m15s\n",
      "Total channels prunned so far: 423\n",
      "\n",
      "Iteration 424 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 63)]\n",
      "Input: 0.115 MB, Params: 2,842,372 (10.843 MB), Total: 10.96 MB, FLOPs: 250,842,732\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Finished fine tuning.\n",
      "Iteration 424/1723 finished in 0m15s\n",
      "Total channels prunned so far: 424\n",
      "\n",
      "Iteration 425 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 3)]\n",
      "Input: 0.115 MB, Params: 2,839,454 (10.832 MB), Total: 10.95 MB, FLOPs: 250,580,202\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Finished fine tuning.\n",
      "Iteration 425/1723 finished in 0m15s\n",
      "Total channels prunned so far: 425\n",
      "\n",
      "Iteration 426 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 5)]\n",
      "Input: 0.115 MB, Params: 2,836,536 (10.821 MB), Total: 10.94 MB, FLOPs: 250,317,672\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Finished fine tuning.\n",
      "Iteration 426/1723 finished in 0m15s\n",
      "Total channels prunned so far: 426\n",
      "\n",
      "Iteration 427 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 24)]\n",
      "Input: 0.115 MB, Params: 2,833,672 (10.810 MB), Total: 10.92 MB, FLOPs: 249,745,495\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Finished fine tuning.\n",
      "Iteration 427/1723 finished in 0m15s\n",
      "Total channels prunned so far: 427\n",
      "\n",
      "Iteration 428 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 273)]\n",
      "Input: 0.115 MB, Params: 2,828,342 (10.789 MB), Total: 10.90 MB, FLOPs: 249,649,573\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Finished fine tuning.\n",
      "Iteration 428/1723 finished in 0m15s\n",
      "Total channels prunned so far: 428\n",
      "\n",
      "Iteration 429 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 17)]\n",
      "Input: 0.115 MB, Params: 2,825,433 (10.778 MB), Total: 10.89 MB, FLOPs: 249,387,853\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Finished fine tuning.\n",
      "Iteration 429/1723 finished in 0m15s\n",
      "Total channels prunned so far: 429\n",
      "\n",
      "Iteration 430 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 8)]\n",
      "Input: 0.115 MB, Params: 2,822,524 (10.767 MB), Total: 10.88 MB, FLOPs: 249,126,133\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Finished fine tuning.\n",
      "Iteration 430/1723 finished in 0m15s\n",
      "Total channels prunned so far: 430\n",
      "\n",
      "Iteration 431 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 129)]\n",
      "Input: 0.115 MB, Params: 2,817,194 (10.747 MB), Total: 10.86 MB, FLOPs: 249,030,211\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Finished fine tuning.\n",
      "Iteration 431/1723 finished in 0m15s\n",
      "Total channels prunned so far: 431\n",
      "\n",
      "Iteration 432 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 36)]\n",
      "Input: 0.115 MB, Params: 2,811,963 (10.727 MB), Total: 10.84 MB, FLOPs: 248,802,439\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Finished fine tuning.\n",
      "Iteration 432/1723 finished in 0m15s\n",
      "Total channels prunned so far: 432\n",
      "\n",
      "Iteration 433 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 233)]\n",
      "Input: 0.115 MB, Params: 2,808,583 (10.714 MB), Total: 10.83 MB, FLOPs: 248,741,643\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Finished fine tuning.\n",
      "Iteration 433/1723 finished in 0m15s\n",
      "Total channels prunned so far: 433\n",
      "\n",
      "Iteration 434 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 99)]\n",
      "Input: 0.115 MB, Params: 2,807,006 (10.708 MB), Total: 10.82 MB, FLOPs: 248,100,211\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.254%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Finished fine tuning.\n",
      "Iteration 434/1723 finished in 0m15s\n",
      "Total channels prunned so far: 434\n",
      "\n",
      "Iteration 435 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 75)]\n",
      "Input: 0.115 MB, Params: 2,804,106 (10.697 MB), Total: 10.81 MB, FLOPs: 247,839,301\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Finished fine tuning.\n",
      "Iteration 435/1723 finished in 0m15s\n",
      "Total channels prunned so far: 435\n",
      "\n",
      "Iteration 436 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 84)]\n",
      "Input: 0.115 MB, Params: 2,802,529 (10.691 MB), Total: 10.81 MB, FLOPs: 247,197,869\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Finished fine tuning.\n",
      "Iteration 436/1723 finished in 0m15s\n",
      "Total channels prunned so far: 436\n",
      "\n",
      "Iteration 437 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 67)]\n",
      "Input: 0.115 MB, Params: 2,797,307 (10.671 MB), Total: 10.79 MB, FLOPs: 246,970,907\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Finished fine tuning.\n",
      "Iteration 437/1723 finished in 0m15s\n",
      "Total channels prunned so far: 437\n",
      "\n",
      "Iteration 438 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 11)]\n",
      "Input: 0.115 MB, Params: 2,795,730 (10.665 MB), Total: 10.78 MB, FLOPs: 246,329,475\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.068%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Finished fine tuning.\n",
      "Iteration 438/1723 finished in 0m15s\n",
      "Total channels prunned so far: 438\n",
      "\n",
      "Iteration 439 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 100)]\n",
      "Input: 0.115 MB, Params: 2,794,153 (10.659 MB), Total: 10.77 MB, FLOPs: 245,688,043\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.339%\n",
      "Finished fine tuning.\n",
      "Iteration 439/1723 finished in 0m15s\n",
      "Total channels prunned so far: 439\n",
      "\n",
      "Iteration 440 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 337)]\n",
      "Input: 0.115 MB, Params: 2,790,773 (10.646 MB), Total: 10.76 MB, FLOPs: 245,627,247\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Finished fine tuning.\n",
      "Iteration 440/1723 finished in 0m15s\n",
      "Total channels prunned so far: 440\n",
      "\n",
      "Iteration 441 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 328)]\n",
      "Input: 0.115 MB, Params: 2,787,393 (10.633 MB), Total: 10.75 MB, FLOPs: 245,566,451\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.492%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.492%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Finished fine tuning.\n",
      "Iteration 441/1723 finished in 0m15s\n",
      "Total channels prunned so far: 441\n",
      "\n",
      "Iteration 442 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 340)]\n",
      "Input: 0.115 MB, Params: 2,784,013 (10.620 MB), Total: 10.74 MB, FLOPs: 245,505,655\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Finished fine tuning.\n",
      "Iteration 442/1723 finished in 0m15s\n",
      "Total channels prunned so far: 442\n",
      "\n",
      "Iteration 443 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 109)]\n",
      "Input: 0.115 MB, Params: 2,778,737 (10.600 MB), Total: 10.72 MB, FLOPs: 245,410,705\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.068%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.492%\n",
      "Finished fine tuning.\n",
      "Iteration 443/1723 finished in 0m15s\n",
      "Total channels prunned so far: 443\n",
      "\n",
      "Iteration 444 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 83)]\n",
      "Input: 0.115 MB, Params: 2,775,936 (10.589 MB), Total: 10.70 MB, FLOPs: 244,855,610\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.068%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Finished fine tuning.\n",
      "Iteration 444/1723 finished in 0m15s\n",
      "Total channels prunned so far: 444\n",
      "\n",
      "Iteration 445 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 15)]\n",
      "Input: 0.115 MB, Params: 2,770,660 (10.569 MB), Total: 10.68 MB, FLOPs: 244,760,660\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.492%\n",
      "Finished fine tuning.\n",
      "Iteration 445/1723 finished in 0m15s\n",
      "Total channels prunned so far: 445\n",
      "\n",
      "Iteration 446 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(3, 29)]\n",
      "Input: 0.115 MB, Params: 2,770,618 (10.569 MB), Total: 10.68 MB, FLOPs: 244,402,667\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.068%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.492%\n",
      "Finished fine tuning.\n",
      "Iteration 446/1723 finished in 0m15s\n",
      "Total channels prunned so far: 446\n",
      "\n",
      "Iteration 447 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 128)]\n",
      "Input: 0.115 MB, Params: 2,765,414 (10.549 MB), Total: 10.66 MB, FLOPs: 244,176,029\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.068%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.983%\n",
      "Finished fine tuning.\n",
      "Iteration 447/1723 finished in 0m15s\n",
      "Total channels prunned so far: 447\n",
      "\n",
      "Iteration 448 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 281)]\n",
      "Input: 0.115 MB, Params: 2,762,052 (10.536 MB), Total: 10.65 MB, FLOPs: 244,115,557\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.831%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Finished fine tuning.\n",
      "Iteration 448/1723 finished in 0m15s\n",
      "Total channels prunned so far: 448\n",
      "\n",
      "Iteration 449 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 49)]\n",
      "Input: 0.115 MB, Params: 2,756,794 (10.516 MB), Total: 10.63 MB, FLOPs: 244,020,931\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Finished fine tuning.\n",
      "Iteration 449/1723 finished in 0m15s\n",
      "Total channels prunned so far: 449\n",
      "\n",
      "Iteration 450 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 2)]\n",
      "Input: 0.115 MB, Params: 2,751,599 (10.497 MB), Total: 10.61 MB, FLOPs: 243,794,455\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Finished fine tuning.\n",
      "Iteration 450/1723 finished in 0m15s\n",
      "Total channels prunned so far: 450\n",
      "\n",
      "Iteration 451 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 268)]\n",
      "Input: 0.115 MB, Params: 2,748,246 (10.484 MB), Total: 10.60 MB, FLOPs: 243,734,145\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Finished fine tuning.\n",
      "Iteration 451/1723 finished in 0m15s\n",
      "Total channels prunned so far: 451\n",
      "\n",
      "Iteration 452 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 281)]\n",
      "Input: 0.115 MB, Params: 2,744,893 (10.471 MB), Total: 10.59 MB, FLOPs: 243,673,835\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Finished fine tuning.\n",
      "Iteration 452/1723 finished in 0m15s\n",
      "Total channels prunned so far: 452\n",
      "\n",
      "Iteration 453 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 362)]\n",
      "Input: 0.115 MB, Params: 2,741,540 (10.458 MB), Total: 10.57 MB, FLOPs: 243,613,525\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Finished fine tuning.\n",
      "Iteration 453/1723 finished in 0m15s\n",
      "Total channels prunned so far: 453\n",
      "\n",
      "Iteration 454 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 16)]\n",
      "Input: 0.115 MB, Params: 2,738,187 (10.445 MB), Total: 10.56 MB, FLOPs: 243,553,215\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Finished fine tuning.\n",
      "Iteration 454/1723 finished in 0m15s\n",
      "Total channels prunned so far: 454\n",
      "\n",
      "Iteration 455 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 33)]\n",
      "Input: 0.115 MB, Params: 2,736,619 (10.439 MB), Total: 10.55 MB, FLOPs: 242,915,446\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Finished fine tuning.\n",
      "Iteration 455/1723 finished in 0m15s\n",
      "Total channels prunned so far: 455\n",
      "\n",
      "Iteration 456 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 81)]\n",
      "Input: 0.115 MB, Params: 2,733,266 (10.427 MB), Total: 10.54 MB, FLOPs: 242,855,136\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Finished fine tuning.\n",
      "Iteration 456/1723 finished in 0m15s\n",
      "Total channels prunned so far: 456\n",
      "\n",
      "Iteration 457 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 122)]\n",
      "Input: 0.115 MB, Params: 2,728,071 (10.407 MB), Total: 10.52 MB, FLOPs: 242,628,660\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Finished fine tuning.\n",
      "Iteration 457/1723 finished in 0m15s\n",
      "Total channels prunned so far: 457\n",
      "\n",
      "Iteration 458 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 204)]\n",
      "Input: 0.115 MB, Params: 2,724,718 (10.394 MB), Total: 10.51 MB, FLOPs: 242,568,350\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.068%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Finished fine tuning.\n",
      "Iteration 458/1723 finished in 0m15s\n",
      "Total channels prunned so far: 458\n",
      "\n",
      "Iteration 459 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 48)]\n",
      "Input: 0.115 MB, Params: 2,719,532 (10.374 MB), Total: 10.49 MB, FLOPs: 242,475,020\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Finished fine tuning.\n",
      "Iteration 459/1723 finished in 0m15s\n",
      "Total channels prunned so far: 459\n",
      "\n",
      "Iteration 460 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 303)]\n",
      "Input: 0.115 MB, Params: 2,716,188 (10.361 MB), Total: 10.48 MB, FLOPs: 242,414,872\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Finished fine tuning.\n",
      "Iteration 460/1723 finished in 0m15s\n",
      "Total channels prunned so far: 460\n",
      "\n",
      "Iteration 461 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 82)]\n",
      "Input: 0.115 MB, Params: 2,711,011 (10.342 MB), Total: 10.46 MB, FLOPs: 242,321,704\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Finished fine tuning.\n",
      "Iteration 461/1723 finished in 0m15s\n",
      "Total channels prunned so far: 461\n",
      "\n",
      "Iteration 462 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 155)]\n",
      "Input: 0.115 MB, Params: 2,705,834 (10.322 MB), Total: 10.44 MB, FLOPs: 242,095,552\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Finished fine tuning.\n",
      "Iteration 462/1723 finished in 0m15s\n",
      "Total channels prunned so far: 462\n",
      "\n",
      "Iteration 463 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 46)]\n",
      "Input: 0.115 MB, Params: 2,703,042 (10.311 MB), Total: 10.43 MB, FLOPs: 241,544,120\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.492%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Finished fine tuning.\n",
      "Iteration 463/1723 finished in 0m15s\n",
      "Total channels prunned so far: 463\n",
      "\n",
      "Iteration 464 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 32)]\n",
      "Input: 0.115 MB, Params: 2,697,874 (10.292 MB), Total: 10.41 MB, FLOPs: 241,451,114\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.492%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.068%\n",
      "Finished fine tuning.\n",
      "Iteration 464/1723 finished in 0m15s\n",
      "Total channels prunned so far: 464\n",
      "\n",
      "Iteration 465 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 191)]\n",
      "Input: 0.115 MB, Params: 2,695,037 (10.281 MB), Total: 10.40 MB, FLOPs: 241,195,874\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.915%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.492%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Finished fine tuning.\n",
      "Iteration 465/1723 finished in 0m15s\n",
      "Total channels prunned so far: 465\n",
      "\n",
      "Iteration 466 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 11)]\n",
      "Input: 0.115 MB, Params: 2,692,200 (10.270 MB), Total: 10.39 MB, FLOPs: 240,940,634\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Finished fine tuning.\n",
      "Iteration 466/1723 finished in 0m15s\n",
      "Total channels prunned so far: 466\n",
      "\n",
      "Iteration 467 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 121)]\n",
      "Input: 0.115 MB, Params: 2,687,032 (10.250 MB), Total: 10.37 MB, FLOPs: 240,847,628\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Finished fine tuning.\n",
      "Iteration 467/1723 finished in 0m15s\n",
      "Total channels prunned so far: 467\n",
      "\n",
      "Iteration 468 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 34)]\n",
      "Input: 0.115 MB, Params: 2,684,195 (10.239 MB), Total: 10.35 MB, FLOPs: 240,592,388\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.068%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Finished fine tuning.\n",
      "Iteration 468/1723 finished in 0m15s\n",
      "Total channels prunned so far: 468\n",
      "\n",
      "Iteration 469 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 55)]\n",
      "Input: 0.115 MB, Params: 2,680,878 (10.227 MB), Total: 10.34 MB, FLOPs: 240,532,726\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Finished fine tuning.\n",
      "Iteration 469/1723 finished in 0m15s\n",
      "Total channels prunned so far: 469\n",
      "\n",
      "Iteration 470 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 19)]\n",
      "Input: 0.115 MB, Params: 2,680,111 (10.224 MB), Total: 10.34 MB, FLOPs: 239,211,376\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Finished fine tuning.\n",
      "Iteration 470/1723 finished in 0m15s\n",
      "Total channels prunned so far: 470\n",
      "\n",
      "Iteration 471 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 50)]\n",
      "Input: 0.115 MB, Params: 2,679,344 (10.221 MB), Total: 10.34 MB, FLOPs: 237,890,026\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Finished fine tuning.\n",
      "Iteration 471/1723 finished in 0m15s\n",
      "Total channels prunned so far: 471\n",
      "\n",
      "Iteration 472 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 42)]\n",
      "Input: 0.115 MB, Params: 2,676,579 (10.210 MB), Total: 10.33 MB, FLOPs: 237,341,024\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Finished fine tuning.\n",
      "Iteration 472/1723 finished in 0m15s\n",
      "Total channels prunned so far: 472\n",
      "\n",
      "Iteration 473 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 29)]\n",
      "Input: 0.115 MB, Params: 2,675,029 (10.204 MB), Total: 10.32 MB, FLOPs: 236,710,581\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.068%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Finished fine tuning.\n",
      "Iteration 473/1723 finished in 0m15s\n",
      "Total channels prunned so far: 473\n",
      "\n",
      "Iteration 474 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 187)]\n",
      "Input: 0.115 MB, Params: 2,669,870 (10.185 MB), Total: 10.30 MB, FLOPs: 236,617,737\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Finished fine tuning.\n",
      "Iteration 474/1723 finished in 0m15s\n",
      "Total channels prunned so far: 474\n",
      "\n",
      "Iteration 475 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 309)]\n",
      "Input: 0.115 MB, Params: 2,666,562 (10.172 MB), Total: 10.29 MB, FLOPs: 236,558,237\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.068%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.068%\n",
      "Finished fine tuning.\n",
      "Iteration 475/1723 finished in 0m15s\n",
      "Total channels prunned so far: 475\n",
      "\n",
      "Iteration 476 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 326)]\n",
      "Input: 0.115 MB, Params: 2,663,254 (10.160 MB), Total: 10.27 MB, FLOPs: 236,498,737\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.915%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Finished fine tuning.\n",
      "Iteration 476/1723 finished in 0m15s\n",
      "Total channels prunned so far: 476\n",
      "\n",
      "Iteration 477 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 350)]\n",
      "Input: 0.115 MB, Params: 2,659,946 (10.147 MB), Total: 10.26 MB, FLOPs: 236,439,237\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Finished fine tuning.\n",
      "Iteration 477/1723 finished in 0m15s\n",
      "Total channels prunned so far: 477\n",
      "\n",
      "Iteration 478 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 57)]\n",
      "Input: 0.115 MB, Params: 2,658,396 (10.141 MB), Total: 10.26 MB, FLOPs: 235,808,794\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Finished fine tuning.\n",
      "Iteration 478/1723 finished in 0m15s\n",
      "Total channels prunned so far: 478\n",
      "\n",
      "Iteration 479 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 55)]\n",
      "Input: 0.115 MB, Params: 2,656,846 (10.135 MB), Total: 10.25 MB, FLOPs: 235,178,351\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Finished fine tuning.\n",
      "Iteration 479/1723 finished in 0m15s\n",
      "Total channels prunned so far: 479\n",
      "\n",
      "Iteration 480 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 273)]\n",
      "Input: 0.115 MB, Params: 2,651,714 (10.115 MB), Total: 10.23 MB, FLOPs: 235,085,993\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Finished fine tuning.\n",
      "Iteration 480/1723 finished in 0m15s\n",
      "Total channels prunned so far: 480\n",
      "\n",
      "Iteration 481 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 209)]\n",
      "Input: 0.115 MB, Params: 2,646,582 (10.096 MB), Total: 10.21 MB, FLOPs: 234,993,635\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Finished fine tuning.\n",
      "Iteration 481/1723 finished in 0m15s\n",
      "Total channels prunned so far: 481\n",
      "\n",
      "Iteration 482 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(14, 13)]\n",
      "Input: 0.115 MB, Params: 2,645,203 (10.091 MB), Total: 10.21 MB, FLOPs: 233,824,881\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Finished fine tuning.\n",
      "Iteration 482/1723 finished in 0m15s\n",
      "Total channels prunned so far: 482\n",
      "\n",
      "Iteration 483 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 321)]\n",
      "Input: 0.115 MB, Params: 2,640,071 (10.071 MB), Total: 10.19 MB, FLOPs: 233,732,523\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Finished fine tuning.\n",
      "Iteration 483/1723 finished in 0m15s\n",
      "Total channels prunned so far: 483\n",
      "\n",
      "Iteration 484 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 316)]\n",
      "Input: 0.115 MB, Params: 2,636,790 (10.059 MB), Total: 10.17 MB, FLOPs: 233,673,509\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.254%\n",
      "Finished fine tuning.\n",
      "Iteration 484/1723 finished in 0m15s\n",
      "Total channels prunned so far: 484\n",
      "\n",
      "Iteration 485 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 314)]\n",
      "Input: 0.115 MB, Params: 2,633,509 (10.046 MB), Total: 10.16 MB, FLOPs: 233,614,495\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Finished fine tuning.\n",
      "Iteration 485/1723 finished in 0m15s\n",
      "Total channels prunned so far: 485\n",
      "\n",
      "Iteration 486 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 75)]\n",
      "Input: 0.115 MB, Params: 2,630,681 (10.035 MB), Total: 10.15 MB, FLOPs: 233,360,065\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Finished fine tuning.\n",
      "Iteration 486/1723 finished in 0m15s\n",
      "Total channels prunned so far: 486\n",
      "\n",
      "Iteration 487 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 178)]\n",
      "Input: 0.115 MB, Params: 2,627,400 (10.023 MB), Total: 10.14 MB, FLOPs: 233,301,051\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.068%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Finished fine tuning.\n",
      "Iteration 487/1723 finished in 0m15s\n",
      "Total channels prunned so far: 487\n",
      "\n",
      "Iteration 488 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 44)]\n",
      "Input: 0.115 MB, Params: 2,622,295 (10.003 MB), Total: 10.12 MB, FLOPs: 233,209,179\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Finished fine tuning.\n",
      "Iteration 488/1723 finished in 0m15s\n",
      "Total channels prunned so far: 488\n",
      "\n",
      "Iteration 489 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 291)]\n",
      "Input: 0.115 MB, Params: 2,617,190 (9.984 MB), Total: 10.10 MB, FLOPs: 233,117,307\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Finished fine tuning.\n",
      "Iteration 489/1723 finished in 0m15s\n",
      "Total channels prunned so far: 489\n",
      "\n",
      "Iteration 490 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 100)]\n",
      "Input: 0.115 MB, Params: 2,612,121 (9.964 MB), Total: 10.08 MB, FLOPs: 232,895,691\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Finished fine tuning.\n",
      "Iteration 490/1723 finished in 0m15s\n",
      "Total channels prunned so far: 490\n",
      "\n",
      "Iteration 491 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 258)]\n",
      "Input: 0.115 MB, Params: 2,607,025 (9.945 MB), Total: 10.06 MB, FLOPs: 232,803,981\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.254%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.831%\n",
      "Finished fine tuning.\n",
      "Iteration 491/1723 finished in 0m15s\n",
      "Total channels prunned so far: 491\n",
      "\n",
      "Iteration 492 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 216)]\n",
      "Input: 0.115 MB, Params: 2,603,771 (9.933 MB), Total: 10.05 MB, FLOPs: 232,745,453\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Finished fine tuning.\n",
      "Iteration 492/1723 finished in 0m15s\n",
      "Total channels prunned so far: 492\n",
      "\n",
      "Iteration 493 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 350)]\n",
      "Input: 0.115 MB, Params: 2,598,684 (9.913 MB), Total: 10.03 MB, FLOPs: 232,653,905\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.068%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.492%\n",
      "Finished fine tuning.\n",
      "Iteration 493/1723 finished in 0m15s\n",
      "Total channels prunned so far: 493\n",
      "\n",
      "Iteration 494 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 71)]\n",
      "Input: 0.115 MB, Params: 2,595,865 (9.902 MB), Total: 10.02 MB, FLOPs: 232,400,285\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Finished fine tuning.\n",
      "Iteration 494/1723 finished in 0m15s\n",
      "Total channels prunned so far: 494\n",
      "\n",
      "Iteration 495 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 112)]\n",
      "Input: 0.115 MB, Params: 2,592,620 (9.890 MB), Total: 10.01 MB, FLOPs: 232,341,919\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Finished fine tuning.\n",
      "Iteration 495/1723 finished in 0m15s\n",
      "Total channels prunned so far: 495\n",
      "\n",
      "Iteration 496 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 125)]\n",
      "Input: 0.115 MB, Params: 2,589,801 (9.879 MB), Total: 9.99 MB, FLOPs: 232,088,299\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Finished fine tuning.\n",
      "Iteration 496/1723 finished in 0m15s\n",
      "Total channels prunned so far: 496\n",
      "\n",
      "Iteration 497 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 15)]\n",
      "Input: 0.115 MB, Params: 2,589,043 (9.876 MB), Total: 9.99 MB, FLOPs: 230,782,474\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.831%\n",
      "Finished fine tuning.\n",
      "Iteration 497/1723 finished in 0m15s\n",
      "Total channels prunned so far: 497\n",
      "\n",
      "Iteration 498 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(7, 25)]\n",
      "Input: 0.115 MB, Params: 2,588,582 (9.875 MB), Total: 9.99 MB, FLOPs: 229,929,864\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Finished fine tuning.\n",
      "Iteration 498/1723 finished in 0m15s\n",
      "Total channels prunned so far: 498\n",
      "\n",
      "Iteration 499 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 292)]\n",
      "Input: 0.115 MB, Params: 2,583,504 (9.855 MB), Total: 9.97 MB, FLOPs: 229,838,478\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Finished fine tuning.\n",
      "Iteration 499/1723 finished in 0m15s\n",
      "Total channels prunned so far: 499\n",
      "\n",
      "Iteration 500 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 252)]\n",
      "Input: 0.115 MB, Params: 2,580,268 (9.843 MB), Total: 9.96 MB, FLOPs: 229,780,274\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.831%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.831%\n",
      "Finished fine tuning.\n",
      "Iteration 500/1723 finished in 0m15s\n",
      "Total channels prunned so far: 500\n",
      "\n",
      "Iteration 501 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(3, 45)]\n",
      "Input: 0.115 MB, Params: 2,580,226 (9.843 MB), Total: 9.96 MB, FLOPs: 226,606,716\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Finished fine tuning.\n",
      "Iteration 501/1723 finished in 0m15s\n",
      "Total channels prunned so far: 501\n",
      "\n",
      "Iteration 502 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 328)]\n",
      "Input: 0.115 MB, Params: 2,576,990 (9.830 MB), Total: 9.95 MB, FLOPs: 226,548,512\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Finished fine tuning.\n",
      "Iteration 502/1723 finished in 0m15s\n",
      "Total channels prunned so far: 502\n",
      "\n",
      "Iteration 503 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 15)]\n",
      "Input: 0.115 MB, Params: 2,574,171 (9.820 MB), Total: 9.93 MB, FLOPs: 226,294,892\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.068%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.068%\n",
      "Finished fine tuning.\n",
      "Iteration 503/1723 finished in 0m15s\n",
      "Total channels prunned so far: 503\n",
      "\n",
      "Iteration 504 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 63)]\n",
      "Input: 0.115 MB, Params: 2,569,111 (9.800 MB), Total: 9.92 MB, FLOPs: 226,203,830\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Finished fine tuning.\n",
      "Iteration 504/1723 finished in 0m15s\n",
      "Total channels prunned so far: 504\n",
      "\n",
      "Iteration 505 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 4)]\n",
      "Input: 0.115 MB, Params: 2,565,884 (9.788 MB), Total: 9.90 MB, FLOPs: 226,145,788\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Finished fine tuning.\n",
      "Iteration 505/1723 finished in 0m15s\n",
      "Total channels prunned so far: 505\n",
      "\n",
      "Iteration 506 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 116)]\n",
      "Input: 0.115 MB, Params: 2,560,833 (9.769 MB), Total: 9.88 MB, FLOPs: 226,054,888\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.068%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Finished fine tuning.\n",
      "Iteration 506/1723 finished in 0m15s\n",
      "Total channels prunned so far: 506\n",
      "\n",
      "Iteration 507 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 175)]\n",
      "Input: 0.115 MB, Params: 2,557,615 (9.757 MB), Total: 9.87 MB, FLOPs: 225,997,008\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.068%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Finished fine tuning.\n",
      "Iteration 507/1723 finished in 0m15s\n",
      "Total channels prunned so far: 507\n",
      "\n",
      "Iteration 508 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 72)]\n",
      "Input: 0.115 MB, Params: 2,554,796 (9.746 MB), Total: 9.86 MB, FLOPs: 225,743,388\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Finished fine tuning.\n",
      "Iteration 508/1723 finished in 0m15s\n",
      "Total channels prunned so far: 508\n",
      "\n",
      "Iteration 509 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 185)]\n",
      "Input: 0.115 MB, Params: 2,551,977 (9.735 MB), Total: 9.85 MB, FLOPs: 225,489,768\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Finished fine tuning.\n",
      "Iteration 509/1723 finished in 0m15s\n",
      "Total channels prunned so far: 509\n",
      "\n",
      "Iteration 510 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 99)]\n",
      "Input: 0.115 MB, Params: 2,548,759 (9.723 MB), Total: 9.84 MB, FLOPs: 225,431,888\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.068%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.492%\n",
      "Finished fine tuning.\n",
      "Iteration 510/1723 finished in 0m15s\n",
      "Total channels prunned so far: 510\n",
      "\n",
      "Iteration 511 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 22)]\n",
      "Input: 0.115 MB, Params: 2,547,218 (9.717 MB), Total: 9.83 MB, FLOPs: 224,805,108\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.492%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Finished fine tuning.\n",
      "Iteration 511/1723 finished in 0m15s\n",
      "Total channels prunned so far: 511\n",
      "\n",
      "Iteration 512 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 338)]\n",
      "Input: 0.115 MB, Params: 2,542,185 (9.698 MB), Total: 9.81 MB, FLOPs: 224,714,532\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Finished fine tuning.\n",
      "Iteration 512/1723 finished in 0m15s\n",
      "Total channels prunned so far: 512\n",
      "\n",
      "Iteration 513 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 142)]\n",
      "Input: 0.115 MB, Params: 2,538,976 (9.685 MB), Total: 9.80 MB, FLOPs: 224,656,814\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.492%\n",
      "Finished fine tuning.\n",
      "Iteration 513/1723 finished in 0m15s\n",
      "Total channels prunned so far: 513\n",
      "\n",
      "Iteration 514 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 1)]\n",
      "Input: 0.115 MB, Params: 2,533,952 (9.666 MB), Total: 9.78 MB, FLOPs: 224,566,400\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.492%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Finished fine tuning.\n",
      "Iteration 514/1723 finished in 0m15s\n",
      "Total channels prunned so far: 514\n",
      "\n",
      "Iteration 515 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 215)]\n",
      "Input: 0.115 MB, Params: 2,530,752 (9.654 MB), Total: 9.77 MB, FLOPs: 224,508,844\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Finished fine tuning.\n",
      "Iteration 515/1723 finished in 0m15s\n",
      "Total channels prunned so far: 515\n",
      "\n",
      "Iteration 516 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 330)]\n",
      "Input: 0.115 MB, Params: 2,525,737 (9.635 MB), Total: 9.75 MB, FLOPs: 224,418,592\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.068%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Finished fine tuning.\n",
      "Iteration 516/1723 finished in 0m15s\n",
      "Total channels prunned so far: 516\n",
      "\n",
      "Iteration 517 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(14, 40)]\n",
      "Input: 0.115 MB, Params: 2,524,376 (9.630 MB), Total: 9.75 MB, FLOPs: 223,302,851\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.492%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Finished fine tuning.\n",
      "Iteration 517/1723 finished in 0m15s\n",
      "Total channels prunned so far: 517\n",
      "\n",
      "Iteration 518 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 54)]\n",
      "Input: 0.115 MB, Params: 2,521,185 (9.618 MB), Total: 9.73 MB, FLOPs: 223,245,457\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.068%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.068%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Finished fine tuning.\n",
      "Iteration 518/1723 finished in 0m15s\n",
      "Total channels prunned so far: 518\n",
      "\n",
      "Iteration 519 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 52)]\n",
      "Input: 0.115 MB, Params: 2,516,179 (9.598 MB), Total: 9.71 MB, FLOPs: 223,155,367\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.915%\n",
      "Finished fine tuning.\n",
      "Iteration 519/1723 finished in 0m15s\n",
      "Total channels prunned so far: 519\n",
      "\n",
      "Iteration 520 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 154)]\n",
      "Input: 0.115 MB, Params: 2,511,173 (9.579 MB), Total: 9.69 MB, FLOPs: 223,065,277\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.492%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.339%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.915%\n",
      "Finished fine tuning.\n",
      "Iteration 520/1723 finished in 0m15s\n",
      "Total channels prunned so far: 520\n",
      "\n",
      "Iteration 521 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 127)]\n",
      "Input: 0.115 MB, Params: 2,508,000 (9.567 MB), Total: 9.68 MB, FLOPs: 223,008,207\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.492%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.068%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.068%\n",
      "Finished fine tuning.\n",
      "Iteration 521/1723 finished in 0m15s\n",
      "Total channels prunned so far: 521\n",
      "\n",
      "Iteration 522 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 43)]\n",
      "Input: 0.115 MB, Params: 2,504,827 (9.555 MB), Total: 9.67 MB, FLOPs: 222,951,137\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.068%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Finished fine tuning.\n",
      "Iteration 522/1723 finished in 0m15s\n",
      "Total channels prunned so far: 522\n",
      "\n",
      "Iteration 523 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 64)]\n",
      "Input: 0.115 MB, Params: 2,499,839 (9.536 MB), Total: 9.65 MB, FLOPs: 222,861,371\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.492%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Finished fine tuning.\n",
      "Iteration 523/1723 finished in 0m15s\n",
      "Total channels prunned so far: 523\n",
      "\n",
      "Iteration 524 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 317)]\n",
      "Input: 0.115 MB, Params: 2,496,675 (9.524 MB), Total: 9.64 MB, FLOPs: 222,804,463\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Finished fine tuning.\n",
      "Iteration 524/1723 finished in 0m15s\n",
      "Total channels prunned so far: 524\n",
      "\n",
      "Iteration 525 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 331)]\n",
      "Input: 0.115 MB, Params: 2,493,511 (9.512 MB), Total: 9.63 MB, FLOPs: 222,747,555\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Finished fine tuning.\n",
      "Iteration 525/1723 finished in 0m15s\n",
      "Total channels prunned so far: 525\n",
      "\n",
      "Iteration 526 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 91)]\n",
      "Input: 0.115 MB, Params: 2,488,541 (9.493 MB), Total: 9.61 MB, FLOPs: 222,658,113\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.492%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.492%\n",
      "Finished fine tuning.\n",
      "Iteration 526/1723 finished in 0m15s\n",
      "Total channels prunned so far: 526\n",
      "\n",
      "Iteration 527 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 212)]\n",
      "Input: 0.115 MB, Params: 2,483,571 (9.474 MB), Total: 9.59 MB, FLOPs: 222,568,671\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.339%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Finished fine tuning.\n",
      "Iteration 527/1723 finished in 0m15s\n",
      "Total channels prunned so far: 527\n",
      "\n",
      "Iteration 528 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 44)]\n",
      "Input: 0.115 MB, Params: 2,478,664 (9.455 MB), Total: 9.57 MB, FLOPs: 222,353,211\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Finished fine tuning.\n",
      "Iteration 528/1723 finished in 0m15s\n",
      "Total channels prunned so far: 528\n",
      "\n",
      "Iteration 529 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 1)]\n",
      "Input: 0.115 MB, Params: 2,475,854 (9.445 MB), Total: 9.56 MB, FLOPs: 222,100,401\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.068%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Finished fine tuning.\n",
      "Iteration 529/1723 finished in 0m15s\n",
      "Total channels prunned so far: 529\n",
      "\n",
      "Iteration 530 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 46)]\n",
      "Input: 0.115 MB, Params: 2,475,114 (9.442 MB), Total: 9.56 MB, FLOPs: 220,881,051\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.915%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Finished fine tuning.\n",
      "Iteration 530/1723 finished in 0m15s\n",
      "Total channels prunned so far: 530\n",
      "\n",
      "Iteration 531 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 292)]\n",
      "Input: 0.115 MB, Params: 2,471,968 (9.430 MB), Total: 9.55 MB, FLOPs: 220,824,467\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Finished fine tuning.\n",
      "Iteration 531/1723 finished in 0m15s\n",
      "Total channels prunned so far: 531\n",
      "\n",
      "Iteration 532 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 43)]\n",
      "Input: 0.115 MB, Params: 2,469,302 (9.420 MB), Total: 9.53 MB, FLOPs: 220,295,787\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.492%\n",
      "Finished fine tuning.\n",
      "Iteration 532/1723 finished in 0m15s\n",
      "Total channels prunned so far: 532\n",
      "\n",
      "Iteration 533 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 73)]\n",
      "Input: 0.115 MB, Params: 2,464,350 (9.401 MB), Total: 9.52 MB, FLOPs: 220,206,669\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.915%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.492%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Finished fine tuning.\n",
      "Iteration 533/1723 finished in 0m15s\n",
      "Total channels prunned so far: 533\n",
      "\n",
      "Iteration 534 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 68)]\n",
      "Input: 0.115 MB, Params: 2,461,684 (9.391 MB), Total: 9.51 MB, FLOPs: 219,677,989\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.068%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.915%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.492%\n",
      "Finished fine tuning.\n",
      "Iteration 534/1723 finished in 0m15s\n",
      "Total channels prunned so far: 534\n",
      "\n",
      "Iteration 535 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 26)]\n",
      "Input: 0.115 MB, Params: 2,460,170 (9.385 MB), Total: 9.50 MB, FLOPs: 219,062,198\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.915%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.915%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.915%\n",
      "Finished fine tuning.\n",
      "Iteration 535/1723 finished in 0m15s\n",
      "Total channels prunned so far: 535\n",
      "\n",
      "Iteration 536 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 110)]\n",
      "Input: 0.115 MB, Params: 2,455,281 (9.366 MB), Total: 9.48 MB, FLOPs: 218,847,710\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.915%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.915%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Finished fine tuning.\n",
      "Iteration 536/1723 finished in 0m15s\n",
      "Total channels prunned so far: 536\n",
      "\n",
      "Iteration 537 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 76)]\n",
      "Input: 0.115 MB, Params: 2,450,338 (9.347 MB), Total: 9.46 MB, FLOPs: 218,758,754\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.068%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Finished fine tuning.\n",
      "Iteration 537/1723 finished in 0m15s\n",
      "Total channels prunned so far: 537\n",
      "\n",
      "Iteration 538 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 6)]\n",
      "Input: 0.115 MB, Params: 2,448,824 (9.342 MB), Total: 9.46 MB, FLOPs: 218,142,963\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.068%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Finished fine tuning.\n",
      "Iteration 538/1723 finished in 0m15s\n",
      "Total channels prunned so far: 538\n",
      "\n",
      "Iteration 539 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 253)]\n",
      "Input: 0.115 MB, Params: 2,443,881 (9.323 MB), Total: 9.44 MB, FLOPs: 218,054,007\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.068%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Finished fine tuning.\n",
      "Iteration 539/1723 finished in 0m15s\n",
      "Total channels prunned so far: 539\n",
      "\n",
      "Iteration 540 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 172)]\n",
      "Input: 0.115 MB, Params: 2,441,098 (9.312 MB), Total: 9.43 MB, FLOPs: 217,803,627\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.492%\n",
      "Finished fine tuning.\n",
      "Iteration 540/1723 finished in 0m15s\n",
      "Total channels prunned so far: 540\n",
      "\n",
      "Iteration 541 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 29)]\n",
      "Input: 0.115 MB, Params: 2,436,155 (9.293 MB), Total: 9.41 MB, FLOPs: 217,714,671\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.068%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.339%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.763%\n",
      "Finished fine tuning.\n",
      "Iteration 541/1723 finished in 0m15s\n",
      "Total channels prunned so far: 541\n",
      "\n",
      "Iteration 542 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 11)]\n",
      "Input: 0.115 MB, Params: 2,431,212 (9.274 MB), Total: 9.39 MB, FLOPs: 217,625,715\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.339%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Finished fine tuning.\n",
      "Iteration 542/1723 finished in 0m15s\n",
      "Total channels prunned so far: 542\n",
      "\n",
      "Iteration 543 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 58)]\n",
      "Input: 0.115 MB, Params: 2,428,429 (9.264 MB), Total: 9.38 MB, FLOPs: 217,375,335\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.915%\n",
      "Finished fine tuning.\n",
      "Iteration 543/1723 finished in 0m15s\n",
      "Total channels prunned so far: 543\n",
      "\n",
      "Iteration 544 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 142)]\n",
      "Input: 0.115 MB, Params: 2,423,594 (9.245 MB), Total: 9.36 MB, FLOPs: 217,163,115\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.339%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.763%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.915%\n",
      "Finished fine tuning.\n",
      "Iteration 544/1723 finished in 0m15s\n",
      "Total channels prunned so far: 544\n",
      "\n",
      "Iteration 545 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 55)]\n",
      "Input: 0.115 MB, Params: 2,418,759 (9.227 MB), Total: 9.34 MB, FLOPs: 216,950,895\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.763%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Finished fine tuning.\n",
      "Iteration 545/1723 finished in 0m15s\n",
      "Total channels prunned so far: 545\n",
      "\n",
      "Iteration 546 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 162)]\n",
      "Input: 0.115 MB, Params: 2,415,658 (9.215 MB), Total: 9.33 MB, FLOPs: 216,895,121\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Finished fine tuning.\n",
      "Iteration 546/1723 finished in 0m15s\n",
      "Total channels prunned so far: 546\n",
      "\n",
      "Iteration 547 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 180)]\n",
      "Input: 0.115 MB, Params: 2,412,557 (9.203 MB), Total: 9.32 MB, FLOPs: 216,839,347\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Finished fine tuning.\n",
      "Iteration 547/1723 finished in 0m15s\n",
      "Total channels prunned so far: 547\n",
      "\n",
      "Iteration 548 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 51)]\n",
      "Input: 0.115 MB, Params: 2,407,722 (9.185 MB), Total: 9.30 MB, FLOPs: 216,627,127\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Finished fine tuning.\n",
      "Iteration 548/1723 finished in 0m15s\n",
      "Total channels prunned so far: 548\n",
      "\n",
      "Iteration 549 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 328)]\n",
      "Input: 0.115 MB, Params: 2,402,824 (9.166 MB), Total: 9.28 MB, FLOPs: 216,538,981\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.068%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Finished fine tuning.\n",
      "Iteration 549/1723 finished in 0m15s\n",
      "Total channels prunned so far: 549\n",
      "\n",
      "Iteration 550 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 181)]\n",
      "Input: 0.115 MB, Params: 2,400,068 (9.156 MB), Total: 9.27 MB, FLOPs: 216,291,031\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.915%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Finished fine tuning.\n",
      "Iteration 550/1723 finished in 0m15s\n",
      "Total channels prunned so far: 550\n",
      "\n",
      "Iteration 551 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 259)]\n",
      "Input: 0.115 MB, Params: 2,396,976 (9.144 MB), Total: 9.26 MB, FLOPs: 216,235,419\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Finished fine tuning.\n",
      "Iteration 551/1723 finished in 0m15s\n",
      "Total channels prunned so far: 551\n",
      "\n",
      "Iteration 552 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 138)]\n",
      "Input: 0.115 MB, Params: 2,393,884 (9.132 MB), Total: 9.25 MB, FLOPs: 216,179,807\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Finished fine tuning.\n",
      "Iteration 552/1723 finished in 0m15s\n",
      "Total channels prunned so far: 552\n",
      "\n",
      "Iteration 553 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 151)]\n",
      "Input: 0.115 MB, Params: 2,389,067 (9.114 MB), Total: 9.23 MB, FLOPs: 215,968,559\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Finished fine tuning.\n",
      "Iteration 553/1723 finished in 0m15s\n",
      "Total channels prunned so far: 553\n",
      "\n",
      "Iteration 554 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 181)]\n",
      "Input: 0.115 MB, Params: 2,384,196 (9.095 MB), Total: 9.21 MB, FLOPs: 215,880,899\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Finished fine tuning.\n",
      "Iteration 554/1723 finished in 0m15s\n",
      "Total channels prunned so far: 554\n",
      "\n",
      "Iteration 555 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(7, 22)]\n",
      "Input: 0.115 MB, Params: 2,383,744 (9.093 MB), Total: 9.21 MB, FLOPs: 215,078,699\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Finished fine tuning.\n",
      "Iteration 555/1723 finished in 0m15s\n",
      "Total channels prunned so far: 555\n",
      "\n",
      "Iteration 556 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 111)]\n",
      "Input: 0.115 MB, Params: 2,378,936 (9.075 MB), Total: 9.19 MB, FLOPs: 214,867,613\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.068%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Finished fine tuning.\n",
      "Iteration 556/1723 finished in 0m15s\n",
      "Total channels prunned so far: 556\n",
      "\n",
      "Iteration 557 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(3, 33)]\n",
      "Input: 0.115 MB, Params: 2,378,894 (9.075 MB), Total: 9.19 MB, FLOPs: 214,512,640\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Finished fine tuning.\n",
      "Iteration 557/1723 finished in 0m15s\n",
      "Total channels prunned so far: 557\n",
      "\n",
      "Iteration 558 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 28)]\n",
      "Input: 0.115 MB, Params: 2,376,273 (9.065 MB), Total: 9.18 MB, FLOPs: 213,993,716\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.492%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.492%\n",
      "Finished fine tuning.\n",
      "Iteration 558/1723 finished in 0m15s\n",
      "Total channels prunned so far: 558\n",
      "\n",
      "Iteration 559 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 158)]\n",
      "Input: 0.115 MB, Params: 2,371,411 (9.046 MB), Total: 9.16 MB, FLOPs: 213,906,218\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.915%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Finished fine tuning.\n",
      "Iteration 559/1723 finished in 0m15s\n",
      "Total channels prunned so far: 559\n",
      "\n",
      "Iteration 560 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 128)]\n",
      "Input: 0.115 MB, Params: 2,368,337 (9.034 MB), Total: 9.15 MB, FLOPs: 213,850,930\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.492%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Finished fine tuning.\n",
      "Iteration 560/1723 finished in 0m15s\n",
      "Total channels prunned so far: 560\n",
      "\n",
      "Iteration 561 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 134)]\n",
      "Input: 0.115 MB, Params: 2,363,484 (9.016 MB), Total: 9.13 MB, FLOPs: 213,763,594\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Finished fine tuning.\n",
      "Iteration 561/1723 finished in 0m15s\n",
      "Total channels prunned so far: 561\n",
      "\n",
      "Iteration 562 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 208)]\n",
      "Input: 0.115 MB, Params: 2,358,631 (8.997 MB), Total: 9.11 MB, FLOPs: 213,676,258\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Finished fine tuning.\n",
      "Iteration 562/1723 finished in 0m15s\n",
      "Total channels prunned so far: 562\n",
      "\n",
      "Iteration 563 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 274)]\n",
      "Input: 0.115 MB, Params: 2,353,778 (8.979 MB), Total: 9.09 MB, FLOPs: 213,588,922\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Finished fine tuning.\n",
      "Iteration 563/1723 finished in 0m15s\n",
      "Total channels prunned so far: 563\n",
      "\n",
      "Iteration 564 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 82)]\n",
      "Input: 0.115 MB, Params: 2,348,925 (8.960 MB), Total: 9.08 MB, FLOPs: 213,501,586\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Finished fine tuning.\n",
      "Iteration 564/1723 finished in 0m15s\n",
      "Total channels prunned so far: 564\n",
      "\n",
      "Iteration 565 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 173)]\n",
      "Input: 0.115 MB, Params: 2,345,887 (8.949 MB), Total: 9.06 MB, FLOPs: 213,446,946\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Finished fine tuning.\n",
      "Iteration 565/1723 finished in 0m15s\n",
      "Total channels prunned so far: 565\n",
      "\n",
      "Iteration 566 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 123)]\n",
      "Input: 0.115 MB, Params: 2,341,124 (8.931 MB), Total: 9.05 MB, FLOPs: 213,236,670\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Finished fine tuning.\n",
      "Iteration 566/1723 finished in 0m15s\n",
      "Total channels prunned so far: 566\n",
      "\n",
      "Iteration 567 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 150)]\n",
      "Input: 0.115 MB, Params: 2,336,289 (8.912 MB), Total: 9.03 MB, FLOPs: 213,149,658\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Finished fine tuning.\n",
      "Iteration 567/1723 finished in 0m15s\n",
      "Total channels prunned so far: 567\n",
      "\n",
      "Iteration 568 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 112)]\n",
      "Input: 0.115 MB, Params: 2,331,454 (8.894 MB), Total: 9.01 MB, FLOPs: 213,062,646\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Finished fine tuning.\n",
      "Iteration 568/1723 finished in 0m15s\n",
      "Total channels prunned so far: 568\n",
      "\n",
      "Iteration 569 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 16)]\n",
      "Input: 0.115 MB, Params: 2,328,833 (8.884 MB), Total: 9.00 MB, FLOPs: 212,543,722\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.068%\n",
      "Finished fine tuning.\n",
      "Iteration 569/1723 finished in 0m15s\n",
      "Total channels prunned so far: 569\n",
      "\n",
      "Iteration 570 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 286)]\n",
      "Input: 0.115 MB, Params: 2,323,998 (8.865 MB), Total: 8.98 MB, FLOPs: 212,456,710\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Finished fine tuning.\n",
      "Iteration 570/1723 finished in 0m15s\n",
      "Total channels prunned so far: 570\n",
      "\n",
      "Iteration 571 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 107)]\n",
      "Input: 0.115 MB, Params: 2,321,377 (8.855 MB), Total: 8.97 MB, FLOPs: 211,937,786\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.915%\n",
      "Finished fine tuning.\n",
      "Iteration 571/1723 finished in 0m15s\n",
      "Total channels prunned so far: 571\n",
      "\n",
      "Iteration 572 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 110)]\n",
      "Input: 0.115 MB, Params: 2,316,542 (8.837 MB), Total: 8.95 MB, FLOPs: 211,850,774\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.915%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.763%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Finished fine tuning.\n",
      "Iteration 572/1723 finished in 0m15s\n",
      "Total channels prunned so far: 572\n",
      "\n",
      "Iteration 573 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 252)]\n",
      "Input: 0.115 MB, Params: 2,311,707 (8.818 MB), Total: 8.93 MB, FLOPs: 211,763,762\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.915%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.915%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.492%\n",
      "Finished fine tuning.\n",
      "Iteration 573/1723 finished in 0m15s\n",
      "Total channels prunned so far: 573\n",
      "\n",
      "Iteration 574 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 101)]\n",
      "Input: 0.115 MB, Params: 2,306,872 (8.800 MB), Total: 8.92 MB, FLOPs: 211,676,750\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.492%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.186%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.186%\n",
      "Finished fine tuning.\n",
      "Iteration 574/1723 finished in 0m15s\n",
      "Total channels prunned so far: 574\n",
      "\n",
      "Iteration 575 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 27)]\n",
      "Input: 0.115 MB, Params: 2,302,037 (8.782 MB), Total: 8.90 MB, FLOPs: 211,589,738\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.610%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.915%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.492%\n",
      "Finished fine tuning.\n",
      "Iteration 575/1723 finished in 0m15s\n",
      "Total channels prunned so far: 575\n",
      "\n",
      "Iteration 576 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(14, 13)]\n",
      "Input: 0.115 MB, Params: 2,300,703 (8.776 MB), Total: 8.89 MB, FLOPs: 210,496,173\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.492%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.068%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.492%\n",
      "Finished fine tuning.\n",
      "Iteration 576/1723 finished in 0m15s\n",
      "Total channels prunned so far: 576\n",
      "\n",
      "Iteration 577 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 41)]\n",
      "Input: 0.115 MB, Params: 2,298,001 (8.766 MB), Total: 8.88 MB, FLOPs: 210,253,083\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.339%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.492%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.915%\n",
      "Finished fine tuning.\n",
      "Iteration 577/1723 finished in 0m15s\n",
      "Total channels prunned so far: 577\n",
      "\n",
      "Iteration 578 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 212)]\n",
      "Input: 0.115 MB, Params: 2,295,026 (8.755 MB), Total: 8.87 MB, FLOPs: 210,199,577\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.915%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.068%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.492%\n",
      "Finished fine tuning.\n",
      "Iteration 578/1723 finished in 0m15s\n",
      "Total channels prunned so far: 578\n",
      "\n",
      "Iteration 579 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 164)]\n",
      "Input: 0.115 MB, Params: 2,292,051 (8.743 MB), Total: 8.86 MB, FLOPs: 210,146,071\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.068%\n",
      "Finished fine tuning.\n",
      "Iteration 579/1723 finished in 0m15s\n",
      "Total channels prunned so far: 579\n",
      "\n",
      "Iteration 580 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 123)]\n",
      "Input: 0.115 MB, Params: 2,289,349 (8.733 MB), Total: 8.85 MB, FLOPs: 209,902,981\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.068%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Finished fine tuning.\n",
      "Iteration 580/1723 finished in 0m15s\n",
      "Total channels prunned so far: 580\n",
      "\n",
      "Iteration 581 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 296)]\n",
      "Input: 0.115 MB, Params: 2,284,532 (8.715 MB), Total: 8.83 MB, FLOPs: 209,816,293\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Finished fine tuning.\n",
      "Iteration 581/1723 finished in 0m15s\n",
      "Total channels prunned so far: 581\n",
      "\n",
      "Iteration 582 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 94)]\n",
      "Input: 0.115 MB, Params: 2,281,929 (8.705 MB), Total: 8.82 MB, FLOPs: 209,298,989\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.068%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.068%\n",
      "Finished fine tuning.\n",
      "Iteration 582/1723 finished in 0m15s\n",
      "Total channels prunned so far: 582\n",
      "\n",
      "Iteration 583 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 71)]\n",
      "Input: 0.115 MB, Params: 2,277,256 (8.687 MB), Total: 8.80 MB, FLOPs: 209,091,629\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.339%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.915%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Finished fine tuning.\n",
      "Iteration 583/1723 finished in 0m15s\n",
      "Total channels prunned so far: 583\n",
      "\n",
      "Iteration 584 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 46)]\n",
      "Input: 0.115 MB, Params: 2,272,583 (8.669 MB), Total: 8.78 MB, FLOPs: 208,884,269\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.068%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.492%\n",
      "Finished fine tuning.\n",
      "Iteration 584/1723 finished in 0m15s\n",
      "Total channels prunned so far: 584\n",
      "\n",
      "Iteration 585 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 257)]\n",
      "Input: 0.115 MB, Params: 2,267,784 (8.651 MB), Total: 8.77 MB, FLOPs: 208,797,905\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.915%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Finished fine tuning.\n",
      "Iteration 585/1723 finished in 0m15s\n",
      "Total channels prunned so far: 585\n",
      "\n",
      "Iteration 586 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 267)]\n",
      "Input: 0.115 MB, Params: 2,264,827 (8.640 MB), Total: 8.75 MB, FLOPs: 208,744,723\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.915%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.915%\n",
      "Finished fine tuning.\n",
      "Iteration 586/1723 finished in 0m15s\n",
      "Total channels prunned so far: 586\n",
      "\n",
      "Iteration 587 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 102)]\n",
      "Input: 0.115 MB, Params: 2,261,870 (8.628 MB), Total: 8.74 MB, FLOPs: 208,691,541\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.492%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.763%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.915%\n",
      "Finished fine tuning.\n",
      "Iteration 587/1723 finished in 0m15s\n",
      "Total channels prunned so far: 587\n",
      "\n",
      "Iteration 588 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 92)]\n",
      "Input: 0.115 MB, Params: 2,259,195 (8.618 MB), Total: 8.73 MB, FLOPs: 208,450,881\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.763%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.763%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.068%\n",
      "Finished fine tuning.\n",
      "Iteration 588/1723 finished in 0m15s\n",
      "Total channels prunned so far: 588\n",
      "\n",
      "Iteration 589 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 124)]\n",
      "Input: 0.115 MB, Params: 2,256,238 (8.607 MB), Total: 8.72 MB, FLOPs: 208,397,699\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.068%\n",
      "Finished fine tuning.\n",
      "Iteration 589/1723 finished in 0m15s\n",
      "Total channels prunned so far: 589\n",
      "\n",
      "Iteration 590 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 2)]\n",
      "Input: 0.115 MB, Params: 2,251,583 (8.589 MB), Total: 8.70 MB, FLOPs: 208,191,311\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.068%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.339%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.339%\n",
      "Finished fine tuning.\n",
      "Iteration 590/1723 finished in 0m15s\n",
      "Total channels prunned so far: 590\n",
      "\n",
      "Iteration 591 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 73)]\n",
      "Input: 0.115 MB, Params: 2,248,917 (8.579 MB), Total: 8.69 MB, FLOPs: 207,951,461\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.186%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.763%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.339%\n",
      "Finished fine tuning.\n",
      "Iteration 591/1723 finished in 0m15s\n",
      "Total channels prunned so far: 591\n",
      "\n",
      "Iteration 592 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 12)]\n",
      "Input: 0.115 MB, Params: 2,244,271 (8.561 MB), Total: 8.68 MB, FLOPs: 207,745,883\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.763%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.763%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Finished fine tuning.\n",
      "Iteration 592/1723 finished in 0m15s\n",
      "Total channels prunned so far: 592\n",
      "\n",
      "Iteration 593 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 187)]\n",
      "Input: 0.115 MB, Params: 2,241,314 (8.550 MB), Total: 8.67 MB, FLOPs: 207,692,701\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.492%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.915%\n",
      "Finished fine tuning.\n",
      "Iteration 593/1723 finished in 0m15s\n",
      "Total channels prunned so far: 593\n",
      "\n",
      "Iteration 594 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 272)]\n",
      "Input: 0.115 MB, Params: 2,236,569 (8.532 MB), Total: 8.65 MB, FLOPs: 207,607,309\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.763%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.068%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.915%\n",
      "Finished fine tuning.\n",
      "Iteration 594/1723 finished in 0m15s\n",
      "Total channels prunned so far: 594\n",
      "\n",
      "Iteration 595 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 97)]\n",
      "Input: 0.115 MB, Params: 2,233,621 (8.521 MB), Total: 8.64 MB, FLOPs: 207,554,289\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.339%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.915%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.339%\n",
      "Finished fine tuning.\n",
      "Iteration 595/1723 finished in 0m15s\n",
      "Total channels prunned so far: 595\n",
      "\n",
      "Iteration 596 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 106)]\n",
      "Input: 0.115 MB, Params: 2,230,673 (8.509 MB), Total: 8.62 MB, FLOPs: 207,501,269\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.763%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.915%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Finished fine tuning.\n",
      "Iteration 596/1723 finished in 0m15s\n",
      "Total channels prunned so far: 596\n",
      "\n",
      "Iteration 597 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 32)]\n",
      "Input: 0.115 MB, Params: 2,227,725 (8.498 MB), Total: 8.61 MB, FLOPs: 207,448,249\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.339%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Finished fine tuning.\n",
      "Iteration 597/1723 finished in 0m15s\n",
      "Total channels prunned so far: 597\n",
      "\n",
      "Iteration 598 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 92)]\n",
      "Input: 0.115 MB, Params: 2,223,088 (8.480 MB), Total: 8.60 MB, FLOPs: 207,242,833\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.068%\n",
      "Finished fine tuning.\n",
      "Iteration 598/1723 finished in 0m15s\n",
      "Total channels prunned so far: 598\n",
      "\n",
      "Iteration 599 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 71)]\n",
      "Input: 0.115 MB, Params: 2,218,451 (8.463 MB), Total: 8.58 MB, FLOPs: 207,037,417\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.915%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Finished fine tuning.\n",
      "Iteration 599/1723 finished in 0m15s\n",
      "Total channels prunned so far: 599\n",
      "\n",
      "Iteration 600 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 21)]\n",
      "Input: 0.115 MB, Params: 2,215,866 (8.453 MB), Total: 8.57 MB, FLOPs: 206,521,733\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Finished fine tuning.\n",
      "Iteration 600/1723 finished in 0m15s\n",
      "Total channels prunned so far: 600\n",
      "\n",
      "Iteration 601 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 137)]\n",
      "Input: 0.115 MB, Params: 2,213,236 (8.443 MB), Total: 8.56 MB, FLOPs: 206,285,123\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.915%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.186%\n",
      "Finished fine tuning.\n",
      "Iteration 601/1723 finished in 0m15s\n",
      "Total channels prunned so far: 601\n",
      "\n",
      "Iteration 602 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 134)]\n",
      "Input: 0.115 MB, Params: 2,210,288 (8.432 MB), Total: 8.55 MB, FLOPs: 206,232,103\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.763%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.339%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Finished fine tuning.\n",
      "Iteration 602/1723 finished in 0m15s\n",
      "Total channels prunned so far: 602\n",
      "\n",
      "Iteration 603 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 229)]\n",
      "Input: 0.115 MB, Params: 2,207,340 (8.420 MB), Total: 8.54 MB, FLOPs: 206,179,083\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.915%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.492%\n",
      "Finished fine tuning.\n",
      "Iteration 603/1723 finished in 0m15s\n",
      "Total channels prunned so far: 603\n",
      "\n",
      "Iteration 604 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 239)]\n",
      "Input: 0.115 MB, Params: 2,204,392 (8.409 MB), Total: 8.52 MB, FLOPs: 206,126,063\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.915%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.492%\n",
      "Finished fine tuning.\n",
      "Iteration 604/1723 finished in 0m15s\n",
      "Total channels prunned so far: 604\n",
      "\n",
      "Iteration 605 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 29)]\n",
      "Input: 0.115 MB, Params: 2,199,719 (8.391 MB), Total: 8.51 MB, FLOPs: 206,041,967\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.068%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Finished fine tuning.\n",
      "Iteration 605/1723 finished in 0m15s\n",
      "Total channels prunned so far: 605\n",
      "\n",
      "Iteration 606 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 151)]\n",
      "Input: 0.115 MB, Params: 2,196,780 (8.380 MB), Total: 8.50 MB, FLOPs: 205,989,109\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.492%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Finished fine tuning.\n",
      "Iteration 606/1723 finished in 0m15s\n",
      "Total channels prunned so far: 606\n",
      "\n",
      "Iteration 607 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 174)]\n",
      "Input: 0.115 MB, Params: 2,193,841 (8.369 MB), Total: 8.48 MB, FLOPs: 205,936,251\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.492%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Finished fine tuning.\n",
      "Iteration 607/1723 finished in 0m15s\n",
      "Total channels prunned so far: 607\n",
      "\n",
      "Iteration 608 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 108)]\n",
      "Input: 0.115 MB, Params: 2,190,902 (8.358 MB), Total: 8.47 MB, FLOPs: 205,883,393\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.915%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Finished fine tuning.\n",
      "Iteration 608/1723 finished in 0m15s\n",
      "Total channels prunned so far: 608\n",
      "\n",
      "Iteration 609 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 173)]\n",
      "Input: 0.115 MB, Params: 2,186,283 (8.340 MB), Total: 8.46 MB, FLOPs: 205,678,949\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.492%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.763%\n",
      "Finished fine tuning.\n",
      "Iteration 609/1723 finished in 0m15s\n",
      "Total channels prunned so far: 609\n",
      "\n",
      "Iteration 610 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 26)]\n",
      "Input: 0.115 MB, Params: 2,184,823 (8.334 MB), Total: 8.45 MB, FLOPs: 205,085,136\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.339%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.068%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.763%\n",
      "Finished fine tuning.\n",
      "Iteration 610/1723 finished in 0m15s\n",
      "Total channels prunned so far: 610\n",
      "\n",
      "Iteration 611 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 310)]\n",
      "Input: 0.115 MB, Params: 2,180,186 (8.317 MB), Total: 8.43 MB, FLOPs: 205,001,688\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.339%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.068%\n",
      "Finished fine tuning.\n",
      "Iteration 611/1723 finished in 0m15s\n",
      "Total channels prunned so far: 611\n",
      "\n",
      "Iteration 612 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 261)]\n",
      "Input: 0.115 MB, Params: 2,177,256 (8.306 MB), Total: 8.42 MB, FLOPs: 204,948,992\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.186%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.339%\n",
      "Finished fine tuning.\n",
      "Iteration 612/1723 finished in 0m15s\n",
      "Total channels prunned so far: 612\n",
      "\n",
      "Iteration 613 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 111)]\n",
      "Input: 0.115 MB, Params: 2,174,326 (8.294 MB), Total: 8.41 MB, FLOPs: 204,896,296\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.763%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Finished fine tuning.\n",
      "Iteration 613/1723 finished in 0m15s\n",
      "Total channels prunned so far: 613\n",
      "\n",
      "Iteration 614 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 31)]\n",
      "Input: 0.115 MB, Params: 2,171,396 (8.283 MB), Total: 8.40 MB, FLOPs: 204,843,600\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Finished fine tuning.\n",
      "Iteration 614/1723 finished in 0m15s\n",
      "Total channels prunned so far: 614\n",
      "\n",
      "Iteration 615 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 93)]\n",
      "Input: 0.115 MB, Params: 2,168,466 (8.272 MB), Total: 8.39 MB, FLOPs: 204,790,904\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Finished fine tuning.\n",
      "Iteration 615/1723 finished in 0m15s\n",
      "Total channels prunned so far: 615\n",
      "\n",
      "Iteration 616 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 145)]\n",
      "Input: 0.115 MB, Params: 2,163,856 (8.254 MB), Total: 8.37 MB, FLOPs: 204,586,622\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Finished fine tuning.\n",
      "Iteration 616/1723 finished in 0m15s\n",
      "Total channels prunned so far: 616\n",
      "\n",
      "Iteration 617 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 78)]\n",
      "Input: 0.115 MB, Params: 2,161,244 (8.244 MB), Total: 8.36 MB, FLOPs: 204,351,632\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.492%\n",
      "Finished fine tuning.\n",
      "Iteration 617/1723 finished in 0m15s\n",
      "Total channels prunned so far: 617\n",
      "\n",
      "Iteration 618 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 66)]\n",
      "Input: 0.115 MB, Params: 2,156,643 (8.227 MB), Total: 8.34 MB, FLOPs: 204,148,160\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.339%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.492%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.492%\n",
      "Finished fine tuning.\n",
      "Iteration 618/1723 finished in 0m15s\n",
      "Total channels prunned so far: 618\n",
      "\n",
      "Iteration 619 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 257)]\n",
      "Input: 0.115 MB, Params: 2,153,713 (8.216 MB), Total: 8.33 MB, FLOPs: 204,095,464\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.492%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.492%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.068%\n",
      "Finished fine tuning.\n",
      "Iteration 619/1723 finished in 0m15s\n",
      "Total channels prunned so far: 619\n",
      "\n",
      "Iteration 620 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 130)]\n",
      "Input: 0.115 MB, Params: 2,149,139 (8.198 MB), Total: 8.31 MB, FLOPs: 204,013,150\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.068%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Finished fine tuning.\n",
      "Iteration 620/1723 finished in 0m15s\n",
      "Total channels prunned so far: 620\n",
      "\n",
      "Iteration 621 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 121)]\n",
      "Input: 0.115 MB, Params: 2,144,547 (8.181 MB), Total: 8.30 MB, FLOPs: 203,809,840\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Finished fine tuning.\n",
      "Iteration 621/1723 finished in 0m15s\n",
      "Total channels prunned so far: 621\n",
      "\n",
      "Iteration 622 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 114)]\n",
      "Input: 0.115 MB, Params: 2,139,982 (8.163 MB), Total: 8.28 MB, FLOPs: 203,727,688\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Finished fine tuning.\n",
      "Iteration 622/1723 finished in 0m15s\n",
      "Total channels prunned so far: 622\n",
      "\n",
      "Iteration 623 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 82)]\n",
      "Input: 0.115 MB, Params: 2,138,522 (8.158 MB), Total: 8.27 MB, FLOPs: 203,133,875\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.492%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.068%\n",
      "Finished fine tuning.\n",
      "Iteration 623/1723 finished in 0m15s\n",
      "Total channels prunned so far: 623\n",
      "\n",
      "Iteration 624 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 175)]\n",
      "Input: 0.115 MB, Params: 2,133,939 (8.140 MB), Total: 8.26 MB, FLOPs: 202,930,727\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.763%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.339%\n",
      "Finished fine tuning.\n",
      "Iteration 624/1723 finished in 0m15s\n",
      "Total channels prunned so far: 624\n",
      "\n",
      "Iteration 625 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 20)]\n",
      "Input: 0.115 MB, Params: 2,129,356 (8.123 MB), Total: 8.24 MB, FLOPs: 202,727,579\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.763%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.763%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.915%\n",
      "Finished fine tuning.\n",
      "Iteration 625/1723 finished in 0m15s\n",
      "Total channels prunned so far: 625\n",
      "\n",
      "Iteration 626 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 13)]\n",
      "Input: 0.115 MB, Params: 2,124,809 (8.106 MB), Total: 8.22 MB, FLOPs: 202,645,751\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.915%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.068%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Finished fine tuning.\n",
      "Iteration 626/1723 finished in 0m15s\n",
      "Total channels prunned so far: 626\n",
      "\n",
      "Iteration 627 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 295)]\n",
      "Input: 0.115 MB, Params: 2,120,262 (8.088 MB), Total: 8.20 MB, FLOPs: 202,563,923\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.915%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.068%\n",
      "Finished fine tuning.\n",
      "Iteration 627/1723 finished in 0m15s\n",
      "Total channels prunned so far: 627\n",
      "\n",
      "Iteration 628 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 176)]\n",
      "Input: 0.115 MB, Params: 2,115,715 (8.071 MB), Total: 8.19 MB, FLOPs: 202,482,095\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.068%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.915%\n",
      "Finished fine tuning.\n",
      "Iteration 628/1723 finished in 0m15s\n",
      "Total channels prunned so far: 628\n",
      "\n",
      "Iteration 629 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 28)]\n",
      "Input: 0.115 MB, Params: 2,111,159 (8.053 MB), Total: 8.17 MB, FLOPs: 202,279,433\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.492%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.492%\n",
      "Finished fine tuning.\n",
      "Iteration 629/1723 finished in 0m15s\n",
      "Total channels prunned so far: 629\n",
      "\n",
      "Iteration 630 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 126)]\n",
      "Input: 0.115 MB, Params: 2,106,603 (8.036 MB), Total: 8.15 MB, FLOPs: 202,076,771\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.915%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Finished fine tuning.\n",
      "Iteration 630/1723 finished in 0m15s\n",
      "Total channels prunned so far: 630\n",
      "\n",
      "Iteration 631 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 186)]\n",
      "Input: 0.115 MB, Params: 2,103,718 (8.025 MB), Total: 8.14 MB, FLOPs: 202,024,885\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.492%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Finished fine tuning.\n",
      "Iteration 631/1723 finished in 0m15s\n",
      "Total channels prunned so far: 631\n",
      "\n",
      "Iteration 632 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 166)]\n",
      "Input: 0.115 MB, Params: 2,099,162 (8.008 MB), Total: 8.12 MB, FLOPs: 201,822,223\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Finished fine tuning.\n",
      "Iteration 632/1723 finished in 0m15s\n",
      "Total channels prunned so far: 632\n",
      "\n",
      "Iteration 633 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 153)]\n",
      "Input: 0.115 MB, Params: 2,096,613 (7.998 MB), Total: 8.11 MB, FLOPs: 201,592,903\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.254%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.339%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.339%\n",
      "Finished fine tuning.\n",
      "Iteration 633/1723 finished in 0m15s\n",
      "Total channels prunned so far: 633\n",
      "\n",
      "Iteration 634 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 243)]\n",
      "Input: 0.115 MB, Params: 2,093,728 (7.987 MB), Total: 8.10 MB, FLOPs: 201,541,017\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 96.186%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.915%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.492%\n",
      "Finished fine tuning.\n",
      "Iteration 634/1723 finished in 0m15s\n",
      "Total channels prunned so far: 634\n",
      "\n",
      "Iteration 635 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 165)]\n",
      "Input: 0.115 MB, Params: 2,090,843 (7.976 MB), Total: 8.09 MB, FLOPs: 201,489,131\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.915%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.068%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Finished fine tuning.\n",
      "Iteration 635/1723 finished in 0m15s\n",
      "Total channels prunned so far: 635\n",
      "\n",
      "Iteration 636 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 138)]\n",
      "Input: 0.115 MB, Params: 2,086,350 (7.959 MB), Total: 8.07 MB, FLOPs: 201,408,275\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.915%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.492%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Finished fine tuning.\n",
      "Iteration 636/1723 finished in 0m15s\n",
      "Total channels prunned so far: 636\n",
      "\n",
      "Iteration 637 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 227)]\n",
      "Input: 0.115 MB, Params: 2,083,474 (7.948 MB), Total: 8.06 MB, FLOPs: 201,356,551\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.492%\n",
      "Finished fine tuning.\n",
      "Iteration 637/1723 finished in 0m15s\n",
      "Total channels prunned so far: 637\n",
      "\n",
      "Iteration 638 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 11)]\n",
      "Input: 0.115 MB, Params: 2,082,752 (7.945 MB), Total: 8.06 MB, FLOPs: 200,166,901\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.068%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Finished fine tuning.\n",
      "Iteration 638/1723 finished in 0m15s\n",
      "Total channels prunned so far: 638\n",
      "\n",
      "Iteration 639 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 167)]\n",
      "Input: 0.115 MB, Params: 2,078,214 (7.928 MB), Total: 8.04 MB, FLOPs: 199,965,211\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Finished fine tuning.\n",
      "Iteration 639/1723 finished in 0m15s\n",
      "Total channels prunned so far: 639\n",
      "\n",
      "Iteration 640 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 177)]\n",
      "Input: 0.115 MB, Params: 2,075,338 (7.917 MB), Total: 8.03 MB, FLOPs: 199,913,487\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.492%\n",
      "Finished fine tuning.\n",
      "Iteration 640/1723 finished in 0m15s\n",
      "Total channels prunned so far: 640\n",
      "\n",
      "Iteration 641 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 66)]\n",
      "Input: 0.115 MB, Params: 2,070,872 (7.900 MB), Total: 8.02 MB, FLOPs: 199,833,117\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.492%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Finished fine tuning.\n",
      "Iteration 641/1723 finished in 0m15s\n",
      "Total channels prunned so far: 641\n",
      "\n",
      "Iteration 642 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 31)]\n",
      "Input: 0.115 MB, Params: 2,068,005 (7.889 MB), Total: 8.00 MB, FLOPs: 199,781,555\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Finished fine tuning.\n",
      "Iteration 642/1723 finished in 0m15s\n",
      "Total channels prunned so far: 642\n",
      "\n",
      "Iteration 643 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 151)]\n",
      "Input: 0.115 MB, Params: 2,065,465 (7.879 MB), Total: 7.99 MB, FLOPs: 199,553,045\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.068%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Finished fine tuning.\n",
      "Iteration 643/1723 finished in 0m15s\n",
      "Total channels prunned so far: 643\n",
      "\n",
      "Iteration 644 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 256)]\n",
      "Input: 0.115 MB, Params: 2,062,598 (7.868 MB), Total: 7.98 MB, FLOPs: 199,501,483\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Finished fine tuning.\n",
      "Iteration 644/1723 finished in 0m15s\n",
      "Total channels prunned so far: 644\n",
      "\n",
      "Iteration 645 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 100)]\n",
      "Input: 0.115 MB, Params: 2,060,067 (7.859 MB), Total: 7.97 MB, FLOPs: 198,996,365\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Finished fine tuning.\n",
      "Iteration 645/1723 finished in 0m15s\n",
      "Total channels prunned so far: 645\n",
      "\n",
      "Iteration 646 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 84)]\n",
      "Input: 0.115 MB, Params: 2,057,536 (7.849 MB), Total: 7.96 MB, FLOPs: 198,491,247\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.254%\n",
      "Finished fine tuning.\n",
      "Iteration 646/1723 finished in 0m15s\n",
      "Total channels prunned so far: 646\n",
      "\n",
      "Iteration 647 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 217)]\n",
      "Input: 0.115 MB, Params: 2,053,088 (7.832 MB), Total: 7.95 MB, FLOPs: 198,411,201\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Finished fine tuning.\n",
      "Iteration 647/1723 finished in 0m15s\n",
      "Total channels prunned so far: 647\n",
      "\n",
      "Iteration 648 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 104)]\n",
      "Input: 0.115 MB, Params: 2,048,640 (7.815 MB), Total: 7.93 MB, FLOPs: 198,331,155\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Finished fine tuning.\n",
      "Iteration 648/1723 finished in 0m15s\n",
      "Total channels prunned so far: 648\n",
      "\n",
      "Iteration 649 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 126)]\n",
      "Input: 0.115 MB, Params: 2,046,118 (7.805 MB), Total: 7.92 MB, FLOPs: 198,104,265\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Finished fine tuning.\n",
      "Iteration 649/1723 finished in 0m15s\n",
      "Total channels prunned so far: 649\n",
      "\n",
      "Iteration 650 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 15)]\n",
      "Input: 0.115 MB, Params: 2,045,396 (7.803 MB), Total: 7.92 MB, FLOPs: 196,914,615\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Finished fine tuning.\n",
      "Iteration 650/1723 finished in 0m15s\n",
      "Total channels prunned so far: 650\n",
      "\n",
      "Iteration 651 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 313)]\n",
      "Input: 0.115 MB, Params: 2,042,547 (7.792 MB), Total: 7.91 MB, FLOPs: 196,863,377\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.288%\n",
      "Finished fine tuning.\n",
      "Iteration 651/1723 finished in 0m15s\n",
      "Total channels prunned so far: 651\n",
      "\n",
      "Iteration 652 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 36)]\n",
      "Input: 0.115 MB, Params: 2,041,105 (7.786 MB), Total: 7.90 MB, FLOPs: 196,276,890\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.136%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.136%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Finished fine tuning.\n",
      "Iteration 652/1723 finished in 0m15s\n",
      "Total channels prunned so far: 652\n",
      "\n",
      "Iteration 653 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 10)]\n",
      "Input: 0.115 MB, Params: 2,038,592 (7.777 MB), Total: 7.89 MB, FLOPs: 195,776,245\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Finished fine tuning.\n",
      "Iteration 653/1723 finished in 0m15s\n",
      "Total channels prunned so far: 653\n",
      "\n",
      "Iteration 654 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 99)]\n",
      "Input: 0.115 MB, Params: 2,034,153 (7.760 MB), Total: 7.87 MB, FLOPs: 195,696,361\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.068%\n",
      "Finished fine tuning.\n",
      "Iteration 654/1723 finished in 0m15s\n",
      "Total channels prunned so far: 654\n",
      "\n",
      "Iteration 655 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 10)]\n",
      "Input: 0.115 MB, Params: 2,032,720 (7.754 MB), Total: 7.87 MB, FLOPs: 195,113,537\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Finished fine tuning.\n",
      "Iteration 655/1723 finished in 0m15s\n",
      "Total channels prunned so far: 655\n",
      "\n",
      "Iteration 656 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 75)]\n",
      "Input: 0.115 MB, Params: 2,031,287 (7.749 MB), Total: 7.86 MB, FLOPs: 194,530,713\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Finished fine tuning.\n",
      "Iteration 656/1723 finished in 0m15s\n",
      "Total channels prunned so far: 656\n",
      "\n",
      "Iteration 657 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 18)]\n",
      "Input: 0.115 MB, Params: 2,026,803 (7.732 MB), Total: 7.85 MB, FLOPs: 194,331,291\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Finished fine tuning.\n",
      "Iteration 657/1723 finished in 0m15s\n",
      "Total channels prunned so far: 657\n",
      "\n",
      "Iteration 658 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(14, 12)]\n",
      "Input: 0.115 MB, Params: 2,025,532 (7.727 MB), Total: 7.84 MB, FLOPs: 193,285,741\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Finished fine tuning.\n",
      "Iteration 658/1723 finished in 0m15s\n",
      "Total channels prunned so far: 658\n",
      "\n",
      "Iteration 659 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 14)]\n",
      "Input: 0.115 MB, Params: 2,022,692 (7.716 MB), Total: 7.83 MB, FLOPs: 193,234,665\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.492%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Finished fine tuning.\n",
      "Iteration 659/1723 finished in 0m15s\n",
      "Total channels prunned so far: 659\n",
      "\n",
      "Iteration 660 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 144)]\n",
      "Input: 0.115 MB, Params: 2,018,208 (7.699 MB), Total: 7.81 MB, FLOPs: 193,035,243\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.068%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Finished fine tuning.\n",
      "Iteration 660/1723 finished in 0m15s\n",
      "Total channels prunned so far: 660\n",
      "\n",
      "Iteration 661 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 123)]\n",
      "Input: 0.115 MB, Params: 2,013,724 (7.682 MB), Total: 7.80 MB, FLOPs: 192,835,821\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Finished fine tuning.\n",
      "Iteration 661/1723 finished in 0m15s\n",
      "Total channels prunned so far: 661\n",
      "\n",
      "Iteration 662 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 110)]\n",
      "Input: 0.115 MB, Params: 2,010,884 (7.671 MB), Total: 7.79 MB, FLOPs: 192,784,745\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.068%\n",
      "Finished fine tuning.\n",
      "Iteration 662/1723 finished in 0m15s\n",
      "Total channels prunned so far: 662\n",
      "\n",
      "Iteration 663 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 42)]\n",
      "Input: 0.115 MB, Params: 2,008,389 (7.661 MB), Total: 7.78 MB, FLOPs: 192,291,426\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.068%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.492%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.492%\n",
      "Finished fine tuning.\n",
      "Iteration 663/1723 finished in 0m15s\n",
      "Total channels prunned so far: 663\n",
      "\n",
      "Iteration 664 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 134)]\n",
      "Input: 0.115 MB, Params: 2,005,549 (7.651 MB), Total: 7.77 MB, FLOPs: 192,240,350\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.339%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Finished fine tuning.\n",
      "Iteration 664/1723 finished in 0m15s\n",
      "Total channels prunned so far: 664\n",
      "\n",
      "Iteration 665 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 170)]\n",
      "Input: 0.115 MB, Params: 2,003,072 (7.641 MB), Total: 7.76 MB, FLOPs: 192,017,510\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.407%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.831%\n",
      "Finished fine tuning.\n",
      "Iteration 665/1723 finished in 0m15s\n",
      "Total channels prunned so far: 665\n",
      "\n",
      "Iteration 666 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 30)]\n",
      "Input: 0.115 MB, Params: 1,998,597 (7.624 MB), Total: 7.74 MB, FLOPs: 191,818,898\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Finished fine tuning.\n",
      "Iteration 666/1723 finished in 0m15s\n",
      "Total channels prunned so far: 666\n",
      "\n",
      "Iteration 667 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 69)]\n",
      "Input: 0.115 MB, Params: 1,994,122 (7.607 MB), Total: 7.72 MB, FLOPs: 191,620,286\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.254%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Finished fine tuning.\n",
      "Iteration 667/1723 finished in 0m15s\n",
      "Total channels prunned so far: 667\n",
      "\n",
      "Iteration 668 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 35)]\n",
      "Input: 0.115 MB, Params: 1,991,282 (7.596 MB), Total: 7.71 MB, FLOPs: 191,569,210\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Finished fine tuning.\n",
      "Iteration 668/1723 finished in 0m15s\n",
      "Total channels prunned so far: 668\n",
      "\n",
      "Iteration 669 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(7, 5)]\n",
      "Input: 0.115 MB, Params: 1,990,848 (7.594 MB), Total: 7.71 MB, FLOPs: 190,798,220\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Finished fine tuning.\n",
      "Iteration 669/1723 finished in 0m15s\n",
      "Total channels prunned so far: 669\n",
      "\n",
      "Iteration 670 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 10)]\n",
      "Input: 0.115 MB, Params: 1,988,008 (7.584 MB), Total: 7.70 MB, FLOPs: 190,747,144\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Finished fine tuning.\n",
      "Iteration 670/1723 finished in 0m15s\n",
      "Total channels prunned so far: 670\n",
      "\n",
      "Iteration 671 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 23)]\n",
      "Input: 0.115 MB, Params: 1,985,549 (7.574 MB), Total: 7.69 MB, FLOPs: 190,525,924\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.254%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Finished fine tuning.\n",
      "Iteration 671/1723 finished in 0m15s\n",
      "Total channels prunned so far: 671\n",
      "\n",
      "Iteration 672 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 180)]\n",
      "Input: 0.115 MB, Params: 1,981,200 (7.558 MB), Total: 7.67 MB, FLOPs: 190,447,660\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Finished fine tuning.\n",
      "Iteration 672/1723 finished in 0m15s\n",
      "Total channels prunned so far: 672\n",
      "\n",
      "Iteration 673 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 37)]\n",
      "Input: 0.115 MB, Params: 1,979,785 (7.552 MB), Total: 7.67 MB, FLOPs: 189,872,162\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.068%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.492%\n",
      "Finished fine tuning.\n",
      "Iteration 673/1723 finished in 0m15s\n",
      "Total channels prunned so far: 673\n",
      "\n",
      "Iteration 674 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(3, 25)]\n",
      "Input: 0.115 MB, Params: 1,979,743 (7.552 MB), Total: 7.67 MB, FLOPs: 182,151,997\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.492%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Finished fine tuning.\n",
      "Iteration 674/1723 finished in 0m15s\n",
      "Total channels prunned so far: 674\n",
      "\n",
      "Iteration 675 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 108)]\n",
      "Input: 0.115 MB, Params: 1,975,394 (7.536 MB), Total: 7.65 MB, FLOPs: 182,073,733\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.068%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Finished fine tuning.\n",
      "Iteration 675/1723 finished in 0m15s\n",
      "Total channels prunned so far: 675\n",
      "\n",
      "Iteration 676 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 42)]\n",
      "Input: 0.115 MB, Params: 1,971,045 (7.519 MB), Total: 7.63 MB, FLOPs: 181,995,469\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.068%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.831%\n",
      "Finished fine tuning.\n",
      "Iteration 676/1723 finished in 0m15s\n",
      "Total channels prunned so far: 676\n",
      "\n",
      "Iteration 677 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 139)]\n",
      "Input: 0.115 MB, Params: 1,968,232 (7.508 MB), Total: 7.62 MB, FLOPs: 181,944,879\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.254%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Finished fine tuning.\n",
      "Iteration 677/1723 finished in 0m15s\n",
      "Total channels prunned so far: 677\n",
      "\n",
      "Iteration 678 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 283)]\n",
      "Input: 0.115 MB, Params: 1,963,892 (7.492 MB), Total: 7.61 MB, FLOPs: 181,866,777\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.831%\n",
      "Finished fine tuning.\n",
      "Iteration 678/1723 finished in 0m15s\n",
      "Total channels prunned so far: 678\n",
      "\n",
      "Iteration 679 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 13)]\n",
      "Input: 0.115 MB, Params: 1,961,088 (7.481 MB), Total: 7.60 MB, FLOPs: 181,816,349\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.254%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Finished fine tuning.\n",
      "Iteration 679/1723 finished in 0m15s\n",
      "Total channels prunned so far: 679\n",
      "\n",
      "Iteration 680 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 176)]\n",
      "Input: 0.115 MB, Params: 1,958,629 (7.472 MB), Total: 7.59 MB, FLOPs: 181,595,129\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.407%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.407%\n",
      "Finished fine tuning.\n",
      "Iteration 680/1723 finished in 0m15s\n",
      "Total channels prunned so far: 680\n",
      "\n",
      "Iteration 681 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 60)]\n",
      "Input: 0.115 MB, Params: 1,954,208 (7.455 MB), Total: 7.57 MB, FLOPs: 181,398,785\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.831%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Finished fine tuning.\n",
      "Iteration 681/1723 finished in 0m15s\n",
      "Total channels prunned so far: 681\n",
      "\n",
      "Iteration 682 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 76)]\n",
      "Input: 0.115 MB, Params: 1,949,886 (7.438 MB), Total: 7.55 MB, FLOPs: 181,321,007\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.068%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.492%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Finished fine tuning.\n",
      "Iteration 682/1723 finished in 0m15s\n",
      "Total channels prunned so far: 682\n",
      "\n",
      "Iteration 683 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 21)]\n",
      "Input: 0.115 MB, Params: 1,948,471 (7.433 MB), Total: 7.55 MB, FLOPs: 180,797,827\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.492%\n",
      "Finished fine tuning.\n",
      "Iteration 683/1723 finished in 0m15s\n",
      "Total channels prunned so far: 683\n",
      "\n",
      "Iteration 684 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 280)]\n",
      "Input: 0.115 MB, Params: 1,945,676 (7.422 MB), Total: 7.54 MB, FLOPs: 180,747,561\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.339%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Finished fine tuning.\n",
      "Iteration 684/1723 finished in 0m15s\n",
      "Total channels prunned so far: 684\n",
      "\n",
      "Iteration 685 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 25)]\n",
      "Input: 0.115 MB, Params: 1,942,881 (7.412 MB), Total: 7.53 MB, FLOPs: 180,697,295\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Finished fine tuning.\n",
      "Iteration 685/1723 finished in 0m15s\n",
      "Total channels prunned so far: 685\n",
      "\n",
      "Iteration 686 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 102)]\n",
      "Input: 0.115 MB, Params: 1,940,086 (7.401 MB), Total: 7.52 MB, FLOPs: 180,647,029\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.068%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Finished fine tuning.\n",
      "Iteration 686/1723 finished in 0m15s\n",
      "Total channels prunned so far: 686\n",
      "\n",
      "Iteration 687 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 39)]\n",
      "Input: 0.115 MB, Params: 1,937,636 (7.391 MB), Total: 7.51 MB, FLOPs: 180,426,619\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Finished fine tuning.\n",
      "Iteration 687/1723 finished in 0m15s\n",
      "Total channels prunned so far: 687\n",
      "\n",
      "Iteration 688 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 85)]\n",
      "Input: 0.115 MB, Params: 1,935,186 (7.382 MB), Total: 7.50 MB, FLOPs: 180,206,209\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Finished fine tuning.\n",
      "Iteration 688/1723 finished in 0m15s\n",
      "Total channels prunned so far: 688\n",
      "\n",
      "Iteration 689 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 97)]\n",
      "Input: 0.115 MB, Params: 1,932,736 (7.373 MB), Total: 7.49 MB, FLOPs: 179,985,799\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Finished fine tuning.\n",
      "Iteration 689/1723 finished in 0m15s\n",
      "Total channels prunned so far: 689\n",
      "\n",
      "Iteration 690 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 167)]\n",
      "Input: 0.115 MB, Params: 1,928,351 (7.356 MB), Total: 7.47 MB, FLOPs: 179,792,047\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Finished fine tuning.\n",
      "Iteration 690/1723 finished in 0m15s\n",
      "Total channels prunned so far: 690\n",
      "\n",
      "Iteration 691 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 95)]\n",
      "Input: 0.115 MB, Params: 1,923,966 (7.339 MB), Total: 7.45 MB, FLOPs: 179,598,295\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Finished fine tuning.\n",
      "Iteration 691/1723 finished in 0m15s\n",
      "Total channels prunned so far: 691\n",
      "\n",
      "Iteration 692 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 17)]\n",
      "Input: 0.115 MB, Params: 1,921,543 (7.330 MB), Total: 7.45 MB, FLOPs: 179,147,835\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Finished fine tuning.\n",
      "Iteration 692/1723 finished in 0m15s\n",
      "Total channels prunned so far: 692\n",
      "\n",
      "Iteration 693 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 54)]\n",
      "Input: 0.115 MB, Params: 1,917,158 (7.313 MB), Total: 7.43 MB, FLOPs: 178,954,083\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.068%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Finished fine tuning.\n",
      "Iteration 693/1723 finished in 0m15s\n",
      "Total channels prunned so far: 693\n",
      "\n",
      "Iteration 694 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 1)]\n",
      "Input: 0.115 MB, Params: 1,912,773 (7.297 MB), Total: 7.41 MB, FLOPs: 178,760,331\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.068%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Finished fine tuning.\n",
      "Iteration 694/1723 finished in 0m15s\n",
      "Total channels prunned so far: 694\n",
      "\n",
      "Iteration 695 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 149)]\n",
      "Input: 0.115 MB, Params: 1,908,388 (7.280 MB), Total: 7.40 MB, FLOPs: 178,566,579\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Finished fine tuning.\n",
      "Iteration 695/1723 finished in 0m15s\n",
      "Total channels prunned so far: 695\n",
      "\n",
      "Iteration 696 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 109)]\n",
      "Input: 0.115 MB, Params: 1,904,003 (7.263 MB), Total: 7.38 MB, FLOPs: 178,372,827\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Finished fine tuning.\n",
      "Iteration 696/1723 finished in 0m15s\n",
      "Total channels prunned so far: 696\n",
      "\n",
      "Iteration 697 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 28)]\n",
      "Input: 0.115 MB, Params: 1,901,580 (7.254 MB), Total: 7.37 MB, FLOPs: 177,922,367\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.492%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Finished fine tuning.\n",
      "Iteration 697/1723 finished in 0m15s\n",
      "Total channels prunned so far: 697\n",
      "\n",
      "Iteration 698 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 112)]\n",
      "Input: 0.115 MB, Params: 1,897,339 (7.238 MB), Total: 7.35 MB, FLOPs: 177,846,047\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Finished fine tuning.\n",
      "Iteration 698/1723 finished in 0m15s\n",
      "Total channels prunned so far: 698\n",
      "\n",
      "Iteration 699 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(3, 27)]\n",
      "Input: 0.115 MB, Params: 1,897,297 (7.238 MB), Total: 7.35 MB, FLOPs: 177,492,584\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.068%\n",
      "Finished fine tuning.\n",
      "Iteration 699/1723 finished in 0m15s\n",
      "Total channels prunned so far: 699\n",
      "\n",
      "Iteration 700 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 14)]\n",
      "Input: 0.115 MB, Params: 1,894,511 (7.227 MB), Total: 7.34 MB, FLOPs: 177,442,480\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.068%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Finished fine tuning.\n",
      "Iteration 700/1723 finished in 0m15s\n",
      "Total channels prunned so far: 700\n",
      "\n",
      "Iteration 701 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 280)]\n",
      "Input: 0.115 MB, Params: 1,891,725 (7.216 MB), Total: 7.33 MB, FLOPs: 177,392,376\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.068%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.339%\n",
      "Finished fine tuning.\n",
      "Iteration 701/1723 finished in 0m15s\n",
      "Total channels prunned so far: 701\n",
      "\n",
      "Iteration 702 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 16)]\n",
      "Input: 0.115 MB, Params: 1,887,502 (7.200 MB), Total: 7.32 MB, FLOPs: 177,316,380\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.068%\n",
      "Finished fine tuning.\n",
      "Iteration 702/1723 finished in 0m15s\n",
      "Total channels prunned so far: 702\n",
      "\n",
      "Iteration 703 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 16)]\n",
      "Input: 0.115 MB, Params: 1,885,079 (7.191 MB), Total: 7.31 MB, FLOPs: 176,865,920\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.492%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.254%\n",
      "Finished fine tuning.\n",
      "Iteration 703/1723 finished in 0m15s\n",
      "Total channels prunned so far: 703\n",
      "\n",
      "Iteration 704 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 280)]\n",
      "Input: 0.115 MB, Params: 1,882,302 (7.180 MB), Total: 7.30 MB, FLOPs: 176,815,978\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.068%\n",
      "Finished fine tuning.\n",
      "Iteration 704/1723 finished in 0m15s\n",
      "Total channels prunned so far: 704\n",
      "\n",
      "Iteration 705 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 44)]\n",
      "Input: 0.115 MB, Params: 1,878,088 (7.164 MB), Total: 7.28 MB, FLOPs: 176,740,144\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.068%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Finished fine tuning.\n",
      "Iteration 705/1723 finished in 0m15s\n",
      "Total channels prunned so far: 705\n",
      "\n",
      "Iteration 706 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 32)]\n",
      "Input: 0.115 MB, Params: 1,873,730 (7.148 MB), Total: 7.26 MB, FLOPs: 176,546,878\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Finished fine tuning.\n",
      "Iteration 706/1723 finished in 0m15s\n",
      "Total channels prunned so far: 706\n",
      "\n",
      "Iteration 707 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 284)]\n",
      "Input: 0.115 MB, Params: 1,869,525 (7.132 MB), Total: 7.25 MB, FLOPs: 176,471,206\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Finished fine tuning.\n",
      "Iteration 707/1723 finished in 0m15s\n",
      "Total channels prunned so far: 707\n",
      "\n",
      "Iteration 708 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 199)]\n",
      "Input: 0.115 MB, Params: 1,866,766 (7.121 MB), Total: 7.24 MB, FLOPs: 176,421,588\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.068%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Finished fine tuning.\n",
      "Iteration 708/1723 finished in 0m15s\n",
      "Total channels prunned so far: 708\n",
      "\n",
      "Iteration 709 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 27)]\n",
      "Input: 0.115 MB, Params: 1,864,406 (7.112 MB), Total: 7.23 MB, FLOPs: 176,209,278\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Finished fine tuning.\n",
      "Iteration 709/1723 finished in 0m15s\n",
      "Total channels prunned so far: 709\n",
      "\n",
      "Iteration 710 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 215)]\n",
      "Input: 0.115 MB, Params: 1,860,210 (7.096 MB), Total: 7.21 MB, FLOPs: 176,133,768\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Finished fine tuning.\n",
      "Iteration 710/1723 finished in 0m15s\n",
      "Total channels prunned so far: 710\n",
      "\n",
      "Iteration 711 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 166)]\n",
      "Input: 0.115 MB, Params: 1,856,014 (7.080 MB), Total: 7.20 MB, FLOPs: 176,058,258\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Finished fine tuning.\n",
      "Iteration 711/1723 finished in 0m15s\n",
      "Total channels prunned so far: 711\n",
      "\n",
      "Iteration 712 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 25)]\n",
      "Input: 0.115 MB, Params: 1,853,273 (7.070 MB), Total: 7.18 MB, FLOPs: 176,008,964\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Finished fine tuning.\n",
      "Iteration 712/1723 finished in 0m15s\n",
      "Total channels prunned so far: 712\n",
      "\n",
      "Iteration 713 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 172)]\n",
      "Input: 0.115 MB, Params: 1,850,913 (7.061 MB), Total: 7.18 MB, FLOPs: 175,796,654\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Finished fine tuning.\n",
      "Iteration 713/1723 finished in 0m15s\n",
      "Total channels prunned so far: 713\n",
      "\n",
      "Iteration 714 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(7, 11)]\n",
      "Input: 0.115 MB, Params: 1,850,479 (7.059 MB), Total: 7.17 MB, FLOPs: 175,060,709\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.407%\n",
      "Finished fine tuning.\n",
      "Iteration 714/1723 finished in 0m15s\n",
      "Total channels prunned so far: 714\n",
      "\n",
      "Iteration 715 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 133)]\n",
      "Input: 0.115 MB, Params: 1,848,119 (7.050 MB), Total: 7.17 MB, FLOPs: 174,848,399\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Finished fine tuning.\n",
      "Iteration 715/1723 finished in 0m15s\n",
      "Total channels prunned so far: 715\n",
      "\n",
      "Iteration 716 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 57)]\n",
      "Input: 0.115 MB, Params: 1,843,932 (7.034 MB), Total: 7.15 MB, FLOPs: 174,773,051\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Finished fine tuning.\n",
      "Iteration 716/1723 finished in 0m15s\n",
      "Total channels prunned so far: 716\n",
      "\n",
      "Iteration 717 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 148)]\n",
      "Input: 0.115 MB, Params: 1,841,200 (7.024 MB), Total: 7.14 MB, FLOPs: 174,723,919\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Finished fine tuning.\n",
      "Iteration 717/1723 finished in 0m15s\n",
      "Total channels prunned so far: 717\n",
      "\n",
      "Iteration 718 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 272)]\n",
      "Input: 0.115 MB, Params: 1,837,022 (7.008 MB), Total: 7.12 MB, FLOPs: 174,648,733\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.068%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Finished fine tuning.\n",
      "Iteration 718/1723 finished in 0m15s\n",
      "Total channels prunned so far: 718\n",
      "\n",
      "Iteration 719 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(14, 2)]\n",
      "Input: 0.115 MB, Params: 1,835,769 (7.003 MB), Total: 7.12 MB, FLOPs: 173,673,093\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Finished fine tuning.\n",
      "Iteration 719/1723 finished in 0m15s\n",
      "Total channels prunned so far: 719\n",
      "\n",
      "Iteration 720 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 134)]\n",
      "Input: 0.115 MB, Params: 1,831,483 (6.987 MB), Total: 7.10 MB, FLOPs: 173,483,067\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Finished fine tuning.\n",
      "Iteration 720/1723 finished in 0m15s\n",
      "Total channels prunned so far: 720\n",
      "\n",
      "Iteration 721 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 279)]\n",
      "Input: 0.115 MB, Params: 1,828,760 (6.976 MB), Total: 7.09 MB, FLOPs: 173,434,097\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.068%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Finished fine tuning.\n",
      "Iteration 721/1723 finished in 0m15s\n",
      "Total channels prunned so far: 721\n",
      "\n",
      "Iteration 722 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 64)]\n",
      "Input: 0.115 MB, Params: 1,824,600 (6.960 MB), Total: 7.08 MB, FLOPs: 173,359,235\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Finished fine tuning.\n",
      "Iteration 722/1723 finished in 0m15s\n",
      "Total channels prunned so far: 722\n",
      "\n",
      "Iteration 723 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 102)]\n",
      "Input: 0.115 MB, Params: 1,820,440 (6.944 MB), Total: 7.06 MB, FLOPs: 173,284,373\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.492%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Finished fine tuning.\n",
      "Iteration 723/1723 finished in 0m15s\n",
      "Total channels prunned so far: 723\n",
      "\n",
      "Iteration 724 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(3, 23)]\n",
      "Input: 0.115 MB, Params: 1,820,398 (6.944 MB), Total: 7.06 MB, FLOPs: 170,506,920\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Finished fine tuning.\n",
      "Iteration 724/1723 finished in 0m15s\n",
      "Total channels prunned so far: 724\n",
      "\n",
      "Iteration 725 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 0)]\n",
      "Input: 0.115 MB, Params: 1,819,712 (6.942 MB), Total: 7.06 MB, FLOPs: 169,479,420\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.746%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.407%\n",
      "Finished fine tuning.\n",
      "Iteration 725/1723 finished in 0m15s\n",
      "Total channels prunned so far: 725\n",
      "\n",
      "Iteration 726 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 291)]\n",
      "Input: 0.115 MB, Params: 1,815,552 (6.926 MB), Total: 7.04 MB, FLOPs: 169,404,558\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.983%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.254%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Finished fine tuning.\n",
      "Iteration 726/1723 finished in 0m15s\n",
      "Total channels prunned so far: 726\n",
      "\n",
      "Iteration 727 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(3, 1)]\n",
      "Input: 0.115 MB, Params: 1,815,510 (6.926 MB), Total: 7.04 MB, FLOPs: 169,052,605\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.407%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.407%\n",
      "Finished fine tuning.\n",
      "Iteration 727/1723 finished in 0m15s\n",
      "Total channels prunned so far: 727\n",
      "\n",
      "Iteration 728 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 23)]\n",
      "Input: 0.115 MB, Params: 1,812,814 (6.915 MB), Total: 7.03 MB, FLOPs: 169,004,121\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.136%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Finished fine tuning.\n",
      "Iteration 728/1723 finished in 0m15s\n",
      "Total channels prunned so far: 728\n",
      "\n",
      "Iteration 729 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 29)]\n",
      "Input: 0.115 MB, Params: 1,812,128 (6.913 MB), Total: 7.03 MB, FLOPs: 167,976,621\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.407%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.254%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.254%\n",
      "Finished fine tuning.\n",
      "Iteration 729/1723 finished in 0m15s\n",
      "Total channels prunned so far: 729\n",
      "\n",
      "Iteration 730 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 174)]\n",
      "Input: 0.115 MB, Params: 1,809,432 (6.902 MB), Total: 7.02 MB, FLOPs: 167,928,137\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.831%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Finished fine tuning.\n",
      "Iteration 730/1723 finished in 0m15s\n",
      "Total channels prunned so far: 730\n",
      "\n",
      "Iteration 731 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 142)]\n",
      "Input: 0.115 MB, Params: 1,806,736 (6.892 MB), Total: 7.01 MB, FLOPs: 167,879,653\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.983%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Finished fine tuning.\n",
      "Iteration 731/1723 finished in 0m15s\n",
      "Total channels prunned so far: 731\n",
      "\n",
      "Iteration 732 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 273)]\n",
      "Input: 0.115 MB, Params: 1,804,040 (6.882 MB), Total: 7.00 MB, FLOPs: 167,831,169\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.068%\n",
      "Finished fine tuning.\n",
      "Iteration 732/1723 finished in 0m15s\n",
      "Total channels prunned so far: 732\n",
      "\n",
      "Iteration 733 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 134)]\n",
      "Input: 0.115 MB, Params: 1,799,916 (6.866 MB), Total: 6.98 MB, FLOPs: 167,756,955\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Finished fine tuning.\n",
      "Iteration 733/1723 finished in 0m15s\n",
      "Total channels prunned so far: 733\n",
      "\n",
      "Iteration 734 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 183)]\n",
      "Input: 0.115 MB, Params: 1,795,792 (6.850 MB), Total: 6.97 MB, FLOPs: 167,682,741\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Finished fine tuning.\n",
      "Iteration 734/1723 finished in 0m15s\n",
      "Total channels prunned so far: 734\n",
      "\n",
      "Iteration 735 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 100)]\n",
      "Input: 0.115 MB, Params: 1,791,551 (6.834 MB), Total: 6.95 MB, FLOPs: 167,493,525\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.068%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Finished fine tuning.\n",
      "Iteration 735/1723 finished in 0m15s\n",
      "Total channels prunned so far: 735\n",
      "\n",
      "Iteration 736 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 159)]\n",
      "Input: 0.115 MB, Params: 1,787,436 (6.819 MB), Total: 6.93 MB, FLOPs: 167,419,473\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.068%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Finished fine tuning.\n",
      "Iteration 736/1723 finished in 0m15s\n",
      "Total channels prunned so far: 736\n",
      "\n",
      "Iteration 737 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 82)]\n",
      "Input: 0.115 MB, Params: 1,784,767 (6.808 MB), Total: 6.92 MB, FLOPs: 167,371,475\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.492%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.831%\n",
      "Finished fine tuning.\n",
      "Iteration 737/1723 finished in 0m15s\n",
      "Total channels prunned so far: 737\n",
      "\n",
      "Iteration 738 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 84)]\n",
      "Input: 0.115 MB, Params: 1,782,371 (6.799 MB), Total: 6.91 MB, FLOPs: 166,923,445\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.407%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Finished fine tuning.\n",
      "Iteration 738/1723 finished in 0m15s\n",
      "Total channels prunned so far: 738\n",
      "\n",
      "Iteration 739 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 170)]\n",
      "Input: 0.115 MB, Params: 1,780,038 (6.790 MB), Total: 6.91 MB, FLOPs: 166,713,565\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Finished fine tuning.\n",
      "Iteration 739/1723 finished in 0m15s\n",
      "Total channels prunned so far: 739\n",
      "\n",
      "Iteration 740 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 34)]\n",
      "Input: 0.115 MB, Params: 1,777,705 (6.781 MB), Total: 6.90 MB, FLOPs: 166,503,685\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.712%\n",
      "Finished fine tuning.\n",
      "Iteration 740/1723 finished in 0m15s\n",
      "Total channels prunned so far: 740\n",
      "\n",
      "Iteration 741 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 82)]\n",
      "Input: 0.115 MB, Params: 1,773,491 (6.765 MB), Total: 6.88 MB, FLOPs: 166,316,251\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.254%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Finished fine tuning.\n",
      "Iteration 741/1723 finished in 0m15s\n",
      "Total channels prunned so far: 741\n",
      "\n",
      "Iteration 742 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 25)]\n",
      "Input: 0.115 MB, Params: 1,772,805 (6.763 MB), Total: 6.88 MB, FLOPs: 165,288,751\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.983%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Finished fine tuning.\n",
      "Iteration 742/1723 finished in 0m15s\n",
      "Total channels prunned so far: 742\n",
      "\n",
      "Iteration 743 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 212)]\n",
      "Input: 0.115 MB, Params: 1,770,136 (6.753 MB), Total: 6.87 MB, FLOPs: 165,240,753\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Finished fine tuning.\n",
      "Iteration 743/1723 finished in 0m15s\n",
      "Total channels prunned so far: 743\n",
      "\n",
      "Iteration 744 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 118)]\n",
      "Input: 0.115 MB, Params: 1,766,048 (6.737 MB), Total: 6.85 MB, FLOPs: 165,167,187\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Finished fine tuning.\n",
      "Iteration 744/1723 finished in 0m15s\n",
      "Total channels prunned so far: 744\n",
      "\n",
      "Iteration 745 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 238)]\n",
      "Input: 0.115 MB, Params: 1,763,388 (6.727 MB), Total: 6.84 MB, FLOPs: 165,119,351\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.593%\n",
      "Finished fine tuning.\n",
      "Iteration 745/1723 finished in 0m15s\n",
      "Total channels prunned so far: 745\n",
      "\n",
      "Iteration 746 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 84)]\n",
      "Input: 0.115 MB, Params: 1,759,183 (6.711 MB), Total: 6.83 MB, FLOPs: 164,932,079\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.407%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.407%\n",
      "Finished fine tuning.\n",
      "Iteration 746/1723 finished in 0m15s\n",
      "Total channels prunned so far: 746\n",
      "\n",
      "Iteration 747 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 17)]\n",
      "Input: 0.115 MB, Params: 1,758,497 (6.708 MB), Total: 6.82 MB, FLOPs: 163,904,579\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.864%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.831%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Finished fine tuning.\n",
      "Iteration 747/1723 finished in 0m15s\n",
      "Total channels prunned so far: 747\n",
      "\n",
      "Iteration 748 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 16)]\n",
      "Input: 0.115 MB, Params: 1,757,811 (6.706 MB), Total: 6.82 MB, FLOPs: 162,877,079\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.254%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.831%\n",
      "Finished fine tuning.\n",
      "Iteration 748/1723 finished in 0m15s\n",
      "Total channels prunned so far: 748\n",
      "\n",
      "Iteration 749 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 139)]\n",
      "Input: 0.115 MB, Params: 1,753,606 (6.689 MB), Total: 6.80 MB, FLOPs: 162,689,807\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.254%\n",
      "Finished fine tuning.\n",
      "Iteration 749/1723 finished in 0m15s\n",
      "Total channels prunned so far: 749\n",
      "\n",
      "Iteration 750 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 149)]\n",
      "Input: 0.115 MB, Params: 1,751,300 (6.681 MB), Total: 6.80 MB, FLOPs: 162,482,357\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Finished fine tuning.\n",
      "Iteration 750/1723 finished in 0m15s\n",
      "Total channels prunned so far: 750\n",
      "\n",
      "Iteration 751 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 228)]\n",
      "Input: 0.115 MB, Params: 1,747,239 (6.665 MB), Total: 6.78 MB, FLOPs: 162,409,277\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.407%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Finished fine tuning.\n",
      "Iteration 751/1723 finished in 0m15s\n",
      "Total channels prunned so far: 751\n",
      "\n",
      "Iteration 752 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 43)]\n",
      "Input: 0.115 MB, Params: 1,744,870 (6.656 MB), Total: 6.77 MB, FLOPs: 161,963,677\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Finished fine tuning.\n",
      "Iteration 752/1723 finished in 0m15s\n",
      "Total channels prunned so far: 752\n",
      "\n",
      "Iteration 753 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 1)]\n",
      "Input: 0.115 MB, Params: 1,740,809 (6.641 MB), Total: 6.76 MB, FLOPs: 161,890,597\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Finished fine tuning.\n",
      "Iteration 753/1723 finished in 0m15s\n",
      "Total channels prunned so far: 753\n",
      "\n",
      "Iteration 754 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 163)]\n",
      "Input: 0.115 MB, Params: 1,738,512 (6.632 MB), Total: 6.75 MB, FLOPs: 161,683,957\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.068%\n",
      "Finished fine tuning.\n",
      "Iteration 754/1723 finished in 0m15s\n",
      "Total channels prunned so far: 754\n",
      "\n",
      "Iteration 755 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 77)]\n",
      "Input: 0.115 MB, Params: 1,736,152 (6.623 MB), Total: 6.74 MB, FLOPs: 161,239,167\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Finished fine tuning.\n",
      "Iteration 755/1723 finished in 0m15s\n",
      "Total channels prunned so far: 755\n",
      "\n",
      "Iteration 756 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 82)]\n",
      "Input: 0.115 MB, Params: 1,734,800 (6.618 MB), Total: 6.73 MB, FLOPs: 160,739,297\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Finished fine tuning.\n",
      "Iteration 756/1723 finished in 0m15s\n",
      "Total channels prunned so far: 756\n",
      "\n",
      "Iteration 757 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 49)]\n",
      "Input: 0.115 MB, Params: 1,732,449 (6.609 MB), Total: 6.72 MB, FLOPs: 160,297,837\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.254%\n",
      "Finished fine tuning.\n",
      "Iteration 757/1723 finished in 0m15s\n",
      "Total channels prunned so far: 757\n",
      "\n",
      "Iteration 758 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 276)]\n",
      "Input: 0.115 MB, Params: 1,729,807 (6.599 MB), Total: 6.71 MB, FLOPs: 160,250,325\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.407%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Finished fine tuning.\n",
      "Iteration 758/1723 finished in 0m15s\n",
      "Total channels prunned so far: 758\n",
      "\n",
      "Iteration 759 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 26)]\n",
      "Input: 0.115 MB, Params: 1,725,755 (6.583 MB), Total: 6.70 MB, FLOPs: 160,177,407\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Finished fine tuning.\n",
      "Iteration 759/1723 finished in 0m15s\n",
      "Total channels prunned so far: 759\n",
      "\n",
      "Iteration 760 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 15)]\n",
      "Input: 0.115 MB, Params: 1,723,122 (6.573 MB), Total: 6.69 MB, FLOPs: 160,130,057\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Finished fine tuning.\n",
      "Iteration 760/1723 finished in 0m15s\n",
      "Total channels prunned so far: 760\n",
      "\n",
      "Iteration 761 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 256)]\n",
      "Input: 0.115 MB, Params: 1,720,489 (6.563 MB), Total: 6.68 MB, FLOPs: 160,082,707\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.068%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 95.339%\n",
      "Finished fine tuning.\n",
      "Iteration 761/1723 finished in 0m15s\n",
      "Total channels prunned so far: 761\n",
      "\n",
      "Iteration 762 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 175)]\n",
      "Input: 0.115 MB, Params: 1,716,455 (6.548 MB), Total: 6.66 MB, FLOPs: 160,010,113\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.068%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Finished fine tuning.\n",
      "Iteration 762/1723 finished in 0m15s\n",
      "Total channels prunned so far: 762\n",
      "\n",
      "Iteration 763 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 147)]\n",
      "Input: 0.115 MB, Params: 1,712,421 (6.532 MB), Total: 6.65 MB, FLOPs: 159,937,519\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Finished fine tuning.\n",
      "Iteration 763/1723 finished in 0m15s\n",
      "Total channels prunned so far: 763\n",
      "\n",
      "Iteration 764 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 120)]\n",
      "Input: 0.115 MB, Params: 1,708,387 (6.517 MB), Total: 6.63 MB, FLOPs: 159,864,925\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.068%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Finished fine tuning.\n",
      "Iteration 764/1723 finished in 0m15s\n",
      "Total channels prunned so far: 764\n",
      "\n",
      "Iteration 765 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 108)]\n",
      "Input: 0.115 MB, Params: 1,706,108 (6.508 MB), Total: 6.62 MB, FLOPs: 159,659,905\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.492%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Finished fine tuning.\n",
      "Iteration 765/1723 finished in 0m15s\n",
      "Total channels prunned so far: 765\n",
      "\n",
      "Iteration 766 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 73)]\n",
      "Input: 0.115 MB, Params: 1,703,829 (6.500 MB), Total: 6.61 MB, FLOPs: 159,454,885\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.068%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Finished fine tuning.\n",
      "Iteration 766/1723 finished in 0m15s\n",
      "Total channels prunned so far: 766\n",
      "\n",
      "Iteration 767 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 18)]\n",
      "Input: 0.115 MB, Params: 1,701,223 (6.490 MB), Total: 6.60 MB, FLOPs: 159,408,021\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.068%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.068%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Finished fine tuning.\n",
      "Iteration 767/1723 finished in 0m15s\n",
      "Total channels prunned so far: 767\n",
      "\n",
      "Iteration 768 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 221)]\n",
      "Input: 0.115 MB, Params: 1,697,198 (6.474 MB), Total: 6.59 MB, FLOPs: 159,335,589\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Finished fine tuning.\n",
      "Iteration 768/1723 finished in 0m15s\n",
      "Total channels prunned so far: 768\n",
      "\n",
      "Iteration 769 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 10)]\n",
      "Input: 0.115 MB, Params: 1,693,092 (6.459 MB), Total: 6.57 MB, FLOPs: 159,152,691\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Finished fine tuning.\n",
      "Iteration 769/1723 finished in 0m15s\n",
      "Total channels prunned so far: 769\n",
      "\n",
      "Iteration 770 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(3, 39)]\n",
      "Input: 0.115 MB, Params: 1,693,050 (6.458 MB), Total: 6.57 MB, FLOPs: 145,231,027\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.831%\n",
      "Finished fine tuning.\n",
      "Iteration 770/1723 finished in 0m15s\n",
      "Total channels prunned so far: 770\n",
      "\n",
      "Iteration 771 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 48)]\n",
      "Input: 0.115 MB, Params: 1,688,944 (6.443 MB), Total: 6.56 MB, FLOPs: 145,075,363\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.983%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Finished fine tuning.\n",
      "Iteration 771/1723 finished in 0m15s\n",
      "Total channels prunned so far: 771\n",
      "\n",
      "Iteration 772 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 135)]\n",
      "Input: 0.115 MB, Params: 1,686,347 (6.433 MB), Total: 6.55 MB, FLOPs: 145,028,661\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Finished fine tuning.\n",
      "Iteration 772/1723 finished in 0m15s\n",
      "Total channels prunned so far: 772\n",
      "\n",
      "Iteration 773 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 90)]\n",
      "Input: 0.115 MB, Params: 1,684,014 (6.424 MB), Total: 6.54 MB, FLOPs: 144,646,449\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.559%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Finished fine tuning.\n",
      "Iteration 773/1723 finished in 0m15s\n",
      "Total channels prunned so far: 773\n",
      "\n",
      "Iteration 774 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 121)]\n",
      "Input: 0.115 MB, Params: 1,680,016 (6.409 MB), Total: 6.52 MB, FLOPs: 144,574,503\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Finished fine tuning.\n",
      "Iteration 774/1723 finished in 0m15s\n",
      "Total channels prunned so far: 774\n",
      "\n",
      "Iteration 775 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 282)]\n",
      "Input: 0.115 MB, Params: 1,676,018 (6.394 MB), Total: 6.51 MB, FLOPs: 144,502,557\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Finished fine tuning.\n",
      "Iteration 775/1723 finished in 0m15s\n",
      "Total channels prunned so far: 775\n",
      "\n",
      "Iteration 776 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 27)]\n",
      "Input: 0.115 MB, Params: 1,673,685 (6.385 MB), Total: 6.50 MB, FLOPs: 144,120,345\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Finished fine tuning.\n",
      "Iteration 776/1723 finished in 0m15s\n",
      "Total channels prunned so far: 776\n",
      "\n",
      "Iteration 777 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 216)]\n",
      "Input: 0.115 MB, Params: 1,671,106 (6.375 MB), Total: 6.49 MB, FLOPs: 144,073,967\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.831%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Finished fine tuning.\n",
      "Iteration 777/1723 finished in 0m15s\n",
      "Total channels prunned so far: 777\n",
      "\n",
      "Iteration 778 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 3)]\n",
      "Input: 0.115 MB, Params: 1,667,117 (6.360 MB), Total: 6.47 MB, FLOPs: 144,002,183\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Finished fine tuning.\n",
      "Iteration 778/1723 finished in 0m15s\n",
      "Total channels prunned so far: 778\n",
      "\n",
      "Iteration 779 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 114)]\n",
      "Input: 0.115 MB, Params: 1,663,128 (6.344 MB), Total: 6.46 MB, FLOPs: 143,930,399\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Finished fine tuning.\n",
      "Iteration 779/1723 finished in 0m15s\n",
      "Total channels prunned so far: 779\n",
      "\n",
      "Iteration 780 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 134)]\n",
      "Input: 0.115 MB, Params: 1,660,567 (6.335 MB), Total: 6.45 MB, FLOPs: 143,884,345\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Finished fine tuning.\n",
      "Iteration 780/1723 finished in 0m15s\n",
      "Total channels prunned so far: 780\n",
      "\n",
      "Iteration 781 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 273)]\n",
      "Input: 0.115 MB, Params: 1,658,006 (6.325 MB), Total: 6.44 MB, FLOPs: 143,838,291\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.254%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Finished fine tuning.\n",
      "Iteration 781/1723 finished in 0m15s\n",
      "Total channels prunned so far: 781\n",
      "\n",
      "Iteration 782 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 134)]\n",
      "Input: 0.115 MB, Params: 1,655,445 (6.315 MB), Total: 6.43 MB, FLOPs: 143,792,237\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.254%\n",
      "Finished fine tuning.\n",
      "Iteration 782/1723 finished in 0m15s\n",
      "Total channels prunned so far: 782\n",
      "\n",
      "Iteration 783 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 3)]\n",
      "Input: 0.115 MB, Params: 1,654,759 (6.312 MB), Total: 6.43 MB, FLOPs: 142,816,112\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.983%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Finished fine tuning.\n",
      "Iteration 783/1723 finished in 0m15s\n",
      "Total channels prunned so far: 783\n",
      "\n",
      "Iteration 784 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 212)]\n",
      "Input: 0.115 MB, Params: 1,650,797 (6.297 MB), Total: 6.41 MB, FLOPs: 142,744,814\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Finished fine tuning.\n",
      "Iteration 784/1723 finished in 0m15s\n",
      "Total channels prunned so far: 784\n",
      "\n",
      "Iteration 785 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 37)]\n",
      "Input: 0.115 MB, Params: 1,648,554 (6.289 MB), Total: 6.40 MB, FLOPs: 142,583,390\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Finished fine tuning.\n",
      "Iteration 785/1723 finished in 0m15s\n",
      "Total channels prunned so far: 785\n",
      "\n",
      "Iteration 786 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 199)]\n",
      "Input: 0.115 MB, Params: 1,646,002 (6.279 MB), Total: 6.39 MB, FLOPs: 142,537,498\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Finished fine tuning.\n",
      "Iteration 786/1723 finished in 0m15s\n",
      "Total channels prunned so far: 786\n",
      "\n",
      "Iteration 787 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 145)]\n",
      "Input: 0.115 MB, Params: 1,642,049 (6.264 MB), Total: 6.38 MB, FLOPs: 142,466,362\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.831%\n",
      "Finished fine tuning.\n",
      "Iteration 787/1723 finished in 0m15s\n",
      "Total channels prunned so far: 787\n",
      "\n",
      "Iteration 788 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 108)]\n",
      "Input: 0.115 MB, Params: 1,639,806 (6.255 MB), Total: 6.37 MB, FLOPs: 142,304,938\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.831%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Finished fine tuning.\n",
      "Iteration 788/1723 finished in 0m15s\n",
      "Total channels prunned so far: 788\n",
      "\n",
      "Iteration 789 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 31)]\n",
      "Input: 0.115 MB, Params: 1,635,853 (6.240 MB), Total: 6.36 MB, FLOPs: 142,233,802\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Finished fine tuning.\n",
      "Iteration 789/1723 finished in 0m15s\n",
      "Total channels prunned so far: 789\n",
      "\n",
      "Iteration 790 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 104)]\n",
      "Input: 0.115 MB, Params: 1,631,900 (6.225 MB), Total: 6.34 MB, FLOPs: 142,162,666\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.831%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Finished fine tuning.\n",
      "Iteration 790/1723 finished in 0m15s\n",
      "Total channels prunned so far: 790\n",
      "\n",
      "Iteration 791 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 266)]\n",
      "Input: 0.115 MB, Params: 1,627,947 (6.210 MB), Total: 6.33 MB, FLOPs: 142,091,530\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Finished fine tuning.\n",
      "Iteration 791/1723 finished in 0m15s\n",
      "Total channels prunned so far: 791\n",
      "\n",
      "Iteration 792 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 259)]\n",
      "Input: 0.115 MB, Params: 1,623,994 (6.195 MB), Total: 6.31 MB, FLOPs: 142,020,394\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Finished fine tuning.\n",
      "Iteration 792/1723 finished in 0m15s\n",
      "Total channels prunned so far: 792\n",
      "\n",
      "Iteration 793 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 198)]\n",
      "Input: 0.115 MB, Params: 1,621,487 (6.185 MB), Total: 6.30 MB, FLOPs: 141,975,312\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.254%\n",
      "Finished fine tuning.\n",
      "Iteration 793/1723 finished in 0m15s\n",
      "Total channels prunned so far: 793\n",
      "\n",
      "Iteration 794 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 127)]\n",
      "Input: 0.115 MB, Params: 1,617,543 (6.170 MB), Total: 6.29 MB, FLOPs: 141,904,338\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Finished fine tuning.\n",
      "Iteration 794/1723 finished in 0m15s\n",
      "Total channels prunned so far: 794\n",
      "\n",
      "Iteration 795 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 69)]\n",
      "Input: 0.115 MB, Params: 1,615,228 (6.162 MB), Total: 6.28 MB, FLOPs: 141,523,422\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.254%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Finished fine tuning.\n",
      "Iteration 795/1723 finished in 0m15s\n",
      "Total channels prunned so far: 795\n",
      "\n",
      "Iteration 796 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 86)]\n",
      "Input: 0.115 MB, Params: 1,612,730 (6.152 MB), Total: 6.27 MB, FLOPs: 141,478,502\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.831%\n",
      "Finished fine tuning.\n",
      "Iteration 796/1723 finished in 0m15s\n",
      "Total channels prunned so far: 796\n",
      "\n",
      "Iteration 797 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 176)]\n",
      "Input: 0.115 MB, Params: 1,610,232 (6.143 MB), Total: 6.26 MB, FLOPs: 141,433,582\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.831%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.407%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.254%\n",
      "Finished fine tuning.\n",
      "Iteration 797/1723 finished in 0m15s\n",
      "Total channels prunned so far: 797\n",
      "\n",
      "Iteration 798 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(14, 0)]\n",
      "Input: 0.115 MB, Params: 1,609,042 (6.138 MB), Total: 6.25 MB, FLOPs: 140,632,273\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.559%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.254%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.559%\n",
      "Finished fine tuning.\n",
      "Iteration 798/1723 finished in 0m15s\n",
      "Total channels prunned so far: 798\n",
      "\n",
      "Iteration 799 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(14, 42)]\n",
      "Input: 0.115 MB, Params: 1,607,852 (6.133 MB), Total: 6.25 MB, FLOPs: 139,830,964\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.712%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Finished fine tuning.\n",
      "Iteration 799/1723 finished in 0m15s\n",
      "Total channels prunned so far: 799\n",
      "\n",
      "Iteration 800 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 30)]\n",
      "Input: 0.115 MB, Params: 1,605,618 (6.125 MB), Total: 6.24 MB, FLOPs: 139,670,188\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Finished fine tuning.\n",
      "Iteration 800/1723 finished in 0m15s\n",
      "Total channels prunned so far: 800\n",
      "\n",
      "Iteration 801 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 102)]\n",
      "Input: 0.115 MB, Params: 1,603,120 (6.115 MB), Total: 6.23 MB, FLOPs: 139,625,268\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.831%\n",
      "Finished fine tuning.\n",
      "Iteration 801/1723 finished in 0m15s\n",
      "Total channels prunned so far: 801\n",
      "\n",
      "Iteration 802 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 241)]\n",
      "Input: 0.115 MB, Params: 1,599,203 (6.100 MB), Total: 6.22 MB, FLOPs: 139,554,780\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.831%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.254%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.831%\n",
      "Finished fine tuning.\n",
      "Iteration 802/1723 finished in 0m15s\n",
      "Total channels prunned so far: 802\n",
      "\n",
      "Iteration 803 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 163)]\n",
      "Input: 0.115 MB, Params: 1,595,286 (6.086 MB), Total: 6.20 MB, FLOPs: 139,484,292\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.831%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Finished fine tuning.\n",
      "Iteration 803/1723 finished in 0m15s\n",
      "Total channels prunned so far: 803\n",
      "\n",
      "Iteration 804 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 177)]\n",
      "Input: 0.115 MB, Params: 1,592,806 (6.076 MB), Total: 6.19 MB, FLOPs: 139,439,696\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.407%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Finished fine tuning.\n",
      "Iteration 804/1723 finished in 0m15s\n",
      "Total channels prunned so far: 804\n",
      "\n",
      "Iteration 805 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 150)]\n",
      "Input: 0.115 MB, Params: 1,590,572 (6.068 MB), Total: 6.18 MB, FLOPs: 139,278,920\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.831%\n",
      "Finished fine tuning.\n",
      "Iteration 805/1723 finished in 0m15s\n",
      "Total channels prunned so far: 805\n",
      "\n",
      "Iteration 806 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 212)]\n",
      "Input: 0.115 MB, Params: 1,588,092 (6.058 MB), Total: 6.17 MB, FLOPs: 139,234,324\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.254%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Finished fine tuning.\n",
      "Iteration 806/1723 finished in 0m15s\n",
      "Total channels prunned so far: 806\n",
      "\n",
      "Iteration 807 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 13)]\n",
      "Input: 0.115 MB, Params: 1,587,424 (6.056 MB), Total: 6.17 MB, FLOPs: 138,283,849\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.831%\n",
      "Finished fine tuning.\n",
      "Iteration 807/1723 finished in 0m15s\n",
      "Total channels prunned so far: 807\n",
      "\n",
      "Iteration 808 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 119)]\n",
      "Input: 0.115 MB, Params: 1,584,944 (6.046 MB), Total: 6.16 MB, FLOPs: 138,239,253\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.831%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Finished fine tuning.\n",
      "Iteration 808/1723 finished in 0m15s\n",
      "Total channels prunned so far: 808\n",
      "\n",
      "Iteration 809 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 74)]\n",
      "Input: 0.115 MB, Params: 1,582,647 (6.037 MB), Total: 6.15 MB, FLOPs: 137,859,633\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.068%\n",
      "Finished fine tuning.\n",
      "Iteration 809/1723 finished in 0m15s\n",
      "Total channels prunned so far: 809\n",
      "\n",
      "Iteration 810 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 46)]\n",
      "Input: 0.115 MB, Params: 1,578,694 (6.022 MB), Total: 6.14 MB, FLOPs: 137,708,667\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Finished fine tuning.\n",
      "Iteration 810/1723 finished in 0m15s\n",
      "Total channels prunned so far: 810\n",
      "\n",
      "Iteration 811 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 51)]\n",
      "Input: 0.115 MB, Params: 1,576,478 (6.014 MB), Total: 6.13 MB, FLOPs: 137,549,187\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.831%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Finished fine tuning.\n",
      "Iteration 811/1723 finished in 0m15s\n",
      "Total channels prunned so far: 811\n",
      "\n",
      "Iteration 812 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 100)]\n",
      "Input: 0.115 MB, Params: 1,572,597 (5.999 MB), Total: 6.11 MB, FLOPs: 137,479,347\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.831%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.831%\n",
      "Finished fine tuning.\n",
      "Iteration 812/1723 finished in 0m15s\n",
      "Total channels prunned so far: 812\n",
      "\n",
      "Iteration 813 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 0)]\n",
      "Input: 0.115 MB, Params: 1,571,308 (5.994 MB), Total: 6.11 MB, FLOPs: 137,050,443\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.254%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Finished fine tuning.\n",
      "Iteration 813/1723 finished in 0m15s\n",
      "Total channels prunned so far: 813\n",
      "\n",
      "Iteration 814 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 241)]\n",
      "Input: 0.115 MB, Params: 1,568,837 (5.985 MB), Total: 6.10 MB, FLOPs: 137,006,009\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.254%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Finished fine tuning.\n",
      "Iteration 814/1723 finished in 0m15s\n",
      "Total channels prunned so far: 814\n",
      "\n",
      "Iteration 815 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 23)]\n",
      "Input: 0.115 MB, Params: 1,564,965 (5.970 MB), Total: 6.09 MB, FLOPs: 136,936,331\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.254%\n",
      "Finished fine tuning.\n",
      "Iteration 815/1723 finished in 0m15s\n",
      "Total channels prunned so far: 815\n",
      "\n",
      "Iteration 816 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 18)]\n",
      "Input: 0.115 MB, Params: 1,562,503 (5.960 MB), Total: 6.08 MB, FLOPs: 136,892,059\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Finished fine tuning.\n",
      "Iteration 816/1723 finished in 0m15s\n",
      "Total channels prunned so far: 816\n",
      "\n",
      "Iteration 817 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 11)]\n",
      "Input: 0.115 MB, Params: 1,561,214 (5.956 MB), Total: 6.07 MB, FLOPs: 136,463,155\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Finished fine tuning.\n",
      "Iteration 817/1723 finished in 0m15s\n",
      "Total channels prunned so far: 817\n",
      "\n",
      "Iteration 818 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 254)]\n",
      "Input: 0.115 MB, Params: 1,557,351 (5.941 MB), Total: 6.06 MB, FLOPs: 136,393,639\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Finished fine tuning.\n",
      "Iteration 818/1723 finished in 0m15s\n",
      "Total channels prunned so far: 818\n",
      "\n",
      "Iteration 819 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 159)]\n",
      "Input: 0.115 MB, Params: 1,553,488 (5.926 MB), Total: 6.04 MB, FLOPs: 136,324,123\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Finished fine tuning.\n",
      "Iteration 819/1723 finished in 0m15s\n",
      "Total channels prunned so far: 819\n",
      "\n",
      "Iteration 820 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 255)]\n",
      "Input: 0.115 MB, Params: 1,551,044 (5.917 MB), Total: 6.03 MB, FLOPs: 136,280,175\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Finished fine tuning.\n",
      "Iteration 820/1723 finished in 0m15s\n",
      "Total channels prunned so far: 820\n",
      "\n",
      "Iteration 821 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(14, 49)]\n",
      "Input: 0.115 MB, Params: 1,549,881 (5.912 MB), Total: 6.03 MB, FLOPs: 135,497,685\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Finished fine tuning.\n",
      "Iteration 821/1723 finished in 0m15s\n",
      "Total channels prunned so far: 821\n",
      "\n",
      "Iteration 822 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 187)]\n",
      "Input: 0.115 MB, Params: 1,546,027 (5.898 MB), Total: 6.01 MB, FLOPs: 135,428,331\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Finished fine tuning.\n",
      "Iteration 822/1723 finished in 0m15s\n",
      "Total channels prunned so far: 822\n",
      "\n",
      "Iteration 823 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 84)]\n",
      "Input: 0.115 MB, Params: 1,543,592 (5.888 MB), Total: 6.00 MB, FLOPs: 135,384,545\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Finished fine tuning.\n",
      "Iteration 823/1723 finished in 0m15s\n",
      "Total channels prunned so far: 823\n",
      "\n",
      "Iteration 824 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(3, 22)]\n",
      "Input: 0.115 MB, Params: 1,543,550 (5.888 MB), Total: 6.00 MB, FLOPs: 135,032,592\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Finished fine tuning.\n",
      "Iteration 824/1723 finished in 0m15s\n",
      "Total channels prunned so far: 824\n",
      "\n",
      "Iteration 825 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 84)]\n",
      "Input: 0.115 MB, Params: 1,539,651 (5.873 MB), Total: 5.99 MB, FLOPs: 134,883,084\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Finished fine tuning.\n",
      "Iteration 825/1723 finished in 0m15s\n",
      "Total channels prunned so far: 825\n",
      "\n",
      "Iteration 826 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 78)]\n",
      "Input: 0.115 MB, Params: 1,537,216 (5.864 MB), Total: 5.98 MB, FLOPs: 134,839,298\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Finished fine tuning.\n",
      "Iteration 826/1723 finished in 0m15s\n",
      "Total channels prunned so far: 826\n",
      "\n",
      "Iteration 827 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 34)]\n",
      "Input: 0.115 MB, Params: 1,533,317 (5.849 MB), Total: 5.96 MB, FLOPs: 134,689,790\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Finished fine tuning.\n",
      "Iteration 827/1723 finished in 0m15s\n",
      "Total channels prunned so far: 827\n",
      "\n",
      "Iteration 828 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 212)]\n",
      "Input: 0.115 MB, Params: 1,530,882 (5.840 MB), Total: 5.96 MB, FLOPs: 134,646,004\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.068%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Finished fine tuning.\n",
      "Iteration 828/1723 finished in 0m15s\n",
      "Total channels prunned so far: 828\n",
      "\n",
      "Iteration 829 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 54)]\n",
      "Input: 0.115 MB, Params: 1,526,983 (5.825 MB), Total: 5.94 MB, FLOPs: 134,496,496\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Finished fine tuning.\n",
      "Iteration 829/1723 finished in 0m15s\n",
      "Total channels prunned so far: 829\n",
      "\n",
      "Iteration 830 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 21)]\n",
      "Input: 0.115 MB, Params: 1,523,183 (5.810 MB), Total: 5.93 MB, FLOPs: 134,428,114\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Finished fine tuning.\n",
      "Iteration 830/1723 finished in 0m15s\n",
      "Total channels prunned so far: 830\n",
      "\n",
      "Iteration 831 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 228)]\n",
      "Input: 0.115 MB, Params: 1,519,383 (5.796 MB), Total: 5.91 MB, FLOPs: 134,359,732\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Finished fine tuning.\n",
      "Iteration 831/1723 finished in 0m15s\n",
      "Total channels prunned so far: 831\n",
      "\n",
      "Iteration 832 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 103)]\n",
      "Input: 0.115 MB, Params: 1,515,502 (5.781 MB), Total: 5.90 MB, FLOPs: 134,210,548\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Finished fine tuning.\n",
      "Iteration 832/1723 finished in 0m15s\n",
      "Total channels prunned so far: 832\n",
      "\n",
      "Iteration 833 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 235)]\n",
      "Input: 0.115 MB, Params: 1,511,711 (5.767 MB), Total: 5.88 MB, FLOPs: 134,142,328\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Finished fine tuning.\n",
      "Iteration 833/1723 finished in 0m15s\n",
      "Total channels prunned so far: 833\n",
      "\n",
      "Iteration 834 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 72)]\n",
      "Input: 0.115 MB, Params: 1,510,431 (5.762 MB), Total: 5.88 MB, FLOPs: 133,716,421\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Finished fine tuning.\n",
      "Iteration 834/1723 finished in 0m15s\n",
      "Total channels prunned so far: 834\n",
      "\n",
      "Iteration 835 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 33)]\n",
      "Input: 0.115 MB, Params: 1,509,151 (5.757 MB), Total: 5.87 MB, FLOPs: 133,290,514\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.492%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Finished fine tuning.\n",
      "Iteration 835/1723 finished in 0m15s\n",
      "Total channels prunned so far: 835\n",
      "\n",
      "Iteration 836 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 73)]\n",
      "Input: 0.115 MB, Params: 1,506,899 (5.748 MB), Total: 5.86 MB, FLOPs: 132,923,530\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Finished fine tuning.\n",
      "Iteration 836/1723 finished in 0m15s\n",
      "Total channels prunned so far: 836\n",
      "\n",
      "Iteration 837 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 33)]\n",
      "Input: 0.115 MB, Params: 1,505,628 (5.744 MB), Total: 5.86 MB, FLOPs: 132,500,620\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Finished fine tuning.\n",
      "Iteration 837/1723 finished in 0m15s\n",
      "Total channels prunned so far: 837\n",
      "\n",
      "Iteration 838 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 57)]\n",
      "Input: 0.115 MB, Params: 1,503,457 (5.735 MB), Total: 5.85 MB, FLOPs: 132,344,380\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Finished fine tuning.\n",
      "Iteration 838/1723 finished in 0m15s\n",
      "Total channels prunned so far: 838\n",
      "\n",
      "Iteration 839 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 29)]\n",
      "Input: 0.115 MB, Params: 1,502,798 (5.733 MB), Total: 5.85 MB, FLOPs: 131,406,730\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.254%\n",
      "Finished fine tuning.\n",
      "Iteration 839/1723 finished in 0m15s\n",
      "Total channels prunned so far: 839\n",
      "\n",
      "Iteration 840 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 128)]\n",
      "Input: 0.115 MB, Params: 1,499,007 (5.718 MB), Total: 5.83 MB, FLOPs: 131,338,510\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.915%\n",
      "Finished fine tuning.\n",
      "Iteration 840/1723 finished in 0m15s\n",
      "Total channels prunned so far: 840\n",
      "\n",
      "Iteration 841 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 180)]\n",
      "Input: 0.115 MB, Params: 1,496,608 (5.709 MB), Total: 5.82 MB, FLOPs: 131,295,372\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.492%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Finished fine tuning.\n",
      "Iteration 841/1723 finished in 0m15s\n",
      "Total channels prunned so far: 841\n",
      "\n",
      "Iteration 842 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 20)]\n",
      "Input: 0.115 MB, Params: 1,494,437 (5.701 MB), Total: 5.82 MB, FLOPs: 131,139,132\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Finished fine tuning.\n",
      "Iteration 842/1723 finished in 0m15s\n",
      "Total channels prunned so far: 842\n",
      "\n",
      "Iteration 843 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 136)]\n",
      "Input: 0.115 MB, Params: 1,492,266 (5.693 MB), Total: 5.81 MB, FLOPs: 130,982,892\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Finished fine tuning.\n",
      "Iteration 843/1723 finished in 0m15s\n",
      "Total channels prunned so far: 843\n",
      "\n",
      "Iteration 844 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 6)]\n",
      "Input: 0.115 MB, Params: 1,489,867 (5.683 MB), Total: 5.80 MB, FLOPs: 130,939,754\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Finished fine tuning.\n",
      "Iteration 844/1723 finished in 0m15s\n",
      "Total channels prunned so far: 844\n",
      "\n",
      "Iteration 845 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 81)]\n",
      "Input: 0.115 MB, Params: 1,486,094 (5.669 MB), Total: 5.78 MB, FLOPs: 130,871,858\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.068%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Finished fine tuning.\n",
      "Iteration 845/1723 finished in 0m15s\n",
      "Total channels prunned so far: 845\n",
      "\n",
      "Iteration 846 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 83)]\n",
      "Input: 0.115 MB, Params: 1,483,704 (5.660 MB), Total: 5.78 MB, FLOPs: 130,828,882\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.492%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Finished fine tuning.\n",
      "Iteration 846/1723 finished in 0m15s\n",
      "Total channels prunned so far: 846\n",
      "\n",
      "Iteration 847 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(3, 36)]\n",
      "Input: 0.115 MB, Params: 1,483,662 (5.660 MB), Total: 5.78 MB, FLOPs: 128,541,629\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.831%\n",
      "Finished fine tuning.\n",
      "Iteration 847/1723 finished in 0m15s\n",
      "Total channels prunned so far: 847\n",
      "\n",
      "Iteration 848 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 202)]\n",
      "Input: 0.115 MB, Params: 1,479,898 (5.645 MB), Total: 5.76 MB, FLOPs: 128,473,895\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Finished fine tuning.\n",
      "Iteration 848/1723 finished in 0m15s\n",
      "Total channels prunned so far: 848\n",
      "\n",
      "Iteration 849 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(3, 36)]\n",
      "Input: 0.115 MB, Params: 1,479,856 (5.645 MB), Total: 5.76 MB, FLOPs: 128,121,942\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Finished fine tuning.\n",
      "Iteration 849/1723 finished in 0m15s\n",
      "Total channels prunned so far: 849\n",
      "\n",
      "Iteration 850 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 42)]\n",
      "Input: 0.115 MB, Params: 1,477,685 (5.637 MB), Total: 5.75 MB, FLOPs: 127,965,702\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Finished fine tuning.\n",
      "Iteration 850/1723 finished in 0m15s\n",
      "Total channels prunned so far: 850\n",
      "\n",
      "Iteration 851 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 126)]\n",
      "Input: 0.115 MB, Params: 1,473,921 (5.623 MB), Total: 5.74 MB, FLOPs: 127,897,968\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.068%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Finished fine tuning.\n",
      "Iteration 851/1723 finished in 0m15s\n",
      "Total channels prunned so far: 851\n",
      "\n",
      "Iteration 852 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 254)]\n",
      "Input: 0.115 MB, Params: 1,470,157 (5.608 MB), Total: 5.72 MB, FLOPs: 127,830,234\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Finished fine tuning.\n",
      "Iteration 852/1723 finished in 0m15s\n",
      "Total channels prunned so far: 852\n",
      "\n",
      "Iteration 853 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 77)]\n",
      "Input: 0.115 MB, Params: 1,467,986 (5.600 MB), Total: 5.72 MB, FLOPs: 127,673,994\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Finished fine tuning.\n",
      "Iteration 853/1723 finished in 0m15s\n",
      "Total channels prunned so far: 853\n",
      "\n",
      "Iteration 854 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 108)]\n",
      "Input: 0.115 MB, Params: 1,465,815 (5.592 MB), Total: 5.71 MB, FLOPs: 127,517,754\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Finished fine tuning.\n",
      "Iteration 854/1723 finished in 0m15s\n",
      "Total channels prunned so far: 854\n",
      "\n",
      "Iteration 855 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 8)]\n",
      "Input: 0.115 MB, Params: 1,463,644 (5.583 MB), Total: 5.70 MB, FLOPs: 127,361,514\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.492%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Finished fine tuning.\n",
      "Iteration 855/1723 finished in 0m15s\n",
      "Total channels prunned so far: 855\n",
      "\n",
      "Iteration 856 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 160)]\n",
      "Input: 0.115 MB, Params: 1,461,281 (5.574 MB), Total: 5.69 MB, FLOPs: 127,319,024\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Finished fine tuning.\n",
      "Iteration 856/1723 finished in 0m15s\n",
      "Total channels prunned so far: 856\n",
      "\n",
      "Iteration 857 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 223)]\n",
      "Input: 0.115 MB, Params: 1,458,918 (5.565 MB), Total: 5.68 MB, FLOPs: 127,276,534\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Finished fine tuning.\n",
      "Iteration 857/1723 finished in 0m15s\n",
      "Total channels prunned so far: 857\n",
      "\n",
      "Iteration 858 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 104)]\n",
      "Input: 0.115 MB, Params: 1,455,154 (5.551 MB), Total: 5.67 MB, FLOPs: 127,132,858\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Finished fine tuning.\n",
      "Iteration 858/1723 finished in 0m15s\n",
      "Total channels prunned so far: 858\n",
      "\n",
      "Iteration 859 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 28)]\n",
      "Input: 0.115 MB, Params: 1,452,974 (5.543 MB), Total: 5.66 MB, FLOPs: 126,773,407\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.407%\n",
      "Finished fine tuning.\n",
      "Iteration 859/1723 finished in 0m15s\n",
      "Total channels prunned so far: 859\n",
      "\n",
      "Iteration 860 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 105)]\n",
      "Input: 0.115 MB, Params: 1,450,821 (5.534 MB), Total: 5.65 MB, FLOPs: 126,618,463\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.407%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Finished fine tuning.\n",
      "Iteration 860/1723 finished in 0m15s\n",
      "Total channels prunned so far: 860\n",
      "\n",
      "Iteration 861 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 256)]\n",
      "Input: 0.115 MB, Params: 1,447,084 (5.520 MB), Total: 5.64 MB, FLOPs: 126,551,215\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Finished fine tuning.\n",
      "Iteration 861/1723 finished in 0m15s\n",
      "Total channels prunned so far: 861\n",
      "\n",
      "Iteration 862 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 45)]\n",
      "Input: 0.115 MB, Params: 1,444,931 (5.512 MB), Total: 5.63 MB, FLOPs: 126,396,271\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Finished fine tuning.\n",
      "Iteration 862/1723 finished in 0m15s\n",
      "Total channels prunned so far: 862\n",
      "\n",
      "Iteration 863 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 64)]\n",
      "Input: 0.115 MB, Params: 1,443,669 (5.507 MB), Total: 5.62 MB, FLOPs: 125,976,358\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Finished fine tuning.\n",
      "Iteration 863/1723 finished in 0m15s\n",
      "Total channels prunned so far: 863\n",
      "\n",
      "Iteration 864 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 41)]\n",
      "Input: 0.115 MB, Params: 1,441,516 (5.499 MB), Total: 5.61 MB, FLOPs: 125,621,200\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.068%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Finished fine tuning.\n",
      "Iteration 864/1723 finished in 0m15s\n",
      "Total channels prunned so far: 864\n",
      "\n",
      "Iteration 865 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 9)]\n",
      "Input: 0.115 MB, Params: 1,437,779 (5.485 MB), Total: 5.60 MB, FLOPs: 125,478,982\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.068%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Finished fine tuning.\n",
      "Iteration 865/1723 finished in 0m15s\n",
      "Total channels prunned so far: 865\n",
      "\n",
      "Iteration 866 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 70)]\n",
      "Input: 0.115 MB, Params: 1,434,042 (5.470 MB), Total: 5.59 MB, FLOPs: 125,336,764\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Finished fine tuning.\n",
      "Iteration 866/1723 finished in 0m15s\n",
      "Total channels prunned so far: 866\n",
      "\n",
      "Iteration 867 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 143)]\n",
      "Input: 0.115 MB, Params: 1,430,305 (5.456 MB), Total: 5.57 MB, FLOPs: 125,194,546\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Finished fine tuning.\n",
      "Iteration 867/1723 finished in 0m15s\n",
      "Total channels prunned so far: 867\n",
      "\n",
      "Iteration 868 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 68)]\n",
      "Input: 0.115 MB, Params: 1,426,595 (5.442 MB), Total: 5.56 MB, FLOPs: 125,127,784\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Finished fine tuning.\n",
      "Iteration 868/1723 finished in 0m15s\n",
      "Total channels prunned so far: 868\n",
      "\n",
      "Iteration 869 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 115)]\n",
      "Input: 0.115 MB, Params: 1,422,885 (5.428 MB), Total: 5.54 MB, FLOPs: 125,061,022\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Finished fine tuning.\n",
      "Iteration 869/1723 finished in 0m15s\n",
      "Total channels prunned so far: 869\n",
      "\n",
      "Iteration 870 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 235)]\n",
      "Input: 0.115 MB, Params: 1,420,549 (5.419 MB), Total: 5.53 MB, FLOPs: 125,019,018\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Finished fine tuning.\n",
      "Iteration 870/1723 finished in 0m15s\n",
      "Total channels prunned so far: 870\n",
      "\n",
      "Iteration 871 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 0)]\n",
      "Input: 0.115 MB, Params: 1,418,213 (5.410 MB), Total: 5.53 MB, FLOPs: 124,977,014\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Finished fine tuning.\n",
      "Iteration 871/1723 finished in 0m15s\n",
      "Total channels prunned so far: 871\n",
      "\n",
      "Iteration 872 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 33)]\n",
      "Input: 0.115 MB, Params: 1,414,494 (5.396 MB), Total: 5.51 MB, FLOPs: 124,835,120\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Finished fine tuning.\n",
      "Iteration 872/1723 finished in 0m15s\n",
      "Total channels prunned so far: 872\n",
      "\n",
      "Iteration 873 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 179)]\n",
      "Input: 0.115 MB, Params: 1,410,811 (5.382 MB), Total: 5.50 MB, FLOPs: 124,768,844\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Finished fine tuning.\n",
      "Iteration 873/1723 finished in 0m15s\n",
      "Total channels prunned so far: 873\n",
      "\n",
      "Iteration 874 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 135)]\n",
      "Input: 0.115 MB, Params: 1,408,484 (5.373 MB), Total: 5.49 MB, FLOPs: 124,727,002\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Finished fine tuning.\n",
      "Iteration 874/1723 finished in 0m15s\n",
      "Total channels prunned so far: 874\n",
      "\n",
      "Iteration 875 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 60)]\n",
      "Input: 0.115 MB, Params: 1,407,231 (5.368 MB), Total: 5.48 MB, FLOPs: 124,310,086\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Finished fine tuning.\n",
      "Iteration 875/1723 finished in 0m15s\n",
      "Total channels prunned so far: 875\n",
      "\n",
      "Iteration 876 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 125)]\n",
      "Input: 0.115 MB, Params: 1,405,123 (5.360 MB), Total: 5.48 MB, FLOPs: 124,158,382\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Finished fine tuning.\n",
      "Iteration 876/1723 finished in 0m15s\n",
      "Total channels prunned so far: 876\n",
      "\n",
      "Iteration 877 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 71)]\n",
      "Input: 0.115 MB, Params: 1,402,796 (5.351 MB), Total: 5.47 MB, FLOPs: 124,116,540\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.068%\n",
      "Finished fine tuning.\n",
      "Iteration 877/1723 finished in 0m15s\n",
      "Total channels prunned so far: 877\n",
      "\n",
      "Iteration 878 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 50)]\n",
      "Input: 0.115 MB, Params: 1,399,131 (5.337 MB), Total: 5.45 MB, FLOPs: 124,050,588\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.492%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Finished fine tuning.\n",
      "Iteration 878/1723 finished in 0m15s\n",
      "Total channels prunned so far: 878\n",
      "\n",
      "Iteration 879 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 255)]\n",
      "Input: 0.115 MB, Params: 1,395,466 (5.323 MB), Total: 5.44 MB, FLOPs: 123,984,636\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.068%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.068%\n",
      "Finished fine tuning.\n",
      "Iteration 879/1723 finished in 0m15s\n",
      "Total channels prunned so far: 879\n",
      "\n",
      "Iteration 880 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 217)]\n",
      "Input: 0.115 MB, Params: 1,393,157 (5.314 MB), Total: 5.43 MB, FLOPs: 123,943,118\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.068%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Finished fine tuning.\n",
      "Iteration 880/1723 finished in 0m15s\n",
      "Total channels prunned so far: 880\n",
      "\n",
      "Iteration 881 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 14)]\n",
      "Input: 0.115 MB, Params: 1,391,049 (5.306 MB), Total: 5.42 MB, FLOPs: 123,791,414\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.068%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.068%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Finished fine tuning.\n",
      "Iteration 881/1723 finished in 0m15s\n",
      "Total channels prunned so far: 881\n",
      "\n",
      "Iteration 882 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 39)]\n",
      "Input: 0.115 MB, Params: 1,388,941 (5.298 MB), Total: 5.41 MB, FLOPs: 123,639,710\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.068%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.068%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Finished fine tuning.\n",
      "Iteration 882/1723 finished in 0m15s\n",
      "Total channels prunned so far: 882\n",
      "\n",
      "Iteration 883 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 189)]\n",
      "Input: 0.115 MB, Params: 1,386,632 (5.290 MB), Total: 5.40 MB, FLOPs: 123,598,192\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.068%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Finished fine tuning.\n",
      "Iteration 883/1723 finished in 0m15s\n",
      "Total channels prunned so far: 883\n",
      "\n",
      "Iteration 884 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 71)]\n",
      "Input: 0.115 MB, Params: 1,385,379 (5.285 MB), Total: 5.40 MB, FLOPs: 123,181,276\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Finished fine tuning.\n",
      "Iteration 884/1723 finished in 0m15s\n",
      "Total channels prunned so far: 884\n",
      "\n",
      "Iteration 885 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 1)]\n",
      "Input: 0.115 MB, Params: 1,383,271 (5.277 MB), Total: 5.39 MB, FLOPs: 123,029,572\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Finished fine tuning.\n",
      "Iteration 885/1723 finished in 0m15s\n",
      "Total channels prunned so far: 885\n",
      "\n",
      "Iteration 886 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 9)]\n",
      "Input: 0.115 MB, Params: 1,380,962 (5.268 MB), Total: 5.38 MB, FLOPs: 122,988,054\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.492%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Finished fine tuning.\n",
      "Iteration 886/1723 finished in 0m15s\n",
      "Total channels prunned so far: 886\n",
      "\n",
      "Iteration 887 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 65)]\n",
      "Input: 0.115 MB, Params: 1,377,324 (5.254 MB), Total: 5.37 MB, FLOPs: 122,922,588\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Finished fine tuning.\n",
      "Iteration 887/1723 finished in 0m15s\n",
      "Total channels prunned so far: 887\n",
      "\n",
      "Iteration 888 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 146)]\n",
      "Input: 0.115 MB, Params: 1,375,024 (5.245 MB), Total: 5.36 MB, FLOPs: 122,881,232\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Finished fine tuning.\n",
      "Iteration 888/1723 finished in 0m15s\n",
      "Total channels prunned so far: 888\n",
      "\n",
      "Iteration 889 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 192)]\n",
      "Input: 0.115 MB, Params: 1,372,724 (5.237 MB), Total: 5.35 MB, FLOPs: 122,839,876\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Finished fine tuning.\n",
      "Iteration 889/1723 finished in 0m15s\n",
      "Total channels prunned so far: 889\n",
      "\n",
      "Iteration 890 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 1)]\n",
      "Input: 0.115 MB, Params: 1,371,471 (5.232 MB), Total: 5.35 MB, FLOPs: 122,422,960\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Finished fine tuning.\n",
      "Iteration 890/1723 finished in 0m15s\n",
      "Total channels prunned so far: 890\n",
      "\n",
      "Iteration 891 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 37)]\n",
      "Input: 0.115 MB, Params: 1,369,381 (5.224 MB), Total: 5.34 MB, FLOPs: 122,079,385\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Finished fine tuning.\n",
      "Iteration 891/1723 finished in 0m15s\n",
      "Total channels prunned so far: 891\n",
      "\n",
      "Iteration 892 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 110)]\n",
      "Input: 0.115 MB, Params: 1,365,761 (5.210 MB), Total: 5.33 MB, FLOPs: 122,014,243\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Finished fine tuning.\n",
      "Iteration 892/1723 finished in 0m15s\n",
      "Total channels prunned so far: 892\n",
      "\n",
      "Iteration 893 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 59)]\n",
      "Input: 0.115 MB, Params: 1,363,671 (5.202 MB), Total: 5.32 MB, FLOPs: 121,670,668\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Finished fine tuning.\n",
      "Iteration 893/1723 finished in 0m15s\n",
      "Total channels prunned so far: 893\n",
      "\n",
      "Iteration 894 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 45)]\n",
      "Input: 0.115 MB, Params: 1,361,581 (5.194 MB), Total: 5.31 MB, FLOPs: 121,327,093\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Finished fine tuning.\n",
      "Iteration 894/1723 finished in 0m15s\n",
      "Total channels prunned so far: 894\n",
      "\n",
      "Iteration 895 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 52)]\n",
      "Input: 0.115 MB, Params: 1,357,943 (5.180 MB), Total: 5.30 MB, FLOPs: 121,188,601\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Finished fine tuning.\n",
      "Iteration 895/1723 finished in 0m15s\n",
      "Total channels prunned so far: 895\n",
      "\n",
      "Iteration 896 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 25)]\n",
      "Input: 0.115 MB, Params: 1,354,305 (5.166 MB), Total: 5.28 MB, FLOPs: 121,050,109\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Finished fine tuning.\n",
      "Iteration 896/1723 finished in 0m15s\n",
      "Total channels prunned so far: 896\n",
      "\n",
      "Iteration 897 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 165)]\n",
      "Input: 0.115 MB, Params: 1,350,703 (5.153 MB), Total: 5.27 MB, FLOPs: 120,985,291\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Finished fine tuning.\n",
      "Iteration 897/1723 finished in 0m15s\n",
      "Total channels prunned so far: 897\n",
      "\n",
      "Iteration 898 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(7, 14)]\n",
      "Input: 0.115 MB, Params: 1,350,341 (5.151 MB), Total: 5.27 MB, FLOPs: 120,451,681\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Finished fine tuning.\n",
      "Iteration 898/1723 finished in 0m15s\n",
      "Total channels prunned so far: 898\n",
      "\n",
      "Iteration 899 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 239)]\n",
      "Input: 0.115 MB, Params: 1,346,739 (5.137 MB), Total: 5.25 MB, FLOPs: 120,386,863\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.068%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Finished fine tuning.\n",
      "Iteration 899/1723 finished in 0m15s\n",
      "Total channels prunned so far: 899\n",
      "\n",
      "Iteration 900 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 206)]\n",
      "Input: 0.115 MB, Params: 1,344,466 (5.129 MB), Total: 5.24 MB, FLOPs: 120,345,993\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Finished fine tuning.\n",
      "Iteration 900/1723 finished in 0m15s\n",
      "Total channels prunned so far: 900\n",
      "\n",
      "Iteration 901 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 71)]\n",
      "Input: 0.115 MB, Params: 1,342,193 (5.120 MB), Total: 5.24 MB, FLOPs: 120,305,123\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Finished fine tuning.\n",
      "Iteration 901/1723 finished in 0m15s\n",
      "Total channels prunned so far: 901\n",
      "\n",
      "Iteration 902 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 123)]\n",
      "Input: 0.115 MB, Params: 1,338,609 (5.106 MB), Total: 5.22 MB, FLOPs: 120,240,629\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Finished fine tuning.\n",
      "Iteration 902/1723 finished in 0m15s\n",
      "Total channels prunned so far: 902\n",
      "\n",
      "Iteration 903 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 115)]\n",
      "Input: 0.115 MB, Params: 1,336,546 (5.099 MB), Total: 5.21 MB, FLOPs: 120,092,165\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Finished fine tuning.\n",
      "Iteration 903/1723 finished in 0m15s\n",
      "Total channels prunned so far: 903\n",
      "\n",
      "Iteration 904 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 55)]\n",
      "Input: 0.115 MB, Params: 1,334,465 (5.091 MB), Total: 5.21 MB, FLOPs: 119,749,238\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Finished fine tuning.\n",
      "Iteration 904/1723 finished in 0m15s\n",
      "Total channels prunned so far: 904\n",
      "\n",
      "Iteration 905 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 32)]\n",
      "Input: 0.115 MB, Params: 1,330,881 (5.077 MB), Total: 5.19 MB, FLOPs: 119,684,744\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Finished fine tuning.\n",
      "Iteration 905/1723 finished in 0m15s\n",
      "Total channels prunned so far: 905\n",
      "\n",
      "Iteration 906 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 1)]\n",
      "Input: 0.115 MB, Params: 1,329,664 (5.072 MB), Total: 5.19 MB, FLOPs: 119,279,816\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Finished fine tuning.\n",
      "Iteration 906/1723 finished in 0m15s\n",
      "Total channels prunned so far: 906\n",
      "\n",
      "Iteration 907 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 7)]\n",
      "Input: 0.115 MB, Params: 1,327,409 (5.064 MB), Total: 5.18 MB, FLOPs: 119,239,270\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Finished fine tuning.\n",
      "Iteration 907/1723 finished in 0m15s\n",
      "Total channels prunned so far: 907\n",
      "\n",
      "Iteration 908 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 220)]\n",
      "Input: 0.115 MB, Params: 1,323,834 (5.050 MB), Total: 5.17 MB, FLOPs: 119,174,938\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Finished fine tuning.\n",
      "Iteration 908/1723 finished in 0m15s\n",
      "Total channels prunned so far: 908\n",
      "\n",
      "Iteration 909 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 49)]\n",
      "Input: 0.115 MB, Params: 1,321,588 (5.041 MB), Total: 5.16 MB, FLOPs: 119,134,554\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Finished fine tuning.\n",
      "Iteration 909/1723 finished in 0m15s\n",
      "Total channels prunned so far: 909\n",
      "\n",
      "Iteration 910 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 1)]\n",
      "Input: 0.115 MB, Params: 1,320,371 (5.037 MB), Total: 5.15 MB, FLOPs: 118,729,626\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Finished fine tuning.\n",
      "Iteration 910/1723 finished in 0m15s\n",
      "Total channels prunned so far: 910\n",
      "\n",
      "Iteration 911 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 73)]\n",
      "Input: 0.115 MB, Params: 1,316,787 (5.023 MB), Total: 5.14 MB, FLOPs: 118,592,592\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Finished fine tuning.\n",
      "Iteration 911/1723 finished in 0m15s\n",
      "Total channels prunned so far: 911\n",
      "\n",
      "Iteration 912 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 36)]\n",
      "Input: 0.115 MB, Params: 1,316,137 (5.021 MB), Total: 5.14 MB, FLOPs: 117,716,442\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.068%\n",
      "Finished fine tuning.\n",
      "Iteration 912/1723 finished in 0m15s\n",
      "Total channels prunned so far: 912\n",
      "\n",
      "Iteration 913 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 61)]\n",
      "Input: 0.115 MB, Params: 1,312,580 (5.007 MB), Total: 5.12 MB, FLOPs: 117,652,434\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Finished fine tuning.\n",
      "Iteration 913/1723 finished in 0m15s\n",
      "Total channels prunned so far: 913\n",
      "\n",
      "Iteration 914 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 24)]\n",
      "Input: 0.115 MB, Params: 1,310,517 (4.999 MB), Total: 5.11 MB, FLOPs: 117,315,501\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Finished fine tuning.\n",
      "Iteration 914/1723 finished in 0m15s\n",
      "Total channels prunned so far: 914\n",
      "\n",
      "Iteration 915 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 18)]\n",
      "Input: 0.115 MB, Params: 1,309,867 (4.997 MB), Total: 5.11 MB, FLOPs: 116,439,351\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Finished fine tuning.\n",
      "Iteration 915/1723 finished in 0m15s\n",
      "Total channels prunned so far: 915\n",
      "\n",
      "Iteration 916 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 186)]\n",
      "Input: 0.115 MB, Params: 1,307,630 (4.988 MB), Total: 5.10 MB, FLOPs: 116,399,129\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Finished fine tuning.\n",
      "Iteration 916/1723 finished in 0m15s\n",
      "Total channels prunned so far: 916\n",
      "\n",
      "Iteration 917 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 54)]\n",
      "Input: 0.115 MB, Params: 1,305,567 (4.980 MB), Total: 5.10 MB, FLOPs: 116,062,196\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Finished fine tuning.\n",
      "Iteration 917/1723 finished in 0m15s\n",
      "Total channels prunned so far: 917\n",
      "\n",
      "Iteration 918 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 235)]\n",
      "Input: 0.115 MB, Params: 1,303,330 (4.972 MB), Total: 5.09 MB, FLOPs: 116,021,974\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Finished fine tuning.\n",
      "Iteration 918/1723 finished in 0m15s\n",
      "Total channels prunned so far: 918\n",
      "\n",
      "Iteration 919 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 217)]\n",
      "Input: 0.115 MB, Params: 1,299,791 (4.958 MB), Total: 5.07 MB, FLOPs: 115,958,290\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Finished fine tuning.\n",
      "Iteration 919/1723 finished in 0m15s\n",
      "Total channels prunned so far: 919\n",
      "\n",
      "Iteration 920 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 42)]\n",
      "Input: 0.115 MB, Params: 1,296,252 (4.945 MB), Total: 5.06 MB, FLOPs: 115,894,606\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Finished fine tuning.\n",
      "Iteration 920/1723 finished in 0m15s\n",
      "Total channels prunned so far: 920\n",
      "\n",
      "Iteration 921 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 224)]\n",
      "Input: 0.115 MB, Params: 1,294,033 (4.936 MB), Total: 5.05 MB, FLOPs: 115,854,708\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Finished fine tuning.\n",
      "Iteration 921/1723 finished in 0m15s\n",
      "Total channels prunned so far: 921\n",
      "\n",
      "Iteration 922 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 52)]\n",
      "Input: 0.115 MB, Params: 1,291,970 (4.928 MB), Total: 5.04 MB, FLOPs: 115,517,775\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Finished fine tuning.\n",
      "Iteration 922/1723 finished in 0m15s\n",
      "Total channels prunned so far: 922\n",
      "\n",
      "Iteration 923 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 99)]\n",
      "Input: 0.115 MB, Params: 1,289,952 (4.921 MB), Total: 5.04 MB, FLOPs: 115,372,551\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Finished fine tuning.\n",
      "Iteration 923/1723 finished in 0m15s\n",
      "Total channels prunned so far: 923\n",
      "\n",
      "Iteration 924 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 140)]\n",
      "Input: 0.115 MB, Params: 1,287,934 (4.913 MB), Total: 5.03 MB, FLOPs: 115,227,327\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Finished fine tuning.\n",
      "Iteration 924/1723 finished in 0m15s\n",
      "Total channels prunned so far: 924\n",
      "\n",
      "Iteration 925 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 18)]\n",
      "Input: 0.115 MB, Params: 1,286,744 (4.909 MB), Total: 5.02 MB, FLOPs: 114,831,390\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Finished fine tuning.\n",
      "Iteration 925/1723 finished in 0m15s\n",
      "Total channels prunned so far: 925\n",
      "\n",
      "Iteration 926 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 110)]\n",
      "Input: 0.115 MB, Params: 1,283,214 (4.895 MB), Total: 5.01 MB, FLOPs: 114,767,868\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Finished fine tuning.\n",
      "Iteration 926/1723 finished in 0m15s\n",
      "Total channels prunned so far: 926\n",
      "\n",
      "Iteration 927 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 236)]\n",
      "Input: 0.115 MB, Params: 1,281,004 (4.887 MB), Total: 5.00 MB, FLOPs: 114,728,132\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Finished fine tuning.\n",
      "Iteration 927/1723 finished in 0m15s\n",
      "Total channels prunned so far: 927\n",
      "\n",
      "Iteration 928 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 211)]\n",
      "Input: 0.115 MB, Params: 1,278,794 (4.878 MB), Total: 4.99 MB, FLOPs: 114,688,396\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Finished fine tuning.\n",
      "Iteration 928/1723 finished in 0m15s\n",
      "Total channels prunned so far: 928\n",
      "\n",
      "Iteration 929 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 56)]\n",
      "Input: 0.115 MB, Params: 1,276,776 (4.871 MB), Total: 4.99 MB, FLOPs: 114,543,172\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Finished fine tuning.\n",
      "Iteration 929/1723 finished in 0m15s\n",
      "Total channels prunned so far: 929\n",
      "\n",
      "Iteration 930 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 218)]\n",
      "Input: 0.115 MB, Params: 1,274,566 (4.862 MB), Total: 4.98 MB, FLOPs: 114,503,436\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Finished fine tuning.\n",
      "Iteration 930/1723 finished in 0m15s\n",
      "Total channels prunned so far: 930\n",
      "\n",
      "Iteration 931 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 14)]\n",
      "Input: 0.115 MB, Params: 1,272,356 (4.854 MB), Total: 4.97 MB, FLOPs: 114,463,700\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Finished fine tuning.\n",
      "Iteration 931/1723 finished in 0m15s\n",
      "Total channels prunned so far: 931\n",
      "\n",
      "Iteration 932 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 74)]\n",
      "Input: 0.115 MB, Params: 1,270,338 (4.846 MB), Total: 4.96 MB, FLOPs: 114,318,476\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Finished fine tuning.\n",
      "Iteration 932/1723 finished in 0m15s\n",
      "Total channels prunned so far: 932\n",
      "\n",
      "Iteration 933 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 123)]\n",
      "Input: 0.115 MB, Params: 1,268,320 (4.838 MB), Total: 4.95 MB, FLOPs: 114,173,252\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Finished fine tuning.\n",
      "Iteration 933/1723 finished in 0m15s\n",
      "Total channels prunned so far: 933\n",
      "\n",
      "Iteration 934 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 10)]\n",
      "Input: 0.115 MB, Params: 1,267,670 (4.836 MB), Total: 4.95 MB, FLOPs: 113,297,102\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Finished fine tuning.\n",
      "Iteration 934/1723 finished in 0m15s\n",
      "Total channels prunned so far: 934\n",
      "\n",
      "Iteration 935 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 87)]\n",
      "Input: 0.115 MB, Params: 1,264,176 (4.822 MB), Total: 4.94 MB, FLOPs: 113,234,228\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Finished fine tuning.\n",
      "Iteration 935/1723 finished in 0m15s\n",
      "Total channels prunned so far: 935\n",
      "\n",
      "Iteration 936 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 140)]\n",
      "Input: 0.115 MB, Params: 1,262,158 (4.815 MB), Total: 4.93 MB, FLOPs: 113,089,004\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Finished fine tuning.\n",
      "Iteration 936/1723 finished in 0m15s\n",
      "Total channels prunned so far: 936\n",
      "\n",
      "Iteration 937 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 193)]\n",
      "Input: 0.115 MB, Params: 1,259,957 (4.806 MB), Total: 4.92 MB, FLOPs: 113,049,430\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Finished fine tuning.\n",
      "Iteration 937/1723 finished in 0m15s\n",
      "Total channels prunned so far: 937\n",
      "\n",
      "Iteration 938 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 202)]\n",
      "Input: 0.115 MB, Params: 1,256,472 (4.793 MB), Total: 4.91 MB, FLOPs: 112,986,718\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Finished fine tuning.\n",
      "Iteration 938/1723 finished in 0m15s\n",
      "Total channels prunned so far: 938\n",
      "\n",
      "Iteration 939 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 56)]\n",
      "Input: 0.115 MB, Params: 1,254,280 (4.785 MB), Total: 4.90 MB, FLOPs: 112,947,306\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Finished fine tuning.\n",
      "Iteration 939/1723 finished in 0m15s\n",
      "Total channels prunned so far: 939\n",
      "\n",
      "Iteration 940 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 169)]\n",
      "Input: 0.115 MB, Params: 1,250,804 (4.771 MB), Total: 4.89 MB, FLOPs: 112,884,756\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Finished fine tuning.\n",
      "Iteration 940/1723 finished in 0m15s\n",
      "Total channels prunned so far: 940\n",
      "\n",
      "Iteration 941 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 118)]\n",
      "Input: 0.115 MB, Params: 1,248,786 (4.764 MB), Total: 4.88 MB, FLOPs: 112,739,532\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Finished fine tuning.\n",
      "Iteration 941/1723 finished in 0m15s\n",
      "Total channels prunned so far: 941\n",
      "\n",
      "Iteration 942 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 13)]\n",
      "Input: 0.115 MB, Params: 1,245,328 (4.751 MB), Total: 4.87 MB, FLOPs: 112,608,168\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Finished fine tuning.\n",
      "Iteration 942/1723 finished in 0m15s\n",
      "Total channels prunned so far: 942\n",
      "\n",
      "Iteration 943 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 64)]\n",
      "Input: 0.115 MB, Params: 1,243,145 (4.742 MB), Total: 4.86 MB, FLOPs: 112,568,918\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Finished fine tuning.\n",
      "Iteration 943/1723 finished in 0m15s\n",
      "Total channels prunned so far: 943\n",
      "\n",
      "Iteration 944 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(7, 12)]\n",
      "Input: 0.115 MB, Params: 1,242,810 (4.741 MB), Total: 4.86 MB, FLOPs: 112,071,758\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Finished fine tuning.\n",
      "Iteration 944/1723 finished in 0m15s\n",
      "Total channels prunned so far: 944\n",
      "\n",
      "Iteration 945 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 78)]\n",
      "Input: 0.115 MB, Params: 1,240,801 (4.733 MB), Total: 4.85 MB, FLOPs: 111,927,182\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Finished fine tuning.\n",
      "Iteration 945/1723 finished in 0m15s\n",
      "Total channels prunned so far: 945\n",
      "\n",
      "Iteration 946 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 27)]\n",
      "Input: 0.115 MB, Params: 1,237,352 (4.720 MB), Total: 4.84 MB, FLOPs: 111,796,466\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Finished fine tuning.\n",
      "Iteration 946/1723 finished in 0m15s\n",
      "Total channels prunned so far: 946\n",
      "\n",
      "Iteration 947 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(14, 29)]\n",
      "Input: 0.115 MB, Params: 1,236,315 (4.716 MB), Total: 4.83 MB, FLOPs: 111,119,621\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Finished fine tuning.\n",
      "Iteration 947/1723 finished in 0m15s\n",
      "Total channels prunned so far: 947\n",
      "\n",
      "Iteration 948 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 72)]\n",
      "Input: 0.115 MB, Params: 1,235,134 (4.712 MB), Total: 4.83 MB, FLOPs: 110,726,681\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Finished fine tuning.\n",
      "Iteration 948/1723 finished in 0m15s\n",
      "Total channels prunned so far: 948\n",
      "\n",
      "Iteration 949 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 134)]\n",
      "Input: 0.115 MB, Params: 1,232,951 (4.703 MB), Total: 4.82 MB, FLOPs: 110,687,431\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Finished fine tuning.\n",
      "Iteration 949/1723 finished in 0m15s\n",
      "Total channels prunned so far: 949\n",
      "\n",
      "Iteration 950 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 11)]\n",
      "Input: 0.115 MB, Params: 1,230,978 (4.696 MB), Total: 4.81 MB, FLOPs: 110,361,676\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.068%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Finished fine tuning.\n",
      "Iteration 950/1723 finished in 0m15s\n",
      "Total channels prunned so far: 950\n",
      "\n",
      "Iteration 951 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 165)]\n",
      "Input: 0.115 MB, Params: 1,227,538 (4.683 MB), Total: 4.80 MB, FLOPs: 110,299,774\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.068%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.068%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Finished fine tuning.\n",
      "Iteration 951/1723 finished in 0m15s\n",
      "Total channels prunned so far: 951\n",
      "\n",
      "Iteration 952 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 54)]\n",
      "Input: 0.115 MB, Params: 1,224,098 (4.670 MB), Total: 4.78 MB, FLOPs: 110,169,220\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Finished fine tuning.\n",
      "Iteration 952/1723 finished in 0m15s\n",
      "Total channels prunned so far: 952\n",
      "\n",
      "Iteration 953 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 214)]\n",
      "Input: 0.115 MB, Params: 1,220,667 (4.656 MB), Total: 4.77 MB, FLOPs: 110,107,480\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.068%\n",
      "Finished fine tuning.\n",
      "Iteration 953/1723 finished in 0m15s\n",
      "Total channels prunned so far: 953\n",
      "\n",
      "Iteration 954 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 23)]\n",
      "Input: 0.115 MB, Params: 1,219,495 (4.652 MB), Total: 4.77 MB, FLOPs: 109,717,537\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.068%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Finished fine tuning.\n",
      "Iteration 954/1723 finished in 0m15s\n",
      "Total channels prunned so far: 954\n",
      "\n",
      "Iteration 955 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 7)]\n",
      "Input: 0.115 MB, Params: 1,216,064 (4.639 MB), Total: 4.75 MB, FLOPs: 109,587,145\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Finished fine tuning.\n",
      "Iteration 955/1723 finished in 0m15s\n",
      "Total channels prunned so far: 955\n",
      "\n",
      "Iteration 956 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 10)]\n",
      "Input: 0.115 MB, Params: 1,214,100 (4.631 MB), Total: 4.75 MB, FLOPs: 109,264,387\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Finished fine tuning.\n",
      "Iteration 956/1723 finished in 0m15s\n",
      "Total channels prunned so far: 956\n",
      "\n",
      "Iteration 957 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 78)]\n",
      "Input: 0.115 MB, Params: 1,210,669 (4.618 MB), Total: 4.73 MB, FLOPs: 109,133,995\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Finished fine tuning.\n",
      "Iteration 957/1723 finished in 0m15s\n",
      "Total channels prunned so far: 957\n",
      "\n",
      "Iteration 958 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 238)]\n",
      "Input: 0.115 MB, Params: 1,208,504 (4.610 MB), Total: 4.73 MB, FLOPs: 109,095,069\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Finished fine tuning.\n",
      "Iteration 958/1723 finished in 0m15s\n",
      "Total channels prunned so far: 958\n",
      "\n",
      "Iteration 959 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 139)]\n",
      "Input: 0.115 MB, Params: 1,206,339 (4.602 MB), Total: 4.72 MB, FLOPs: 109,056,143\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Finished fine tuning.\n",
      "Iteration 959/1723 finished in 0m15s\n",
      "Total channels prunned so far: 959\n",
      "\n",
      "Iteration 960 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 37)]\n",
      "Input: 0.115 MB, Params: 1,205,176 (4.597 MB), Total: 4.71 MB, FLOPs: 108,669,197\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Finished fine tuning.\n",
      "Iteration 960/1723 finished in 0m15s\n",
      "Total channels prunned so far: 960\n",
      "\n",
      "Iteration 961 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 67)]\n",
      "Input: 0.115 MB, Params: 1,201,745 (4.584 MB), Total: 4.70 MB, FLOPs: 108,538,805\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Finished fine tuning.\n",
      "Iteration 961/1723 finished in 0m15s\n",
      "Total channels prunned so far: 961\n",
      "\n",
      "Iteration 962 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 60)]\n",
      "Input: 0.115 MB, Params: 1,198,314 (4.571 MB), Total: 4.69 MB, FLOPs: 108,408,413\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Finished fine tuning.\n",
      "Iteration 962/1723 finished in 0m15s\n",
      "Total channels prunned so far: 962\n",
      "\n",
      "Iteration 963 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 236)]\n",
      "Input: 0.115 MB, Params: 1,194,937 (4.558 MB), Total: 4.67 MB, FLOPs: 108,347,645\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Finished fine tuning.\n",
      "Iteration 963/1723 finished in 0m15s\n",
      "Total channels prunned so far: 963\n",
      "\n",
      "Iteration 964 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 117)]\n",
      "Input: 0.115 MB, Params: 1,191,560 (4.545 MB), Total: 4.66 MB, FLOPs: 108,286,877\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Finished fine tuning.\n",
      "Iteration 964/1723 finished in 0m15s\n",
      "Total channels prunned so far: 964\n",
      "\n",
      "Iteration 965 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 85)]\n",
      "Input: 0.115 MB, Params: 1,188,147 (4.532 MB), Total: 4.65 MB, FLOPs: 108,156,809\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Finished fine tuning.\n",
      "Iteration 965/1723 finished in 0m15s\n",
      "Total channels prunned so far: 965\n",
      "\n",
      "Iteration 966 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 153)]\n",
      "Input: 0.115 MB, Params: 1,184,779 (4.520 MB), Total: 4.63 MB, FLOPs: 108,096,203\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.644%\n",
      "Finished fine tuning.\n",
      "Iteration 966/1723 finished in 0m15s\n",
      "Total channels prunned so far: 966\n",
      "\n",
      "Iteration 967 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 9)]\n",
      "Input: 0.115 MB, Params: 1,182,851 (4.512 MB), Total: 4.63 MB, FLOPs: 107,957,459\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Finished fine tuning.\n",
      "Iteration 967/1723 finished in 0m15s\n",
      "Total channels prunned so far: 967\n",
      "\n",
      "Iteration 968 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 20)]\n",
      "Input: 0.115 MB, Params: 1,179,483 (4.499 MB), Total: 4.61 MB, FLOPs: 107,896,853\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Finished fine tuning.\n",
      "Iteration 968/1723 finished in 0m15s\n",
      "Total channels prunned so far: 968\n",
      "\n",
      "Iteration 969 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 129)]\n",
      "Input: 0.115 MB, Params: 1,176,115 (4.487 MB), Total: 4.60 MB, FLOPs: 107,836,247\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Finished fine tuning.\n",
      "Iteration 969/1723 finished in 0m15s\n",
      "Total channels prunned so far: 969\n",
      "\n",
      "Iteration 970 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 124)]\n",
      "Input: 0.115 MB, Params: 1,174,187 (4.479 MB), Total: 4.59 MB, FLOPs: 107,697,503\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Finished fine tuning.\n",
      "Iteration 970/1723 finished in 0m15s\n",
      "Total channels prunned so far: 970\n",
      "\n",
      "Iteration 971 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 60)]\n",
      "Input: 0.115 MB, Params: 1,172,250 (4.472 MB), Total: 4.59 MB, FLOPs: 107,379,038\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.254%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Finished fine tuning.\n",
      "Iteration 971/1723 finished in 0m15s\n",
      "Total channels prunned so far: 971\n",
      "\n",
      "Iteration 972 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 24)]\n",
      "Input: 0.115 MB, Params: 1,168,882 (4.459 MB), Total: 4.57 MB, FLOPs: 107,318,432\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Finished fine tuning.\n",
      "Iteration 972/1723 finished in 0m15s\n",
      "Total channels prunned so far: 972\n",
      "\n",
      "Iteration 973 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 205)]\n",
      "Input: 0.115 MB, Params: 1,165,514 (4.446 MB), Total: 4.56 MB, FLOPs: 107,257,826\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Finished fine tuning.\n",
      "Iteration 973/1723 finished in 0m15s\n",
      "Total channels prunned so far: 973\n",
      "\n",
      "Iteration 974 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 181)]\n",
      "Input: 0.115 MB, Params: 1,162,146 (4.433 MB), Total: 4.55 MB, FLOPs: 107,197,220\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Finished fine tuning.\n",
      "Iteration 974/1723 finished in 0m15s\n",
      "Total channels prunned so far: 974\n",
      "\n",
      "Iteration 975 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 67)]\n",
      "Input: 0.115 MB, Params: 1,160,992 (4.429 MB), Total: 4.54 MB, FLOPs: 106,813,271\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Finished fine tuning.\n",
      "Iteration 975/1723 finished in 0m15s\n",
      "Total channels prunned so far: 975\n",
      "\n",
      "Iteration 976 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 26)]\n",
      "Input: 0.115 MB, Params: 1,158,899 (4.421 MB), Total: 4.54 MB, FLOPs: 106,775,641\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.254%\n",
      "Finished fine tuning.\n",
      "Iteration 976/1723 finished in 0m15s\n",
      "Total channels prunned so far: 976\n",
      "\n",
      "Iteration 977 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 117)]\n",
      "Input: 0.115 MB, Params: 1,156,806 (4.413 MB), Total: 4.53 MB, FLOPs: 106,738,011\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Finished fine tuning.\n",
      "Iteration 977/1723 finished in 0m15s\n",
      "Total channels prunned so far: 977\n",
      "\n",
      "Iteration 978 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 34)]\n",
      "Input: 0.115 MB, Params: 1,153,456 (4.400 MB), Total: 4.52 MB, FLOPs: 106,677,729\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Finished fine tuning.\n",
      "Iteration 978/1723 finished in 0m15s\n",
      "Total channels prunned so far: 978\n",
      "\n",
      "Iteration 979 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 119)]\n",
      "Input: 0.115 MB, Params: 1,150,124 (4.387 MB), Total: 4.50 MB, FLOPs: 106,550,091\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Finished fine tuning.\n",
      "Iteration 979/1723 finished in 0m15s\n",
      "Total channels prunned so far: 979\n",
      "\n",
      "Iteration 980 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 6)]\n",
      "Input: 0.115 MB, Params: 1,148,196 (4.380 MB), Total: 4.50 MB, FLOPs: 106,234,623\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Finished fine tuning.\n",
      "Iteration 980/1723 finished in 0m15s\n",
      "Total channels prunned so far: 980\n",
      "\n",
      "Iteration 981 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 32)]\n",
      "Input: 0.115 MB, Params: 1,144,864 (4.367 MB), Total: 4.48 MB, FLOPs: 106,106,985\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Finished fine tuning.\n",
      "Iteration 981/1723 finished in 0m15s\n",
      "Total channels prunned so far: 981\n",
      "\n",
      "Iteration 982 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 30)]\n",
      "Input: 0.115 MB, Params: 1,141,532 (4.355 MB), Total: 4.47 MB, FLOPs: 106,047,027\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Finished fine tuning.\n",
      "Iteration 982/1723 finished in 0m15s\n",
      "Total channels prunned so far: 982\n",
      "\n",
      "Iteration 983 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 184)]\n",
      "Input: 0.115 MB, Params: 1,139,457 (4.347 MB), Total: 4.46 MB, FLOPs: 106,009,721\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Finished fine tuning.\n",
      "Iteration 983/1723 finished in 0m15s\n",
      "Total channels prunned so far: 983\n",
      "\n",
      "Iteration 984 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 96)]\n",
      "Input: 0.115 MB, Params: 1,137,382 (4.339 MB), Total: 4.45 MB, FLOPs: 105,972,415\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Finished fine tuning.\n",
      "Iteration 984/1723 finished in 0m15s\n",
      "Total channels prunned so far: 984\n",
      "\n",
      "Iteration 985 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 73)]\n",
      "Input: 0.115 MB, Params: 1,135,490 (4.332 MB), Total: 4.45 MB, FLOPs: 105,836,263\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Finished fine tuning.\n",
      "Iteration 985/1723 finished in 0m15s\n",
      "Total channels prunned so far: 985\n",
      "\n",
      "Iteration 986 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 121)]\n",
      "Input: 0.115 MB, Params: 1,132,176 (4.319 MB), Total: 4.43 MB, FLOPs: 105,709,435\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Finished fine tuning.\n",
      "Iteration 986/1723 finished in 0m15s\n",
      "Total channels prunned so far: 986\n",
      "\n",
      "Iteration 987 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 130)]\n",
      "Input: 0.115 MB, Params: 1,130,101 (4.311 MB), Total: 4.43 MB, FLOPs: 105,672,129\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Finished fine tuning.\n",
      "Iteration 987/1723 finished in 0m15s\n",
      "Total channels prunned so far: 987\n",
      "\n",
      "Iteration 988 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 40)]\n",
      "Input: 0.115 MB, Params: 1,126,805 (4.298 MB), Total: 4.41 MB, FLOPs: 105,612,819\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Finished fine tuning.\n",
      "Iteration 988/1723 finished in 0m15s\n",
      "Total channels prunned so far: 988\n",
      "\n",
      "Iteration 989 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 35)]\n",
      "Input: 0.115 MB, Params: 1,124,886 (4.291 MB), Total: 4.41 MB, FLOPs: 105,297,999\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Finished fine tuning.\n",
      "Iteration 989/1723 finished in 0m15s\n",
      "Total channels prunned so far: 989\n",
      "\n",
      "Iteration 990 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 108)]\n",
      "Input: 0.115 MB, Params: 1,123,012 (4.284 MB), Total: 4.40 MB, FLOPs: 105,163,143\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Finished fine tuning.\n",
      "Iteration 990/1723 finished in 0m15s\n",
      "Total channels prunned so far: 990\n",
      "\n",
      "Iteration 991 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 127)]\n",
      "Input: 0.115 MB, Params: 1,119,716 (4.271 MB), Total: 4.39 MB, FLOPs: 105,103,833\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Finished fine tuning.\n",
      "Iteration 991/1723 finished in 0m15s\n",
      "Total channels prunned so far: 991\n",
      "\n",
      "Iteration 992 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 47)]\n",
      "Input: 0.115 MB, Params: 1,116,420 (4.259 MB), Total: 4.37 MB, FLOPs: 105,044,523\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Finished fine tuning.\n",
      "Iteration 992/1723 finished in 0m15s\n",
      "Total channels prunned so far: 992\n",
      "\n",
      "Iteration 993 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 73)]\n",
      "Input: 0.115 MB, Params: 1,115,284 (4.254 MB), Total: 4.37 MB, FLOPs: 104,666,568\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Finished fine tuning.\n",
      "Iteration 993/1723 finished in 0m15s\n",
      "Total channels prunned so far: 993\n",
      "\n",
      "Iteration 994 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 180)]\n",
      "Input: 0.115 MB, Params: 1,111,988 (4.242 MB), Total: 4.36 MB, FLOPs: 104,607,258\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Finished fine tuning.\n",
      "Iteration 994/1723 finished in 0m15s\n",
      "Total channels prunned so far: 994\n",
      "\n",
      "Iteration 995 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 126)]\n",
      "Input: 0.115 MB, Params: 1,108,692 (4.229 MB), Total: 4.34 MB, FLOPs: 104,547,948\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Finished fine tuning.\n",
      "Iteration 995/1723 finished in 0m15s\n",
      "Total channels prunned so far: 995\n",
      "\n",
      "Iteration 996 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(14, 27)]\n",
      "Input: 0.115 MB, Params: 1,107,700 (4.226 MB), Total: 4.34 MB, FLOPs: 103,886,088\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Finished fine tuning.\n",
      "Iteration 996/1723 finished in 0m15s\n",
      "Total channels prunned so far: 996\n",
      "\n",
      "Iteration 997 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 61)]\n",
      "Input: 0.115 MB, Params: 1,104,440 (4.213 MB), Total: 4.33 MB, FLOPs: 103,760,718\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 94.068%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Finished fine tuning.\n",
      "Iteration 997/1723 finished in 0m15s\n",
      "Total channels prunned so far: 997\n",
      "\n",
      "Iteration 998 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 12)]\n",
      "Input: 0.115 MB, Params: 1,102,539 (4.206 MB), Total: 4.32 MB, FLOPs: 103,449,543\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Finished fine tuning.\n",
      "Iteration 998/1723 finished in 0m15s\n",
      "Total channels prunned so far: 998\n",
      "\n",
      "Iteration 999 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 74)]\n",
      "Input: 0.115 MB, Params: 1,100,683 (4.199 MB), Total: 4.31 MB, FLOPs: 103,315,983\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Finished fine tuning.\n",
      "Iteration 999/1723 finished in 0m15s\n",
      "Total channels prunned so far: 999\n",
      "\n",
      "Iteration 1000 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 108)]\n",
      "Input: 0.115 MB, Params: 1,098,653 (4.191 MB), Total: 4.31 MB, FLOPs: 103,279,487\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Finished fine tuning.\n",
      "Iteration 1000/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1000\n",
      "\n",
      "Iteration 1001 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 52)]\n",
      "Input: 0.115 MB, Params: 1,096,623 (4.183 MB), Total: 4.30 MB, FLOPs: 103,242,991\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Finished fine tuning.\n",
      "Iteration 1001/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1001\n",
      "\n",
      "Iteration 1002 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 39)]\n",
      "Input: 0.115 MB, Params: 1,093,372 (4.171 MB), Total: 4.29 MB, FLOPs: 103,118,269\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Finished fine tuning.\n",
      "Iteration 1002/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1002\n",
      "\n",
      "Iteration 1003 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 40)]\n",
      "Input: 0.115 MB, Params: 1,091,525 (4.164 MB), Total: 4.28 MB, FLOPs: 102,985,357\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Finished fine tuning.\n",
      "Iteration 1003/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1003\n",
      "\n",
      "Iteration 1004 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 122)]\n",
      "Input: 0.115 MB, Params: 1,088,265 (4.151 MB), Total: 4.27 MB, FLOPs: 102,926,695\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Finished fine tuning.\n",
      "Iteration 1004/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1004\n",
      "\n",
      "Iteration 1005 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 64)]\n",
      "Input: 0.115 MB, Params: 1,086,382 (4.144 MB), Total: 4.26 MB, FLOPs: 102,616,816\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Finished fine tuning.\n",
      "Iteration 1005/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1005\n",
      "\n",
      "Iteration 1006 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 68)]\n",
      "Input: 0.115 MB, Params: 1,084,499 (4.137 MB), Total: 4.25 MB, FLOPs: 102,306,937\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Finished fine tuning.\n",
      "Iteration 1006/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1006\n",
      "\n",
      "Iteration 1007 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 27)]\n",
      "Input: 0.115 MB, Params: 1,082,478 (4.129 MB), Total: 4.24 MB, FLOPs: 102,270,603\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Finished fine tuning.\n",
      "Iteration 1007/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1007\n",
      "\n",
      "Iteration 1008 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 58)]\n",
      "Input: 0.115 MB, Params: 1,079,227 (4.117 MB), Total: 4.23 MB, FLOPs: 102,212,103\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Finished fine tuning.\n",
      "Iteration 1008/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1008\n",
      "\n",
      "Iteration 1009 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 209)]\n",
      "Input: 0.115 MB, Params: 1,077,215 (4.109 MB), Total: 4.22 MB, FLOPs: 102,175,931\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Finished fine tuning.\n",
      "Iteration 1009/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1009\n",
      "\n",
      "Iteration 1010 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 221)]\n",
      "Input: 0.115 MB, Params: 1,075,203 (4.102 MB), Total: 4.22 MB, FLOPs: 102,139,759\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Finished fine tuning.\n",
      "Iteration 1010/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1010\n",
      "\n",
      "Iteration 1011 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 15)]\n",
      "Input: 0.115 MB, Params: 1,074,103 (4.097 MB), Total: 4.21 MB, FLOPs: 101,773,792\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Finished fine tuning.\n",
      "Iteration 1011/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1011\n",
      "\n",
      "Iteration 1012 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 209)]\n",
      "Input: 0.115 MB, Params: 1,072,091 (4.090 MB), Total: 4.21 MB, FLOPs: 101,737,620\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Finished fine tuning.\n",
      "Iteration 1012/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1012\n",
      "\n",
      "Iteration 1013 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 59)]\n",
      "Input: 0.115 MB, Params: 1,068,867 (4.077 MB), Total: 4.19 MB, FLOPs: 101,679,606\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Finished fine tuning.\n",
      "Iteration 1013/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1013\n",
      "\n",
      "Iteration 1014 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(14, 37)]\n",
      "Input: 0.115 MB, Params: 1,067,884 (4.074 MB), Total: 4.19 MB, FLOPs: 101,020,743\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.254%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Finished fine tuning.\n",
      "Iteration 1014/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1014\n",
      "\n",
      "Iteration 1015 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(3, 35)]\n",
      "Input: 0.115 MB, Params: 1,067,842 (4.073 MB), Total: 4.19 MB, FLOPs: 96,053,101\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Finished fine tuning.\n",
      "Iteration 1015/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1015\n",
      "\n",
      "Iteration 1016 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 135)]\n",
      "Input: 0.115 MB, Params: 1,064,618 (4.061 MB), Total: 4.18 MB, FLOPs: 95,995,087\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.254%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Finished fine tuning.\n",
      "Iteration 1016/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1016\n",
      "\n",
      "Iteration 1017 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 4)]\n",
      "Input: 0.115 MB, Params: 1,062,789 (4.054 MB), Total: 4.17 MB, FLOPs: 95,863,471\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.254%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Finished fine tuning.\n",
      "Iteration 1017/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1017\n",
      "\n",
      "Iteration 1018 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 28)]\n",
      "Input: 0.115 MB, Params: 1,060,795 (4.047 MB), Total: 4.16 MB, FLOPs: 95,827,623\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.254%\n",
      "Finished fine tuning.\n",
      "Iteration 1018/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1018\n",
      "\n",
      "Iteration 1019 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 40)]\n",
      "Input: 0.115 MB, Params: 1,058,966 (4.040 MB), Total: 4.15 MB, FLOPs: 95,696,007\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Finished fine tuning.\n",
      "Iteration 1019/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1019\n",
      "\n",
      "Iteration 1020 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 189)]\n",
      "Input: 0.115 MB, Params: 1,056,972 (4.032 MB), Total: 4.15 MB, FLOPs: 95,660,159\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Finished fine tuning.\n",
      "Iteration 1020/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1020\n",
      "\n",
      "Iteration 1021 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 106)]\n",
      "Input: 0.115 MB, Params: 1,053,766 (4.020 MB), Total: 4.14 MB, FLOPs: 95,602,469\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Finished fine tuning.\n",
      "Iteration 1021/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1021\n",
      "\n",
      "Iteration 1022 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 167)]\n",
      "Input: 0.115 MB, Params: 1,050,560 (4.008 MB), Total: 4.12 MB, FLOPs: 95,544,779\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Finished fine tuning.\n",
      "Iteration 1022/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1022\n",
      "\n",
      "Iteration 1023 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 119)]\n",
      "Input: 0.115 MB, Params: 1,047,354 (3.995 MB), Total: 4.11 MB, FLOPs: 95,487,089\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Finished fine tuning.\n",
      "Iteration 1023/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1023\n",
      "\n",
      "Iteration 1024 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 45)]\n",
      "Input: 0.115 MB, Params: 1,044,193 (3.983 MB), Total: 4.10 MB, FLOPs: 95,365,445\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Finished fine tuning.\n",
      "Iteration 1024/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1024\n",
      "\n",
      "Iteration 1025 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 54)]\n",
      "Input: 0.115 MB, Params: 1,040,996 (3.971 MB), Total: 4.09 MB, FLOPs: 95,307,917\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Finished fine tuning.\n",
      "Iteration 1025/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1025\n",
      "\n",
      "Iteration 1026 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 59)]\n",
      "Input: 0.115 MB, Params: 1,037,844 (3.959 MB), Total: 4.07 MB, FLOPs: 95,186,435\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Finished fine tuning.\n",
      "Iteration 1026/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1026\n",
      "\n",
      "Iteration 1027 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 156)]\n",
      "Input: 0.115 MB, Params: 1,035,886 (3.952 MB), Total: 4.07 MB, FLOPs: 95,151,235\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Finished fine tuning.\n",
      "Iteration 1027/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1027\n",
      "\n",
      "Iteration 1028 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 55)]\n",
      "Input: 0.115 MB, Params: 1,034,030 (3.945 MB), Total: 4.06 MB, FLOPs: 94,869,995\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.407%\n",
      "Finished fine tuning.\n",
      "Iteration 1028/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1028\n",
      "\n",
      "Iteration 1029 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 55)]\n",
      "Input: 0.115 MB, Params: 1,030,851 (3.932 MB), Total: 4.05 MB, FLOPs: 94,812,791\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Finished fine tuning.\n",
      "Iteration 1029/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1029\n",
      "\n",
      "Iteration 1030 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 109)]\n",
      "Input: 0.115 MB, Params: 1,027,672 (3.920 MB), Total: 4.04 MB, FLOPs: 94,755,587\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Finished fine tuning.\n",
      "Iteration 1030/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1030\n",
      "\n",
      "Iteration 1031 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 83)]\n",
      "Input: 0.115 MB, Params: 1,025,870 (3.913 MB), Total: 4.03 MB, FLOPs: 94,625,915\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Finished fine tuning.\n",
      "Iteration 1031/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1031\n",
      "\n",
      "Iteration 1032 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 179)]\n",
      "Input: 0.115 MB, Params: 1,023,930 (3.906 MB), Total: 4.02 MB, FLOPs: 94,591,039\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Finished fine tuning.\n",
      "Iteration 1032/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1032\n",
      "\n",
      "Iteration 1033 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 147)]\n",
      "Input: 0.115 MB, Params: 1,020,760 (3.894 MB), Total: 4.01 MB, FLOPs: 94,533,997\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Finished fine tuning.\n",
      "Iteration 1033/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1033\n",
      "\n",
      "Iteration 1034 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 98)]\n",
      "Input: 0.115 MB, Params: 1,018,829 (3.887 MB), Total: 4.00 MB, FLOPs: 94,499,283\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Finished fine tuning.\n",
      "Iteration 1034/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1034\n",
      "\n",
      "Iteration 1035 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 82)]\n",
      "Input: 0.115 MB, Params: 1,015,713 (3.875 MB), Total: 3.99 MB, FLOPs: 94,378,935\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Finished fine tuning.\n",
      "Iteration 1035/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1035\n",
      "\n",
      "Iteration 1036 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 38)]\n",
      "Input: 0.115 MB, Params: 1,012,561 (3.863 MB), Total: 3.98 MB, FLOPs: 94,322,217\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Finished fine tuning.\n",
      "Iteration 1036/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1036\n",
      "\n",
      "Iteration 1037 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 212)]\n",
      "Input: 0.115 MB, Params: 1,010,639 (3.855 MB), Total: 3.97 MB, FLOPs: 94,287,665\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Finished fine tuning.\n",
      "Iteration 1037/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1037\n",
      "\n",
      "Iteration 1038 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 32)]\n",
      "Input: 0.115 MB, Params: 1,008,792 (3.848 MB), Total: 3.96 MB, FLOPs: 94,007,073\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Finished fine tuning.\n",
      "Iteration 1038/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1038\n",
      "\n",
      "Iteration 1039 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 194)]\n",
      "Input: 0.115 MB, Params: 1,005,649 (3.836 MB), Total: 3.95 MB, FLOPs: 93,950,517\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Finished fine tuning.\n",
      "Iteration 1039/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1039\n",
      "\n",
      "Iteration 1040 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 165)]\n",
      "Input: 0.115 MB, Params: 1,003,736 (3.829 MB), Total: 3.94 MB, FLOPs: 93,916,127\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Finished fine tuning.\n",
      "Iteration 1040/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1040\n",
      "\n",
      "Iteration 1041 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 187)]\n",
      "Input: 0.115 MB, Params: 1,000,602 (3.817 MB), Total: 3.93 MB, FLOPs: 93,859,733\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Finished fine tuning.\n",
      "Iteration 1041/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1041\n",
      "\n",
      "Iteration 1042 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 201)]\n",
      "Input: 0.115 MB, Params: 997,468 (3.805 MB), Total: 3.92 MB, FLOPs: 93,803,339\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.254%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Finished fine tuning.\n",
      "Iteration 1042/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1042\n",
      "\n",
      "Iteration 1043 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 59)]\n",
      "Input: 0.115 MB, Params: 995,621 (3.798 MB), Total: 3.91 MB, FLOPs: 93,522,747\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Finished fine tuning.\n",
      "Iteration 1043/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1043\n",
      "\n",
      "Iteration 1044 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 151)]\n",
      "Input: 0.115 MB, Params: 993,726 (3.791 MB), Total: 3.91 MB, FLOPs: 93,488,681\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Finished fine tuning.\n",
      "Iteration 1044/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1044\n",
      "\n",
      "Iteration 1045 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 37)]\n",
      "Input: 0.115 MB, Params: 991,951 (3.784 MB), Total: 3.90 MB, FLOPs: 93,360,953\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Finished fine tuning.\n",
      "Iteration 1045/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1045\n",
      "\n",
      "Iteration 1046 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 43)]\n",
      "Input: 0.115 MB, Params: 990,887 (3.780 MB), Total: 3.90 MB, FLOPs: 93,046,305\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Finished fine tuning.\n",
      "Iteration 1046/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1046\n",
      "\n",
      "Iteration 1047 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 167)]\n",
      "Input: 0.115 MB, Params: 987,762 (3.768 MB), Total: 3.88 MB, FLOPs: 92,990,073\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Finished fine tuning.\n",
      "Iteration 1047/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1047\n",
      "\n",
      "Iteration 1048 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 22)]\n",
      "Input: 0.115 MB, Params: 985,933 (3.761 MB), Total: 3.88 MB, FLOPs: 92,712,793\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Finished fine tuning.\n",
      "Iteration 1048/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1048\n",
      "\n",
      "Iteration 1049 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 109)]\n",
      "Input: 0.115 MB, Params: 984,167 (3.754 MB), Total: 3.87 MB, FLOPs: 92,585,713\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Finished fine tuning.\n",
      "Iteration 1049/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1049\n",
      "\n",
      "Iteration 1050 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 7)]\n",
      "Input: 0.115 MB, Params: 983,112 (3.750 MB), Total: 3.87 MB, FLOPs: 92,273,729\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.831%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.254%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Finished fine tuning.\n",
      "Iteration 1050/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1050\n",
      "\n",
      "Iteration 1051 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 46)]\n",
      "Input: 0.115 MB, Params: 981,226 (3.743 MB), Total: 3.86 MB, FLOPs: 92,239,825\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Finished fine tuning.\n",
      "Iteration 1051/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1051\n",
      "\n",
      "Iteration 1052 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 135)]\n",
      "Input: 0.115 MB, Params: 978,110 (3.731 MB), Total: 3.85 MB, FLOPs: 92,183,755\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Finished fine tuning.\n",
      "Iteration 1052/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1052\n",
      "\n",
      "Iteration 1053 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 35)]\n",
      "Input: 0.115 MB, Params: 975,066 (3.720 MB), Total: 3.83 MB, FLOPs: 92,065,675\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Finished fine tuning.\n",
      "Iteration 1053/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1053\n",
      "\n",
      "Iteration 1054 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(7, 14)]\n",
      "Input: 0.115 MB, Params: 974,731 (3.718 MB), Total: 3.83 MB, FLOPs: 91,594,625\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.051%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Finished fine tuning.\n",
      "Iteration 1054/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1054\n",
      "\n",
      "Iteration 1055 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 68)]\n",
      "Input: 0.115 MB, Params: 973,676 (3.714 MB), Total: 3.83 MB, FLOPs: 91,282,641\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.831%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Finished fine tuning.\n",
      "Iteration 1055/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1055\n",
      "\n",
      "Iteration 1056 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 20)]\n",
      "Input: 0.115 MB, Params: 970,569 (3.702 MB), Total: 3.82 MB, FLOPs: 91,226,733\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Finished fine tuning.\n",
      "Iteration 1056/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1056\n",
      "\n",
      "Iteration 1057 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 100)]\n",
      "Input: 0.115 MB, Params: 967,462 (3.691 MB), Total: 3.81 MB, FLOPs: 91,170,825\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.831%\n",
      "Finished fine tuning.\n",
      "Iteration 1057/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1057\n",
      "\n",
      "Iteration 1058 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 65)]\n",
      "Input: 0.115 MB, Params: 966,407 (3.687 MB), Total: 3.80 MB, FLOPs: 90,858,841\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Finished fine tuning.\n",
      "Iteration 1058/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1058\n",
      "\n",
      "Iteration 1059 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 21)]\n",
      "Input: 0.115 MB, Params: 963,300 (3.675 MB), Total: 3.79 MB, FLOPs: 90,802,933\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.831%\n",
      "Finished fine tuning.\n",
      "Iteration 1059/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1059\n",
      "\n",
      "Iteration 1060 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 191)]\n",
      "Input: 0.115 MB, Params: 960,193 (3.663 MB), Total: 3.78 MB, FLOPs: 90,747,025\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Finished fine tuning.\n",
      "Iteration 1060/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1060\n",
      "\n",
      "Iteration 1061 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 193)]\n",
      "Input: 0.115 MB, Params: 957,086 (3.651 MB), Total: 3.77 MB, FLOPs: 90,691,117\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Finished fine tuning.\n",
      "Iteration 1061/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1061\n",
      "\n",
      "Iteration 1062 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 138)]\n",
      "Input: 0.115 MB, Params: 955,254 (3.644 MB), Total: 3.76 MB, FLOPs: 90,658,185\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Finished fine tuning.\n",
      "Iteration 1062/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1062\n",
      "\n",
      "Iteration 1063 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 80)]\n",
      "Input: 0.115 MB, Params: 953,422 (3.637 MB), Total: 3.75 MB, FLOPs: 90,625,253\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Finished fine tuning.\n",
      "Iteration 1063/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1063\n",
      "\n",
      "Iteration 1064 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 98)]\n",
      "Input: 0.115 MB, Params: 951,665 (3.630 MB), Total: 3.75 MB, FLOPs: 90,498,821\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Finished fine tuning.\n",
      "Iteration 1064/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1064\n",
      "\n",
      "Iteration 1065 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 47)]\n",
      "Input: 0.115 MB, Params: 949,833 (3.623 MB), Total: 3.74 MB, FLOPs: 90,465,889\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.254%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Finished fine tuning.\n",
      "Iteration 1065/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1065\n",
      "\n",
      "Iteration 1066 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 115)]\n",
      "Input: 0.115 MB, Params: 946,753 (3.612 MB), Total: 3.73 MB, FLOPs: 90,410,467\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.254%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Finished fine tuning.\n",
      "Iteration 1066/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1066\n",
      "\n",
      "Iteration 1067 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 164)]\n",
      "Input: 0.115 MB, Params: 943,673 (3.600 MB), Total: 3.72 MB, FLOPs: 90,355,045\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.254%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Finished fine tuning.\n",
      "Iteration 1067/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1067\n",
      "\n",
      "Iteration 1068 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(7, 5)]\n",
      "Input: 0.115 MB, Params: 943,338 (3.599 MB), Total: 3.71 MB, FLOPs: 89,883,995\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 52.542%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.559%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Finished fine tuning.\n",
      "Iteration 1068/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1068\n",
      "\n",
      "Iteration 1069 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 194)]\n",
      "Input: 0.115 MB, Params: 940,258 (3.587 MB), Total: 3.70 MB, FLOPs: 89,828,573\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.254%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.254%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Finished fine tuning.\n",
      "Iteration 1069/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1069\n",
      "\n",
      "Iteration 1070 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(3, 17)]\n",
      "Input: 0.115 MB, Params: 940,216 (3.587 MB), Total: 3.70 MB, FLOPs: 89,482,660\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.254%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.983%\n",
      "Finished fine tuning.\n",
      "Iteration 1070/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1070\n",
      "\n",
      "Iteration 1071 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 63)]\n",
      "Input: 0.115 MB, Params: 937,253 (3.575 MB), Total: 3.69 MB, FLOPs: 89,366,524\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.831%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.254%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.831%\n",
      "Finished fine tuning.\n",
      "Iteration 1071/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1071\n",
      "\n",
      "Iteration 1072 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 124)]\n",
      "Input: 0.115 MB, Params: 935,505 (3.569 MB), Total: 3.68 MB, FLOPs: 89,240,740\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.254%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Finished fine tuning.\n",
      "Iteration 1072/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1072\n",
      "\n",
      "Iteration 1073 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 25)]\n",
      "Input: 0.115 MB, Params: 933,700 (3.562 MB), Total: 3.68 MB, FLOPs: 89,208,294\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.254%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.831%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.254%\n",
      "Finished fine tuning.\n",
      "Iteration 1073/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1073\n",
      "\n",
      "Iteration 1074 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 45)]\n",
      "Input: 0.115 MB, Params: 930,638 (3.550 MB), Total: 3.67 MB, FLOPs: 89,153,196\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.831%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.254%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.254%\n",
      "Finished fine tuning.\n",
      "Iteration 1074/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1074\n",
      "\n",
      "Iteration 1075 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 104)]\n",
      "Input: 0.115 MB, Params: 927,693 (3.539 MB), Total: 3.65 MB, FLOPs: 89,037,870\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.831%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.407%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.407%\n",
      "Finished fine tuning.\n",
      "Iteration 1075/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1075\n",
      "\n",
      "Iteration 1076 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 151)]\n",
      "Input: 0.115 MB, Params: 924,640 (3.527 MB), Total: 3.64 MB, FLOPs: 88,982,934\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.559%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.407%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Finished fine tuning.\n",
      "Iteration 1076/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1076\n",
      "\n",
      "Iteration 1077 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 136)]\n",
      "Input: 0.115 MB, Params: 922,853 (3.520 MB), Total: 3.64 MB, FLOPs: 88,950,812\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.831%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.407%\n",
      "Finished fine tuning.\n",
      "Iteration 1077/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1077\n",
      "\n",
      "Iteration 1078 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 57)]\n",
      "Input: 0.115 MB, Params: 919,917 (3.509 MB), Total: 3.62 MB, FLOPs: 88,835,648\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.407%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.831%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.831%\n",
      "Finished fine tuning.\n",
      "Iteration 1078/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1078\n",
      "\n",
      "Iteration 1079 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(14, 20)]\n",
      "Input: 0.115 MB, Params: 918,970 (3.506 MB), Total: 3.62 MB, FLOPs: 88,236,273\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.407%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.254%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Finished fine tuning.\n",
      "Iteration 1079/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1079\n",
      "\n",
      "Iteration 1080 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 84)]\n",
      "Input: 0.115 MB, Params: 915,935 (3.494 MB), Total: 3.61 MB, FLOPs: 88,181,661\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.831%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.254%\n",
      "Finished fine tuning.\n",
      "Iteration 1080/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1080\n",
      "\n",
      "Iteration 1081 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 186)]\n",
      "Input: 0.115 MB, Params: 912,900 (3.482 MB), Total: 3.60 MB, FLOPs: 88,127,049\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.407%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.254%\n",
      "Finished fine tuning.\n",
      "Iteration 1081/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1081\n",
      "\n",
      "Iteration 1082 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 182)]\n",
      "Input: 0.115 MB, Params: 911,131 (3.476 MB), Total: 3.59 MB, FLOPs: 88,095,251\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.407%\n",
      "Finished fine tuning.\n",
      "Iteration 1082/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1082\n",
      "\n",
      "Iteration 1083 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 19)]\n",
      "Input: 0.115 MB, Params: 908,105 (3.464 MB), Total: 3.58 MB, FLOPs: 88,040,801\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.407%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.407%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.254%\n",
      "Finished fine tuning.\n",
      "Iteration 1083/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1083\n",
      "\n",
      "Iteration 1084 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 136)]\n",
      "Input: 0.115 MB, Params: 905,079 (3.453 MB), Total: 3.57 MB, FLOPs: 87,986,351\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.254%\n",
      "Finished fine tuning.\n",
      "Iteration 1084/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1084\n",
      "\n",
      "Iteration 1085 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 3)]\n",
      "Input: 0.115 MB, Params: 903,304 (3.446 MB), Total: 3.56 MB, FLOPs: 87,719,007\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.831%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Finished fine tuning.\n",
      "Iteration 1085/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1085\n",
      "\n",
      "Iteration 1086 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 190)]\n",
      "Input: 0.115 MB, Params: 900,278 (3.434 MB), Total: 3.55 MB, FLOPs: 87,664,557\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.254%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Finished fine tuning.\n",
      "Iteration 1086/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1086\n",
      "\n",
      "Iteration 1087 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 83)]\n",
      "Input: 0.115 MB, Params: 897,252 (3.423 MB), Total: 3.54 MB, FLOPs: 87,610,107\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.254%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Finished fine tuning.\n",
      "Iteration 1087/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1087\n",
      "\n",
      "Iteration 1088 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 94)]\n",
      "Input: 0.115 MB, Params: 895,519 (3.416 MB), Total: 3.53 MB, FLOPs: 87,578,957\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.831%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Finished fine tuning.\n",
      "Iteration 1088/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1088\n",
      "\n",
      "Iteration 1089 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 6)]\n",
      "Input: 0.115 MB, Params: 892,637 (3.405 MB), Total: 3.52 MB, FLOPs: 87,464,765\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.254%\n",
      "Finished fine tuning.\n",
      "Iteration 1089/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1089\n",
      "\n",
      "Iteration 1090 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 44)]\n",
      "Input: 0.115 MB, Params: 890,904 (3.399 MB), Total: 3.51 MB, FLOPs: 87,433,615\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.831%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.254%\n",
      "Finished fine tuning.\n",
      "Iteration 1090/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1090\n",
      "\n",
      "Iteration 1091 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 131)]\n",
      "Input: 0.115 MB, Params: 887,905 (3.387 MB), Total: 3.50 MB, FLOPs: 87,379,651\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.983%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.407%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.831%\n",
      "Finished fine tuning.\n",
      "Iteration 1091/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1091\n",
      "\n",
      "Iteration 1092 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 41)]\n",
      "Input: 0.115 MB, Params: 885,032 (3.376 MB), Total: 3.49 MB, FLOPs: 87,265,621\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.407%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.407%\n",
      "Finished fine tuning.\n",
      "Iteration 1092/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1092\n",
      "\n",
      "Iteration 1093 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 15)]\n",
      "Input: 0.115 MB, Params: 883,995 (3.372 MB), Total: 3.49 MB, FLOPs: 86,958,965\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Finished fine tuning.\n",
      "Iteration 1093/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1093\n",
      "\n",
      "Iteration 1094 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 33)]\n",
      "Input: 0.115 MB, Params: 882,271 (3.366 MB), Total: 3.48 MB, FLOPs: 86,927,977\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.254%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Finished fine tuning.\n",
      "Iteration 1094/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1094\n",
      "\n",
      "Iteration 1095 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 53)]\n",
      "Input: 0.115 MB, Params: 879,290 (3.354 MB), Total: 3.47 MB, FLOPs: 86,874,337\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Finished fine tuning.\n",
      "Iteration 1095/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1095\n",
      "\n",
      "Iteration 1096 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 0)]\n",
      "Input: 0.115 MB, Params: 878,253 (3.350 MB), Total: 3.47 MB, FLOPs: 86,567,681\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Finished fine tuning.\n",
      "Iteration 1096/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1096\n",
      "\n",
      "Iteration 1097 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 165)]\n",
      "Input: 0.115 MB, Params: 876,538 (3.344 MB), Total: 3.46 MB, FLOPs: 86,536,855\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Finished fine tuning.\n",
      "Iteration 1097/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1097\n",
      "\n",
      "Iteration 1098 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 171)]\n",
      "Input: 0.115 MB, Params: 873,566 (3.332 MB), Total: 3.45 MB, FLOPs: 86,483,377\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.254%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Finished fine tuning.\n",
      "Iteration 1098/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1098\n",
      "\n",
      "Iteration 1099 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 28)]\n",
      "Input: 0.115 MB, Params: 872,529 (3.328 MB), Total: 3.44 MB, FLOPs: 86,176,721\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.831%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Finished fine tuning.\n",
      "Iteration 1099/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1099\n",
      "\n",
      "Iteration 1100 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(3, 13)]\n",
      "Input: 0.115 MB, Params: 872,487 (3.328 MB), Total: 3.44 MB, FLOPs: 84,239,458\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Finished fine tuning.\n",
      "Iteration 1100/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1100\n",
      "\n",
      "Iteration 1101 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 75)]\n",
      "Input: 0.115 MB, Params: 869,515 (3.317 MB), Total: 3.43 MB, FLOPs: 84,185,980\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Finished fine tuning.\n",
      "Iteration 1101/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1101\n",
      "\n",
      "Iteration 1102 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(14, 0)]\n",
      "Input: 0.115 MB, Params: 868,595 (3.313 MB), Total: 3.43 MB, FLOPs: 83,618,972\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Finished fine tuning.\n",
      "Iteration 1102/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1102\n",
      "\n",
      "Iteration 1103 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(7, 16)]\n",
      "Input: 0.115 MB, Params: 868,260 (3.312 MB), Total: 3.43 MB, FLOPs: 83,175,542\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.254%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Finished fine tuning.\n",
      "Iteration 1103/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1103\n",
      "\n",
      "Iteration 1104 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 70)]\n",
      "Input: 0.115 MB, Params: 865,288 (3.301 MB), Total: 3.42 MB, FLOPs: 83,122,064\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Finished fine tuning.\n",
      "Iteration 1104/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1104\n",
      "\n",
      "Iteration 1105 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 115)]\n",
      "Input: 0.115 MB, Params: 862,451 (3.290 MB), Total: 3.41 MB, FLOPs: 83,008,682\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.254%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Finished fine tuning.\n",
      "Iteration 1105/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1105\n",
      "\n",
      "Iteration 1106 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 105)]\n",
      "Input: 0.115 MB, Params: 859,488 (3.279 MB), Total: 3.39 MB, FLOPs: 82,955,366\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Finished fine tuning.\n",
      "Iteration 1106/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1106\n",
      "\n",
      "Iteration 1107 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 157)]\n",
      "Input: 0.115 MB, Params: 856,525 (3.267 MB), Total: 3.38 MB, FLOPs: 82,902,050\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Finished fine tuning.\n",
      "Iteration 1107/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1107\n",
      "\n",
      "Iteration 1108 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 16)]\n",
      "Input: 0.115 MB, Params: 855,956 (3.265 MB), Total: 3.38 MB, FLOPs: 82,220,450\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.831%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Finished fine tuning.\n",
      "Iteration 1108/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1108\n",
      "\n",
      "Iteration 1109 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 18)]\n",
      "Input: 0.115 MB, Params: 853,137 (3.254 MB), Total: 3.37 MB, FLOPs: 82,107,392\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Finished fine tuning.\n",
      "Iteration 1109/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1109\n",
      "\n",
      "Iteration 1110 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 75)]\n",
      "Input: 0.115 MB, Params: 850,183 (3.243 MB), Total: 3.36 MB, FLOPs: 82,054,238\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Finished fine tuning.\n",
      "Iteration 1110/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1110\n",
      "\n",
      "Iteration 1111 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 34)]\n",
      "Input: 0.115 MB, Params: 848,522 (3.237 MB), Total: 3.35 MB, FLOPs: 82,024,384\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Finished fine tuning.\n",
      "Iteration 1111/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1111\n",
      "\n",
      "Iteration 1112 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 68)]\n",
      "Input: 0.115 MB, Params: 845,712 (3.226 MB), Total: 3.34 MB, FLOPs: 81,911,488\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Finished fine tuning.\n",
      "Iteration 1112/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1112\n",
      "\n",
      "Iteration 1113 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 86)]\n",
      "Input: 0.115 MB, Params: 842,902 (3.215 MB), Total: 3.33 MB, FLOPs: 81,798,592\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.254%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Finished fine tuning.\n",
      "Iteration 1113/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1113\n",
      "\n",
      "Iteration 1114 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 46)]\n",
      "Input: 0.115 MB, Params: 841,874 (3.211 MB), Total: 3.33 MB, FLOPs: 81,494,600\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Finished fine tuning.\n",
      "Iteration 1114/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1114\n",
      "\n",
      "Iteration 1115 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 136)]\n",
      "Input: 0.115 MB, Params: 840,213 (3.205 MB), Total: 3.32 MB, FLOPs: 81,464,746\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Finished fine tuning.\n",
      "Iteration 1115/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1115\n",
      "\n",
      "Iteration 1116 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 155)]\n",
      "Input: 0.115 MB, Params: 838,552 (3.199 MB), Total: 3.31 MB, FLOPs: 81,434,892\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Finished fine tuning.\n",
      "Iteration 1116/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1116\n",
      "\n",
      "Iteration 1117 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 19)]\n",
      "Input: 0.115 MB, Params: 835,742 (3.188 MB), Total: 3.30 MB, FLOPs: 81,321,996\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Finished fine tuning.\n",
      "Iteration 1117/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1117\n",
      "\n",
      "Iteration 1118 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 200)]\n",
      "Input: 0.115 MB, Params: 834,081 (3.182 MB), Total: 3.30 MB, FLOPs: 81,292,142\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Finished fine tuning.\n",
      "Iteration 1118/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1118\n",
      "\n",
      "Iteration 1119 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 36)]\n",
      "Input: 0.115 MB, Params: 831,190 (3.171 MB), Total: 3.29 MB, FLOPs: 81,240,122\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Finished fine tuning.\n",
      "Iteration 1119/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1119\n",
      "\n",
      "Iteration 1120 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 89)]\n",
      "Input: 0.115 MB, Params: 829,532 (3.164 MB), Total: 3.28 MB, FLOPs: 81,120,818\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Finished fine tuning.\n",
      "Iteration 1120/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1120\n",
      "\n",
      "Iteration 1121 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 35)]\n",
      "Input: 0.115 MB, Params: 827,802 (3.158 MB), Total: 3.27 MB, FLOPs: 80,864,778\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.831%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.254%\n",
      "Finished fine tuning.\n",
      "Iteration 1121/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1121\n",
      "\n",
      "Iteration 1122 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(14, 37)]\n",
      "Input: 0.115 MB, Params: 826,900 (3.154 MB), Total: 3.27 MB, FLOPs: 80,311,234\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.254%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Finished fine tuning.\n",
      "Iteration 1122/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1122\n",
      "\n",
      "Iteration 1123 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 18)]\n",
      "Input: 0.115 MB, Params: 826,340 (3.152 MB), Total: 3.27 MB, FLOPs: 79,640,434\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Finished fine tuning.\n",
      "Iteration 1123/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1123\n",
      "\n",
      "Iteration 1124 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 104)]\n",
      "Input: 0.115 MB, Params: 823,449 (3.141 MB), Total: 3.26 MB, FLOPs: 79,588,414\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.254%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Finished fine tuning.\n",
      "Iteration 1124/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1124\n",
      "\n",
      "Iteration 1125 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 23)]\n",
      "Input: 0.115 MB, Params: 821,806 (3.135 MB), Total: 3.25 MB, FLOPs: 79,558,884\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.254%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.831%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Finished fine tuning.\n",
      "Iteration 1125/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1125\n",
      "\n",
      "Iteration 1126 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 57)]\n",
      "Input: 0.115 MB, Params: 818,924 (3.124 MB), Total: 3.24 MB, FLOPs: 79,507,026\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Finished fine tuning.\n",
      "Iteration 1126/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1126\n",
      "\n",
      "Iteration 1127 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 5)]\n",
      "Input: 0.115 MB, Params: 818,364 (3.122 MB), Total: 3.24 MB, FLOPs: 78,836,226\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Finished fine tuning.\n",
      "Iteration 1127/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1127\n",
      "\n",
      "Iteration 1128 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 58)]\n",
      "Input: 0.115 MB, Params: 816,715 (3.116 MB), Total: 3.23 MB, FLOPs: 78,717,570\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.254%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Finished fine tuning.\n",
      "Iteration 1128/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1128\n",
      "\n",
      "Iteration 1129 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 18)]\n",
      "Input: 0.115 MB, Params: 814,994 (3.109 MB), Total: 3.22 MB, FLOPs: 78,462,178\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Finished fine tuning.\n",
      "Iteration 1129/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1129\n",
      "\n",
      "Iteration 1130 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 184)]\n",
      "Input: 0.115 MB, Params: 813,360 (3.103 MB), Total: 3.22 MB, FLOPs: 78,432,810\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Finished fine tuning.\n",
      "Iteration 1130/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1130\n",
      "\n",
      "Iteration 1131 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 21)]\n",
      "Input: 0.115 MB, Params: 812,800 (3.101 MB), Total: 3.22 MB, FLOPs: 77,762,010\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Finished fine tuning.\n",
      "Iteration 1131/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1131\n",
      "\n",
      "Iteration 1132 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 187)]\n",
      "Input: 0.115 MB, Params: 811,166 (3.094 MB), Total: 3.21 MB, FLOPs: 77,732,642\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.831%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.831%\n",
      "Finished fine tuning.\n",
      "Iteration 1132/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1132\n",
      "\n",
      "Iteration 1133 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 0)]\n",
      "Input: 0.115 MB, Params: 810,165 (3.091 MB), Total: 3.21 MB, FLOPs: 77,436,642\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Finished fine tuning.\n",
      "Iteration 1133/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1133\n",
      "\n",
      "Iteration 1134 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 48)]\n",
      "Input: 0.115 MB, Params: 807,400 (3.080 MB), Total: 3.20 MB, FLOPs: 77,325,528\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Finished fine tuning.\n",
      "Iteration 1134/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1134\n",
      "\n",
      "Iteration 1135 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 55)]\n",
      "Input: 0.115 MB, Params: 804,635 (3.069 MB), Total: 3.18 MB, FLOPs: 77,214,414\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.254%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Finished fine tuning.\n",
      "Iteration 1135/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1135\n",
      "\n",
      "Iteration 1136 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 25)]\n",
      "Input: 0.115 MB, Params: 804,075 (3.067 MB), Total: 3.18 MB, FLOPs: 76,543,614\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.254%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.254%\n",
      "Finished fine tuning.\n",
      "Iteration 1136/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1136\n",
      "\n",
      "Iteration 1137 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 29)]\n",
      "Input: 0.115 MB, Params: 801,310 (3.057 MB), Total: 3.17 MB, FLOPs: 76,432,500\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.254%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Finished fine tuning.\n",
      "Iteration 1137/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1137\n",
      "\n",
      "Iteration 1138 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 169)]\n",
      "Input: 0.115 MB, Params: 798,473 (3.046 MB), Total: 3.16 MB, FLOPs: 76,381,452\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Finished fine tuning.\n",
      "Iteration 1138/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1138\n",
      "\n",
      "Iteration 1139 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 179)]\n",
      "Input: 0.115 MB, Params: 796,848 (3.040 MB), Total: 3.16 MB, FLOPs: 76,352,246\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.254%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Finished fine tuning.\n",
      "Iteration 1139/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1139\n",
      "\n",
      "Iteration 1140 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 139)]\n",
      "Input: 0.115 MB, Params: 795,223 (3.034 MB), Total: 3.15 MB, FLOPs: 76,323,040\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.254%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Finished fine tuning.\n",
      "Iteration 1140/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1140\n",
      "\n",
      "Iteration 1141 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(14, 19)]\n",
      "Input: 0.115 MB, Params: 794,366 (3.030 MB), Total: 3.15 MB, FLOPs: 75,815,360\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Finished fine tuning.\n",
      "Iteration 1141/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1141\n",
      "\n",
      "Iteration 1142 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 82)]\n",
      "Input: 0.115 MB, Params: 792,741 (3.024 MB), Total: 3.14 MB, FLOPs: 75,786,154\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Finished fine tuning.\n",
      "Iteration 1142/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1142\n",
      "\n",
      "Iteration 1143 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 150)]\n",
      "Input: 0.115 MB, Params: 789,931 (3.013 MB), Total: 3.13 MB, FLOPs: 75,735,592\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Finished fine tuning.\n",
      "Iteration 1143/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1143\n",
      "\n",
      "Iteration 1144 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 24)]\n",
      "Input: 0.115 MB, Params: 788,318 (3.007 MB), Total: 3.12 MB, FLOPs: 75,619,528\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Finished fine tuning.\n",
      "Iteration 1144/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1144\n",
      "\n",
      "Iteration 1145 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 43)]\n",
      "Input: 0.115 MB, Params: 787,326 (3.003 MB), Total: 3.12 MB, FLOPs: 75,326,192\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Finished fine tuning.\n",
      "Iteration 1145/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1145\n",
      "\n",
      "Iteration 1146 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 116)]\n",
      "Input: 0.115 MB, Params: 784,516 (2.993 MB), Total: 3.11 MB, FLOPs: 75,275,630\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Finished fine tuning.\n",
      "Iteration 1146/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1146\n",
      "\n",
      "Iteration 1147 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 59)]\n",
      "Input: 0.115 MB, Params: 781,706 (2.982 MB), Total: 3.10 MB, FLOPs: 75,225,068\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Finished fine tuning.\n",
      "Iteration 1147/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1147\n",
      "\n",
      "Iteration 1148 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 183)]\n",
      "Input: 0.115 MB, Params: 780,108 (2.976 MB), Total: 3.09 MB, FLOPs: 75,196,348\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Finished fine tuning.\n",
      "Iteration 1148/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1148\n",
      "\n",
      "Iteration 1149 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 84)]\n",
      "Input: 0.115 MB, Params: 777,307 (2.965 MB), Total: 3.08 MB, FLOPs: 75,145,948\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Finished fine tuning.\n",
      "Iteration 1149/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1149\n",
      "\n",
      "Iteration 1150 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 143)]\n",
      "Input: 0.115 MB, Params: 775,718 (2.959 MB), Total: 3.07 MB, FLOPs: 75,117,390\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Finished fine tuning.\n",
      "Iteration 1150/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1150\n",
      "\n",
      "Iteration 1151 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 1)]\n",
      "Input: 0.115 MB, Params: 773,007 (2.949 MB), Total: 3.06 MB, FLOPs: 75,007,734\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Finished fine tuning.\n",
      "Iteration 1151/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1151\n",
      "\n",
      "Iteration 1152 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 39)]\n",
      "Input: 0.115 MB, Params: 770,224 (2.938 MB), Total: 3.05 MB, FLOPs: 74,957,658\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Finished fine tuning.\n",
      "Iteration 1152/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1152\n",
      "\n",
      "Iteration 1153 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 121)]\n",
      "Input: 0.115 MB, Params: 768,620 (2.932 MB), Total: 3.05 MB, FLOPs: 74,842,242\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Finished fine tuning.\n",
      "Iteration 1153/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1153\n",
      "\n",
      "Iteration 1154 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 35)]\n",
      "Input: 0.115 MB, Params: 765,927 (2.922 MB), Total: 3.04 MB, FLOPs: 74,733,396\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Finished fine tuning.\n",
      "Iteration 1154/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1154\n",
      "\n",
      "Iteration 1155 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 186)]\n",
      "Input: 0.115 MB, Params: 764,347 (2.916 MB), Total: 3.03 MB, FLOPs: 74,705,000\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Finished fine tuning.\n",
      "Iteration 1155/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1155\n",
      "\n",
      "Iteration 1156 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 85)]\n",
      "Input: 0.115 MB, Params: 761,582 (2.905 MB), Total: 3.02 MB, FLOPs: 74,655,248\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Finished fine tuning.\n",
      "Iteration 1156/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1156\n",
      "\n",
      "Iteration 1157 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 20)]\n",
      "Input: 0.115 MB, Params: 758,817 (2.895 MB), Total: 3.01 MB, FLOPs: 74,605,496\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Finished fine tuning.\n",
      "Iteration 1157/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1157\n",
      "\n",
      "Iteration 1158 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 1)]\n",
      "Input: 0.115 MB, Params: 757,132 (2.888 MB), Total: 3.00 MB, FLOPs: 74,356,728\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.254%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Finished fine tuning.\n",
      "Iteration 1158/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1158\n",
      "\n",
      "Iteration 1159 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 61)]\n",
      "Input: 0.115 MB, Params: 754,367 (2.878 MB), Total: 2.99 MB, FLOPs: 74,306,976\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Finished fine tuning.\n",
      "Iteration 1159/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1159\n",
      "\n",
      "Iteration 1160 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 13)]\n",
      "Input: 0.115 MB, Params: 752,682 (2.871 MB), Total: 2.99 MB, FLOPs: 74,058,208\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Finished fine tuning.\n",
      "Iteration 1160/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1160\n",
      "\n",
      "Iteration 1161 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 107)]\n",
      "Input: 0.115 MB, Params: 751,105 (2.865 MB), Total: 2.98 MB, FLOPs: 73,944,736\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Finished fine tuning.\n",
      "Iteration 1161/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1161\n",
      "\n",
      "Iteration 1162 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 37)]\n",
      "Input: 0.115 MB, Params: 748,340 (2.855 MB), Total: 2.97 MB, FLOPs: 73,894,984\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Finished fine tuning.\n",
      "Iteration 1162/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1162\n",
      "\n",
      "Iteration 1163 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 80)]\n",
      "Input: 0.115 MB, Params: 745,575 (2.844 MB), Total: 2.96 MB, FLOPs: 73,845,232\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.254%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Finished fine tuning.\n",
      "Iteration 1163/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1163\n",
      "\n",
      "Iteration 1164 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 20)]\n",
      "Input: 0.115 MB, Params: 745,024 (2.842 MB), Total: 2.96 MB, FLOPs: 73,185,232\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Finished fine tuning.\n",
      "Iteration 1164/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1164\n",
      "\n",
      "Iteration 1165 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 75)]\n",
      "Input: 0.115 MB, Params: 743,489 (2.836 MB), Total: 2.95 MB, FLOPs: 73,157,646\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Finished fine tuning.\n",
      "Iteration 1165/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1165\n",
      "\n",
      "Iteration 1166 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 62)]\n",
      "Input: 0.115 MB, Params: 741,954 (2.830 MB), Total: 2.95 MB, FLOPs: 73,130,060\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Finished fine tuning.\n",
      "Iteration 1166/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1166\n",
      "\n",
      "Iteration 1167 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 28)]\n",
      "Input: 0.115 MB, Params: 740,980 (2.827 MB), Total: 2.94 MB, FLOPs: 72,842,052\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Finished fine tuning.\n",
      "Iteration 1167/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1167\n",
      "\n",
      "Iteration 1168 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 57)]\n",
      "Input: 0.115 MB, Params: 738,341 (2.817 MB), Total: 2.93 MB, FLOPs: 72,734,664\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Finished fine tuning.\n",
      "Iteration 1168/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1168\n",
      "\n",
      "Iteration 1169 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 102)]\n",
      "Input: 0.115 MB, Params: 735,702 (2.806 MB), Total: 2.92 MB, FLOPs: 72,627,276\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Finished fine tuning.\n",
      "Iteration 1169/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1169\n",
      "\n",
      "Iteration 1170 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 158)]\n",
      "Input: 0.115 MB, Params: 734,167 (2.801 MB), Total: 2.92 MB, FLOPs: 72,599,690\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Finished fine tuning.\n",
      "Iteration 1170/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1170\n",
      "\n",
      "Iteration 1171 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 21)]\n",
      "Input: 0.115 MB, Params: 732,500 (2.794 MB), Total: 2.91 MB, FLOPs: 72,354,234\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Finished fine tuning.\n",
      "Iteration 1171/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1171\n",
      "\n",
      "Iteration 1172 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 120)]\n",
      "Input: 0.115 MB, Params: 730,950 (2.788 MB), Total: 2.90 MB, FLOPs: 72,242,706\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Finished fine tuning.\n",
      "Iteration 1172/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1172\n",
      "\n",
      "Iteration 1173 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 153)]\n",
      "Input: 0.115 MB, Params: 728,230 (2.778 MB), Total: 2.89 MB, FLOPs: 72,193,764\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Finished fine tuning.\n",
      "Iteration 1173/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1173\n",
      "\n",
      "Iteration 1174 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(3, 24)]\n",
      "Input: 0.115 MB, Params: 728,188 (2.778 MB), Total: 2.89 MB, FLOPs: 71,849,361\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Finished fine tuning.\n",
      "Iteration 1174/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1174\n",
      "\n",
      "Iteration 1175 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 86)]\n",
      "Input: 0.115 MB, Params: 726,638 (2.772 MB), Total: 2.89 MB, FLOPs: 71,737,833\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 93.220%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Finished fine tuning.\n",
      "Iteration 1175/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1175\n",
      "\n",
      "Iteration 1176 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 68)]\n",
      "Input: 0.115 MB, Params: 724,026 (2.762 MB), Total: 2.88 MB, FLOPs: 71,631,903\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Finished fine tuning.\n",
      "Iteration 1176/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1176\n",
      "\n",
      "Iteration 1177 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 73)]\n",
      "Input: 0.115 MB, Params: 722,485 (2.756 MB), Total: 2.87 MB, FLOPs: 71,521,023\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Finished fine tuning.\n",
      "Iteration 1177/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1177\n",
      "\n",
      "Iteration 1178 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 19)]\n",
      "Input: 0.115 MB, Params: 721,934 (2.754 MB), Total: 2.87 MB, FLOPs: 70,861,023\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.136%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.983%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.983%\n",
      "Finished fine tuning.\n",
      "Iteration 1178/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1178\n",
      "\n",
      "Iteration 1179 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 7)]\n",
      "Input: 0.115 MB, Params: 721,383 (2.752 MB), Total: 2.87 MB, FLOPs: 70,201,023\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.983%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.559%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.254%\n",
      "Finished fine tuning.\n",
      "Iteration 1179/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1179\n",
      "\n",
      "Iteration 1180 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 176)]\n",
      "Input: 0.115 MB, Params: 719,857 (2.746 MB), Total: 2.86 MB, FLOPs: 70,173,599\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Finished fine tuning.\n",
      "Iteration 1180/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1180\n",
      "\n",
      "Iteration 1181 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 8)]\n",
      "Input: 0.115 MB, Params: 718,316 (2.740 MB), Total: 2.86 MB, FLOPs: 70,062,719\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Finished fine tuning.\n",
      "Iteration 1181/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1181\n",
      "\n",
      "Iteration 1182 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 29)]\n",
      "Input: 0.115 MB, Params: 715,614 (2.730 MB), Total: 2.85 MB, FLOPs: 70,014,101\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.254%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.983%\n",
      "Finished fine tuning.\n",
      "Iteration 1182/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1182\n",
      "\n",
      "Iteration 1183 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(7, 10)]\n",
      "Input: 0.115 MB, Params: 715,351 (2.729 MB), Total: 2.84 MB, FLOPs: 69,658,581\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.983%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.983%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.831%\n",
      "Finished fine tuning.\n",
      "Iteration 1183/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1183\n",
      "\n",
      "Iteration 1184 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 44)]\n",
      "Input: 0.115 MB, Params: 713,720 (2.723 MB), Total: 2.84 MB, FLOPs: 69,415,717\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.831%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.831%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Finished fine tuning.\n",
      "Iteration 1184/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1184\n",
      "\n",
      "Iteration 1185 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 67)]\n",
      "Input: 0.115 MB, Params: 711,018 (2.712 MB), Total: 2.83 MB, FLOPs: 69,367,099\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Finished fine tuning.\n",
      "Iteration 1185/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1185\n",
      "\n",
      "Iteration 1186 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 10)]\n",
      "Input: 0.115 MB, Params: 708,316 (2.702 MB), Total: 2.82 MB, FLOPs: 69,318,481\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.831%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.254%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Finished fine tuning.\n",
      "Iteration 1186/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1186\n",
      "\n",
      "Iteration 1187 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 86)]\n",
      "Input: 0.115 MB, Params: 705,749 (2.692 MB), Total: 2.81 MB, FLOPs: 69,214,333\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Finished fine tuning.\n",
      "Iteration 1187/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1187\n",
      "\n",
      "Iteration 1188 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 64)]\n",
      "Input: 0.115 MB, Params: 704,226 (2.686 MB), Total: 2.80 MB, FLOPs: 69,104,749\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.983%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.831%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.254%\n",
      "Finished fine tuning.\n",
      "Iteration 1188/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1188\n",
      "\n",
      "Iteration 1189 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 30)]\n",
      "Input: 0.115 MB, Params: 702,727 (2.681 MB), Total: 2.80 MB, FLOPs: 69,077,811\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.254%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.831%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Finished fine tuning.\n",
      "Iteration 1189/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1189\n",
      "\n",
      "Iteration 1190 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(14, 0)]\n",
      "Input: 0.115 MB, Params: 701,915 (2.678 MB), Total: 2.79 MB, FLOPs: 68,607,859\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.441%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.831%\n",
      "Finished fine tuning.\n",
      "Iteration 1190/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1190\n",
      "\n",
      "Iteration 1191 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 51)]\n",
      "Input: 0.115 MB, Params: 700,968 (2.674 MB), Total: 2.79 MB, FLOPs: 68,327,843\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.831%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.407%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Finished fine tuning.\n",
      "Iteration 1191/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1191\n",
      "\n",
      "Iteration 1192 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 150)]\n",
      "Input: 0.115 MB, Params: 699,469 (2.668 MB), Total: 2.78 MB, FLOPs: 68,300,905\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.254%\n",
      "Finished fine tuning.\n",
      "Iteration 1192/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1192\n",
      "\n",
      "Iteration 1193 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(14, 24)]\n",
      "Input: 0.115 MB, Params: 698,666 (2.665 MB), Total: 2.78 MB, FLOPs: 67,833,617\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Finished fine tuning.\n",
      "Iteration 1193/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1193\n",
      "\n",
      "Iteration 1194 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 31)]\n",
      "Input: 0.115 MB, Params: 697,728 (2.662 MB), Total: 2.78 MB, FLOPs: 67,556,265\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.407%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Finished fine tuning.\n",
      "Iteration 1194/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1194\n",
      "\n",
      "Iteration 1195 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 86)]\n",
      "Input: 0.115 MB, Params: 696,229 (2.656 MB), Total: 2.77 MB, FLOPs: 67,529,327\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.712%\n",
      "Finished fine tuning.\n",
      "Iteration 1195/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1195\n",
      "\n",
      "Iteration 1196 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 137)]\n",
      "Input: 0.115 MB, Params: 693,563 (2.646 MB), Total: 2.76 MB, FLOPs: 67,481,357\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.407%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.831%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.831%\n",
      "Finished fine tuning.\n",
      "Iteration 1196/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1196\n",
      "\n",
      "Iteration 1197 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 2)]\n",
      "Input: 0.115 MB, Params: 691,014 (2.636 MB), Total: 2.75 MB, FLOPs: 67,378,019\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.407%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.254%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Finished fine tuning.\n",
      "Iteration 1197/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1197\n",
      "\n",
      "Iteration 1198 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(14, 33)]\n",
      "Input: 0.115 MB, Params: 690,220 (2.633 MB), Total: 2.75 MB, FLOPs: 66,913,395\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.831%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.831%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.831%\n",
      "Finished fine tuning.\n",
      "Iteration 1198/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1198\n",
      "\n",
      "Iteration 1199 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 138)]\n",
      "Input: 0.115 MB, Params: 687,563 (2.623 MB), Total: 2.74 MB, FLOPs: 66,865,587\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.407%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.983%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.407%\n",
      "Finished fine tuning.\n",
      "Iteration 1199/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1199\n",
      "\n",
      "Iteration 1200 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 1)]\n",
      "Input: 0.115 MB, Params: 687,048 (2.621 MB), Total: 2.74 MB, FLOPs: 66,248,787\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.831%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.407%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.407%\n",
      "Finished fine tuning.\n",
      "Iteration 1200/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1200\n",
      "\n",
      "Iteration 1201 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 122)]\n",
      "Input: 0.115 MB, Params: 684,391 (2.611 MB), Total: 2.73 MB, FLOPs: 66,200,979\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.254%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.407%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.831%\n",
      "Finished fine tuning.\n",
      "Iteration 1201/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1201\n",
      "\n",
      "Iteration 1202 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 70)]\n",
      "Input: 0.115 MB, Params: 682,919 (2.605 MB), Total: 2.72 MB, FLOPs: 66,174,527\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.254%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.831%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Finished fine tuning.\n",
      "Iteration 1202/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1202\n",
      "\n",
      "Iteration 1203 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 1)]\n",
      "Input: 0.115 MB, Params: 681,315 (2.599 MB), Total: 2.71 MB, FLOPs: 65,937,639\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.559%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.983%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.559%\n",
      "Finished fine tuning.\n",
      "Iteration 1203/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1203\n",
      "\n",
      "Iteration 1204 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 1)]\n",
      "Input: 0.115 MB, Params: 680,395 (2.596 MB), Total: 2.71 MB, FLOPs: 65,665,615\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.136%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.831%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Finished fine tuning.\n",
      "Iteration 1204/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1204\n",
      "\n",
      "Iteration 1205 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 85)]\n",
      "Input: 0.115 MB, Params: 678,923 (2.590 MB), Total: 2.71 MB, FLOPs: 65,639,163\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.831%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Finished fine tuning.\n",
      "Iteration 1205/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1205\n",
      "\n",
      "Iteration 1206 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 19)]\n",
      "Input: 0.115 MB, Params: 676,392 (2.580 MB), Total: 2.70 MB, FLOPs: 65,536,149\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Finished fine tuning.\n",
      "Iteration 1206/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1206\n",
      "\n",
      "Iteration 1207 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 5)]\n",
      "Input: 0.115 MB, Params: 674,920 (2.575 MB), Total: 2.69 MB, FLOPs: 65,509,697\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.407%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.254%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Finished fine tuning.\n",
      "Iteration 1207/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1207\n",
      "\n",
      "Iteration 1208 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 52)]\n",
      "Input: 0.115 MB, Params: 673,325 (2.569 MB), Total: 2.68 MB, FLOPs: 65,275,473\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Finished fine tuning.\n",
      "Iteration 1208/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1208\n",
      "\n",
      "Iteration 1209 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 60)]\n",
      "Input: 0.115 MB, Params: 671,853 (2.563 MB), Total: 2.68 MB, FLOPs: 65,249,021\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.254%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.254%\n",
      "Finished fine tuning.\n",
      "Iteration 1209/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1209\n",
      "\n",
      "Iteration 1210 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 63)]\n",
      "Input: 0.115 MB, Params: 669,241 (2.553 MB), Total: 2.67 MB, FLOPs: 65,202,023\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.797%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Finished fine tuning.\n",
      "Iteration 1210/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1210\n",
      "\n",
      "Iteration 1211 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(0, 1)]\n",
      "Input: 0.115 MB, Params: 669,070 (2.552 MB), Total: 2.67 MB, FLOPs: 63,842,453\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.136%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.831%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.831%\n",
      "Finished fine tuning.\n",
      "Iteration 1211/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1211\n",
      "\n",
      "Iteration 1212 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 19)]\n",
      "Input: 0.115 MB, Params: 667,607 (2.547 MB), Total: 2.66 MB, FLOPs: 63,816,163\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.136%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.983%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.407%\n",
      "Finished fine tuning.\n",
      "Iteration 1212/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1212\n",
      "\n",
      "Iteration 1213 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 23)]\n",
      "Input: 0.115 MB, Params: 666,696 (2.543 MB), Total: 2.66 MB, FLOPs: 63,546,803\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.407%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.407%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.288%\n",
      "Finished fine tuning.\n",
      "Iteration 1213/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1213\n",
      "\n",
      "Iteration 1214 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 59)]\n",
      "Input: 0.115 MB, Params: 665,233 (2.538 MB), Total: 2.65 MB, FLOPs: 63,520,513\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.712%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.712%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.017%\n",
      "Finished fine tuning.\n",
      "Iteration 1214/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1214\n",
      "\n",
      "Iteration 1215 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 14)]\n",
      "Input: 0.115 MB, Params: 662,639 (2.528 MB), Total: 2.64 MB, FLOPs: 63,473,839\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.864%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.288%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.017%\n",
      "Finished fine tuning.\n",
      "Iteration 1215/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1215\n",
      "\n",
      "Iteration 1216 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 32)]\n",
      "Input: 0.115 MB, Params: 661,053 (2.522 MB), Total: 2.64 MB, FLOPs: 63,242,279\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.288%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.136%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.559%\n",
      "Finished fine tuning.\n",
      "Iteration 1216/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1216\n",
      "\n",
      "Iteration 1217 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 5)]\n",
      "Input: 0.115 MB, Params: 658,540 (2.512 MB), Total: 2.63 MB, FLOPs: 63,139,589\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.559%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.983%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.136%\n",
      "Finished fine tuning.\n",
      "Iteration 1217/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1217\n",
      "\n",
      "Iteration 1218 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 5)]\n",
      "Input: 0.115 MB, Params: 656,954 (2.506 MB), Total: 2.62 MB, FLOPs: 62,908,029\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.593%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.441%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.864%\n",
      "Finished fine tuning.\n",
      "Iteration 1218/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1218\n",
      "\n",
      "Iteration 1219 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 29)]\n",
      "Input: 0.115 MB, Params: 655,368 (2.500 MB), Total: 2.62 MB, FLOPs: 62,676,469\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.864%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.288%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.441%\n",
      "Finished fine tuning.\n",
      "Iteration 1219/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1219\n",
      "\n",
      "Iteration 1220 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 2)]\n",
      "Input: 0.115 MB, Params: 654,853 (2.498 MB), Total: 2.61 MB, FLOPs: 62,059,669\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.712%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.288%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.712%\n",
      "Finished fine tuning.\n",
      "Iteration 1220/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1220\n",
      "\n",
      "Iteration 1221 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 78)]\n",
      "Input: 0.115 MB, Params: 653,399 (2.493 MB), Total: 2.61 MB, FLOPs: 62,033,541\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.136%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.712%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.136%\n",
      "Finished fine tuning.\n",
      "Iteration 1221/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1221\n",
      "\n",
      "Iteration 1222 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 147)]\n",
      "Input: 0.115 MB, Params: 651,945 (2.487 MB), Total: 2.60 MB, FLOPs: 62,007,413\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.136%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.983%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.864%\n",
      "Finished fine tuning.\n",
      "Iteration 1222/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1222\n",
      "\n",
      "Iteration 1223 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 4)]\n",
      "Input: 0.115 MB, Params: 650,359 (2.481 MB), Total: 2.60 MB, FLOPs: 61,775,853\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.288%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.441%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.288%\n",
      "Finished fine tuning.\n",
      "Iteration 1223/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1223\n",
      "\n",
      "Iteration 1224 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 0)]\n",
      "Input: 0.115 MB, Params: 647,792 (2.471 MB), Total: 2.59 MB, FLOPs: 61,729,665\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.288%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.983%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.136%\n",
      "Finished fine tuning.\n",
      "Iteration 1224/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1224\n",
      "\n",
      "Iteration 1225 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 120)]\n",
      "Input: 0.115 MB, Params: 646,347 (2.466 MB), Total: 2.58 MB, FLOPs: 61,703,699\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.983%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.407%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.983%\n",
      "Finished fine tuning.\n",
      "Iteration 1225/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1225\n",
      "\n",
      "Iteration 1226 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 96)]\n",
      "Input: 0.115 MB, Params: 643,789 (2.456 MB), Total: 2.57 MB, FLOPs: 61,657,673\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.983%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.712%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.983%\n",
      "Finished fine tuning.\n",
      "Iteration 1226/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1226\n",
      "\n",
      "Iteration 1227 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 29)]\n",
      "Input: 0.115 MB, Params: 641,231 (2.446 MB), Total: 2.56 MB, FLOPs: 61,611,647\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.559%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.983%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.136%\n",
      "Finished fine tuning.\n",
      "Iteration 1227/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1227\n",
      "\n",
      "Iteration 1228 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 159)]\n",
      "Input: 0.115 MB, Params: 639,804 (2.441 MB), Total: 2.56 MB, FLOPs: 61,586,005\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.559%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.136%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.407%\n",
      "Finished fine tuning.\n",
      "Iteration 1228/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1228\n",
      "\n",
      "Iteration 1229 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 78)]\n",
      "Input: 0.115 MB, Params: 637,318 (2.431 MB), Total: 2.55 MB, FLOPs: 61,483,801\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.407%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.407%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.559%\n",
      "Finished fine tuning.\n",
      "Iteration 1229/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1229\n",
      "\n",
      "Iteration 1230 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 40)]\n",
      "Input: 0.115 MB, Params: 635,891 (2.426 MB), Total: 2.54 MB, FLOPs: 61,458,159\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.407%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.136%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.407%\n",
      "Finished fine tuning.\n",
      "Iteration 1230/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1230\n",
      "\n",
      "Iteration 1231 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 2)]\n",
      "Input: 0.115 MB, Params: 635,016 (2.422 MB), Total: 2.54 MB, FLOPs: 61,199,455\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.983%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.983%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.983%\n",
      "Finished fine tuning.\n",
      "Iteration 1231/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1231\n",
      "\n",
      "Iteration 1232 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 83)]\n",
      "Input: 0.115 MB, Params: 632,485 (2.413 MB), Total: 2.53 MB, FLOPs: 61,153,915\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.136%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.983%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.983%\n",
      "Finished fine tuning.\n",
      "Iteration 1232/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1232\n",
      "\n",
      "Iteration 1233 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(0, 3)]\n",
      "Input: 0.115 MB, Params: 632,314 (2.412 MB), Total: 2.53 MB, FLOPs: 59,794,345\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 68.220%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.864%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.864%\n",
      "Finished fine tuning.\n",
      "Iteration 1233/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1233\n",
      "\n",
      "Iteration 1234 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 26)]\n",
      "Input: 0.115 MB, Params: 631,439 (2.409 MB), Total: 2.52 MB, FLOPs: 59,535,641\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.136%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.559%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.441%\n",
      "Finished fine tuning.\n",
      "Iteration 1234/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1234\n",
      "\n",
      "Iteration 1235 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 0)]\n",
      "Input: 0.115 MB, Params: 630,924 (2.407 MB), Total: 2.52 MB, FLOPs: 58,918,841\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.288%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.288%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.288%\n",
      "Finished fine tuning.\n",
      "Iteration 1235/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1235\n",
      "\n",
      "Iteration 1236 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 70)]\n",
      "Input: 0.115 MB, Params: 628,447 (2.397 MB), Total: 2.51 MB, FLOPs: 58,816,799\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.288%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.559%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.831%\n",
      "Finished fine tuning.\n",
      "Iteration 1236/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1236\n",
      "\n",
      "Iteration 1237 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 99)]\n",
      "Input: 0.115 MB, Params: 627,023 (2.392 MB), Total: 2.51 MB, FLOPs: 58,714,343\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.407%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.407%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.407%\n",
      "Finished fine tuning.\n",
      "Iteration 1237/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1237\n",
      "\n",
      "Iteration 1238 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 123)]\n",
      "Input: 0.115 MB, Params: 625,605 (2.386 MB), Total: 2.50 MB, FLOPs: 58,688,863\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.559%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.712%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.712%\n",
      "Finished fine tuning.\n",
      "Iteration 1238/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1238\n",
      "\n",
      "Iteration 1239 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 80)]\n",
      "Input: 0.115 MB, Params: 623,092 (2.377 MB), Total: 2.49 MB, FLOPs: 58,643,647\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.864%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.712%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.712%\n",
      "Finished fine tuning.\n",
      "Iteration 1239/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1239\n",
      "\n",
      "Iteration 1240 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 17)]\n",
      "Input: 0.115 MB, Params: 620,633 (2.368 MB), Total: 2.48 MB, FLOPs: 58,542,415\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.559%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.983%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.017%\n",
      "Finished fine tuning.\n",
      "Iteration 1240/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1240\n",
      "\n",
      "Iteration 1241 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 126)]\n",
      "Input: 0.115 MB, Params: 618,129 (2.358 MB), Total: 2.47 MB, FLOPs: 58,497,361\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.864%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.712%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.559%\n",
      "Finished fine tuning.\n",
      "Iteration 1241/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1241\n",
      "\n",
      "Iteration 1242 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 88)]\n",
      "Input: 0.115 MB, Params: 615,625 (2.348 MB), Total: 2.46 MB, FLOPs: 58,452,307\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.136%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.288%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.288%\n",
      "Finished fine tuning.\n",
      "Iteration 1242/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1242\n",
      "\n",
      "Iteration 1243 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 16)]\n",
      "Input: 0.115 MB, Params: 614,750 (2.345 MB), Total: 2.46 MB, FLOPs: 58,193,603\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.983%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.136%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.441%\n",
      "Finished fine tuning.\n",
      "Iteration 1243/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1243\n",
      "\n",
      "Iteration 1244 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 127)]\n",
      "Input: 0.115 MB, Params: 612,246 (2.336 MB), Total: 2.45 MB, FLOPs: 58,148,549\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.593%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.593%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.593%\n",
      "Finished fine tuning.\n",
      "Iteration 1244/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1244\n",
      "\n",
      "Iteration 1245 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 63)]\n",
      "Input: 0.115 MB, Params: 610,831 (2.330 MB), Total: 2.45 MB, FLOPs: 58,046,741\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.017%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.136%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.712%\n",
      "Finished fine tuning.\n",
      "Iteration 1245/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1245\n",
      "\n",
      "Iteration 1246 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 20)]\n",
      "Input: 0.115 MB, Params: 608,327 (2.321 MB), Total: 2.44 MB, FLOPs: 58,001,687\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.712%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.559%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.983%\n",
      "Finished fine tuning.\n",
      "Iteration 1246/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1246\n",
      "\n",
      "Iteration 1247 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 39)]\n",
      "Input: 0.115 MB, Params: 607,452 (2.317 MB), Total: 2.43 MB, FLOPs: 57,742,983\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.559%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.288%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.712%\n",
      "Finished fine tuning.\n",
      "Iteration 1247/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1247\n",
      "\n",
      "Iteration 1248 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 90)]\n",
      "Input: 0.115 MB, Params: 606,037 (2.312 MB), Total: 2.43 MB, FLOPs: 57,641,175\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.288%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.712%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.712%\n",
      "Finished fine tuning.\n",
      "Iteration 1248/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1248\n",
      "\n",
      "Iteration 1249 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 14)]\n",
      "Input: 0.115 MB, Params: 605,162 (2.309 MB), Total: 2.42 MB, FLOPs: 57,382,471\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.136%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.983%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.983%\n",
      "Finished fine tuning.\n",
      "Iteration 1249/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1249\n",
      "\n",
      "Iteration 1250 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 46)]\n",
      "Input: 0.115 MB, Params: 603,747 (2.303 MB), Total: 2.42 MB, FLOPs: 57,280,663\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.407%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.983%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.983%\n",
      "Finished fine tuning.\n",
      "Iteration 1250/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1250\n",
      "\n",
      "Iteration 1251 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 63)]\n",
      "Input: 0.115 MB, Params: 602,332 (2.298 MB), Total: 2.41 MB, FLOPs: 57,178,855\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.831%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.407%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.407%\n",
      "Finished fine tuning.\n",
      "Iteration 1251/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1251\n",
      "\n",
      "Iteration 1252 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 81)]\n",
      "Input: 0.115 MB, Params: 600,917 (2.292 MB), Total: 2.41 MB, FLOPs: 57,077,047\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.407%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.559%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.407%\n",
      "Finished fine tuning.\n",
      "Iteration 1252/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1252\n",
      "\n",
      "Iteration 1253 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 155)]\n",
      "Input: 0.115 MB, Params: 599,544 (2.287 MB), Total: 2.40 MB, FLOPs: 57,052,377\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.831%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.407%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.407%\n",
      "Finished fine tuning.\n",
      "Iteration 1253/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1253\n",
      "\n",
      "Iteration 1254 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 117)]\n",
      "Input: 0.115 MB, Params: 598,171 (2.282 MB), Total: 2.40 MB, FLOPs: 57,027,707\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.407%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.983%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.864%\n",
      "Finished fine tuning.\n",
      "Iteration 1254/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1254\n",
      "\n",
      "Iteration 1255 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 148)]\n",
      "Input: 0.115 MB, Params: 595,685 (2.272 MB), Total: 2.39 MB, FLOPs: 56,982,977\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.441%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.864%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.288%\n",
      "Finished fine tuning.\n",
      "Iteration 1255/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1255\n",
      "\n",
      "Iteration 1256 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 17)]\n",
      "Input: 0.115 MB, Params: 595,170 (2.270 MB), Total: 2.39 MB, FLOPs: 56,366,177\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.712%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.136%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.712%\n",
      "Finished fine tuning.\n",
      "Iteration 1256/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1256\n",
      "\n",
      "Iteration 1257 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 169)]\n",
      "Input: 0.115 MB, Params: 593,806 (2.265 MB), Total: 2.38 MB, FLOPs: 56,341,669\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.712%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.831%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.864%\n",
      "Finished fine tuning.\n",
      "Iteration 1257/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1257\n",
      "\n",
      "Iteration 1258 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 15)]\n",
      "Input: 0.115 MB, Params: 591,329 (2.256 MB), Total: 2.37 MB, FLOPs: 56,297,101\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.288%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.288%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.136%\n",
      "Finished fine tuning.\n",
      "Iteration 1258/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1258\n",
      "\n",
      "Iteration 1259 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 25)]\n",
      "Input: 0.115 MB, Params: 589,914 (2.250 MB), Total: 2.37 MB, FLOPs: 56,195,293\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.407%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.983%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.407%\n",
      "Finished fine tuning.\n",
      "Iteration 1259/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1259\n",
      "\n",
      "Iteration 1260 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 26)]\n",
      "Input: 0.115 MB, Params: 588,559 (2.245 MB), Total: 2.36 MB, FLOPs: 56,170,947\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.831%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.559%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.288%\n",
      "Finished fine tuning.\n",
      "Iteration 1260/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1260\n",
      "\n",
      "Iteration 1261 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 27)]\n",
      "Input: 0.115 MB, Params: 587,204 (2.240 MB), Total: 2.36 MB, FLOPs: 56,146,601\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.712%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.864%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.288%\n",
      "Finished fine tuning.\n",
      "Iteration 1261/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1261\n",
      "\n",
      "Iteration 1262 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 26)]\n",
      "Input: 0.115 MB, Params: 584,745 (2.231 MB), Total: 2.35 MB, FLOPs: 56,102,357\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.983%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.983%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.288%\n",
      "Finished fine tuning.\n",
      "Iteration 1262/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1262\n",
      "\n",
      "Iteration 1263 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 97)]\n",
      "Input: 0.115 MB, Params: 582,403 (2.222 MB), Total: 2.34 MB, FLOPs: 56,006,147\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.831%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.254%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.831%\n",
      "Finished fine tuning.\n",
      "Iteration 1263/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1263\n",
      "\n",
      "Iteration 1264 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(7, 14)]\n",
      "Input: 0.115 MB, Params: 582,176 (2.221 MB), Total: 2.34 MB, FLOPs: 55,693,827\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.780%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Finished fine tuning.\n",
      "Iteration 1264/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1264\n",
      "\n",
      "Iteration 1265 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 41)]\n",
      "Input: 0.115 MB, Params: 580,698 (2.215 MB), Total: 2.33 MB, FLOPs: 55,480,123\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.559%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.254%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.407%\n",
      "Finished fine tuning.\n",
      "Iteration 1265/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1265\n",
      "\n",
      "Iteration 1266 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 87)]\n",
      "Input: 0.115 MB, Params: 579,301 (2.210 MB), Total: 2.33 MB, FLOPs: 55,379,611\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.407%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.831%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.712%\n",
      "Finished fine tuning.\n",
      "Iteration 1266/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1266\n",
      "\n",
      "Iteration 1267 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 17)]\n",
      "Input: 0.115 MB, Params: 578,435 (2.207 MB), Total: 2.32 MB, FLOPs: 55,123,571\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.712%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.559%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Finished fine tuning.\n",
      "Iteration 1267/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1267\n",
      "\n",
      "Iteration 1268 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 51)]\n",
      "Input: 0.115 MB, Params: 575,985 (2.197 MB), Total: 2.31 MB, FLOPs: 55,079,489\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.254%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.136%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.441%\n",
      "Finished fine tuning.\n",
      "Iteration 1268/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1268\n",
      "\n",
      "Iteration 1269 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 125)]\n",
      "Input: 0.115 MB, Params: 573,535 (2.188 MB), Total: 2.30 MB, FLOPs: 55,035,407\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.712%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.254%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.831%\n",
      "Finished fine tuning.\n",
      "Iteration 1269/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1269\n",
      "\n",
      "Iteration 1270 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(14, 26)]\n",
      "Input: 0.115 MB, Params: 572,849 (2.185 MB), Total: 2.30 MB, FLOPs: 54,635,295\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.983%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.441%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.864%\n",
      "Finished fine tuning.\n",
      "Iteration 1270/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1270\n",
      "\n",
      "Iteration 1271 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 33)]\n",
      "Input: 0.115 MB, Params: 571,452 (2.180 MB), Total: 2.30 MB, FLOPs: 54,534,783\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.712%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.712%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.983%\n",
      "Finished fine tuning.\n",
      "Iteration 1271/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1271\n",
      "\n",
      "Iteration 1272 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 5)]\n",
      "Input: 0.115 MB, Params: 569,002 (2.171 MB), Total: 2.29 MB, FLOPs: 54,490,701\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.136%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.712%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.864%\n",
      "Finished fine tuning.\n",
      "Iteration 1272/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1272\n",
      "\n",
      "Iteration 1273 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 85)]\n",
      "Input: 0.115 MB, Params: 566,705 (2.162 MB), Total: 2.28 MB, FLOPs: 54,396,273\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.017%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.136%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.712%\n",
      "Finished fine tuning.\n",
      "Iteration 1273/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1273\n",
      "\n",
      "Iteration 1274 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 7)]\n",
      "Input: 0.115 MB, Params: 566,208 (2.160 MB), Total: 2.28 MB, FLOPs: 53,801,073\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.712%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.136%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.712%\n",
      "Finished fine tuning.\n",
      "Iteration 1274/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1274\n",
      "\n",
      "Iteration 1275 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 67)]\n",
      "Input: 0.115 MB, Params: 564,889 (2.155 MB), Total: 2.27 MB, FLOPs: 53,777,375\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.288%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.288%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.441%\n",
      "Finished fine tuning.\n",
      "Iteration 1275/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1275\n",
      "\n",
      "Iteration 1276 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 43)]\n",
      "Input: 0.115 MB, Params: 564,032 (2.152 MB), Total: 2.27 MB, FLOPs: 53,523,999\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.593%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.441%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.864%\n",
      "Finished fine tuning.\n",
      "Iteration 1276/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1276\n",
      "\n",
      "Iteration 1277 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 163)]\n",
      "Input: 0.115 MB, Params: 562,713 (2.147 MB), Total: 2.26 MB, FLOPs: 53,500,301\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.441%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.017%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.441%\n",
      "Finished fine tuning.\n",
      "Iteration 1277/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1277\n",
      "\n",
      "Iteration 1278 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 2)]\n",
      "Input: 0.115 MB, Params: 561,271 (2.141 MB), Total: 2.26 MB, FLOPs: 53,293,221\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.017%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.136%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.712%\n",
      "Finished fine tuning.\n",
      "Iteration 1278/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1278\n",
      "\n",
      "Iteration 1279 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(14, 33)]\n",
      "Input: 0.115 MB, Params: 560,603 (2.139 MB), Total: 2.25 MB, FLOPs: 52,906,573\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.712%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.864%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.441%\n",
      "Finished fine tuning.\n",
      "Iteration 1279/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1279\n",
      "\n",
      "Iteration 1280 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 92)]\n",
      "Input: 0.115 MB, Params: 558,306 (2.130 MB), Total: 2.25 MB, FLOPs: 52,812,145\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.017%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.136%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.593%\n",
      "Finished fine tuning.\n",
      "Iteration 1280/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1280\n",
      "\n",
      "Iteration 1281 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 72)]\n",
      "Input: 0.115 MB, Params: 556,009 (2.121 MB), Total: 2.24 MB, FLOPs: 52,717,717\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.593%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.136%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.712%\n",
      "Finished fine tuning.\n",
      "Iteration 1281/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1281\n",
      "\n",
      "Iteration 1282 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 0)]\n",
      "Input: 0.115 MB, Params: 555,170 (2.118 MB), Total: 2.23 MB, FLOPs: 52,469,669\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.441%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.712%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.864%\n",
      "Finished fine tuning.\n",
      "Iteration 1282/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1282\n",
      "\n",
      "Iteration 1283 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 76)]\n",
      "Input: 0.115 MB, Params: 552,873 (2.109 MB), Total: 2.22 MB, FLOPs: 52,375,241\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.864%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.288%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.559%\n",
      "Finished fine tuning.\n",
      "Iteration 1283/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1283\n",
      "\n",
      "Iteration 1284 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 70)]\n",
      "Input: 0.115 MB, Params: 551,554 (2.104 MB), Total: 2.22 MB, FLOPs: 52,351,543\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.559%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.559%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.712%\n",
      "Finished fine tuning.\n",
      "Iteration 1284/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1284\n",
      "\n",
      "Iteration 1285 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 49)]\n",
      "Input: 0.115 MB, Params: 550,121 (2.099 MB), Total: 2.21 MB, FLOPs: 52,147,127\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.712%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.864%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.288%\n",
      "Finished fine tuning.\n",
      "Iteration 1285/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1285\n",
      "\n",
      "Iteration 1286 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 3)]\n",
      "Input: 0.115 MB, Params: 547,734 (2.089 MB), Total: 2.20 MB, FLOPs: 52,104,179\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.136%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.136%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.136%\n",
      "Finished fine tuning.\n",
      "Iteration 1286/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1286\n",
      "\n",
      "Iteration 1287 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 45)]\n",
      "Input: 0.115 MB, Params: 545,446 (2.081 MB), Total: 2.20 MB, FLOPs: 52,009,913\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.864%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.136%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.136%\n",
      "Finished fine tuning.\n",
      "Iteration 1287/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1287\n",
      "\n",
      "Iteration 1288 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 35)]\n",
      "Input: 0.115 MB, Params: 544,136 (2.076 MB), Total: 2.19 MB, FLOPs: 51,986,377\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.136%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.831%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.254%\n",
      "Finished fine tuning.\n",
      "Iteration 1288/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1288\n",
      "\n",
      "Iteration 1289 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(14, 19)]\n",
      "Input: 0.115 MB, Params: 543,477 (2.073 MB), Total: 2.19 MB, FLOPs: 51,602,393\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.983%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.983%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.712%\n",
      "Finished fine tuning.\n",
      "Iteration 1289/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1289\n",
      "\n",
      "Iteration 1290 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 87)]\n",
      "Input: 0.115 MB, Params: 541,108 (2.064 MB), Total: 2.18 MB, FLOPs: 51,559,769\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.288%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.559%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.712%\n",
      "Finished fine tuning.\n",
      "Iteration 1290/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1290\n",
      "\n",
      "Iteration 1291 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 78)]\n",
      "Input: 0.115 MB, Params: 538,739 (2.055 MB), Total: 2.17 MB, FLOPs: 51,517,145\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.864%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.831%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.254%\n",
      "Finished fine tuning.\n",
      "Iteration 1291/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1291\n",
      "\n",
      "Iteration 1292 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 98)]\n",
      "Input: 0.115 MB, Params: 536,370 (2.046 MB), Total: 2.16 MB, FLOPs: 51,474,521\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.254%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.831%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Finished fine tuning.\n",
      "Iteration 1292/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1292\n",
      "\n",
      "Iteration 1293 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 80)]\n",
      "Input: 0.115 MB, Params: 534,001 (2.037 MB), Total: 2.15 MB, FLOPs: 51,431,897\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.983%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.136%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.136%\n",
      "Finished fine tuning.\n",
      "Iteration 1293/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1293\n",
      "\n",
      "Iteration 1294 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 13)]\n",
      "Input: 0.115 MB, Params: 532,667 (2.032 MB), Total: 2.15 MB, FLOPs: 51,335,921\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.288%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.136%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.559%\n",
      "Finished fine tuning.\n",
      "Iteration 1294/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1294\n",
      "\n",
      "Iteration 1295 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 67)]\n",
      "Input: 0.115 MB, Params: 531,393 (2.027 MB), Total: 2.14 MB, FLOPs: 51,313,033\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.559%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.559%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.136%\n",
      "Finished fine tuning.\n",
      "Iteration 1295/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1295\n",
      "\n",
      "Iteration 1296 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 19)]\n",
      "Input: 0.115 MB, Params: 530,572 (2.024 MB), Total: 2.14 MB, FLOPs: 51,070,313\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.864%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Finished fine tuning.\n",
      "Iteration 1296/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1296\n",
      "\n",
      "Iteration 1297 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 28)]\n",
      "Input: 0.115 MB, Params: 529,238 (2.019 MB), Total: 2.13 MB, FLOPs: 50,974,337\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.559%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.407%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.712%\n",
      "Finished fine tuning.\n",
      "Iteration 1297/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1297\n",
      "\n",
      "Iteration 1298 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 30)]\n",
      "Input: 0.115 MB, Params: 527,964 (2.014 MB), Total: 2.13 MB, FLOPs: 50,951,449\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.559%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.136%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.136%\n",
      "Finished fine tuning.\n",
      "Iteration 1298/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1298\n",
      "\n",
      "Iteration 1299 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 114)]\n",
      "Input: 0.115 MB, Params: 525,613 (2.005 MB), Total: 2.12 MB, FLOPs: 50,909,149\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.136%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.441%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.559%\n",
      "Finished fine tuning.\n",
      "Iteration 1299/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1299\n",
      "\n",
      "Iteration 1300 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 48)]\n",
      "Input: 0.115 MB, Params: 524,348 (2.000 MB), Total: 2.12 MB, FLOPs: 50,886,423\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.559%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.831%\n",
      "Finished fine tuning.\n",
      "Iteration 1300/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1300\n",
      "\n",
      "Iteration 1301 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 56)]\n",
      "Input: 0.115 MB, Params: 522,123 (1.992 MB), Total: 2.11 MB, FLOPs: 50,794,263\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.831%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.136%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.712%\n",
      "Finished fine tuning.\n",
      "Iteration 1301/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1301\n",
      "\n",
      "Iteration 1302 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 74)]\n",
      "Input: 0.115 MB, Params: 520,798 (1.987 MB), Total: 2.10 MB, FLOPs: 50,698,935\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.983%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.254%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.983%\n",
      "Finished fine tuning.\n",
      "Iteration 1302/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1302\n",
      "\n",
      "Iteration 1303 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 12)]\n",
      "Input: 0.115 MB, Params: 519,533 (1.982 MB), Total: 2.10 MB, FLOPs: 50,676,209\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.407%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Finished fine tuning.\n",
      "Iteration 1303/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1303\n",
      "\n",
      "Iteration 1304 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 126)]\n",
      "Input: 0.115 MB, Params: 517,209 (1.973 MB), Total: 2.09 MB, FLOPs: 50,634,395\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.983%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.983%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.712%\n",
      "Finished fine tuning.\n",
      "Iteration 1304/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1304\n",
      "\n",
      "Iteration 1305 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 12)]\n",
      "Input: 0.115 MB, Params: 515,812 (1.968 MB), Total: 2.08 MB, FLOPs: 50,434,587\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.559%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.407%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.136%\n",
      "Finished fine tuning.\n",
      "Iteration 1305/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1305\n",
      "\n",
      "Iteration 1306 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 8)]\n",
      "Input: 0.115 MB, Params: 515,000 (1.965 MB), Total: 2.08 MB, FLOPs: 50,194,531\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.983%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.831%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.983%\n",
      "Finished fine tuning.\n",
      "Iteration 1306/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1306\n",
      "\n",
      "Iteration 1307 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(14, 8)]\n",
      "Input: 0.115 MB, Params: 514,359 (1.962 MB), Total: 2.08 MB, FLOPs: 49,815,875\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.407%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.831%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.983%\n",
      "Finished fine tuning.\n",
      "Iteration 1307/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1307\n",
      "\n",
      "Iteration 1308 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 21)]\n",
      "Input: 0.115 MB, Params: 512,035 (1.953 MB), Total: 2.07 MB, FLOPs: 49,774,061\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.136%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.254%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.831%\n",
      "Finished fine tuning.\n",
      "Iteration 1308/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1308\n",
      "\n",
      "Iteration 1309 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 81)]\n",
      "Input: 0.115 MB, Params: 510,719 (1.948 MB), Total: 2.06 MB, FLOPs: 49,679,381\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.407%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.254%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.254%\n",
      "Finished fine tuning.\n",
      "Iteration 1309/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1309\n",
      "\n",
      "Iteration 1310 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 18)]\n",
      "Input: 0.115 MB, Params: 508,395 (1.939 MB), Total: 2.05 MB, FLOPs: 49,637,567\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.831%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.254%\n",
      "Finished fine tuning.\n",
      "Iteration 1310/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1310\n",
      "\n",
      "Iteration 1311 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 64)]\n",
      "Input: 0.115 MB, Params: 506,071 (1.931 MB), Total: 2.05 MB, FLOPs: 49,595,753\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.831%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.254%\n",
      "Finished fine tuning.\n",
      "Iteration 1311/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1311\n",
      "\n",
      "Iteration 1312 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 134)]\n",
      "Input: 0.115 MB, Params: 503,747 (1.922 MB), Total: 2.04 MB, FLOPs: 49,553,939\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.831%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.254%\n",
      "Finished fine tuning.\n",
      "Iteration 1312/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1312\n",
      "\n",
      "Iteration 1313 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 77)]\n",
      "Input: 0.115 MB, Params: 502,431 (1.917 MB), Total: 2.03 MB, FLOPs: 49,459,259\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.983%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.407%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.254%\n",
      "Finished fine tuning.\n",
      "Iteration 1313/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1313\n",
      "\n",
      "Iteration 1314 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 61)]\n",
      "Input: 0.115 MB, Params: 501,115 (1.912 MB), Total: 2.03 MB, FLOPs: 49,364,579\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Finished fine tuning.\n",
      "Iteration 1314/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1314\n",
      "\n",
      "Iteration 1315 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 75)]\n",
      "Input: 0.115 MB, Params: 499,895 (1.907 MB), Total: 2.02 MB, FLOPs: 49,342,663\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.831%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Finished fine tuning.\n",
      "Iteration 1315/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1315\n",
      "\n",
      "Iteration 1316 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 131)]\n",
      "Input: 0.115 MB, Params: 498,675 (1.902 MB), Total: 2.02 MB, FLOPs: 49,320,747\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.407%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.559%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Finished fine tuning.\n",
      "Iteration 1316/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1316\n",
      "\n",
      "Iteration 1317 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 83)]\n",
      "Input: 0.115 MB, Params: 496,531 (1.894 MB), Total: 2.01 MB, FLOPs: 49,231,989\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 92.373%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.254%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Finished fine tuning.\n",
      "Iteration 1317/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1317\n",
      "\n",
      "Iteration 1318 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(14, 18)]\n",
      "Input: 0.115 MB, Params: 495,890 (1.892 MB), Total: 2.01 MB, FLOPs: 48,853,333\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.831%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Finished fine tuning.\n",
      "Iteration 1318/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1318\n",
      "\n",
      "Iteration 1319 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 82)]\n",
      "Input: 0.115 MB, Params: 494,583 (1.887 MB), Total: 2.00 MB, FLOPs: 48,759,301\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.254%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.559%\n",
      "Finished fine tuning.\n",
      "Iteration 1319/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1319\n",
      "\n",
      "Iteration 1320 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 32)]\n",
      "Input: 0.115 MB, Params: 493,363 (1.882 MB), Total: 2.00 MB, FLOPs: 48,737,385\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.407%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.983%\n",
      "Finished fine tuning.\n",
      "Iteration 1320/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1320\n",
      "\n",
      "Iteration 1321 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 91)]\n",
      "Input: 0.115 MB, Params: 491,075 (1.873 MB), Total: 1.99 MB, FLOPs: 48,696,219\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.407%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.254%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.407%\n",
      "Finished fine tuning.\n",
      "Iteration 1321/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1321\n",
      "\n",
      "Iteration 1322 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 66)]\n",
      "Input: 0.115 MB, Params: 488,787 (1.865 MB), Total: 1.98 MB, FLOPs: 48,655,053\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.559%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.831%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.983%\n",
      "Finished fine tuning.\n",
      "Iteration 1322/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1322\n",
      "\n",
      "Iteration 1323 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 40)]\n",
      "Input: 0.115 MB, Params: 487,585 (1.860 MB), Total: 1.98 MB, FLOPs: 48,633,461\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.254%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.407%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.136%\n",
      "Finished fine tuning.\n",
      "Iteration 1323/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1323\n",
      "\n",
      "Iteration 1324 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 14)]\n",
      "Input: 0.115 MB, Params: 486,278 (1.855 MB), Total: 1.97 MB, FLOPs: 48,539,429\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.559%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.559%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.559%\n",
      "Finished fine tuning.\n",
      "Iteration 1324/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1324\n",
      "\n",
      "Iteration 1325 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 3)]\n",
      "Input: 0.115 MB, Params: 485,076 (1.850 MB), Total: 1.97 MB, FLOPs: 48,517,837\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.831%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.407%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.559%\n",
      "Finished fine tuning.\n",
      "Iteration 1325/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1325\n",
      "\n",
      "Iteration 1326 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 65)]\n",
      "Input: 0.115 MB, Params: 483,769 (1.845 MB), Total: 1.96 MB, FLOPs: 48,423,805\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.559%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.983%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.407%\n",
      "Finished fine tuning.\n",
      "Iteration 1326/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1326\n",
      "\n",
      "Iteration 1327 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 117)]\n",
      "Input: 0.115 MB, Params: 481,499 (1.837 MB), Total: 1.95 MB, FLOPs: 48,382,963\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.983%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.983%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.407%\n",
      "Finished fine tuning.\n",
      "Iteration 1327/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1327\n",
      "\n",
      "Iteration 1328 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 56)]\n",
      "Input: 0.115 MB, Params: 480,192 (1.832 MB), Total: 1.95 MB, FLOPs: 48,288,931\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.407%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.102%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.831%\n",
      "Finished fine tuning.\n",
      "Iteration 1328/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1328\n",
      "\n",
      "Iteration 1329 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 51)]\n",
      "Input: 0.115 MB, Params: 478,111 (1.824 MB), Total: 1.94 MB, FLOPs: 48,203,251\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.559%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.407%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.136%\n",
      "Finished fine tuning.\n",
      "Iteration 1329/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1329\n",
      "\n",
      "Iteration 1330 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 33)]\n",
      "Input: 0.115 MB, Params: 476,813 (1.819 MB), Total: 1.93 MB, FLOPs: 48,109,867\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.559%\n",
      "Finished fine tuning.\n",
      "Iteration 1330/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1330\n",
      "\n",
      "Iteration 1331 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 23)]\n",
      "Input: 0.115 MB, Params: 475,497 (1.814 MB), Total: 1.93 MB, FLOPs: 47,917,907\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.254%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.407%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.983%\n",
      "Finished fine tuning.\n",
      "Iteration 1331/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1331\n",
      "\n",
      "Iteration 1332 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 18)]\n",
      "Input: 0.115 MB, Params: 474,304 (1.809 MB), Total: 1.92 MB, FLOPs: 47,896,477\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.254%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.407%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.864%\n",
      "Finished fine tuning.\n",
      "Iteration 1332/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1332\n",
      "\n",
      "Iteration 1333 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 129)]\n",
      "Input: 0.115 MB, Params: 472,052 (1.801 MB), Total: 1.92 MB, FLOPs: 47,855,959\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.712%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.864%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.407%\n",
      "Finished fine tuning.\n",
      "Iteration 1333/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1333\n",
      "\n",
      "Iteration 1334 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 71)]\n",
      "Input: 0.115 MB, Params: 470,868 (1.796 MB), Total: 1.91 MB, FLOPs: 47,834,691\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.983%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.288%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.288%\n",
      "Finished fine tuning.\n",
      "Iteration 1334/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1334\n",
      "\n",
      "Iteration 1335 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(14, 14)]\n",
      "Input: 0.115 MB, Params: 470,227 (1.794 MB), Total: 1.91 MB, FLOPs: 47,456,035\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.136%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.559%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.288%\n",
      "Finished fine tuning.\n",
      "Iteration 1335/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1335\n",
      "\n",
      "Iteration 1336 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 76)]\n",
      "Input: 0.115 MB, Params: 468,164 (1.786 MB), Total: 1.90 MB, FLOPs: 47,371,165\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.017%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.136%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.983%\n",
      "Finished fine tuning.\n",
      "Iteration 1336/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1336\n",
      "\n",
      "Iteration 1337 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 136)]\n",
      "Input: 0.115 MB, Params: 466,980 (1.781 MB), Total: 1.90 MB, FLOPs: 47,349,897\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.559%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.288%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.407%\n",
      "Finished fine tuning.\n",
      "Iteration 1337/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1337\n",
      "\n",
      "Iteration 1338 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 152)]\n",
      "Input: 0.115 MB, Params: 465,796 (1.777 MB), Total: 1.89 MB, FLOPs: 47,328,629\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.407%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.136%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.678%\n",
      "Finished fine tuning.\n",
      "Iteration 1338/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1338\n",
      "\n",
      "Iteration 1339 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 24)]\n",
      "Input: 0.115 MB, Params: 465,020 (1.774 MB), Total: 1.89 MB, FLOPs: 47,099,229\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.407%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.831%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.983%\n",
      "Finished fine tuning.\n",
      "Iteration 1339/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1339\n",
      "\n",
      "Iteration 1340 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 38)]\n",
      "Input: 0.115 MB, Params: 463,713 (1.769 MB), Total: 1.88 MB, FLOPs: 46,909,933\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.407%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.525%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.407%\n",
      "Finished fine tuning.\n",
      "Iteration 1340/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1340\n",
      "\n",
      "Iteration 1341 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 101)]\n",
      "Input: 0.115 MB, Params: 462,529 (1.764 MB), Total: 1.88 MB, FLOPs: 46,888,665\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.407%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.983%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.559%\n",
      "Finished fine tuning.\n",
      "Iteration 1341/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1341\n",
      "\n",
      "Iteration 1342 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(14, 17)]\n",
      "Input: 0.115 MB, Params: 461,897 (1.762 MB), Total: 1.88 MB, FLOPs: 46,512,673\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.288%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.831%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.136%\n",
      "Finished fine tuning.\n",
      "Iteration 1342/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1342\n",
      "\n",
      "Iteration 1343 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 94)]\n",
      "Input: 0.115 MB, Params: 460,713 (1.757 MB), Total: 1.87 MB, FLOPs: 46,491,405\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.864%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.407%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.559%\n",
      "Finished fine tuning.\n",
      "Iteration 1343/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1343\n",
      "\n",
      "Iteration 1344 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(14, 25)]\n",
      "Input: 0.115 MB, Params: 460,081 (1.755 MB), Total: 1.87 MB, FLOPs: 46,115,413\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.712%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.136%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.559%\n",
      "Finished fine tuning.\n",
      "Iteration 1344/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1344\n",
      "\n",
      "Iteration 1345 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 104)]\n",
      "Input: 0.115 MB, Params: 457,883 (1.747 MB), Total: 1.86 MB, FLOPs: 46,075,867\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.831%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.407%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.983%\n",
      "Finished fine tuning.\n",
      "Iteration 1345/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1345\n",
      "\n",
      "Iteration 1346 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 20)]\n",
      "Input: 0.115 MB, Params: 456,708 (1.742 MB), Total: 1.86 MB, FLOPs: 46,054,761\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.712%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.559%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.983%\n",
      "Finished fine tuning.\n",
      "Iteration 1346/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1346\n",
      "\n",
      "Iteration 1347 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 24)]\n",
      "Input: 0.115 MB, Params: 454,519 (1.734 MB), Total: 1.85 MB, FLOPs: 46,015,377\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.831%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.559%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.831%\n",
      "Finished fine tuning.\n",
      "Iteration 1347/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1347\n",
      "\n",
      "Iteration 1348 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 4)]\n",
      "Input: 0.115 MB, Params: 453,353 (1.729 MB), Total: 1.84 MB, FLOPs: 45,994,433\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 91.949%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.407%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.136%\n",
      "Finished fine tuning.\n",
      "Iteration 1348/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1348\n",
      "\n",
      "Iteration 1349 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 6)]\n",
      "Input: 0.115 MB, Params: 452,604 (1.727 MB), Total: 1.84 MB, FLOPs: 45,773,025\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.288%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.831%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.136%\n",
      "Finished fine tuning.\n",
      "Iteration 1349/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1349\n",
      "\n",
      "Iteration 1350 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 97)]\n",
      "Input: 0.115 MB, Params: 451,333 (1.722 MB), Total: 1.84 MB, FLOPs: 45,681,585\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.136%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.983%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.983%\n",
      "Finished fine tuning.\n",
      "Iteration 1350/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1350\n",
      "\n",
      "Iteration 1351 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 72)]\n",
      "Input: 0.115 MB, Params: 449,297 (1.714 MB), Total: 1.83 MB, FLOPs: 45,597,687\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.983%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.559%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.441%\n",
      "Finished fine tuning.\n",
      "Iteration 1351/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1351\n",
      "\n",
      "Iteration 1352 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 24)]\n",
      "Input: 0.115 MB, Params: 448,131 (1.709 MB), Total: 1.82 MB, FLOPs: 45,576,743\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.712%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.593%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.136%\n",
      "Finished fine tuning.\n",
      "Iteration 1352/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1352\n",
      "\n",
      "Iteration 1353 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 30)]\n",
      "Input: 0.115 MB, Params: 446,095 (1.702 MB), Total: 1.82 MB, FLOPs: 45,492,845\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.712%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.288%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.559%\n",
      "Finished fine tuning.\n",
      "Iteration 1353/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1353\n",
      "\n",
      "Iteration 1354 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 4)]\n",
      "Input: 0.115 MB, Params: 445,661 (1.700 MB), Total: 1.82 MB, FLOPs: 44,973,245\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.441%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.169%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.441%\n",
      "Finished fine tuning.\n",
      "Iteration 1354/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1354\n",
      "\n",
      "Iteration 1355 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 12)]\n",
      "Input: 0.115 MB, Params: 444,408 (1.695 MB), Total: 1.81 MB, FLOPs: 44,883,101\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.746%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.169%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.288%\n",
      "Finished fine tuning.\n",
      "Iteration 1355/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1355\n",
      "\n",
      "Iteration 1356 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 30)]\n",
      "Input: 0.115 MB, Params: 442,255 (1.687 MB), Total: 1.80 MB, FLOPs: 44,844,365\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.559%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.864%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.288%\n",
      "Finished fine tuning.\n",
      "Iteration 1356/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1356\n",
      "\n",
      "Iteration 1357 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 117)]\n",
      "Input: 0.115 MB, Params: 440,102 (1.679 MB), Total: 1.79 MB, FLOPs: 44,805,629\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.441%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.559%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.441%\n",
      "Finished fine tuning.\n",
      "Iteration 1357/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1357\n",
      "\n",
      "Iteration 1358 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 109)]\n",
      "Input: 0.115 MB, Params: 437,949 (1.671 MB), Total: 1.79 MB, FLOPs: 44,766,893\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.288%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.983%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.407%\n",
      "Finished fine tuning.\n",
      "Iteration 1358/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1358\n",
      "\n",
      "Iteration 1359 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 23)]\n",
      "Input: 0.115 MB, Params: 435,796 (1.662 MB), Total: 1.78 MB, FLOPs: 44,728,157\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.407%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.407%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.559%\n",
      "Finished fine tuning.\n",
      "Iteration 1359/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1359\n",
      "\n",
      "Iteration 1360 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 50)]\n",
      "Input: 0.115 MB, Params: 433,643 (1.654 MB), Total: 1.77 MB, FLOPs: 44,689,421\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.136%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.712%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.136%\n",
      "Finished fine tuning.\n",
      "Iteration 1360/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1360\n",
      "\n",
      "Iteration 1361 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 7)]\n",
      "Input: 0.115 MB, Params: 432,363 (1.649 MB), Total: 1.76 MB, FLOPs: 44,504,085\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.136%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.288%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.288%\n",
      "Finished fine tuning.\n",
      "Iteration 1361/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1361\n",
      "\n",
      "Iteration 1362 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 33)]\n",
      "Input: 0.115 MB, Params: 431,119 (1.645 MB), Total: 1.76 MB, FLOPs: 44,414,589\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.712%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.983%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.559%\n",
      "Finished fine tuning.\n",
      "Iteration 1362/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1362\n",
      "\n",
      "Iteration 1363 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 23)]\n",
      "Input: 0.115 MB, Params: 429,998 (1.640 MB), Total: 1.76 MB, FLOPs: 44,394,455\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.136%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.136%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.559%\n",
      "Finished fine tuning.\n",
      "Iteration 1363/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1363\n",
      "\n",
      "Iteration 1364 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 112)]\n",
      "Input: 0.115 MB, Params: 428,877 (1.636 MB), Total: 1.75 MB, FLOPs: 44,374,321\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.136%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.136%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.983%\n",
      "Finished fine tuning.\n",
      "Iteration 1364/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1364\n",
      "\n",
      "Iteration 1365 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 86)]\n",
      "Input: 0.115 MB, Params: 427,633 (1.631 MB), Total: 1.75 MB, FLOPs: 44,284,825\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.407%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.407%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.712%\n",
      "Finished fine tuning.\n",
      "Iteration 1365/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1365\n",
      "\n",
      "Iteration 1366 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 55)]\n",
      "Input: 0.115 MB, Params: 425,669 (1.624 MB), Total: 1.74 MB, FLOPs: 44,203,681\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.983%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.983%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.559%\n",
      "Finished fine tuning.\n",
      "Iteration 1366/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1366\n",
      "\n",
      "Iteration 1367 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 3)]\n",
      "Input: 0.115 MB, Params: 424,434 (1.619 MB), Total: 1.73 MB, FLOPs: 44,114,833\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.559%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.136%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.712%\n",
      "Finished fine tuning.\n",
      "Iteration 1367/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1367\n",
      "\n",
      "Iteration 1368 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 84)]\n",
      "Input: 0.115 MB, Params: 422,308 (1.611 MB), Total: 1.73 MB, FLOPs: 44,076,583\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.712%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.983%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.983%\n",
      "Finished fine tuning.\n",
      "Iteration 1368/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1368\n",
      "\n",
      "Iteration 1369 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(14, 21)]\n",
      "Input: 0.115 MB, Params: 421,694 (1.609 MB), Total: 1.72 MB, FLOPs: 43,714,055\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.136%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.831%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.559%\n",
      "Finished fine tuning.\n",
      "Iteration 1369/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1369\n",
      "\n",
      "Iteration 1370 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 19)]\n",
      "Input: 0.115 MB, Params: 420,582 (1.604 MB), Total: 1.72 MB, FLOPs: 43,694,083\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.712%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.441%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.136%\n",
      "Finished fine tuning.\n",
      "Iteration 1370/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1370\n",
      "\n",
      "Iteration 1371 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 13)]\n",
      "Input: 0.115 MB, Params: 418,636 (1.597 MB), Total: 1.71 MB, FLOPs: 43,613,749\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.983%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.288%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.593%\n",
      "Finished fine tuning.\n",
      "Iteration 1371/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1371\n",
      "\n",
      "Iteration 1372 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 41)]\n",
      "Input: 0.115 MB, Params: 417,905 (1.594 MB), Total: 1.71 MB, FLOPs: 43,397,669\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.983%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.864%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.136%\n",
      "Finished fine tuning.\n",
      "Iteration 1372/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1372\n",
      "\n",
      "Iteration 1373 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 18)]\n",
      "Input: 0.115 MB, Params: 415,797 (1.586 MB), Total: 1.70 MB, FLOPs: 43,359,743\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.559%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.983%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.407%\n",
      "Finished fine tuning.\n",
      "Iteration 1373/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1373\n",
      "\n",
      "Iteration 1374 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 0)]\n",
      "Input: 0.115 MB, Params: 413,860 (1.579 MB), Total: 1.69 MB, FLOPs: 43,279,571\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.559%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.407%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.983%\n",
      "Finished fine tuning.\n",
      "Iteration 1374/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1374\n",
      "\n",
      "Iteration 1375 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 28)]\n",
      "Input: 0.115 MB, Params: 412,643 (1.574 MB), Total: 1.69 MB, FLOPs: 43,192,019\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.983%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.407%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.559%\n",
      "Finished fine tuning.\n",
      "Iteration 1375/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1375\n",
      "\n",
      "Iteration 1376 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 6)]\n",
      "Input: 0.115 MB, Params: 410,544 (1.566 MB), Total: 1.68 MB, FLOPs: 43,154,255\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.407%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.983%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.136%\n",
      "Finished fine tuning.\n",
      "Iteration 1376/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1376\n",
      "\n",
      "Iteration 1377 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 5)]\n",
      "Input: 0.115 MB, Params: 408,445 (1.558 MB), Total: 1.67 MB, FLOPs: 43,116,491\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.983%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.441%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.288%\n",
      "Finished fine tuning.\n",
      "Iteration 1377/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1377\n",
      "\n",
      "Iteration 1378 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 14)]\n",
      "Input: 0.115 MB, Params: 406,535 (1.551 MB), Total: 1.67 MB, FLOPs: 43,037,291\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.864%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.136%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.559%\n",
      "Finished fine tuning.\n",
      "Iteration 1378/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1378\n",
      "\n",
      "Iteration 1379 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 65)]\n",
      "Input: 0.115 MB, Params: 405,327 (1.546 MB), Total: 1.66 MB, FLOPs: 42,950,387\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.017%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.746%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.712%\n",
      "Finished fine tuning.\n",
      "Iteration 1379/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1379\n",
      "\n",
      "Iteration 1380 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 76)]\n",
      "Input: 0.115 MB, Params: 403,426 (1.539 MB), Total: 1.65 MB, FLOPs: 42,871,835\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.712%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.322%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.169%\n",
      "Finished fine tuning.\n",
      "Iteration 1380/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1380\n",
      "\n",
      "Iteration 1381 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 94)]\n",
      "Input: 0.115 MB, Params: 401,345 (1.531 MB), Total: 1.65 MB, FLOPs: 42,834,395\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.746%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.169%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.746%\n",
      "Finished fine tuning.\n",
      "Iteration 1381/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1381\n",
      "\n",
      "Iteration 1382 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 112)]\n",
      "Input: 0.115 MB, Params: 400,269 (1.527 MB), Total: 1.64 MB, FLOPs: 42,815,071\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.746%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.593%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.593%\n",
      "Finished fine tuning.\n",
      "Iteration 1382/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1382\n",
      "\n",
      "Iteration 1383 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 144)]\n",
      "Input: 0.115 MB, Params: 399,193 (1.523 MB), Total: 1.64 MB, FLOPs: 42,795,747\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.746%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.593%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.746%\n",
      "Finished fine tuning.\n",
      "Iteration 1383/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1383\n",
      "\n",
      "Iteration 1384 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 40)]\n",
      "Input: 0.115 MB, Params: 397,130 (1.515 MB), Total: 1.63 MB, FLOPs: 42,758,631\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.746%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.712%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.017%\n",
      "Finished fine tuning.\n",
      "Iteration 1384/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1384\n",
      "\n",
      "Iteration 1385 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 0)]\n",
      "Input: 0.115 MB, Params: 395,067 (1.507 MB), Total: 1.62 MB, FLOPs: 42,721,515\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.864%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.593%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.593%\n",
      "Finished fine tuning.\n",
      "Iteration 1385/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1385\n",
      "\n",
      "Iteration 1386 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 8)]\n",
      "Input: 0.115 MB, Params: 393,193 (1.500 MB), Total: 1.62 MB, FLOPs: 42,643,449\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.288%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.746%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.017%\n",
      "Finished fine tuning.\n",
      "Iteration 1386/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1386\n",
      "\n",
      "Iteration 1387 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 80)]\n",
      "Input: 0.115 MB, Params: 391,139 (1.492 MB), Total: 1.61 MB, FLOPs: 42,606,495\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.593%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.441%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.593%\n",
      "Finished fine tuning.\n",
      "Iteration 1387/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1387\n",
      "\n",
      "Iteration 1388 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 15)]\n",
      "Input: 0.115 MB, Params: 389,949 (1.488 MB), Total: 1.60 MB, FLOPs: 42,520,887\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.746%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.441%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.288%\n",
      "Finished fine tuning.\n",
      "Iteration 1388/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1388\n",
      "\n",
      "Iteration 1389 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 29)]\n",
      "Input: 0.115 MB, Params: 389,218 (1.485 MB), Total: 1.60 MB, FLOPs: 42,304,807\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.559%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.407%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.136%\n",
      "Finished fine tuning.\n",
      "Iteration 1389/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1389\n",
      "\n",
      "Iteration 1390 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 102)]\n",
      "Input: 0.115 MB, Params: 387,164 (1.477 MB), Total: 1.59 MB, FLOPs: 42,267,853\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.983%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.559%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.864%\n",
      "Finished fine tuning.\n",
      "Iteration 1390/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1390\n",
      "\n",
      "Iteration 1391 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 16)]\n",
      "Input: 0.115 MB, Params: 385,110 (1.469 MB), Total: 1.58 MB, FLOPs: 42,230,899\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.559%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.136%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.864%\n",
      "Finished fine tuning.\n",
      "Iteration 1391/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1391\n",
      "\n",
      "Iteration 1392 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 94)]\n",
      "Input: 0.115 MB, Params: 383,056 (1.461 MB), Total: 1.58 MB, FLOPs: 42,193,945\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.136%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.712%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.288%\n",
      "Finished fine tuning.\n",
      "Iteration 1392/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1392\n",
      "\n",
      "Iteration 1393 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 21)]\n",
      "Input: 0.115 MB, Params: 382,631 (1.460 MB), Total: 1.57 MB, FLOPs: 41,685,145\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.627%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.288%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.288%\n",
      "Finished fine tuning.\n",
      "Iteration 1393/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1393\n",
      "\n",
      "Iteration 1394 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 29)]\n",
      "Input: 0.115 MB, Params: 381,441 (1.455 MB), Total: 1.57 MB, FLOPs: 41,599,537\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.288%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.864%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.017%\n",
      "Finished fine tuning.\n",
      "Iteration 1394/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1394\n",
      "\n",
      "Iteration 1395 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 0)]\n",
      "Input: 0.115 MB, Params: 380,710 (1.452 MB), Total: 1.57 MB, FLOPs: 41,383,457\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.746%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.864%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.441%\n",
      "Finished fine tuning.\n",
      "Iteration 1395/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1395\n",
      "\n",
      "Iteration 1396 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 4)]\n",
      "Input: 0.115 MB, Params: 379,688 (1.448 MB), Total: 1.56 MB, FLOPs: 41,365,105\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.017%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.864%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.017%\n",
      "Finished fine tuning.\n",
      "Iteration 1396/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1396\n",
      "\n",
      "Iteration 1397 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 125)]\n",
      "Input: 0.115 MB, Params: 378,666 (1.444 MB), Total: 1.56 MB, FLOPs: 41,346,753\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.712%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.712%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.593%\n",
      "Finished fine tuning.\n",
      "Iteration 1397/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1397\n",
      "\n",
      "Iteration 1398 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 32)]\n",
      "Input: 0.115 MB, Params: 377,935 (1.442 MB), Total: 1.56 MB, FLOPs: 41,130,673\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.746%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.288%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.712%\n",
      "Finished fine tuning.\n",
      "Iteration 1398/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1398\n",
      "\n",
      "Iteration 1399 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 60)]\n",
      "Input: 0.115 MB, Params: 375,899 (1.434 MB), Total: 1.55 MB, FLOPs: 41,094,043\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.864%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.441%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.288%\n",
      "Finished fine tuning.\n",
      "Iteration 1399/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1399\n",
      "\n",
      "Iteration 1400 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 24)]\n",
      "Input: 0.115 MB, Params: 374,718 (1.429 MB), Total: 1.54 MB, FLOPs: 40,923,899\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.322%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.169%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.288%\n",
      "Finished fine tuning.\n",
      "Iteration 1400/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1400\n",
      "\n",
      "Iteration 1401 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 16)]\n",
      "Input: 0.115 MB, Params: 373,537 (1.425 MB), Total: 1.54 MB, FLOPs: 40,838,939\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.017%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.017%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.017%\n",
      "Finished fine tuning.\n",
      "Iteration 1401/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1401\n",
      "\n",
      "Iteration 1402 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 71)]\n",
      "Input: 0.115 MB, Params: 372,356 (1.420 MB), Total: 1.54 MB, FLOPs: 40,753,979\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.136%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.017%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.441%\n",
      "Finished fine tuning.\n",
      "Iteration 1402/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1402\n",
      "\n",
      "Iteration 1403 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 19)]\n",
      "Input: 0.115 MB, Params: 370,563 (1.414 MB), Total: 1.53 MB, FLOPs: 40,679,315\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.864%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.441%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.441%\n",
      "Finished fine tuning.\n",
      "Iteration 1403/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1403\n",
      "\n",
      "Iteration 1404 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 67)]\n",
      "Input: 0.115 MB, Params: 369,391 (1.409 MB), Total: 1.52 MB, FLOPs: 40,595,003\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.441%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.288%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.864%\n",
      "Finished fine tuning.\n",
      "Iteration 1404/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1404\n",
      "\n",
      "Iteration 1405 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 18)]\n",
      "Input: 0.115 MB, Params: 367,364 (1.401 MB), Total: 1.52 MB, FLOPs: 40,558,535\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.983%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.288%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.712%\n",
      "Finished fine tuning.\n",
      "Iteration 1405/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1405\n",
      "\n",
      "Iteration 1406 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 110)]\n",
      "Input: 0.115 MB, Params: 365,337 (1.394 MB), Total: 1.51 MB, FLOPs: 40,522,067\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.559%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.864%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.712%\n",
      "Finished fine tuning.\n",
      "Iteration 1406/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1406\n",
      "\n",
      "Iteration 1407 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 16)]\n",
      "Input: 0.115 MB, Params: 364,912 (1.392 MB), Total: 1.51 MB, FLOPs: 40,013,267\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.593%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.017%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.288%\n",
      "Finished fine tuning.\n",
      "Iteration 1407/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1407\n",
      "\n",
      "Iteration 1408 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 9)]\n",
      "Input: 0.115 MB, Params: 364,487 (1.390 MB), Total: 1.51 MB, FLOPs: 39,504,467\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.169%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.864%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.593%\n",
      "Finished fine tuning.\n",
      "Iteration 1408/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1408\n",
      "\n",
      "Iteration 1409 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 122)]\n",
      "Input: 0.115 MB, Params: 363,492 (1.387 MB), Total: 1.50 MB, FLOPs: 39,486,601\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.017%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.712%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.864%\n",
      "Finished fine tuning.\n",
      "Iteration 1409/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1409\n",
      "\n",
      "Iteration 1410 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(14, 26)]\n",
      "Input: 0.115 MB, Params: 362,941 (1.385 MB), Total: 1.50 MB, FLOPs: 39,167,129\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.153%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.593%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.169%\n",
      "Finished fine tuning.\n",
      "Iteration 1410/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1410\n",
      "\n",
      "Iteration 1411 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 33)]\n",
      "Input: 0.115 MB, Params: 361,787 (1.380 MB), Total: 1.50 MB, FLOPs: 38,998,929\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.441%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.983%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.559%\n",
      "Finished fine tuning.\n",
      "Iteration 1411/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1411\n",
      "\n",
      "Iteration 1412 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 101)]\n",
      "Input: 0.115 MB, Params: 359,769 (1.372 MB), Total: 1.49 MB, FLOPs: 38,962,623\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.983%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.136%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.712%\n",
      "Finished fine tuning.\n",
      "Iteration 1412/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1412\n",
      "\n",
      "Iteration 1413 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(14, 7)]\n",
      "Input: 0.115 MB, Params: 359,218 (1.370 MB), Total: 1.49 MB, FLOPs: 38,643,151\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.983%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.983%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.136%\n",
      "Finished fine tuning.\n",
      "Iteration 1413/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1413\n",
      "\n",
      "Iteration 1414 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 88)]\n",
      "Input: 0.115 MB, Params: 357,200 (1.363 MB), Total: 1.48 MB, FLOPs: 38,606,845\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.864%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.712%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.288%\n",
      "Finished fine tuning.\n",
      "Iteration 1414/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1414\n",
      "\n",
      "Iteration 1415 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 54)]\n",
      "Input: 0.115 MB, Params: 356,223 (1.359 MB), Total: 1.47 MB, FLOPs: 38,589,303\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.559%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.288%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.559%\n",
      "Finished fine tuning.\n",
      "Iteration 1415/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1415\n",
      "\n",
      "Iteration 1416 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(7, 7)]\n",
      "Input: 0.115 MB, Params: 356,041 (1.358 MB), Total: 1.47 MB, FLOPs: 38,330,983\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.559%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.254%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.983%\n",
      "Finished fine tuning.\n",
      "Iteration 1416/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1416\n",
      "\n",
      "Iteration 1417 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 12)]\n",
      "Input: 0.115 MB, Params: 355,064 (1.354 MB), Total: 1.47 MB, FLOPs: 38,313,441\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.136%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.831%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.831%\n",
      "Finished fine tuning.\n",
      "Iteration 1417/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1417\n",
      "\n",
      "Iteration 1418 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 68)]\n",
      "Input: 0.115 MB, Params: 353,316 (1.348 MB), Total: 1.46 MB, FLOPs: 38,240,073\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.136%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.407%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.559%\n",
      "Finished fine tuning.\n",
      "Iteration 1418/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1418\n",
      "\n",
      "Iteration 1419 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 18)]\n",
      "Input: 0.115 MB, Params: 351,568 (1.341 MB), Total: 1.46 MB, FLOPs: 38,166,705\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.559%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.831%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.831%\n",
      "Finished fine tuning.\n",
      "Iteration 1419/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1419\n",
      "\n",
      "Iteration 1420 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 78)]\n",
      "Input: 0.115 MB, Params: 350,423 (1.337 MB), Total: 1.45 MB, FLOPs: 38,084,337\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.983%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.983%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.831%\n",
      "Finished fine tuning.\n",
      "Iteration 1420/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1420\n",
      "\n",
      "Iteration 1421 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 18)]\n",
      "Input: 0.115 MB, Params: 349,728 (1.334 MB), Total: 1.45 MB, FLOPs: 37,878,913\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.831%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.831%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.559%\n",
      "Finished fine tuning.\n",
      "Iteration 1421/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1421\n",
      "\n",
      "Iteration 1422 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 9)]\n",
      "Input: 0.115 MB, Params: 348,751 (1.330 MB), Total: 1.45 MB, FLOPs: 37,861,371\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.407%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.831%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 90.254%\n",
      "Finished fine tuning.\n",
      "Iteration 1422/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1422\n",
      "\n",
      "Iteration 1423 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 1)]\n",
      "Input: 0.115 MB, Params: 348,056 (1.328 MB), Total: 1.44 MB, FLOPs: 37,655,947\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.407%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.983%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.407%\n",
      "Finished fine tuning.\n",
      "Iteration 1423/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1423\n",
      "\n",
      "Iteration 1424 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 15)]\n",
      "Input: 0.115 MB, Params: 346,083 (1.320 MB), Total: 1.44 MB, FLOPs: 37,620,451\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.983%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.983%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.407%\n",
      "Finished fine tuning.\n",
      "Iteration 1424/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1424\n",
      "\n",
      "Iteration 1425 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 52)]\n",
      "Input: 0.115 MB, Params: 344,110 (1.313 MB), Total: 1.43 MB, FLOPs: 37,584,955\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.407%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.407%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.559%\n",
      "Finished fine tuning.\n",
      "Iteration 1425/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1425\n",
      "\n",
      "Iteration 1426 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 27)]\n",
      "Input: 0.115 MB, Params: 342,137 (1.305 MB), Total: 1.42 MB, FLOPs: 37,549,459\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.136%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.136%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.407%\n",
      "Finished fine tuning.\n",
      "Iteration 1426/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1426\n",
      "\n",
      "Iteration 1427 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 94)]\n",
      "Input: 0.115 MB, Params: 340,164 (1.298 MB), Total: 1.41 MB, FLOPs: 37,513,963\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.559%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.559%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.983%\n",
      "Finished fine tuning.\n",
      "Iteration 1427/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1427\n",
      "\n",
      "Iteration 1428 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 57)]\n",
      "Input: 0.115 MB, Params: 339,019 (1.293 MB), Total: 1.41 MB, FLOPs: 37,431,595\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.983%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.983%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.136%\n",
      "Finished fine tuning.\n",
      "Iteration 1428/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1428\n",
      "\n",
      "Iteration 1429 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 48)]\n",
      "Input: 0.115 MB, Params: 337,046 (1.286 MB), Total: 1.40 MB, FLOPs: 37,396,099\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 89.407%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.559%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.559%\n",
      "Finished fine tuning.\n",
      "Iteration 1429/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1429\n",
      "\n",
      "Iteration 1430 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(0, 1)]\n",
      "Input: 0.115 MB, Params: 336,875 (1.285 MB), Total: 1.40 MB, FLOPs: 36,036,529\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.441%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.593%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.169%\n",
      "Finished fine tuning.\n",
      "Iteration 1430/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1430\n",
      "\n",
      "Iteration 1431 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 12)]\n",
      "Input: 0.115 MB, Params: 336,477 (1.284 MB), Total: 1.40 MB, FLOPs: 35,560,129\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.746%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.017%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.441%\n",
      "Finished fine tuning.\n",
      "Iteration 1431/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1431\n",
      "\n",
      "Iteration 1432 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 10)]\n",
      "Input: 0.115 MB, Params: 335,332 (1.279 MB), Total: 1.39 MB, FLOPs: 35,477,761\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.746%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.593%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.593%\n",
      "Finished fine tuning.\n",
      "Iteration 1432/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1432\n",
      "\n",
      "Iteration 1433 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 12)]\n",
      "Input: 0.115 MB, Params: 334,934 (1.278 MB), Total: 1.39 MB, FLOPs: 35,001,361\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.051%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.746%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.169%\n",
      "Finished fine tuning.\n",
      "Iteration 1433/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1433\n",
      "\n",
      "Iteration 1434 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 57)]\n",
      "Input: 0.115 MB, Params: 332,961 (1.270 MB), Total: 1.39 MB, FLOPs: 34,965,865\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.475%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.593%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.746%\n",
      "Finished fine tuning.\n",
      "Iteration 1434/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1434\n",
      "\n",
      "Iteration 1435 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(14, 18)]\n",
      "Input: 0.115 MB, Params: 332,446 (1.268 MB), Total: 1.38 MB, FLOPs: 34,673,321\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.017%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.898%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.322%\n",
      "Finished fine tuning.\n",
      "Iteration 1435/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1435\n",
      "\n",
      "Iteration 1436 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 78)]\n",
      "Input: 0.115 MB, Params: 330,779 (1.262 MB), Total: 1.38 MB, FLOPs: 34,602,869\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.169%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.475%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.322%\n",
      "Finished fine tuning.\n",
      "Iteration 1436/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1436\n",
      "\n",
      "Iteration 1437 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 1)]\n",
      "Input: 0.115 MB, Params: 329,112 (1.255 MB), Total: 1.37 MB, FLOPs: 34,532,417\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.746%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.322%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.746%\n",
      "Finished fine tuning.\n",
      "Iteration 1437/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1437\n",
      "\n",
      "Iteration 1438 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 14)]\n",
      "Input: 0.115 MB, Params: 328,723 (1.254 MB), Total: 1.37 MB, FLOPs: 34,066,817\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.288%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.746%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.475%\n",
      "Finished fine tuning.\n",
      "Iteration 1438/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1438\n",
      "\n",
      "Iteration 1439 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 80)]\n",
      "Input: 0.115 MB, Params: 327,800 (1.250 MB), Total: 1.37 MB, FLOPs: 34,050,247\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.017%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.746%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.051%\n",
      "Finished fine tuning.\n",
      "Iteration 1439/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1439\n",
      "\n",
      "Iteration 1440 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 122)]\n",
      "Input: 0.115 MB, Params: 326,877 (1.247 MB), Total: 1.36 MB, FLOPs: 34,033,677\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.475%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.017%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.627%\n",
      "Finished fine tuning.\n",
      "Iteration 1440/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1440\n",
      "\n",
      "Iteration 1441 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 51)]\n",
      "Input: 0.115 MB, Params: 324,940 (1.240 MB), Total: 1.35 MB, FLOPs: 33,998,829\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.017%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.017%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.712%\n",
      "Finished fine tuning.\n",
      "Iteration 1441/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1441\n",
      "\n",
      "Iteration 1442 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 28)]\n",
      "Input: 0.115 MB, Params: 323,003 (1.232 MB), Total: 1.35 MB, FLOPs: 33,963,981\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.169%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.169%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.169%\n",
      "Finished fine tuning.\n",
      "Iteration 1442/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1442\n",
      "\n",
      "Iteration 1443 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 33)]\n",
      "Input: 0.115 MB, Params: 321,876 (1.228 MB), Total: 1.34 MB, FLOPs: 33,882,909\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.169%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.746%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.746%\n",
      "Finished fine tuning.\n",
      "Iteration 1443/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1443\n",
      "\n",
      "Iteration 1444 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 3)]\n",
      "Input: 0.115 MB, Params: 320,236 (1.222 MB), Total: 1.34 MB, FLOPs: 33,813,429\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.136%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.288%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.017%\n",
      "Finished fine tuning.\n",
      "Iteration 1444/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1444\n",
      "\n",
      "Iteration 1445 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 20)]\n",
      "Input: 0.115 MB, Params: 319,136 (1.217 MB), Total: 1.33 MB, FLOPs: 33,653,149\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.593%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.017%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.017%\n",
      "Finished fine tuning.\n",
      "Iteration 1445/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1445\n",
      "\n",
      "Iteration 1446 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 12)]\n",
      "Input: 0.115 MB, Params: 318,036 (1.213 MB), Total: 1.33 MB, FLOPs: 33,492,869\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.441%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.288%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.864%\n",
      "Finished fine tuning.\n",
      "Iteration 1446/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1446\n",
      "\n",
      "Iteration 1447 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 30)]\n",
      "Input: 0.115 MB, Params: 316,936 (1.209 MB), Total: 1.32 MB, FLOPs: 33,413,741\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.441%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.441%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.593%\n",
      "Finished fine tuning.\n",
      "Iteration 1447/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1447\n",
      "\n",
      "Iteration 1448 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 74)]\n",
      "Input: 0.115 MB, Params: 316,031 (1.206 MB), Total: 1.32 MB, FLOPs: 33,397,495\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.593%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.864%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.017%\n",
      "Finished fine tuning.\n",
      "Iteration 1448/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1448\n",
      "\n",
      "Iteration 1449 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 33)]\n",
      "Input: 0.115 MB, Params: 314,400 (1.199 MB), Total: 1.31 MB, FLOPs: 33,328,663\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.712%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.169%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.864%\n",
      "Finished fine tuning.\n",
      "Iteration 1449/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1449\n",
      "\n",
      "Iteration 1450 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 16)]\n",
      "Input: 0.115 MB, Params: 313,309 (1.195 MB), Total: 1.31 MB, FLOPs: 33,250,183\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.017%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.441%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.864%\n",
      "Finished fine tuning.\n",
      "Iteration 1450/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1450\n",
      "\n",
      "Iteration 1451 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 63)]\n",
      "Input: 0.115 MB, Params: 311,399 (1.188 MB), Total: 1.30 MB, FLOPs: 33,215,821\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.017%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.441%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.593%\n",
      "Finished fine tuning.\n",
      "Iteration 1451/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1451\n",
      "\n",
      "Iteration 1452 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 88)]\n",
      "Input: 0.115 MB, Params: 309,489 (1.181 MB), Total: 1.30 MB, FLOPs: 33,181,459\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.136%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.712%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.288%\n",
      "Finished fine tuning.\n",
      "Iteration 1452/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1452\n",
      "\n",
      "Iteration 1453 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 12)]\n",
      "Input: 0.115 MB, Params: 308,407 (1.176 MB), Total: 1.29 MB, FLOPs: 33,022,475\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.017%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.864%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.864%\n",
      "Finished fine tuning.\n",
      "Iteration 1453/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1453\n",
      "\n",
      "Iteration 1454 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 43)]\n",
      "Input: 0.115 MB, Params: 306,803 (1.170 MB), Total: 1.29 MB, FLOPs: 32,954,615\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.864%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.017%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.017%\n",
      "Finished fine tuning.\n",
      "Iteration 1454/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1454\n",
      "\n",
      "Iteration 1455 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 36)]\n",
      "Input: 0.115 MB, Params: 305,721 (1.166 MB), Total: 1.28 MB, FLOPs: 32,795,631\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.593%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.017%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.288%\n",
      "Finished fine tuning.\n",
      "Iteration 1455/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1455\n",
      "\n",
      "Iteration 1456 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 22)]\n",
      "Input: 0.115 MB, Params: 304,834 (1.163 MB), Total: 1.28 MB, FLOPs: 32,779,709\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.593%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.864%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.593%\n",
      "Finished fine tuning.\n",
      "Iteration 1456/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1456\n",
      "\n",
      "Iteration 1457 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 109)]\n",
      "Input: 0.115 MB, Params: 303,947 (1.159 MB), Total: 1.27 MB, FLOPs: 32,763,787\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.441%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.441%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.288%\n",
      "Finished fine tuning.\n",
      "Iteration 1457/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1457\n",
      "\n",
      "Iteration 1458 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 30)]\n",
      "Input: 0.115 MB, Params: 302,865 (1.155 MB), Total: 1.27 MB, FLOPs: 32,604,803\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.627%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.017%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.712%\n",
      "Finished fine tuning.\n",
      "Iteration 1458/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1458\n",
      "\n",
      "Iteration 1459 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 0)]\n",
      "Input: 0.115 MB, Params: 301,261 (1.149 MB), Total: 1.26 MB, FLOPs: 32,536,943\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.288%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.864%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.864%\n",
      "Finished fine tuning.\n",
      "Iteration 1459/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1459\n",
      "\n",
      "Iteration 1460 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 57)]\n",
      "Input: 0.115 MB, Params: 299,387 (1.142 MB), Total: 1.26 MB, FLOPs: 32,503,229\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.864%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.864%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.864%\n",
      "Finished fine tuning.\n",
      "Iteration 1460/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1460\n",
      "\n",
      "Iteration 1461 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(14, 21)]\n",
      "Input: 0.115 MB, Params: 298,881 (1.140 MB), Total: 1.26 MB, FLOPs: 32,221,485\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.712%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.017%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.169%\n",
      "Finished fine tuning.\n",
      "Iteration 1461/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1461\n",
      "\n",
      "Iteration 1462 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 30)]\n",
      "Input: 0.115 MB, Params: 298,003 (1.137 MB), Total: 1.25 MB, FLOPs: 32,205,725\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.169%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.593%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.169%\n",
      "Finished fine tuning.\n",
      "Iteration 1462/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1462\n",
      "\n",
      "Iteration 1463 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 15)]\n",
      "Input: 0.115 MB, Params: 296,957 (1.133 MB), Total: 1.25 MB, FLOPs: 32,130,485\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.864%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.864%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.288%\n",
      "Finished fine tuning.\n",
      "Iteration 1463/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1463\n",
      "\n",
      "Iteration 1464 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 36)]\n",
      "Input: 0.115 MB, Params: 295,911 (1.129 MB), Total: 1.24 MB, FLOPs: 32,055,245\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.593%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.864%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.864%\n",
      "Finished fine tuning.\n",
      "Iteration 1464/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1464\n",
      "\n",
      "Iteration 1465 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 47)]\n",
      "Input: 0.115 MB, Params: 294,046 (1.122 MB), Total: 1.24 MB, FLOPs: 32,021,693\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.864%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.169%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.441%\n",
      "Finished fine tuning.\n",
      "Iteration 1465/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1465\n",
      "\n",
      "Iteration 1466 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 67)]\n",
      "Input: 0.115 MB, Params: 292,478 (1.116 MB), Total: 1.23 MB, FLOPs: 31,955,453\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.136%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.441%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.169%\n",
      "Finished fine tuning.\n",
      "Iteration 1466/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1466\n",
      "\n",
      "Iteration 1467 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 56)]\n",
      "Input: 0.115 MB, Params: 290,622 (1.109 MB), Total: 1.22 MB, FLOPs: 31,922,063\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.322%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.746%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.593%\n",
      "Finished fine tuning.\n",
      "Iteration 1467/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1467\n",
      "\n",
      "Iteration 1468 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 29)]\n",
      "Input: 0.115 MB, Params: 289,585 (1.105 MB), Total: 1.22 MB, FLOPs: 31,847,471\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.169%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.441%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.593%\n",
      "Finished fine tuning.\n",
      "Iteration 1468/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1468\n",
      "\n",
      "Iteration 1469 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 41)]\n",
      "Input: 0.115 MB, Params: 287,729 (1.098 MB), Total: 1.21 MB, FLOPs: 31,814,081\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.441%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.288%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.593%\n",
      "Finished fine tuning.\n",
      "Iteration 1469/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1469\n",
      "\n",
      "Iteration 1470 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 49)]\n",
      "Input: 0.115 MB, Params: 285,873 (1.091 MB), Total: 1.21 MB, FLOPs: 31,780,691\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.593%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.169%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.864%\n",
      "Finished fine tuning.\n",
      "Iteration 1470/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1470\n",
      "\n",
      "Iteration 1471 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 11)]\n",
      "Input: 0.115 MB, Params: 285,493 (1.089 MB), Total: 1.20 MB, FLOPs: 31,325,891\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 75.424%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.119%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.780%\n",
      "Finished fine tuning.\n",
      "Iteration 1471/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1471\n",
      "\n",
      "Iteration 1472 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 87)]\n",
      "Input: 0.115 MB, Params: 283,637 (1.082 MB), Total: 1.20 MB, FLOPs: 31,292,501\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.356%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.508%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.780%\n",
      "Finished fine tuning.\n",
      "Iteration 1472/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1472\n",
      "\n",
      "Iteration 1473 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 39)]\n",
      "Input: 0.115 MB, Params: 281,781 (1.075 MB), Total: 1.19 MB, FLOPs: 31,259,111\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.203%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.475%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.898%\n",
      "Finished fine tuning.\n",
      "Iteration 1473/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1473\n",
      "\n",
      "Iteration 1474 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 91)]\n",
      "Input: 0.115 MB, Params: 280,957 (1.072 MB), Total: 1.19 MB, FLOPs: 31,244,323\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.898%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.356%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.898%\n",
      "Finished fine tuning.\n",
      "Iteration 1474/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1474\n",
      "\n",
      "Iteration 1475 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 54)]\n",
      "Input: 0.115 MB, Params: 280,133 (1.069 MB), Total: 1.18 MB, FLOPs: 31,229,535\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.898%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.322%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.322%\n",
      "Finished fine tuning.\n",
      "Iteration 1475/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1475\n",
      "\n",
      "Iteration 1476 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 42)]\n",
      "Input: 0.115 MB, Params: 278,295 (1.062 MB), Total: 1.18 MB, FLOPs: 31,196,469\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.169%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.322%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.322%\n",
      "Finished fine tuning.\n",
      "Iteration 1476/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1476\n",
      "\n",
      "Iteration 1477 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 37)]\n",
      "Input: 0.115 MB, Params: 276,457 (1.055 MB), Total: 1.17 MB, FLOPs: 31,163,403\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.475%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.322%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.475%\n",
      "Finished fine tuning.\n",
      "Iteration 1477/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1477\n",
      "\n",
      "Iteration 1478 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 51)]\n",
      "Input: 0.115 MB, Params: 275,651 (1.052 MB), Total: 1.17 MB, FLOPs: 31,148,939\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.780%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.627%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.475%\n",
      "Finished fine tuning.\n",
      "Iteration 1478/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1478\n",
      "\n",
      "Iteration 1479 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 15)]\n",
      "Input: 0.115 MB, Params: 274,845 (1.048 MB), Total: 1.16 MB, FLOPs: 31,134,475\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.051%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.898%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.898%\n",
      "Finished fine tuning.\n",
      "Iteration 1479/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1479\n",
      "\n",
      "Iteration 1480 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 5)]\n",
      "Input: 0.115 MB, Params: 274,465 (1.047 MB), Total: 1.16 MB, FLOPs: 30,679,675\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.508%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.475%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.169%\n",
      "Finished fine tuning.\n",
      "Iteration 1480/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1480\n",
      "\n",
      "Iteration 1481 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 1)]\n",
      "Input: 0.115 MB, Params: 273,833 (1.045 MB), Total: 1.16 MB, FLOPs: 30,492,899\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.085%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.051%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.593%\n",
      "Finished fine tuning.\n",
      "Iteration 1481/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1481\n",
      "\n",
      "Iteration 1482 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 7)]\n",
      "Input: 0.115 MB, Params: 272,337 (1.039 MB), Total: 1.15 MB, FLOPs: 30,428,441\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.441%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.627%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.475%\n",
      "Finished fine tuning.\n",
      "Iteration 1482/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1482\n",
      "\n",
      "Iteration 1483 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(14, 9)]\n",
      "Input: 0.115 MB, Params: 271,858 (1.037 MB), Total: 1.15 MB, FLOPs: 30,170,961\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.169%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.051%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.898%\n",
      "Finished fine tuning.\n",
      "Iteration 1483/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1483\n",
      "\n",
      "Iteration 1484 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(14, 3)]\n",
      "Input: 0.115 MB, Params: 271,379 (1.035 MB), Total: 1.15 MB, FLOPs: 29,913,481\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.898%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.203%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.898%\n",
      "Finished fine tuning.\n",
      "Iteration 1484/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1484\n",
      "\n",
      "Iteration 1485 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 53)]\n",
      "Input: 0.115 MB, Params: 270,573 (1.032 MB), Total: 1.15 MB, FLOPs: 29,899,017\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.898%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.475%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.203%\n",
      "Finished fine tuning.\n",
      "Iteration 1485/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1485\n",
      "\n",
      "Iteration 1486 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 12)]\n",
      "Input: 0.115 MB, Params: 269,077 (1.026 MB), Total: 1.14 MB, FLOPs: 29,834,559\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.898%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.898%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.746%\n",
      "Finished fine tuning.\n",
      "Iteration 1486/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1486\n",
      "\n",
      "Iteration 1487 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 38)]\n",
      "Input: 0.115 MB, Params: 268,058 (1.023 MB), Total: 1.14 MB, FLOPs: 29,761,263\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.203%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.051%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.475%\n",
      "Finished fine tuning.\n",
      "Iteration 1487/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1487\n",
      "\n",
      "Iteration 1488 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 80)]\n",
      "Input: 0.115 MB, Params: 266,265 (1.016 MB), Total: 1.13 MB, FLOPs: 29,729,007\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.051%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.475%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.322%\n",
      "Finished fine tuning.\n",
      "Iteration 1488/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1488\n",
      "\n",
      "Iteration 1489 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 6)]\n",
      "Input: 0.115 MB, Params: 264,787 (1.010 MB), Total: 1.13 MB, FLOPs: 29,665,359\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.051%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.203%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.051%\n",
      "Finished fine tuning.\n",
      "Iteration 1489/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1489\n",
      "\n",
      "Iteration 1490 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 5)]\n",
      "Input: 0.115 MB, Params: 263,990 (1.007 MB), Total: 1.12 MB, FLOPs: 29,651,057\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.203%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.898%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.169%\n",
      "Finished fine tuning.\n",
      "Iteration 1490/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1490\n",
      "\n",
      "Iteration 1491 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 19)]\n",
      "Input: 0.115 MB, Params: 262,980 (1.003 MB), Total: 1.12 MB, FLOPs: 29,578,409\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.322%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.051%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.746%\n",
      "Finished fine tuning.\n",
      "Iteration 1491/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1491\n",
      "\n",
      "Iteration 1492 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 122)]\n",
      "Input: 0.115 MB, Params: 262,183 (1.000 MB), Total: 1.12 MB, FLOPs: 29,564,107\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.051%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.051%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.898%\n",
      "Finished fine tuning.\n",
      "Iteration 1492/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1492\n",
      "\n",
      "Iteration 1493 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 14)]\n",
      "Input: 0.115 MB, Params: 260,714 (0.995 MB), Total: 1.11 MB, FLOPs: 29,501,107\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.203%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.322%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.627%\n",
      "Finished fine tuning.\n",
      "Iteration 1493/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1493\n",
      "\n",
      "Iteration 1494 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 57)]\n",
      "Input: 0.115 MB, Params: 259,917 (0.992 MB), Total: 1.11 MB, FLOPs: 29,486,805\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.322%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.627%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.475%\n",
      "Finished fine tuning.\n",
      "Iteration 1494/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1494\n",
      "\n",
      "Iteration 1495 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 2)]\n",
      "Input: 0.115 MB, Params: 258,448 (0.986 MB), Total: 1.10 MB, FLOPs: 29,423,805\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.627%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.475%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.898%\n",
      "Finished fine tuning.\n",
      "Iteration 1495/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1495\n",
      "\n",
      "Iteration 1496 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 3)]\n",
      "Input: 0.115 MB, Params: 257,834 (0.984 MB), Total: 1.10 MB, FLOPs: 29,242,357\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.203%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.627%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.051%\n",
      "Finished fine tuning.\n",
      "Iteration 1496/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1496\n",
      "\n",
      "Iteration 1497 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 13)]\n",
      "Input: 0.115 MB, Params: 257,037 (0.981 MB), Total: 1.10 MB, FLOPs: 29,228,055\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.356%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.051%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.898%\n",
      "Finished fine tuning.\n",
      "Iteration 1497/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1497\n",
      "\n",
      "Iteration 1498 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 81)]\n",
      "Input: 0.115 MB, Params: 256,240 (0.977 MB), Total: 1.09 MB, FLOPs: 29,213,753\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.169%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.051%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.898%\n",
      "Finished fine tuning.\n",
      "Iteration 1498/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1498\n",
      "\n",
      "Iteration 1499 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 36)]\n",
      "Input: 0.115 MB, Params: 255,626 (0.975 MB), Total: 1.09 MB, FLOPs: 29,032,305\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.746%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.898%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.322%\n",
      "Finished fine tuning.\n",
      "Iteration 1499/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1499\n",
      "\n",
      "Iteration 1500 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 53)]\n",
      "Input: 0.115 MB, Params: 253,905 (0.969 MB), Total: 1.08 MB, FLOPs: 29,001,345\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.475%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.475%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.475%\n",
      "Finished fine tuning.\n",
      "Iteration 1500/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1500\n",
      "\n",
      "Iteration 1501 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 5)]\n",
      "Input: 0.115 MB, Params: 252,445 (0.963 MB), Total: 1.08 MB, FLOPs: 28,938,507\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.169%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.627%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.898%\n",
      "Finished fine tuning.\n",
      "Iteration 1501/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1501\n",
      "\n",
      "Iteration 1502 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 60)]\n",
      "Input: 0.115 MB, Params: 250,985 (0.957 MB), Total: 1.07 MB, FLOPs: 28,875,669\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.203%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.746%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.475%\n",
      "Finished fine tuning.\n",
      "Iteration 1502/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1502\n",
      "\n",
      "Iteration 1503 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 9)]\n",
      "Input: 0.115 MB, Params: 250,197 (0.954 MB), Total: 1.07 MB, FLOPs: 28,861,529\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.475%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.898%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.898%\n",
      "Finished fine tuning.\n",
      "Iteration 1503/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1503\n",
      "\n",
      "Iteration 1504 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(14, 19)]\n",
      "Input: 0.115 MB, Params: 249,736 (0.953 MB), Total: 1.07 MB, FLOPs: 28,609,377\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.729%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.356%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.898%\n",
      "Finished fine tuning.\n",
      "Iteration 1504/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1504\n",
      "\n",
      "Iteration 1505 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 32)]\n",
      "Input: 0.115 MB, Params: 249,131 (0.950 MB), Total: 1.07 MB, FLOPs: 28,430,593\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.051%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.085%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.932%\n",
      "Finished fine tuning.\n",
      "Iteration 1505/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1505\n",
      "\n",
      "Iteration 1506 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 37)]\n",
      "Input: 0.115 MB, Params: 247,671 (0.945 MB), Total: 1.06 MB, FLOPs: 28,367,755\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.356%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.356%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.508%\n",
      "Finished fine tuning.\n",
      "Iteration 1506/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1506\n",
      "\n",
      "Iteration 1507 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 35)]\n",
      "Input: 0.115 MB, Params: 246,883 (0.942 MB), Total: 1.06 MB, FLOPs: 28,353,615\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.508%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.051%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.661%\n",
      "Finished fine tuning.\n",
      "Iteration 1507/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1507\n",
      "\n",
      "Iteration 1508 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 14)]\n",
      "Input: 0.115 MB, Params: 246,278 (0.939 MB), Total: 1.05 MB, FLOPs: 28,174,831\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.475%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.085%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.508%\n",
      "Finished fine tuning.\n",
      "Iteration 1508/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1508\n",
      "\n",
      "Iteration 1509 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 96)]\n",
      "Input: 0.115 MB, Params: 245,490 (0.936 MB), Total: 1.05 MB, FLOPs: 28,160,691\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.356%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.780%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.627%\n",
      "Finished fine tuning.\n",
      "Iteration 1509/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1509\n",
      "\n",
      "Iteration 1510 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 65)]\n",
      "Input: 0.115 MB, Params: 244,525 (0.933 MB), Total: 1.05 MB, FLOPs: 28,091,283\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.237%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.356%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.898%\n",
      "Finished fine tuning.\n",
      "Iteration 1510/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1510\n",
      "\n",
      "Iteration 1511 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 47)]\n",
      "Input: 0.115 MB, Params: 242,858 (0.926 MB), Total: 1.04 MB, FLOPs: 28,061,295\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.475%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.746%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.322%\n",
      "Finished fine tuning.\n",
      "Iteration 1511/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1511\n",
      "\n",
      "Iteration 1512 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 41)]\n",
      "Input: 0.115 MB, Params: 241,893 (0.923 MB), Total: 1.04 MB, FLOPs: 27,991,887\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.627%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.322%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.475%\n",
      "Finished fine tuning.\n",
      "Iteration 1512/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1512\n",
      "\n",
      "Iteration 1513 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 4)]\n",
      "Input: 0.115 MB, Params: 240,928 (0.919 MB), Total: 1.03 MB, FLOPs: 27,922,479\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.475%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.898%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.746%\n",
      "Finished fine tuning.\n",
      "Iteration 1513/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1513\n",
      "\n",
      "Iteration 1514 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 1)]\n",
      "Input: 0.115 MB, Params: 240,575 (0.918 MB), Total: 1.03 MB, FLOPs: 27,500,079\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.322%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.475%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.898%\n",
      "Finished fine tuning.\n",
      "Iteration 1514/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1514\n",
      "\n",
      "Iteration 1515 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 32)]\n",
      "Input: 0.115 MB, Params: 239,610 (0.914 MB), Total: 1.03 MB, FLOPs: 27,430,671\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.746%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.322%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.017%\n",
      "Finished fine tuning.\n",
      "Iteration 1515/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1515\n",
      "\n",
      "Iteration 1516 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 20)]\n",
      "Input: 0.115 MB, Params: 238,831 (0.911 MB), Total: 1.03 MB, FLOPs: 27,416,693\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.169%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.475%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.203%\n",
      "Finished fine tuning.\n",
      "Iteration 1516/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1516\n",
      "\n",
      "Iteration 1517 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 71)]\n",
      "Input: 0.115 MB, Params: 238,052 (0.908 MB), Total: 1.02 MB, FLOPs: 27,402,715\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.746%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.898%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.356%\n",
      "Finished fine tuning.\n",
      "Iteration 1517/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1517\n",
      "\n",
      "Iteration 1518 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(14, 16)]\n",
      "Input: 0.115 MB, Params: 237,618 (0.906 MB), Total: 1.02 MB, FLOPs: 27,166,691\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.068%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.169%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.169%\n",
      "Finished fine tuning.\n",
      "Iteration 1518/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1518\n",
      "\n",
      "Iteration 1519 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 43)]\n",
      "Input: 0.115 MB, Params: 235,969 (0.900 MB), Total: 1.02 MB, FLOPs: 27,137,027\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.898%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.475%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.746%\n",
      "Finished fine tuning.\n",
      "Iteration 1519/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1519\n",
      "\n",
      "Iteration 1520 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 44)]\n",
      "Input: 0.115 MB, Params: 235,199 (0.897 MB), Total: 1.01 MB, FLOPs: 27,123,211\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.169%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.898%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.746%\n",
      "Finished fine tuning.\n",
      "Iteration 1520/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1520\n",
      "\n",
      "Iteration 1521 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 15)]\n",
      "Input: 0.115 MB, Params: 234,429 (0.894 MB), Total: 1.01 MB, FLOPs: 27,109,395\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.169%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.593%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.898%\n",
      "Finished fine tuning.\n",
      "Iteration 1521/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1521\n",
      "\n",
      "Iteration 1522 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 11)]\n",
      "Input: 0.115 MB, Params: 232,798 (0.888 MB), Total: 1.00 MB, FLOPs: 27,080,055\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.322%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.169%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.441%\n",
      "Finished fine tuning.\n",
      "Iteration 1522/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1522\n",
      "\n",
      "Iteration 1523 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 18)]\n",
      "Input: 0.115 MB, Params: 231,842 (0.884 MB), Total: 1.00 MB, FLOPs: 26,940,223\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.746%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.017%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.898%\n",
      "Finished fine tuning.\n",
      "Iteration 1523/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1523\n",
      "\n",
      "Iteration 1524 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 3)]\n",
      "Input: 0.115 MB, Params: 230,886 (0.881 MB), Total: 1.00 MB, FLOPs: 26,800,391\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.322%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.475%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.203%\n",
      "Finished fine tuning.\n",
      "Iteration 1524/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1524\n",
      "\n",
      "Iteration 1525 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 3)]\n",
      "Input: 0.115 MB, Params: 230,542 (0.879 MB), Total: 0.99 MB, FLOPs: 26,388,791\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 69.068%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.627%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.051%\n",
      "Finished fine tuning.\n",
      "Iteration 1525/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1525\n",
      "\n",
      "Iteration 1526 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 56)]\n",
      "Input: 0.115 MB, Params: 229,595 (0.876 MB), Total: 0.99 MB, FLOPs: 26,320,679\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.017%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.322%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.898%\n",
      "Finished fine tuning.\n",
      "Iteration 1526/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1526\n",
      "\n",
      "Iteration 1527 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 69)]\n",
      "Input: 0.115 MB, Params: 227,964 (0.870 MB), Total: 0.98 MB, FLOPs: 26,291,339\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.475%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.322%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.627%\n",
      "Finished fine tuning.\n",
      "Iteration 1527/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1527\n",
      "\n",
      "Iteration 1528 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 17)]\n",
      "Input: 0.115 MB, Params: 226,585 (0.864 MB), Total: 0.98 MB, FLOPs: 26,232,389\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.898%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.746%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.593%\n",
      "Finished fine tuning.\n",
      "Iteration 1528/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1528\n",
      "\n",
      "Iteration 1529 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(14, 17)]\n",
      "Input: 0.115 MB, Params: 226,160 (0.863 MB), Total: 0.98 MB, FLOPs: 26,007,165\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.169%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.017%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.475%\n",
      "Finished fine tuning.\n",
      "Iteration 1529/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1529\n",
      "\n",
      "Iteration 1530 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 40)]\n",
      "Input: 0.115 MB, Params: 225,222 (0.859 MB), Total: 0.97 MB, FLOPs: 25,939,701\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.017%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.322%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.898%\n",
      "Finished fine tuning.\n",
      "Iteration 1530/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1530\n",
      "\n",
      "Iteration 1531 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 106)]\n",
      "Input: 0.115 MB, Params: 224,470 (0.856 MB), Total: 0.97 MB, FLOPs: 25,926,209\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.864%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.712%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.017%\n",
      "Finished fine tuning.\n",
      "Iteration 1531/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1531\n",
      "\n",
      "Iteration 1532 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 7)]\n",
      "Input: 0.115 MB, Params: 223,718 (0.853 MB), Total: 0.97 MB, FLOPs: 25,912,717\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.864%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.441%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.017%\n",
      "Finished fine tuning.\n",
      "Iteration 1532/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1532\n",
      "\n",
      "Iteration 1533 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 13)]\n",
      "Input: 0.115 MB, Params: 222,780 (0.850 MB), Total: 0.97 MB, FLOPs: 25,774,181\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.746%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.864%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.017%\n",
      "Finished fine tuning.\n",
      "Iteration 1533/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1533\n",
      "\n",
      "Iteration 1534 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(7, 13)]\n",
      "Input: 0.115 MB, Params: 222,661 (0.849 MB), Total: 0.96 MB, FLOPs: 25,591,461\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.169%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.169%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.169%\n",
      "Finished fine tuning.\n",
      "Iteration 1534/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1534\n",
      "\n",
      "Iteration 1535 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 17)]\n",
      "Input: 0.115 MB, Params: 221,732 (0.846 MB), Total: 0.96 MB, FLOPs: 25,524,645\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.864%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.864%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.169%\n",
      "Finished fine tuning.\n",
      "Iteration 1535/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1535\n",
      "\n",
      "Iteration 1536 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 42)]\n",
      "Input: 0.115 MB, Params: 220,371 (0.841 MB), Total: 0.96 MB, FLOPs: 25,466,991\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.288%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.593%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.441%\n",
      "Finished fine tuning.\n",
      "Iteration 1536/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1536\n",
      "\n",
      "Iteration 1537 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 28)]\n",
      "Input: 0.115 MB, Params: 219,619 (0.838 MB), Total: 0.95 MB, FLOPs: 25,453,499\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.712%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.864%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.136%\n",
      "Finished fine tuning.\n",
      "Iteration 1537/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1537\n",
      "\n",
      "Iteration 1538 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 17)]\n",
      "Input: 0.115 MB, Params: 218,867 (0.835 MB), Total: 0.95 MB, FLOPs: 25,440,007\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.864%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.593%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.864%\n",
      "Finished fine tuning.\n",
      "Iteration 1538/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1538\n",
      "\n",
      "Iteration 1539 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 47)]\n",
      "Input: 0.115 MB, Params: 217,506 (0.830 MB), Total: 0.95 MB, FLOPs: 25,382,353\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.441%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.712%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.559%\n",
      "Finished fine tuning.\n",
      "Iteration 1539/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1539\n",
      "\n",
      "Iteration 1540 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 48)]\n",
      "Input: 0.115 MB, Params: 216,595 (0.826 MB), Total: 0.94 MB, FLOPs: 25,316,833\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.712%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.136%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.288%\n",
      "Finished fine tuning.\n",
      "Iteration 1540/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1540\n",
      "\n",
      "Iteration 1541 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 37)]\n",
      "Input: 0.115 MB, Params: 215,243 (0.821 MB), Total: 0.94 MB, FLOPs: 25,259,827\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.864%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.288%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.983%\n",
      "Finished fine tuning.\n",
      "Iteration 1541/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1541\n",
      "\n",
      "Iteration 1542 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 46)]\n",
      "Input: 0.115 MB, Params: 214,341 (0.818 MB), Total: 0.93 MB, FLOPs: 25,194,955\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.288%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.136%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.288%\n",
      "Finished fine tuning.\n",
      "Iteration 1542/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1542\n",
      "\n",
      "Iteration 1543 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 32)]\n",
      "Input: 0.115 MB, Params: 213,430 (0.814 MB), Total: 0.93 MB, FLOPs: 25,058,363\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.017%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.169%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.746%\n",
      "Finished fine tuning.\n",
      "Iteration 1543/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1543\n",
      "\n",
      "Iteration 1544 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 21)]\n",
      "Input: 0.115 MB, Params: 212,087 (0.809 MB), Total: 0.92 MB, FLOPs: 25,002,005\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.864%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.203%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.017%\n",
      "Finished fine tuning.\n",
      "Iteration 1544/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1544\n",
      "\n",
      "Iteration 1545 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 47)]\n",
      "Input: 0.115 MB, Params: 210,537 (0.803 MB), Total: 0.92 MB, FLOPs: 24,974,123\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.864%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.288%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.441%\n",
      "Finished fine tuning.\n",
      "Iteration 1545/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1545\n",
      "\n",
      "Iteration 1546 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 50)]\n",
      "Input: 0.115 MB, Params: 209,794 (0.800 MB), Total: 0.92 MB, FLOPs: 24,960,793\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.441%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.288%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.441%\n",
      "Finished fine tuning.\n",
      "Iteration 1546/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1546\n",
      "\n",
      "Iteration 1547 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 15)]\n",
      "Input: 0.115 MB, Params: 209,051 (0.797 MB), Total: 0.91 MB, FLOPs: 24,947,463\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.864%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.593%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.441%\n",
      "Finished fine tuning.\n",
      "Iteration 1547/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1547\n",
      "\n",
      "Iteration 1548 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 17)]\n",
      "Input: 0.115 MB, Params: 207,717 (0.792 MB), Total: 0.91 MB, FLOPs: 24,891,267\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.136%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.288%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.559%\n",
      "Finished fine tuning.\n",
      "Iteration 1548/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1548\n",
      "\n",
      "Iteration 1549 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 78)]\n",
      "Input: 0.115 MB, Params: 206,974 (0.790 MB), Total: 0.90 MB, FLOPs: 24,877,937\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.017%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.593%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.169%\n",
      "Finished fine tuning.\n",
      "Iteration 1549/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1549\n",
      "\n",
      "Iteration 1550 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 16)]\n",
      "Input: 0.115 MB, Params: 206,423 (0.787 MB), Total: 0.90 MB, FLOPs: 24,715,137\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.814%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.593%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.017%\n",
      "Finished fine tuning.\n",
      "Iteration 1550/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1550\n",
      "\n",
      "Iteration 1551 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 20)]\n",
      "Input: 0.115 MB, Params: 205,548 (0.784 MB), Total: 0.90 MB, FLOPs: 24,652,209\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.746%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.169%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.864%\n",
      "Finished fine tuning.\n",
      "Iteration 1551/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1551\n",
      "\n",
      "Iteration 1552 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 76)]\n",
      "Input: 0.115 MB, Params: 204,805 (0.781 MB), Total: 0.90 MB, FLOPs: 24,638,879\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.136%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.017%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.288%\n",
      "Finished fine tuning.\n",
      "Iteration 1552/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1552\n",
      "\n",
      "Iteration 1553 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 16)]\n",
      "Input: 0.115 MB, Params: 203,300 (0.776 MB), Total: 0.89 MB, FLOPs: 24,611,807\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.864%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.593%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.593%\n",
      "Finished fine tuning.\n",
      "Iteration 1553/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1553\n",
      "\n",
      "Iteration 1554 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(14, 4)]\n",
      "Input: 0.115 MB, Params: 202,884 (0.774 MB), Total: 0.89 MB, FLOPs: 24,389,247\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.898%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.864%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.322%\n",
      "Finished fine tuning.\n",
      "Iteration 1554/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1554\n",
      "\n",
      "Iteration 1555 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 71)]\n",
      "Input: 0.115 MB, Params: 201,379 (0.768 MB), Total: 0.88 MB, FLOPs: 24,362,175\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.051%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.322%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.898%\n",
      "Finished fine tuning.\n",
      "Iteration 1555/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1555\n",
      "\n",
      "Iteration 1556 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 5)]\n",
      "Input: 0.115 MB, Params: 200,486 (0.765 MB), Total: 0.88 MB, FLOPs: 24,228,895\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.475%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.169%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.441%\n",
      "Finished fine tuning.\n",
      "Iteration 1556/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1556\n",
      "\n",
      "Iteration 1557 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 4)]\n",
      "Input: 0.115 MB, Params: 199,593 (0.761 MB), Total: 0.88 MB, FLOPs: 24,095,615\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.932%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.169%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.746%\n",
      "Finished fine tuning.\n",
      "Iteration 1557/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1557\n",
      "\n",
      "Iteration 1558 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 30)]\n",
      "Input: 0.115 MB, Params: 198,736 (0.758 MB), Total: 0.87 MB, FLOPs: 24,033,983\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.322%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.746%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.169%\n",
      "Finished fine tuning.\n",
      "Iteration 1558/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1558\n",
      "\n",
      "Iteration 1559 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 62)]\n",
      "Input: 0.115 MB, Params: 197,231 (0.752 MB), Total: 0.87 MB, FLOPs: 24,006,911\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.322%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.017%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.169%\n",
      "Finished fine tuning.\n",
      "Iteration 1559/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1559\n",
      "\n",
      "Iteration 1560 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 62)]\n",
      "Input: 0.115 MB, Params: 195,726 (0.747 MB), Total: 0.86 MB, FLOPs: 23,979,839\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.593%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.593%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.593%\n",
      "Finished fine tuning.\n",
      "Iteration 1560/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1560\n",
      "\n",
      "Iteration 1561 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 3)]\n",
      "Input: 0.115 MB, Params: 194,221 (0.741 MB), Total: 0.86 MB, FLOPs: 23,952,767\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.898%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.169%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.898%\n",
      "Finished fine tuning.\n",
      "Iteration 1561/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1561\n",
      "\n",
      "Iteration 1562 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 31)]\n",
      "Input: 0.115 MB, Params: 193,697 (0.739 MB), Total: 0.85 MB, FLOPs: 23,797,959\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.169%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.746%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.051%\n",
      "Finished fine tuning.\n",
      "Iteration 1562/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1562\n",
      "\n",
      "Iteration 1563 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 3)]\n",
      "Input: 0.115 MB, Params: 193,380 (0.738 MB), Total: 0.85 MB, FLOPs: 23,418,759\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 73.305%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.051%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.051%\n",
      "Finished fine tuning.\n",
      "Iteration 1563/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1563\n",
      "\n",
      "Iteration 1564 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 104)]\n",
      "Input: 0.115 MB, Params: 192,682 (0.735 MB), Total: 0.85 MB, FLOPs: 23,406,239\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.475%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.169%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.593%\n",
      "Finished fine tuning.\n",
      "Iteration 1564/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1564\n",
      "\n",
      "Iteration 1565 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 32)]\n",
      "Input: 0.115 MB, Params: 191,825 (0.732 MB), Total: 0.85 MB, FLOPs: 23,344,607\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.288%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.627%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.051%\n",
      "Finished fine tuning.\n",
      "Iteration 1565/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1565\n",
      "\n",
      "Iteration 1566 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 15)]\n",
      "Input: 0.115 MB, Params: 191,127 (0.729 MB), Total: 0.84 MB, FLOPs: 23,332,087\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.169%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.475%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.169%\n",
      "Finished fine tuning.\n",
      "Iteration 1566/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1566\n",
      "\n",
      "Iteration 1567 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 3)]\n",
      "Input: 0.115 MB, Params: 190,603 (0.727 MB), Total: 0.84 MB, FLOPs: 23,177,279\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.475%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.593%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.051%\n",
      "Finished fine tuning.\n",
      "Iteration 1567/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1567\n",
      "\n",
      "Iteration 1568 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 57)]\n",
      "Input: 0.115 MB, Params: 189,905 (0.724 MB), Total: 0.84 MB, FLOPs: 23,164,759\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.475%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.475%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.898%\n",
      "Finished fine tuning.\n",
      "Iteration 1568/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1568\n",
      "\n",
      "Iteration 1569 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 46)]\n",
      "Input: 0.115 MB, Params: 189,207 (0.722 MB), Total: 0.84 MB, FLOPs: 23,152,239\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.627%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.051%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.475%\n",
      "Finished fine tuning.\n",
      "Iteration 1569/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1569\n",
      "\n",
      "Iteration 1570 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 33)]\n",
      "Input: 0.115 MB, Params: 188,350 (0.718 MB), Total: 0.83 MB, FLOPs: 23,090,607\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.475%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.898%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.746%\n",
      "Finished fine tuning.\n",
      "Iteration 1570/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1570\n",
      "\n",
      "Iteration 1571 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 8)]\n",
      "Input: 0.115 MB, Params: 188,033 (0.717 MB), Total: 0.83 MB, FLOPs: 22,711,407\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 71.610%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.017%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.780%\n",
      "Finished fine tuning.\n",
      "Iteration 1571/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1571\n",
      "\n",
      "Iteration 1572 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 40)]\n",
      "Input: 0.115 MB, Params: 187,335 (0.715 MB), Total: 0.83 MB, FLOPs: 22,698,887\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.322%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.475%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.746%\n",
      "Finished fine tuning.\n",
      "Iteration 1572/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1572\n",
      "\n",
      "Iteration 1573 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 46)]\n",
      "Input: 0.115 MB, Params: 186,637 (0.712 MB), Total: 0.83 MB, FLOPs: 22,686,367\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.475%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.322%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.746%\n",
      "Finished fine tuning.\n",
      "Iteration 1573/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1573\n",
      "\n",
      "Iteration 1574 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 7)]\n",
      "Input: 0.115 MB, Params: 186,113 (0.710 MB), Total: 0.83 MB, FLOPs: 22,531,559\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.051%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.203%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.017%\n",
      "Finished fine tuning.\n",
      "Iteration 1574/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1574\n",
      "\n",
      "Iteration 1575 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 59)]\n",
      "Input: 0.115 MB, Params: 184,662 (0.704 MB), Total: 0.82 MB, FLOPs: 22,505,459\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.203%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.051%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.932%\n",
      "Finished fine tuning.\n",
      "Iteration 1575/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1575\n",
      "\n",
      "Iteration 1576 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 23)]\n",
      "Input: 0.115 MB, Params: 183,973 (0.702 MB), Total: 0.82 MB, FLOPs: 22,493,101\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.627%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.322%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.322%\n",
      "Finished fine tuning.\n",
      "Iteration 1576/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1576\n",
      "\n",
      "Iteration 1577 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 33)]\n",
      "Input: 0.115 MB, Params: 182,531 (0.696 MB), Total: 0.81 MB, FLOPs: 22,467,163\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.051%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.203%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.051%\n",
      "Finished fine tuning.\n",
      "Iteration 1577/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1577\n",
      "\n",
      "Iteration 1578 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 20)]\n",
      "Input: 0.115 MB, Params: 182,007 (0.694 MB), Total: 0.81 MB, FLOPs: 22,312,355\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.322%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.051%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.051%\n",
      "Finished fine tuning.\n",
      "Iteration 1578/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1578\n",
      "\n",
      "Iteration 1579 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 21)]\n",
      "Input: 0.115 MB, Params: 181,150 (0.691 MB), Total: 0.81 MB, FLOPs: 22,250,723\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.746%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.051%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.627%\n",
      "Finished fine tuning.\n",
      "Iteration 1579/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1579\n",
      "\n",
      "Iteration 1580 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(7, 4)]\n",
      "Input: 0.115 MB, Params: 181,049 (0.691 MB), Total: 0.81 MB, FLOPs: 22,089,603\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 63.983%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.051%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.356%\n",
      "Finished fine tuning.\n",
      "Iteration 1580/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1580\n",
      "\n",
      "Iteration 1581 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 12)]\n",
      "Input: 0.115 MB, Params: 180,228 (0.688 MB), Total: 0.80 MB, FLOPs: 21,969,571\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.898%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.780%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.508%\n",
      "Finished fine tuning.\n",
      "Iteration 1581/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1581\n",
      "\n",
      "Iteration 1582 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 1)]\n",
      "Input: 0.115 MB, Params: 179,407 (0.684 MB), Total: 0.80 MB, FLOPs: 21,849,539\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 74.153%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.085%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.085%\n",
      "Finished fine tuning.\n",
      "Iteration 1582/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1582\n",
      "\n",
      "Iteration 1583 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 4)]\n",
      "Input: 0.115 MB, Params: 178,901 (0.682 MB), Total: 0.80 MB, FLOPs: 21,700,059\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.932%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.661%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.661%\n",
      "Finished fine tuning.\n",
      "Iteration 1583/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1583\n",
      "\n",
      "Iteration 1584 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 17)]\n",
      "Input: 0.115 MB, Params: 178,395 (0.681 MB), Total: 0.80 MB, FLOPs: 21,550,579\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.627%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.966%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 77.966%\n",
      "Finished fine tuning.\n",
      "Iteration 1584/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1584\n",
      "\n",
      "Iteration 1585 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 18)]\n",
      "Input: 0.115 MB, Params: 176,953 (0.675 MB), Total: 0.79 MB, FLOPs: 21,524,641\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.780%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.051%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.627%\n",
      "Finished fine tuning.\n",
      "Iteration 1585/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1585\n",
      "\n",
      "Iteration 1586 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 41)]\n",
      "Input: 0.115 MB, Params: 175,511 (0.670 MB), Total: 0.78 MB, FLOPs: 21,498,703\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.780%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.051%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.932%\n",
      "Finished fine tuning.\n",
      "Iteration 1586/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1586\n",
      "\n",
      "Iteration 1587 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 79)]\n",
      "Input: 0.115 MB, Params: 174,849 (0.667 MB), Total: 0.78 MB, FLOPs: 21,486,831\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.932%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.814%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.627%\n",
      "Finished fine tuning.\n",
      "Iteration 1587/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1587\n",
      "\n",
      "Iteration 1588 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 15)]\n",
      "Input: 0.115 MB, Params: 173,641 (0.662 MB), Total: 0.78 MB, FLOPs: 21,435,333\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.475%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.475%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.898%\n",
      "Finished fine tuning.\n",
      "Iteration 1588/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1588\n",
      "\n",
      "Iteration 1589 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 64)]\n",
      "Input: 0.115 MB, Params: 172,217 (0.657 MB), Total: 0.77 MB, FLOPs: 21,409,719\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.898%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.627%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.898%\n",
      "Finished fine tuning.\n",
      "Iteration 1589/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1589\n",
      "\n",
      "Iteration 1590 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 91)]\n",
      "Input: 0.115 MB, Params: 171,564 (0.654 MB), Total: 0.77 MB, FLOPs: 21,398,009\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.898%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.051%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.169%\n",
      "Finished fine tuning.\n",
      "Iteration 1590/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1590\n",
      "\n",
      "Iteration 1591 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 64)]\n",
      "Input: 0.115 MB, Params: 170,149 (0.649 MB), Total: 0.76 MB, FLOPs: 21,372,557\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.898%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.627%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.475%\n",
      "Finished fine tuning.\n",
      "Iteration 1591/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1591\n",
      "\n",
      "Iteration 1592 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 89)]\n",
      "Input: 0.115 MB, Params: 169,505 (0.647 MB), Total: 0.76 MB, FLOPs: 21,361,009\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.051%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.898%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.203%\n",
      "Finished fine tuning.\n",
      "Iteration 1592/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1592\n",
      "\n",
      "Iteration 1593 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 35)]\n",
      "Input: 0.115 MB, Params: 168,099 (0.641 MB), Total: 0.76 MB, FLOPs: 21,335,719\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.051%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.051%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.203%\n",
      "Finished fine tuning.\n",
      "Iteration 1593/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1593\n",
      "\n",
      "Iteration 1594 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(7, 12)]\n",
      "Input: 0.115 MB, Params: 167,998 (0.641 MB), Total: 0.76 MB, FLOPs: 21,174,599\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 66.525%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.051%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.746%\n",
      "Finished fine tuning.\n",
      "Iteration 1594/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1594\n",
      "\n",
      "Iteration 1595 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 30)]\n",
      "Input: 0.115 MB, Params: 166,817 (0.636 MB), Total: 0.75 MB, FLOPs: 21,123,587\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.322%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.322%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.322%\n",
      "Finished fine tuning.\n",
      "Iteration 1595/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1595\n",
      "\n",
      "Iteration 1596 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 14)]\n",
      "Input: 0.115 MB, Params: 165,420 (0.631 MB), Total: 0.75 MB, FLOPs: 21,098,459\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.746%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.898%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.898%\n",
      "Finished fine tuning.\n",
      "Iteration 1596/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1596\n",
      "\n",
      "Iteration 1597 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 52)]\n",
      "Input: 0.115 MB, Params: 164,794 (0.629 MB), Total: 0.74 MB, FLOPs: 21,087,235\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.627%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.475%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.169%\n",
      "Finished fine tuning.\n",
      "Iteration 1597/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1597\n",
      "\n",
      "Iteration 1598 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 9)]\n",
      "Input: 0.115 MB, Params: 164,495 (0.627 MB), Total: 0.74 MB, FLOPs: 20,729,635\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 76.695%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.627%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.475%\n",
      "Finished fine tuning.\n",
      "Iteration 1598/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1598\n",
      "\n",
      "Iteration 1599 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 2)]\n",
      "Input: 0.115 MB, Params: 163,323 (0.623 MB), Total: 0.74 MB, FLOPs: 20,678,785\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.322%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.898%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.627%\n",
      "Finished fine tuning.\n",
      "Iteration 1599/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1599\n",
      "\n",
      "Iteration 1600 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 18)]\n",
      "Input: 0.115 MB, Params: 162,817 (0.621 MB), Total: 0.74 MB, FLOPs: 20,529,305\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.169%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.898%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.475%\n",
      "Finished fine tuning.\n",
      "Iteration 1600/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1600\n",
      "\n",
      "Iteration 1601 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 80)]\n",
      "Input: 0.115 MB, Params: 162,191 (0.619 MB), Total: 0.73 MB, FLOPs: 20,518,081\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.627%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.475%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.746%\n",
      "Finished fine tuning.\n",
      "Iteration 1601/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1601\n",
      "\n",
      "Iteration 1602 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 6)]\n",
      "Input: 0.115 MB, Params: 160,821 (0.613 MB), Total: 0.73 MB, FLOPs: 20,493,439\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.051%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.746%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.898%\n",
      "Finished fine tuning.\n",
      "Iteration 1602/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1602\n",
      "\n",
      "Iteration 1603 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 18)]\n",
      "Input: 0.115 MB, Params: 159,451 (0.608 MB), Total: 0.72 MB, FLOPs: 20,468,797\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.898%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.898%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.898%\n",
      "Finished fine tuning.\n",
      "Iteration 1603/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1603\n",
      "\n",
      "Iteration 1604 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 39)]\n",
      "Input: 0.115 MB, Params: 158,639 (0.605 MB), Total: 0.72 MB, FLOPs: 20,410,405\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.169%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.169%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.169%\n",
      "Finished fine tuning.\n",
      "Iteration 1604/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1604\n",
      "\n",
      "Iteration 1605 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 14)]\n",
      "Input: 0.115 MB, Params: 157,269 (0.600 MB), Total: 0.72 MB, FLOPs: 20,385,763\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.898%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.746%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.746%\n",
      "Finished fine tuning.\n",
      "Iteration 1605/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1605\n",
      "\n",
      "Iteration 1606 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 45)]\n",
      "Input: 0.115 MB, Params: 156,670 (0.598 MB), Total: 0.71 MB, FLOPs: 20,375,025\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.169%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.322%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.746%\n",
      "Finished fine tuning.\n",
      "Iteration 1606/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1606\n",
      "\n",
      "Iteration 1607 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 29)]\n",
      "Input: 0.115 MB, Params: 155,309 (0.592 MB), Total: 0.71 MB, FLOPs: 20,350,545\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.322%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.746%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.322%\n",
      "Finished fine tuning.\n",
      "Iteration 1607/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1607\n",
      "\n",
      "Iteration 1608 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 76)]\n",
      "Input: 0.115 MB, Params: 154,719 (0.590 MB), Total: 0.71 MB, FLOPs: 20,339,969\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.322%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.475%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.322%\n",
      "Finished fine tuning.\n",
      "Iteration 1608/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1608\n",
      "\n",
      "Iteration 1609 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 59)]\n",
      "Input: 0.115 MB, Params: 153,907 (0.587 MB), Total: 0.70 MB, FLOPs: 20,281,577\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.746%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.322%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.746%\n",
      "Finished fine tuning.\n",
      "Iteration 1609/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1609\n",
      "\n",
      "Iteration 1610 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 5)]\n",
      "Input: 0.115 MB, Params: 153,401 (0.585 MB), Total: 0.70 MB, FLOPs: 20,132,097\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.898%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.441%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.017%\n",
      "Finished fine tuning.\n",
      "Iteration 1610/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1610\n",
      "\n",
      "Iteration 1611 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 30)]\n",
      "Input: 0.115 MB, Params: 152,283 (0.581 MB), Total: 0.70 MB, FLOPs: 20,083,191\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.864%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.441%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.593%\n",
      "Finished fine tuning.\n",
      "Iteration 1611/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1611\n",
      "\n",
      "Iteration 1612 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 62)]\n",
      "Input: 0.115 MB, Params: 151,693 (0.579 MB), Total: 0.69 MB, FLOPs: 20,072,615\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.322%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.169%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.898%\n",
      "Finished fine tuning.\n",
      "Iteration 1612/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1612\n",
      "\n",
      "Iteration 1613 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(7, 2)]\n",
      "Input: 0.115 MB, Params: 151,601 (0.578 MB), Total: 0.69 MB, FLOPs: 19,922,295\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 65.678%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.203%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.898%\n",
      "Finished fine tuning.\n",
      "Iteration 1613/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1613\n",
      "\n",
      "Iteration 1614 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 4)]\n",
      "Input: 0.115 MB, Params: 151,095 (0.576 MB), Total: 0.69 MB, FLOPs: 19,772,815\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.475%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.898%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.051%\n",
      "Finished fine tuning.\n",
      "Iteration 1614/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1614\n",
      "\n",
      "Iteration 1615 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 20)]\n",
      "Input: 0.115 MB, Params: 149,761 (0.571 MB), Total: 0.69 MB, FLOPs: 19,748,821\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.475%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.898%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.475%\n",
      "Finished fine tuning.\n",
      "Iteration 1615/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1615\n",
      "\n",
      "Iteration 1616 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 66)]\n",
      "Input: 0.115 MB, Params: 149,180 (0.569 MB), Total: 0.68 MB, FLOPs: 19,738,407\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.898%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.898%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.898%\n",
      "Finished fine tuning.\n",
      "Iteration 1616/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1616\n",
      "\n",
      "Iteration 1617 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 0)]\n",
      "Input: 0.115 MB, Params: 147,855 (0.564 MB), Total: 0.68 MB, FLOPs: 19,714,575\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.898%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.898%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.627%\n",
      "Finished fine tuning.\n",
      "Iteration 1617/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1617\n",
      "\n",
      "Iteration 1618 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 53)]\n",
      "Input: 0.115 MB, Params: 146,530 (0.559 MB), Total: 0.67 MB, FLOPs: 19,690,743\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.898%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.475%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.898%\n",
      "Finished fine tuning.\n",
      "Iteration 1618/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1618\n",
      "\n",
      "Iteration 1619 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 18)]\n",
      "Input: 0.115 MB, Params: 145,727 (0.556 MB), Total: 0.67 MB, FLOPs: 19,632,999\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.475%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.593%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.746%\n",
      "Finished fine tuning.\n",
      "Iteration 1619/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1619\n",
      "\n",
      "Iteration 1620 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(14, 15)]\n",
      "Input: 0.115 MB, Params: 145,419 (0.555 MB), Total: 0.67 MB, FLOPs: 19,466,815\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.593%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.746%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.288%\n",
      "Finished fine tuning.\n",
      "Iteration 1620/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1620\n",
      "\n",
      "Iteration 1621 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(14, 11)]\n",
      "Input: 0.115 MB, Params: 145,111 (0.554 MB), Total: 0.67 MB, FLOPs: 19,300,631\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.475%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.017%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.017%\n",
      "Finished fine tuning.\n",
      "Iteration 1621/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1621\n",
      "\n",
      "Iteration 1622 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 24)]\n",
      "Input: 0.115 MB, Params: 144,029 (0.549 MB), Total: 0.66 MB, FLOPs: 19,252,859\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.017%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.593%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.864%\n",
      "Finished fine tuning.\n",
      "Iteration 1622/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1622\n",
      "\n",
      "Iteration 1623 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 7)]\n",
      "Input: 0.115 MB, Params: 142,947 (0.545 MB), Total: 0.66 MB, FLOPs: 19,205,087\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.593%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.441%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.864%\n",
      "Finished fine tuning.\n",
      "Iteration 1623/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1623\n",
      "\n",
      "Iteration 1624 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 4)]\n",
      "Input: 0.115 MB, Params: 141,865 (0.541 MB), Total: 0.66 MB, FLOPs: 19,157,315\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.441%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.593%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.864%\n",
      "Finished fine tuning.\n",
      "Iteration 1624/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1624\n",
      "\n",
      "Iteration 1625 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 18)]\n",
      "Input: 0.115 MB, Params: 141,377 (0.539 MB), Total: 0.65 MB, FLOPs: 19,013,163\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.475%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.593%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.593%\n",
      "Finished fine tuning.\n",
      "Iteration 1625/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1625\n",
      "\n",
      "Iteration 1626 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 3)]\n",
      "Input: 0.115 MB, Params: 140,889 (0.537 MB), Total: 0.65 MB, FLOPs: 18,869,011\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.864%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.288%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.288%\n",
      "Finished fine tuning.\n",
      "Iteration 1626/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1626\n",
      "\n",
      "Iteration 1627 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 1)]\n",
      "Input: 0.115 MB, Params: 140,401 (0.536 MB), Total: 0.65 MB, FLOPs: 18,724,859\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.017%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.559%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.864%\n",
      "Finished fine tuning.\n",
      "Iteration 1627/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1627\n",
      "\n",
      "Iteration 1628 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 12)]\n",
      "Input: 0.115 MB, Params: 139,319 (0.531 MB), Total: 0.65 MB, FLOPs: 18,677,087\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.864%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.593%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.017%\n",
      "Finished fine tuning.\n",
      "Iteration 1628/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1628\n",
      "\n",
      "Iteration 1629 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 70)]\n",
      "Input: 0.115 MB, Params: 138,756 (0.529 MB), Total: 0.64 MB, FLOPs: 18,666,997\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.864%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.169%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.593%\n",
      "Finished fine tuning.\n",
      "Iteration 1629/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1629\n",
      "\n",
      "Iteration 1630 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 21)]\n",
      "Input: 0.115 MB, Params: 137,989 (0.526 MB), Total: 0.64 MB, FLOPs: 18,611,845\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.593%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.017%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.864%\n",
      "Finished fine tuning.\n",
      "Iteration 1630/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1630\n",
      "\n",
      "Iteration 1631 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 44)]\n",
      "Input: 0.115 MB, Params: 136,709 (0.522 MB), Total: 0.64 MB, FLOPs: 18,588,823\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.017%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.864%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.169%\n",
      "Finished fine tuning.\n",
      "Iteration 1631/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1631\n",
      "\n",
      "Iteration 1632 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(14, 13)]\n",
      "Input: 0.115 MB, Params: 136,428 (0.520 MB), Total: 0.64 MB, FLOPs: 18,430,631\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.475%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.169%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.593%\n",
      "Finished fine tuning.\n",
      "Iteration 1632/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1632\n",
      "\n",
      "Iteration 1633 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 56)]\n",
      "Input: 0.115 MB, Params: 135,661 (0.518 MB), Total: 0.63 MB, FLOPs: 18,375,479\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.356%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.017%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.288%\n",
      "Finished fine tuning.\n",
      "Iteration 1633/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1633\n",
      "\n",
      "Iteration 1634 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 71)]\n",
      "Input: 0.115 MB, Params: 135,107 (0.515 MB), Total: 0.63 MB, FLOPs: 18,365,551\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.441%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.864%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.864%\n",
      "Finished fine tuning.\n",
      "Iteration 1634/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1634\n",
      "\n",
      "Iteration 1635 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 41)]\n",
      "Input: 0.115 MB, Params: 134,052 (0.511 MB), Total: 0.63 MB, FLOPs: 18,319,237\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.864%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.712%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.288%\n",
      "Finished fine tuning.\n",
      "Iteration 1635/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1635\n",
      "\n",
      "Iteration 1636 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 0)]\n",
      "Input: 0.115 MB, Params: 132,997 (0.507 MB), Total: 0.62 MB, FLOPs: 18,272,923\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.017%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.288%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.322%\n",
      "Finished fine tuning.\n",
      "Iteration 1636/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1636\n",
      "\n",
      "Iteration 1637 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 15)]\n",
      "Input: 0.115 MB, Params: 131,744 (0.503 MB), Total: 0.62 MB, FLOPs: 18,250,387\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.288%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.746%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.593%\n",
      "Finished fine tuning.\n",
      "Iteration 1637/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1637\n",
      "\n",
      "Iteration 1638 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 50)]\n",
      "Input: 0.115 MB, Params: 131,199 (0.500 MB), Total: 0.62 MB, FLOPs: 18,240,621\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.864%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.864%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.017%\n",
      "Finished fine tuning.\n",
      "Iteration 1638/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1638\n",
      "\n",
      "Iteration 1639 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 10)]\n",
      "Input: 0.115 MB, Params: 130,153 (0.496 MB), Total: 0.61 MB, FLOPs: 18,194,469\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.475%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.017%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.898%\n",
      "Finished fine tuning.\n",
      "Iteration 1639/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1639\n",
      "\n",
      "Iteration 1640 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 35)]\n",
      "Input: 0.115 MB, Params: 129,107 (0.493 MB), Total: 0.61 MB, FLOPs: 18,148,317\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.746%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.475%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.475%\n",
      "Finished fine tuning.\n",
      "Iteration 1640/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1640\n",
      "\n",
      "Iteration 1641 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 44)]\n",
      "Input: 0.115 MB, Params: 128,562 (0.490 MB), Total: 0.61 MB, FLOPs: 18,138,551\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.322%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.593%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.746%\n",
      "Finished fine tuning.\n",
      "Iteration 1641/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1641\n",
      "\n",
      "Iteration 1642 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 14)]\n",
      "Input: 0.115 MB, Params: 128,017 (0.488 MB), Total: 0.60 MB, FLOPs: 18,128,785\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.169%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.322%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.746%\n",
      "Finished fine tuning.\n",
      "Iteration 1642/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1642\n",
      "\n",
      "Iteration 1643 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 43)]\n",
      "Input: 0.115 MB, Params: 126,971 (0.484 MB), Total: 0.60 MB, FLOPs: 18,082,633\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.593%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.169%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.169%\n",
      "Finished fine tuning.\n",
      "Iteration 1643/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1643\n",
      "\n",
      "Iteration 1644 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 13)]\n",
      "Input: 0.115 MB, Params: 126,267 (0.482 MB), Total: 0.60 MB, FLOPs: 17,987,153\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.814%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.746%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.169%\n",
      "Finished fine tuning.\n",
      "Iteration 1644/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1644\n",
      "\n",
      "Iteration 1645 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 23)]\n",
      "Input: 0.115 MB, Params: 125,068 (0.477 MB), Total: 0.59 MB, FLOPs: 17,965,589\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.169%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.746%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.169%\n",
      "Finished fine tuning.\n",
      "Iteration 1645/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1645\n",
      "\n",
      "Iteration 1646 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 33)]\n",
      "Input: 0.115 MB, Params: 124,355 (0.474 MB), Total: 0.59 MB, FLOPs: 17,914,325\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.627%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.203%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.322%\n",
      "Finished fine tuning.\n",
      "Iteration 1646/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1646\n",
      "\n",
      "Iteration 1647 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 11)]\n",
      "Input: 0.115 MB, Params: 123,642 (0.472 MB), Total: 0.59 MB, FLOPs: 17,863,061\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.475%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.898%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.475%\n",
      "Finished fine tuning.\n",
      "Iteration 1647/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1647\n",
      "\n",
      "Iteration 1648 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 28)]\n",
      "Input: 0.115 MB, Params: 122,929 (0.469 MB), Total: 0.58 MB, FLOPs: 17,811,797\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.898%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.898%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.322%\n",
      "Finished fine tuning.\n",
      "Iteration 1648/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1648\n",
      "\n",
      "Iteration 1649 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 36)]\n",
      "Input: 0.115 MB, Params: 122,393 (0.467 MB), Total: 0.58 MB, FLOPs: 17,802,193\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.898%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.051%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.356%\n",
      "Finished fine tuning.\n",
      "Iteration 1649/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1649\n",
      "\n",
      "Iteration 1650 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 61)]\n",
      "Input: 0.115 MB, Params: 121,857 (0.465 MB), Total: 0.58 MB, FLOPs: 17,792,589\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.932%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.746%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.746%\n",
      "Finished fine tuning.\n",
      "Iteration 1650/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1650\n",
      "\n",
      "Iteration 1651 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 32)]\n",
      "Input: 0.115 MB, Params: 120,847 (0.461 MB), Total: 0.58 MB, FLOPs: 17,748,543\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.169%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.746%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.780%\n",
      "Finished fine tuning.\n",
      "Iteration 1651/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1651\n",
      "\n",
      "Iteration 1652 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 21)]\n",
      "Input: 0.115 MB, Params: 120,170 (0.458 MB), Total: 0.57 MB, FLOPs: 17,655,007\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.356%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.746%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.898%\n",
      "Finished fine tuning.\n",
      "Iteration 1652/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1652\n",
      "\n",
      "Iteration 1653 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 42)]\n",
      "Input: 0.115 MB, Params: 118,998 (0.454 MB), Total: 0.57 MB, FLOPs: 17,633,929\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.593%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.051%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.746%\n",
      "Finished fine tuning.\n",
      "Iteration 1653/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1653\n",
      "\n",
      "Iteration 1654 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 19)]\n",
      "Input: 0.115 MB, Params: 117,997 (0.450 MB), Total: 0.57 MB, FLOPs: 17,590,045\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.475%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.017%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.746%\n",
      "Finished fine tuning.\n",
      "Iteration 1654/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1654\n",
      "\n",
      "Iteration 1655 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 39)]\n",
      "Input: 0.115 MB, Params: 116,996 (0.446 MB), Total: 0.56 MB, FLOPs: 17,546,161\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.593%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.169%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.475%\n",
      "Finished fine tuning.\n",
      "Iteration 1655/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1655\n",
      "\n",
      "Iteration 1656 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(7, 3)]\n",
      "Input: 0.115 MB, Params: 116,904 (0.446 MB), Total: 0.56 MB, FLOPs: 17,395,841\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.898%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.864%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.051%\n",
      "Finished fine tuning.\n",
      "Iteration 1656/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1656\n",
      "\n",
      "Iteration 1657 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 4)]\n",
      "Input: 0.115 MB, Params: 115,903 (0.442 MB), Total: 0.56 MB, FLOPs: 17,351,957\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.169%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.322%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.051%\n",
      "Finished fine tuning.\n",
      "Iteration 1657/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1657\n",
      "\n",
      "Iteration 1658 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 0)]\n",
      "Input: 0.115 MB, Params: 114,902 (0.438 MB), Total: 0.55 MB, FLOPs: 17,308,073\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.169%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.441%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.593%\n",
      "Finished fine tuning.\n",
      "Iteration 1658/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1658\n",
      "\n",
      "Iteration 1659 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 44)]\n",
      "Input: 0.115 MB, Params: 114,243 (0.436 MB), Total: 0.55 MB, FLOPs: 17,260,697\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.780%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.898%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.746%\n",
      "Finished fine tuning.\n",
      "Iteration 1659/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1659\n",
      "\n",
      "Iteration 1660 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 10)]\n",
      "Input: 0.115 MB, Params: 113,584 (0.433 MB), Total: 0.55 MB, FLOPs: 17,213,321\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.627%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.898%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.898%\n",
      "Finished fine tuning.\n",
      "Iteration 1660/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1660\n",
      "\n",
      "Iteration 1661 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 4)]\n",
      "Input: 0.115 MB, Params: 113,123 (0.432 MB), Total: 0.55 MB, FLOPs: 17,077,161\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.051%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.051%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.051%\n",
      "Finished fine tuning.\n",
      "Iteration 1661/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1661\n",
      "\n",
      "Iteration 1662 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 4)]\n",
      "Input: 0.115 MB, Params: 112,464 (0.429 MB), Total: 0.54 MB, FLOPs: 17,029,785\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.627%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.203%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.780%\n",
      "Finished fine tuning.\n",
      "Iteration 1662/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1662\n",
      "\n",
      "Iteration 1663 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 43)]\n",
      "Input: 0.115 MB, Params: 111,328 (0.425 MB), Total: 0.54 MB, FLOPs: 17,009,355\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.627%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.051%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.203%\n",
      "Finished fine tuning.\n",
      "Iteration 1663/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1663\n",
      "\n",
      "Iteration 1664 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 20)]\n",
      "Input: 0.115 MB, Params: 110,363 (0.421 MB), Total: 0.54 MB, FLOPs: 16,967,577\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.169%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.356%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.203%\n",
      "Finished fine tuning.\n",
      "Iteration 1664/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1664\n",
      "\n",
      "Iteration 1665 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 36)]\n",
      "Input: 0.115 MB, Params: 109,236 (0.417 MB), Total: 0.53 MB, FLOPs: 16,947,309\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.627%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.746%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.627%\n",
      "Finished fine tuning.\n",
      "Iteration 1665/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1665\n",
      "\n",
      "Iteration 1666 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 14)]\n",
      "Input: 0.115 MB, Params: 108,775 (0.415 MB), Total: 0.53 MB, FLOPs: 16,811,149\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.475%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.203%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.780%\n",
      "Finished fine tuning.\n",
      "Iteration 1666/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1666\n",
      "\n",
      "Iteration 1667 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 8)]\n",
      "Input: 0.115 MB, Params: 108,143 (0.413 MB), Total: 0.53 MB, FLOPs: 16,724,885\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.169%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.627%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.627%\n",
      "Finished fine tuning.\n",
      "Iteration 1667/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1667\n",
      "\n",
      "Iteration 1668 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 55)]\n",
      "Input: 0.115 MB, Params: 107,634 (0.411 MB), Total: 0.53 MB, FLOPs: 16,715,767\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.593%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.051%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.475%\n",
      "Finished fine tuning.\n",
      "Iteration 1668/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1668\n",
      "\n",
      "Iteration 1669 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 33)]\n",
      "Input: 0.115 MB, Params: 106,516 (0.406 MB), Total: 0.52 MB, FLOPs: 16,695,661\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.051%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.322%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.051%\n",
      "Finished fine tuning.\n",
      "Iteration 1669/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1669\n",
      "\n",
      "Iteration 1670 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 37)]\n",
      "Input: 0.115 MB, Params: 105,398 (0.402 MB), Total: 0.52 MB, FLOPs: 16,675,555\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.898%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.051%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.898%\n",
      "Finished fine tuning.\n",
      "Iteration 1670/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1670\n",
      "\n",
      "Iteration 1671 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 14)]\n",
      "Input: 0.115 MB, Params: 104,757 (0.400 MB), Total: 0.51 MB, FLOPs: 16,629,475\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.169%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.746%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.169%\n",
      "Finished fine tuning.\n",
      "Iteration 1671/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1671\n",
      "\n",
      "Iteration 1672 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 29)]\n",
      "Input: 0.115 MB, Params: 103,828 (0.396 MB), Total: 0.51 MB, FLOPs: 16,588,831\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.356%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.508%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.203%\n",
      "Finished fine tuning.\n",
      "Iteration 1672/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1672\n",
      "\n",
      "Iteration 1673 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 23)]\n",
      "Input: 0.115 MB, Params: 102,719 (0.392 MB), Total: 0.51 MB, FLOPs: 16,568,887\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.203%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.780%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.898%\n",
      "Finished fine tuning.\n",
      "Iteration 1673/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1673\n",
      "\n",
      "Iteration 1674 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 24)]\n",
      "Input: 0.115 MB, Params: 102,096 (0.389 MB), Total: 0.50 MB, FLOPs: 16,483,271\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.627%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.356%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.085%\n",
      "Finished fine tuning.\n",
      "Iteration 1674/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1674\n",
      "\n",
      "Iteration 1675 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 0)]\n",
      "Input: 0.115 MB, Params: 101,614 (0.388 MB), Total: 0.50 MB, FLOPs: 16,474,639\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.203%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.475%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.898%\n",
      "Finished fine tuning.\n",
      "Iteration 1675/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1675\n",
      "\n",
      "Iteration 1676 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 24)]\n",
      "Input: 0.115 MB, Params: 100,991 (0.385 MB), Total: 0.50 MB, FLOPs: 16,429,855\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 79.237%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.203%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.780%\n",
      "Finished fine tuning.\n",
      "Iteration 1676/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1676\n",
      "\n",
      "Iteration 1677 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 24)]\n",
      "Input: 0.115 MB, Params: 99,891 (0.381 MB), Total: 0.50 MB, FLOPs: 16,410,073\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.508%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.898%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.475%\n",
      "Finished fine tuning.\n",
      "Iteration 1677/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1677\n",
      "\n",
      "Iteration 1678 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 12)]\n",
      "Input: 0.115 MB, Params: 99,418 (0.379 MB), Total: 0.49 MB, FLOPs: 16,401,603\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.203%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.356%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.051%\n",
      "Finished fine tuning.\n",
      "Iteration 1678/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1678\n",
      "\n",
      "Iteration 1679 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 5)]\n",
      "Input: 0.115 MB, Params: 98,327 (0.375 MB), Total: 0.49 MB, FLOPs: 16,381,983\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.051%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.508%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.780%\n",
      "Finished fine tuning.\n",
      "Iteration 1679/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1679\n",
      "\n",
      "Iteration 1680 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 9)]\n",
      "Input: 0.115 MB, Params: 97,713 (0.373 MB), Total: 0.49 MB, FLOPs: 16,297,015\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 78.814%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.780%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.780%\n",
      "Finished fine tuning.\n",
      "Iteration 1680/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1680\n",
      "\n",
      "Iteration 1681 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 28)]\n",
      "Input: 0.115 MB, Params: 97,099 (0.370 MB), Total: 0.49 MB, FLOPs: 16,252,879\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.475%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.627%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.051%\n",
      "Finished fine tuning.\n",
      "Iteration 1681/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1681\n",
      "\n",
      "Iteration 1682 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 29)]\n",
      "Input: 0.115 MB, Params: 96,485 (0.368 MB), Total: 0.48 MB, FLOPs: 16,208,743\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.932%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.203%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.475%\n",
      "Finished fine tuning.\n",
      "Iteration 1682/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1682\n",
      "\n",
      "Iteration 1683 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 15)]\n",
      "Input: 0.115 MB, Params: 95,610 (0.365 MB), Total: 0.48 MB, FLOPs: 16,170,529\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.356%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.780%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.780%\n",
      "Finished fine tuning.\n",
      "Iteration 1683/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1683\n",
      "\n",
      "Iteration 1684 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 23)]\n",
      "Input: 0.115 MB, Params: 95,005 (0.362 MB), Total: 0.48 MB, FLOPs: 16,127,041\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.932%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.356%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.780%\n",
      "Finished fine tuning.\n",
      "Iteration 1684/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1684\n",
      "\n",
      "Iteration 1685 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 25)]\n",
      "Input: 0.115 MB, Params: 93,923 (0.358 MB), Total: 0.47 MB, FLOPs: 16,107,583\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.356%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.780%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.932%\n",
      "Finished fine tuning.\n",
      "Iteration 1685/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1685\n",
      "\n",
      "Iteration 1686 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 22)]\n",
      "Input: 0.115 MB, Params: 93,066 (0.355 MB), Total: 0.47 MB, FLOPs: 16,070,179\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 80.085%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.780%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.780%\n",
      "Finished fine tuning.\n",
      "Iteration 1686/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1686\n",
      "\n",
      "Iteration 1687 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 6)]\n",
      "Input: 0.115 MB, Params: 92,479 (0.353 MB), Total: 0.47 MB, FLOPs: 15,987,155\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.627%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.203%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.627%\n",
      "Finished fine tuning.\n",
      "Iteration 1687/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1687\n",
      "\n",
      "Iteration 1688 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 0)]\n",
      "Input: 0.115 MB, Params: 91,406 (0.349 MB), Total: 0.46 MB, FLOPs: 15,967,859\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.475%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.475%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.627%\n",
      "Finished fine tuning.\n",
      "Iteration 1688/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1688\n",
      "\n",
      "Iteration 1689 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 12)]\n",
      "Input: 0.115 MB, Params: 90,333 (0.345 MB), Total: 0.46 MB, FLOPs: 15,948,563\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.051%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.627%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 81.780%\n",
      "Finished fine tuning.\n",
      "Iteration 1689/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1689\n",
      "\n",
      "Iteration 1690 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 4)]\n",
      "Input: 0.115 MB, Params: 89,260 (0.340 MB), Total: 0.46 MB, FLOPs: 15,929,267\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.051%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.898%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.203%\n",
      "Finished fine tuning.\n",
      "Iteration 1690/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1690\n",
      "\n",
      "Iteration 1691 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 26)]\n",
      "Input: 0.115 MB, Params: 88,673 (0.338 MB), Total: 0.45 MB, FLOPs: 15,887,075\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.051%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.898%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.898%\n",
      "Finished fine tuning.\n",
      "Iteration 1691/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1691\n",
      "\n",
      "Iteration 1692 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 37)]\n",
      "Input: 0.115 MB, Params: 88,245 (0.337 MB), Total: 0.45 MB, FLOPs: 15,879,415\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.051%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.322%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.051%\n",
      "Finished fine tuning.\n",
      "Iteration 1692/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1692\n",
      "\n",
      "Iteration 1693 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 35)]\n",
      "Input: 0.115 MB, Params: 87,658 (0.334 MB), Total: 0.45 MB, FLOPs: 15,837,223\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.475%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.051%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.898%\n",
      "Finished fine tuning.\n",
      "Iteration 1693/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1693\n",
      "\n",
      "Iteration 1694 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 12)]\n",
      "Input: 0.115 MB, Params: 87,230 (0.333 MB), Total: 0.45 MB, FLOPs: 15,829,563\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.746%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.051%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.627%\n",
      "Finished fine tuning.\n",
      "Iteration 1694/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1694\n",
      "\n",
      "Iteration 1695 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 6)]\n",
      "Input: 0.115 MB, Params: 86,643 (0.331 MB), Total: 0.45 MB, FLOPs: 15,787,371\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 82.627%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.475%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.475%\n",
      "Finished fine tuning.\n",
      "Iteration 1695/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1695\n",
      "\n",
      "Iteration 1696 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(14, 8)]\n",
      "Input: 0.115 MB, Params: 86,380 (0.330 MB), Total: 0.44 MB, FLOPs: 15,634,507\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 70.763%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.475%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.864%\n",
      "Finished fine tuning.\n",
      "Iteration 1696/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1696\n",
      "\n",
      "Iteration 1697 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 0)]\n",
      "Input: 0.115 MB, Params: 85,325 (0.325 MB), Total: 0.44 MB, FLOPs: 15,615,535\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.169%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.169%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.322%\n",
      "Finished fine tuning.\n",
      "Iteration 1697/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1697\n",
      "\n",
      "Iteration 1698 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 10)]\n",
      "Input: 0.115 MB, Params: 84,765 (0.323 MB), Total: 0.44 MB, FLOPs: 15,534,455\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.475%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.475%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.441%\n",
      "Finished fine tuning.\n",
      "Iteration 1698/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1698\n",
      "\n",
      "Iteration 1699 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 11)]\n",
      "Input: 0.115 MB, Params: 84,358 (0.322 MB), Total: 0.44 MB, FLOPs: 15,414,279\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.898%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.746%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.593%\n",
      "Finished fine tuning.\n",
      "Iteration 1699/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1699\n",
      "\n",
      "Iteration 1700 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 35)]\n",
      "Input: 0.115 MB, Params: 83,303 (0.318 MB), Total: 0.43 MB, FLOPs: 15,395,307\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.593%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.898%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.593%\n",
      "Finished fine tuning.\n",
      "Iteration 1700/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1700\n",
      "\n",
      "Iteration 1701 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 29)]\n",
      "Input: 0.115 MB, Params: 82,893 (0.316 MB), Total: 0.43 MB, FLOPs: 15,387,971\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.593%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.322%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.593%\n",
      "Finished fine tuning.\n",
      "Iteration 1701/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1701\n",
      "\n",
      "Iteration 1702 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 11)]\n",
      "Input: 0.115 MB, Params: 82,315 (0.314 MB), Total: 0.43 MB, FLOPs: 15,346,427\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.322%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.322%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.017%\n",
      "Finished fine tuning.\n",
      "Iteration 1702/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1702\n",
      "\n",
      "Iteration 1703 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(21, 10)]\n",
      "Input: 0.115 MB, Params: 81,773 (0.312 MB), Total: 0.43 MB, FLOPs: 15,268,659\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.441%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.898%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.593%\n",
      "Finished fine tuning.\n",
      "Iteration 1703/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1703\n",
      "\n",
      "Iteration 1704 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 37)]\n",
      "Input: 0.115 MB, Params: 81,363 (0.310 MB), Total: 0.43 MB, FLOPs: 15,261,323\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.017%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.864%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.441%\n",
      "Finished fine tuning.\n",
      "Iteration 1704/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1704\n",
      "\n",
      "Iteration 1705 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 34)]\n",
      "Input: 0.115 MB, Params: 80,953 (0.309 MB), Total: 0.42 MB, FLOPs: 15,253,987\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.898%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.593%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.593%\n",
      "Finished fine tuning.\n",
      "Iteration 1705/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1705\n",
      "\n",
      "Iteration 1706 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 34)]\n",
      "Input: 0.115 MB, Params: 79,925 (0.305 MB), Total: 0.42 MB, FLOPs: 15,235,501\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.169%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.169%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.593%\n",
      "Finished fine tuning.\n",
      "Iteration 1706/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1706\n",
      "\n",
      "Iteration 1707 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 61)]\n",
      "Input: 0.115 MB, Params: 79,524 (0.303 MB), Total: 0.42 MB, FLOPs: 15,228,327\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.288%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.864%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 88.136%\n",
      "Finished fine tuning.\n",
      "Iteration 1707/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1707\n",
      "\n",
      "Iteration 1708 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 16)]\n",
      "Input: 0.115 MB, Params: 78,505 (0.299 MB), Total: 0.41 MB, FLOPs: 15,210,003\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.441%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.864%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.017%\n",
      "Finished fine tuning.\n",
      "Iteration 1708/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1708\n",
      "\n",
      "Iteration 1709 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 23)]\n",
      "Input: 0.115 MB, Params: 78,113 (0.298 MB), Total: 0.41 MB, FLOPs: 15,202,991\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.017%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.169%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 87.288%\n",
      "Finished fine tuning.\n",
      "Iteration 1709/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1709\n",
      "\n",
      "Iteration 1710 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 45)]\n",
      "Input: 0.115 MB, Params: 77,721 (0.296 MB), Total: 0.41 MB, FLOPs: 15,195,979\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.475%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.441%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.593%\n",
      "Finished fine tuning.\n",
      "Iteration 1710/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1710\n",
      "\n",
      "Iteration 1711 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 24)]\n",
      "Input: 0.115 MB, Params: 76,720 (0.293 MB), Total: 0.41 MB, FLOPs: 15,177,979\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.864%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.169%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.593%\n",
      "Finished fine tuning.\n",
      "Iteration 1711/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1711\n",
      "\n",
      "Iteration 1712 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 43)]\n",
      "Input: 0.115 MB, Params: 76,337 (0.291 MB), Total: 0.41 MB, FLOPs: 15,171,129\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.864%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.441%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.441%\n",
      "Finished fine tuning.\n",
      "Iteration 1712/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1712\n",
      "\n",
      "Iteration 1713 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(11, 6)]\n",
      "Input: 0.115 MB, Params: 76,092 (0.290 MB), Total: 0.41 MB, FLOPs: 14,878,329\n",
      "Current Testing Performance - Val: Loss -0.120  Acc(top1) 63.983%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.169%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.864%\n",
      "Finished fine tuning.\n",
      "Iteration 1713/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1713\n",
      "\n",
      "Iteration 1714 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 26)]\n",
      "Input: 0.115 MB, Params: 75,343 (0.287 MB), Total: 0.40 MB, FLOPs: 14,844,813\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.017%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.746%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.746%\n",
      "Finished fine tuning.\n",
      "Iteration 1714/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1714\n",
      "\n",
      "Iteration 1715 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(18, 9)]\n",
      "Input: 0.115 MB, Params: 74,945 (0.286 MB), Total: 0.40 MB, FLOPs: 14,727,301\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.593%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.864%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.593%\n",
      "Finished fine tuning.\n",
      "Iteration 1715/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1715\n",
      "\n",
      "Iteration 1716 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 53)]\n",
      "Input: 0.115 MB, Params: 74,562 (0.284 MB), Total: 0.40 MB, FLOPs: 14,720,451\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.441%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.322%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.017%\n",
      "Finished fine tuning.\n",
      "Iteration 1716/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1716\n",
      "\n",
      "Iteration 1717 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 13)]\n",
      "Input: 0.115 MB, Params: 74,002 (0.282 MB), Total: 0.40 MB, FLOPs: 14,680,203\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.441%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.322%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.475%\n",
      "Finished fine tuning.\n",
      "Iteration 1717/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1717\n",
      "\n",
      "Iteration 1718 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(28, 34)]\n",
      "Input: 0.115 MB, Params: 73,262 (0.279 MB), Total: 0.39 MB, FLOPs: 14,647,335\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.169%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.051%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 83.475%\n",
      "Finished fine tuning.\n",
      "Iteration 1718/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1718\n",
      "\n",
      "Iteration 1719 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(35, 51)]\n",
      "Input: 0.115 MB, Params: 72,879 (0.278 MB), Total: 0.39 MB, FLOPs: 14,640,485\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.746%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.593%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.746%\n",
      "Finished fine tuning.\n",
      "Iteration 1719/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1719\n",
      "\n",
      "Iteration 1720 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(25, 10)]\n",
      "Input: 0.115 MB, Params: 72,328 (0.276 MB), Total: 0.39 MB, FLOPs: 14,600,885\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.746%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.169%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.746%\n",
      "Finished fine tuning.\n",
      "Iteration 1720/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1720\n",
      "\n",
      "Iteration 1721 of 1721 starts..\n",
      "Ranking channels.. \n",
      "Pruning channels: [(32, 23)]\n",
      "Input: 0.115 MB, Params: 71,372 (0.272 MB), Total: 0.39 MB, FLOPs: 14,583,695\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 84.746%\n",
      "Fine tuning 2 epochs to recover from prunning iteration.\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 85.593%\n",
      "Current Testing Performance - Val: Loss nan  Acc(top1) 86.017%\n",
      "Finished fine tuning.\n",
      "Iteration 1721/1723 finished in 0m15s\n",
      "Total channels prunned so far: 1721\n",
      "+----------------------------------------------------------------------------+\n",
      "+                           Pytorch Model Summary                            +\n",
      "------------------------------------------------------------------------------\n",
      "   Layer (type)       Input Shape      Output Shape    Param #      FLOPS #\n",
      "==============================================================================\n",
      "       Conv2d-1     (1, 1, 30225)     (5, 1, 15109)         45      679,905\n",
      "  BatchNorm2d-2     (5, 1, 15109)     (5, 1, 15109)         10            0\n",
      "         ReLu-3     (5, 1, 15109)     (5, 1, 15109)          0       75,545\n",
      "       Conv2d-4     (5, 1, 15109)     (32, 1, 7553)        800    6,042,400\n",
      "  BatchNorm2d-5     (32, 1, 7553)     (32, 1, 7553)         64            0\n",
      "         ReLu-6     (32, 1, 7553)     (32, 1, 7553)          0      241,696\n",
      "    MaxPool2d-7     (32, 1, 7553)      (32, 1, 151)          0      241,600\n",
      "      Permute-8      (32, 1, 151)      (1, 32, 151)          0            0\n",
      "       Conv2d-9      (1, 32, 151)     (10, 32, 151)         90      434,880\n",
      " BatchNorm2d-10     (10, 32, 151)     (10, 32, 151)         20            0\n",
      "        ReLu-11     (10, 32, 151)     (10, 32, 151)          0       48,320\n",
      "   MaxPool2d-12     (10, 32, 151)      (10, 16, 75)          0       48,000\n",
      "      Conv2d-13      (10, 16, 75)       (8, 16, 75)        720      864,000\n",
      " BatchNorm2d-14       (8, 16, 75)       (8, 16, 75)         16            0\n",
      "        ReLu-15       (8, 16, 75)       (8, 16, 75)          0        9,600\n",
      "      Conv2d-16       (8, 16, 75)      (17, 16, 75)      1,224    1,468,800\n",
      " BatchNorm2d-17      (17, 16, 75)      (17, 16, 75)         34            0\n",
      "        ReLu-18      (17, 16, 75)      (17, 16, 75)          0       20,400\n",
      "   MaxPool2d-19      (17, 16, 75)       (17, 8, 37)          0       20,128\n",
      "      Conv2d-20       (17, 8, 37)       (18, 8, 37)      2,754      815,184\n",
      " BatchNorm2d-21       (18, 8, 37)       (18, 8, 37)         36            0\n",
      "        ReLu-22       (18, 8, 37)       (18, 8, 37)          0        5,328\n",
      "      Conv2d-23       (18, 8, 37)       (27, 8, 37)      4,374    1,294,704\n",
      " BatchNorm2d-24       (27, 8, 37)       (27, 8, 37)         54            0\n",
      "        ReLu-25       (27, 8, 37)       (27, 8, 37)          0        7,992\n",
      "   MaxPool2d-26       (27, 8, 37)       (27, 4, 18)          0        7,776\n",
      "      Conv2d-27       (27, 4, 18)       (39, 4, 18)      9,477      682,344\n",
      " BatchNorm2d-28       (39, 4, 18)       (39, 4, 18)         78            0\n",
      "        ReLu-29       (39, 4, 18)       (39, 4, 18)          0        2,808\n",
      "      Conv2d-30       (39, 4, 18)       (34, 4, 18)     11,934      859,248\n",
      " BatchNorm2d-31       (34, 4, 18)       (34, 4, 18)         68            0\n",
      "        ReLu-32       (34, 4, 18)       (34, 4, 18)          0        2,448\n",
      "   MaxPool2d-33       (34, 4, 18)        (34, 2, 9)          0        2,448\n",
      "      Conv2d-34        (34, 2, 9)        (41, 2, 9)     12,546      225,828\n",
      " BatchNorm2d-35        (41, 2, 9)        (41, 2, 9)         82            0\n",
      "        ReLu-36        (41, 2, 9)        (41, 2, 9)          0          738\n",
      "      Conv2d-37        (41, 2, 9)        (72, 2, 9)     26,568      478,224\n",
      " BatchNorm2d-38        (72, 2, 9)        (72, 2, 9)        144            0\n",
      "        ReLu-39        (72, 2, 9)        (72, 2, 9)          0        1,296\n",
      "   MaxPool2d-40        (72, 2, 9)        (72, 1, 4)          0        1,152\n",
      "      Conv2d-41        (72, 1, 4)         (3, 1, 4)        216          864\n",
      " BatchNorm2d-42         (3, 1, 4)         (3, 1, 4)          6            0\n",
      "        ReLu-43         (3, 1, 4)         (3, 1, 4)          0           12\n",
      "   AvgPool2d-44         (3, 1, 4)         (3, 1, 1)          0           12\n",
      "     Flatten-45         (3, 1, 1)            (1, 3)          0            0\n",
      "      Linear-46            (1, 3)            (1, 3)         12           12\n",
      "     Softmax-47            (1, 3)            (1, 3)          0            3\n",
      "==============================================================================\n",
      "Total Params: 71,372\n",
      "Total FLOPs : 14,583,695\n",
      "------------------------------------------------------------------------------\n",
      "Input size (MB) : 0.12\n",
      "Params size (MB): 0.27\n",
      "Total size (MB) : 0.39\n",
      "------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12cbe351-bc11-4e98-89ce-6c0531393ed9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c660e0-e1c1-4f30-be4f-d8d322c93eeb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
