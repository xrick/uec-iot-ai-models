{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7cc9cb1-7673-4e90-b4c6-a32aba2e4c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys;\n",
    "import os;\n",
    "import glob;\n",
    "import math;\n",
    "import numpy as np;\n",
    "import glob;\n",
    "import random;\n",
    "import time;\n",
    "import torch;\n",
    "import torch.optim as optim;\n",
    "import torch.nn as nn;\n",
    "import json\n",
    "sys.path.append(os.getcwd());\n",
    "sys.path.append('../../');\n",
    "sys.path.append(os.path.abspath('../../../src/'));\n",
    "# sys.path.append(os.path.join(os.getcwd(), 'torch/resources'));\n",
    "import common.utils as U;\n",
    "import common.opts as opts;\n",
    "# import resources.models as models;\n",
    "import th.resources.calculator as calc;\n",
    "import common.tlopts as tlopts\n",
    "# import resources.train_generator as train_generator;\n",
    "import argparse\n",
    "from itertools import repeat\n",
    "import pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0815030-17d2-4406-b087-0409a9863de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from SharedLibs.config_utility import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62f53e33-c3ee-4c51-a448-5ebfc6da731d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reproducibility\n",
    "seed = 42;\n",
    "random.seed(seed);\n",
    "np.random.seed(seed);\n",
    "torch.manual_seed(seed);\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(seed);\n",
    "torch.backends.cudnn.deterministic = True;\n",
    "torch.backends.cudnn.benchmark = False;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d6d743ea-3384-413a-9f9e-a05dd4af34d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_acdnet = '../../../src/th/resources/pretrained_models/acdnet_20khz_trained_model_fold4_91.00.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef4db556-eeba-4d16-9306-bbcf4d98420c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ChkAndCreateSingleDir(dir_path):\n",
    "    if not pathlib.Path(dir_path).is_dir():\n",
    "        os.mkdir(dir_path);\n",
    "        print(f\"'{dir_path}' folder is created.\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "18981e2e-3bd0-4f04-91dc-a6174d0d699c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#log object\n",
    "logObj = None;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc86727a-e2c4-4ad3-aa51-7b73f675b008",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "037be559-e258-4780-9416-dd969489d029",
   "metadata": {},
   "source": [
    "## define TLTraining Generator Class\n",
    "The Class is an python iterator class for generating data for trainer to train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f9850c9d-6a7d-41ed-9244-a802f25b316a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TLGenerator():\n",
    "    #Generates data for Keras\n",
    "    def __init__(self, samples=None, labels=None, options=None, classes_dict=None):\n",
    "        random.seed(42);\n",
    "        #Initialization\n",
    "        # print(f\"length of samples:{len(samples)}\")\n",
    "        self.data = [(samples[i], labels[i]) for i in range (0, len(samples))];\n",
    "        self.opt = options;\n",
    "        self.batch_size = options.batchSize;\n",
    "        self.preprocess_funcs = self.preprocess_setup();\n",
    "        self.mapdict = classes_dict\n",
    "\n",
    "    def __len__(self):\n",
    "        #Denotes the number of batches per epoch\n",
    "        return int(np.floor(len(self.data) / self.batch_size));\n",
    "        #return len(self.samples);\n",
    "\n",
    "    def __getitem__(self, batchIndex):\n",
    "        #Generate one batch of data\n",
    "        # batchX, batchY = self.generate_batch(batchIndex);\n",
    "        batchX, batchY = self.generate_batch_select_fixed_class(batchIndex)\n",
    "        batchX = np.expand_dims(batchX, axis=1);\n",
    "        batchX = np.expand_dims(batchX, axis=3);\n",
    "        return batchX, batchY\n",
    "\n",
    "    def generate_batch(self, batchIndex):\n",
    "        #Generates data containing batch_size samples\n",
    "        sounds = [];\n",
    "        labels = [];\n",
    "        indexes = None;\n",
    "        \n",
    "        for i in range(self.batch_size):\n",
    "            # Training phase of BC learning\n",
    "            # Select two training examples\n",
    "            while True:\n",
    "                sound1, label1 = self.data[random.randint(0, len(self.data) - 1)]\n",
    "                sound2, label2 = self.data[random.randint(0, len(self.data) - 1)]\n",
    "                if label1 != label2:\n",
    "                    break\n",
    "            sound1 = self.preprocess(sound1)\n",
    "            sound2 = self.preprocess(sound2)\n",
    "\n",
    "            # Mix two examples\n",
    "            r = np.array(random.random())\n",
    "            sound = U.mix(sound1, sound2, r, self.opt.sr).astype(np.float32)\n",
    "            # print(f\"sound length after U.mix is {len(sound)}\")\n",
    "            # print(f\"nClasses:{self.opt.nClasses}, type of mapdict:{type(self.mapdict)}, type of label1:{type(label1)}\")\n",
    "            eye = np.eye(self.opt.nClasses)\n",
    "            idx1 = self.mapdict[str(label1)]- 1\n",
    "            idx2 = self.mapdict[str(label2)] - 1\n",
    "            label = (eye[idx1] * r + eye[idx2] * (1 - r)).astype(np.float32)\n",
    "            # label = (eye[label1] * r + eye[label2] * (1 - r)).astype(np.float32)\n",
    "\n",
    "            #For stronger augmentation\n",
    "            sound = U.random_gain(6)(sound).astype(np.float32)\n",
    "            # print(f\"sound length after U.random_gain is {len(sound)}\")\n",
    "            sounds.append(sound);\n",
    "            labels.append(label);\n",
    "\n",
    "        sounds = np.asarray(sounds);\n",
    "        labels = np.asarray(labels);\n",
    "        print(f\"batchIndex is {batchIndex}, total sounds is {len(sounds)}\")\n",
    "        # print(f\"labels in generate_batch is:\\n{labels}\")\n",
    "        return sounds, labels;\n",
    "\n",
    "    def generate_batch_select_fixed_class(self, batchIndex):\n",
    "        #Generates data containing batch_size samples\n",
    "        sounds = [];\n",
    "        labels = [];\n",
    "        indexes = None;\n",
    "        #two variables recording alarm and moaning sounds count\n",
    "        alarm_selected = 0;\n",
    "        moaning_selected = 0;\n",
    "        help_eng_selected = 0;\n",
    "        for i in range(self.batch_size):\n",
    "            # Training phase of BC learning\n",
    "            # Select two training examples\n",
    "            while True:\n",
    "                # print(\"enter while true\")\n",
    "                sound1, label1 = self.data[random.randint(0, len(self.data) - 1)]\n",
    "                sound2, label2 = self.data[random.randint(0, len(self.data) - 1)]\n",
    "                lbl1_int = np.int16(label1);\n",
    "                lbl2_int = np.int16(label2);\n",
    "                # print(f\"label1:{label1} and label2:{label2}\")\n",
    "                # print(f\"label1:{type(label1)} and label2:{type(label2)}\")\n",
    "                if label1 != label2:\n",
    "                    # print(\"enter first layer if\");\n",
    "                    if (lbl1_int == 52 and lbl2_int == 99) or (lbl1_int == 99 and lbl2_int ==52):\n",
    "                        # print(\"enter 52 second layer if\");\n",
    "                        # if (alarm_selected < moaning_selected) or (alarm_selected == moaning_selected):\n",
    "                        if (alarm_selected == moaning_selected) and (alarm_selected == help_eng_selected):\n",
    "                            # print(\"enter 52 third layer if\");\n",
    "                            alarm_selected += 1;\n",
    "                            # print(f\"alarm sound selected, label1:{label1}, label2:{label2}, alarm_selected:{alarm_selected}, moaning_selected:{moaning_selected}\");\n",
    "                            # print(\"perform break at 52\");\n",
    "                            break;\n",
    "                    if (lbl1_int == 56 and lbl2_int == 99) or (lbl1_int == 99 and lbl2_int == 56):\n",
    "                        # print(\"enter 56 second layer if\");\n",
    "                        # if (moaning_selected < alarm_selected) or (alarm_selected == moaning_selected):\n",
    "                        if (moaning_selected < alarm_selected) and (moaning_selected == help_eng_selected):\n",
    "                            # print(\"enter 56 third layer if\");\n",
    "                            moaning_selected += 1;\n",
    "                            # print(f\"alarm sound selected, label1:{label1}, label2:{label2}, alarm_selected:{alarm_selected}, moaning_selected:{moaning_selected}\");\n",
    "                            # print(\"perform break at 56\");\n",
    "                            break;\n",
    "                    if (lbl1_int == 71 and lbl2_int == 99) or (lbl1_int == 99 and lbl2_int == 71):\n",
    "                        # print(\"enter 56 second layer if\");\n",
    "                        if (help_eng_selected < alarm_selected) and (help_eng_selected < moaning_selected):\n",
    "                            # print(\"enter 56 third layer if\");\n",
    "                            moaning_selected += 1;\n",
    "                            # print(f\"alarm sound selected, label1:{label1}, label2:{label2}, alarm_selected:{alarm_selected}, moaning_selected:{moaning_selected}\");\n",
    "                            # print(\"perform break at 56\");\n",
    "                            break;\n",
    "            # print(f\"escape for loop\");\n",
    "            sound1 = self.preprocess(sound1)\n",
    "            sound2 = self.preprocess(sound2)\n",
    "\n",
    "            # Mix two examples\n",
    "            r = np.array(random.random());\n",
    "            #######make wanted class mix ration above 0.5##########\n",
    "            # iLbl1 = np.int16(label1);\n",
    "            # iLbl2 = np.int16(label2);\n",
    "            # r = 1.0;\n",
    "            # p_ratio1 = 0.4\n",
    "            # p_ratio2 = 0.6\n",
    "            # while True:\n",
    "            #     r = np.array(random.random());\n",
    "            #     if r > p_ratio1 and iLbl1 != 99 :\n",
    "            #         break;\n",
    "            #     if r < p_ratio2 and iLbl2 != 99 :\n",
    "            #         break;\n",
    "            #######################End#######################\n",
    "            # print(f\"r:{r}, lbl1:{label1}, lbl2:{label2}\")  \n",
    "            sound = U.mix(sound1, sound2, r, self.opt.sr).astype(np.float32)\n",
    "            eye = np.eye(self.opt.nClasses)\n",
    "            idx1 = self.mapdict[str(label1)]- 1\n",
    "            idx2 = self.mapdict[str(label2)] - 1\n",
    "            label = (eye[idx1] * r + eye[idx2] * (1 - r)).astype(np.float32)\n",
    "            \n",
    "\n",
    "            #For stronger augmentation\n",
    "            sound = U.random_gain(6)(sound).astype(np.float32)\n",
    "            # print(f\"sound length after U.random_gain is {len(sound)}\")\n",
    "            sounds.append(sound);\n",
    "            labels.append(label);\n",
    "\n",
    "        sounds = np.asarray(sounds);\n",
    "        labels = np.asarray(labels);\n",
    "        # print(f\"batchIndex is {batchIndex}, total sounds is {len(sounds)}\")\n",
    "        # print(f\"labels in generate_batch is:\\n{labels}\")\n",
    "        # print(f\"alarm_selected:{alarm_selected}, moaning_selected:{moaning_selected}\");\n",
    "        return sounds, labels;\n",
    "    \n",
    "    def preprocess_setup(self):\n",
    "        funcs = []\n",
    "        if self.opt.strongAugment:\n",
    "            funcs += [U.random_scale(1.25)]\n",
    "\n",
    "        funcs += [U.padding(self.opt.inputLength // 2),\n",
    "                  U.random_crop(self.opt.inputLength),\n",
    "                  U.normalize(32768.0)]\n",
    "        return funcs\n",
    "\n",
    "    def preprocess(self, sound):\n",
    "        for f in self.preprocess_funcs:\n",
    "            sound = f(sound)\n",
    "\n",
    "        return sound;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed1262f5-e327-4ba4-b8ea-f8570463bcaf",
   "metadata": {},
   "source": [
    "## ACDNetV2 define the acdnet model structure.\n",
    "定義原本的ACDNetV2，for載入pretrained acdnet model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f5099b20-938b-4841-85d7-fa6ee30ce834",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ACDNetV2(nn.Module):\n",
    "    def __init__(self, input_length, n_class, sr, ch_conf=None):\n",
    "        super(ACDNetV2, self).__init__();\n",
    "        self.input_length = input_length;\n",
    "        self.ch_config = ch_conf;\n",
    "\n",
    "        stride1 = 2;\n",
    "        stride2 = 2;\n",
    "        channels = 8;\n",
    "        k_size = (3, 3);\n",
    "        n_frames = (sr/1000)*10; #No of frames per 10ms\n",
    "\n",
    "        sfeb_pool_size = int(n_frames/(stride1*stride2));\n",
    "        # tfeb_pool_size = (2,2);\n",
    "        if self.ch_config is None:\n",
    "            self.ch_config = [channels, channels*8, channels*4, channels*8, channels*8, channels*16, channels*16, channels*32, channels*32, channels*64, channels*64, n_class];\n",
    "        # avg_pool_kernel_size = (1,4) if self.ch_config[1] < 64 else (2,4);\n",
    "        fcn_no_of_inputs = self.ch_config[-1];\n",
    "        conv1, bn1 = self.make_layers(1, self.ch_config[0], (1, 9), (1, stride1));\n",
    "        conv2, bn2 = self.make_layers(self.ch_config[0], self.ch_config[1], (1, 5), (1, stride2));\n",
    "        conv3, bn3 = self.make_layers(1, self.ch_config[2], k_size, padding=1);\n",
    "        conv4, bn4 = self.make_layers(self.ch_config[2], self.ch_config[3], k_size, padding=1);\n",
    "        conv5, bn5 = self.make_layers(self.ch_config[3], self.ch_config[4], k_size, padding=1);\n",
    "        conv6, bn6 = self.make_layers(self.ch_config[4], self.ch_config[5], k_size, padding=1);\n",
    "        conv7, bn7 = self.make_layers(self.ch_config[5], self.ch_config[6], k_size, padding=1);\n",
    "        conv8, bn8 = self.make_layers(self.ch_config[6], self.ch_config[7], k_size, padding=1);\n",
    "        conv9, bn9 = self.make_layers(self.ch_config[7], self.ch_config[8], k_size, padding=1);\n",
    "        conv10, bn10 = self.make_layers(self.ch_config[8], self.ch_config[9], k_size, padding=1);\n",
    "        conv11, bn11 = self.make_layers(self.ch_config[9], self.ch_config[10], k_size, padding=1);\n",
    "        conv12, bn12 = self.make_layers(self.ch_config[10], self.ch_config[11], (1, 1));\n",
    "        fcn = nn.Linear(fcn_no_of_inputs, n_class);\n",
    "        nn.init.kaiming_normal_(fcn.weight, nonlinearity='sigmoid') # kaiming with sigoid is equivalent to lecun_normal in keras\n",
    "\n",
    "        self.sfeb = nn.Sequential(\n",
    "            #Start: Filter bank\n",
    "            conv1, bn1, nn.ReLU(),\\\n",
    "            conv2, bn2, nn.ReLU(),\\\n",
    "            nn.MaxPool2d(kernel_size=(1, sfeb_pool_size))\n",
    "        );\n",
    "\n",
    "        tfeb_modules = [];\n",
    "        self.tfeb_width = int(((self.input_length / sr)*1000)/10); # 10ms frames of audio length in seconds\n",
    "        tfeb_pool_sizes = self.get_tfeb_pool_sizes(self.ch_config[1], self.tfeb_width);\n",
    "        p_index = 0;\n",
    "        for i in [3,4,6,8,10]:\n",
    "            tfeb_modules.extend([eval('conv{}'.format(i)), eval('bn{}'.format(i)), nn.ReLU()]);\n",
    "\n",
    "            if i != 3:\n",
    "                tfeb_modules.extend([eval('conv{}'.format(i+1)), eval('bn{}'.format(i+1)), nn.ReLU()]);\n",
    "\n",
    "            h, w = tfeb_pool_sizes[p_index];\n",
    "            if h>1 or w>1:\n",
    "                tfeb_modules.append(nn.MaxPool2d(kernel_size = (h,w)));\n",
    "            p_index += 1;\n",
    "\n",
    "        tfeb_modules.append(nn.Dropout(0.2));\n",
    "        tfeb_modules.extend([conv12, bn12, nn.ReLU()]);\n",
    "        h, w = tfeb_pool_sizes[-1];\n",
    "        if h>1 or w>1:\n",
    "            tfeb_modules.append(nn.AvgPool2d(kernel_size = (h,w)));\n",
    "        tfeb_modules.extend([nn.Flatten(), fcn]);\n",
    "\n",
    "        self.tfeb = nn.Sequential(*tfeb_modules);\n",
    "\n",
    "        self.output = nn.Sequential(\n",
    "            nn.Softmax(dim=1)\n",
    "        );\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.sfeb(x);\n",
    "        #swapaxes\n",
    "        x = x.permute((0, 2, 1, 3));\n",
    "        x = self.tfeb(x);\n",
    "        y = self.output[0](x);\n",
    "        return y;\n",
    "\n",
    "    def make_layers(self, in_channels, out_channels, kernel_size, stride=(1,1), padding=0, bias=False):\n",
    "        conv = nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, stride=stride, padding=padding, bias=bias);\n",
    "        nn.init.kaiming_normal_(conv.weight, nonlinearity='relu'); # kaiming with relu is equivalent to he_normal in keras\n",
    "        bn = nn.BatchNorm2d(out_channels);\n",
    "        return conv, bn;\n",
    "\n",
    "    def get_tfeb_pool_sizes(self, con2_ch, width):\n",
    "        h = self.get_tfeb_pool_size_component(con2_ch);\n",
    "        w = self.get_tfeb_pool_size_component(width);\n",
    "        # print(w);\n",
    "        pool_size = [];\n",
    "        for  (h1, w1) in zip(h, w):\n",
    "            pool_size.append((h1, w1));\n",
    "        return pool_size;\n",
    "\n",
    "    def get_tfeb_pool_size_component(self, length):\n",
    "        # print(length);\n",
    "        c = [];\n",
    "        index = 1;\n",
    "        while index <= 6:\n",
    "            if length >= 2:\n",
    "                if index == 6:\n",
    "                    c.append(length);\n",
    "                else:\n",
    "                    c.append(2);\n",
    "                    length = length // 2;\n",
    "            else:\n",
    "               c.append(1);\n",
    "\n",
    "            index += 1;\n",
    "\n",
    "        return c;\n",
    "\n",
    "def GetACDNetModel(input_len=30225, nclass=4, sr=20000, channel_config=None):\n",
    "    net = ACDNetV2(input_len, nclass, sr, ch_conf=channel_config);\n",
    "    return net;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47820f3a-2b2a-4eae-b56f-590433fef0ab",
   "metadata": {},
   "source": [
    "## load pretrained acdnet weights of 20khz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f8e74198-72bd-48f2-90a9-8f4f29b9f2be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getOpts():\n",
    "    parser = argparse.ArgumentParser(description='Transfer Learning for ACDNet');\n",
    "    parser.add_argument('--netType', default='ACDNet_TL_Model_Extend',  required=False);\n",
    "    parser.add_argument('--data', default='../datasets/processed/',  required=False);\n",
    "    parser.add_argument('--dataset', required=False, default='uec_iot', choices=['10']);\n",
    "    parser.add_argument('--BC', default=True, action='store_true', help='BC learning');\n",
    "    parser.add_argument('--strongAugment', default=True,  action='store_true', help='Add scale and gain augmentation');\n",
    "    #在ipynb中，不能使用parser.parse，要改用parser.parse_known_args()\n",
    "    opt, unknown = parser.parse_known_args();\n",
    "    \n",
    "    #Leqarning settings\n",
    "    opt.batchSize = 64;\n",
    "    opt.LR = 0.1;\n",
    "    opt.weightDecay = 5e-4#9e-3;#5e-3;#5e-2;#1e-2;#5e-4;\n",
    "    opt.momentum = 0.09;\n",
    "    opt.nEpochs = 1600;\n",
    "    opt.schedule = [0.3, 0.6, 0.9];\n",
    "    opt.warmup = 10;\n",
    "    if torch.backends.mps.is_available():\n",
    "        opt.device=\"mps\"; #for apple m2 gpu\n",
    "    elif torch.cuda.is_available():\n",
    "        opt.device=\"cuda:0\"; #for nVidia gpu\n",
    "    else:\n",
    "        opt.device=\"cpu\"\n",
    "    print(f\"***Use device:{opt.device}\");\n",
    "    # opt.device = torch.device(\"cuda:0\" if  else \"cpu\");\n",
    "    #Basic Net Settings\n",
    "    opt.nClasses = 4#50;\n",
    "    opt.nFolds = 1;\n",
    "    opt.splits = [i for i in range(1, opt.nFolds + 1)];\n",
    "    opt.sr = 20000;\n",
    "    opt.inputLength = 30225;\n",
    "    #Test data\n",
    "    opt.nCrops = 2;\n",
    "    opt.TLAcdnetConfig = [8,64,32,64,64,128,128,256,256,512,512,4];\n",
    "    return opt\n",
    "    # opt = parser.parse_args();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "82574608-e5c1-47ea-817f-c1bfa8ffba9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_layers(in_channels, out_channels, kernel_size, stride=(1,1), padding=0, bias=False):\n",
    "        conv = nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, stride=stride, padding=padding, bias=bias);\n",
    "        nn.init.kaiming_normal_(conv.weight, nonlinearity='relu'); # kaiming with relu is equivalent to he_normal in keras\n",
    "        bn = nn.BatchNorm2d(out_channels);\n",
    "        return conv, bn;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "771ea414-dd74-4897-9f3d-f7566ea543fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "ch_confing_10 = 8 * 64\n",
    "ch_n_class = 4\n",
    "fcn_no_of_inputs = 4\n",
    "# conv12, bn12 = self.make_layers(self.ch_config[10], self.ch_config[11], (1, 1));\n",
    "conv12, bn12 = make_layers(in_channels = ch_confing_10, out_channels = ch_n_class, kernel_size = (1, 1));\n",
    "fcn = nn.Linear(fcn_no_of_inputs, ch_n_class);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4f157eff-03da-4e48-9701-606b472663e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ACDNet_TL_Model_Extend(nn.Module):\n",
    "    def __init__(self, PretrainedWeights='acdnet_20khz_trained_model_fold4_91.00.pt',opt=None):\n",
    "        super(ACDNet_TL_Model_Extend, self).__init__()\n",
    "        acdnet_model = GetACDNetModel(); # load original acdnet model first, note:n_classes is 50 because original acdnet\n",
    "        # device = opt#torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.opt = opt;\n",
    "        self.ch_config = None;\n",
    "        print(f\"device is {self.opt.device}\")\n",
    "        pretrain_weight= torch.load(PretrainedWeights, map_location=torch.device(self.opt.device))['weight']\n",
    "        model_state = acdnet_model.state_dict()\n",
    "        model_state.update(pretrain_weight)\n",
    "        acdnet_model.load_state_dict(pretrain_weight, strict=False)\n",
    "        if self.ch_config is None:\n",
    "            self.ch_config = opt.TLAcdnetConfig;\n",
    "            #[channels, channels*8, channels*4, channels*8, channels*8, channels*16, channels*16, channels*32, channels*32, channels*64, channels*64, n_class];\n",
    "\n",
    "        for k, v in acdnet_model.named_parameters():\n",
    "            v.requires_grad = False\n",
    "        # print(f\"count is {count}\");\n",
    "        self.sfeb = nn.Sequential(*list(acdnet_model.children())[0])\n",
    "        tfeb_modules = []\n",
    "        tfeb_modules.extend([*list(acdnet_model.tfeb.children())[:-6]])\n",
    "        tfeb_modules.extend([conv12, bn12, nn.ReLU()]);\n",
    "        tfeb_modules.append(nn.AvgPool2d(kernel_size = (2,4)));\n",
    "        tfeb_modules.extend([nn.Flatten(), fcn]);\n",
    "        # self.retrained_layers = nn.Sequential(*list(acdnet_model.tfeb.children())[:-1])\n",
    "        # fcn_no_of_inputs = 50, n_class=10\n",
    "        # n_class=6\n",
    "        # fc = nn.Linear(50, n_class);\n",
    "        # fc.requires_grad = True\n",
    "        # tfeb_modules.extend([fc])\n",
    "        self.tfeb = nn.Sequential(*tfeb_modules)\n",
    "        self.output = nn.Sequential(\n",
    "        nn.Softmax(dim=1));\n",
    "        # print(f\"type of self.tfeb is {type(self.tfeb)}\")\n",
    "        # for k2, v2 in self.tfeb:\n",
    "        #     print(f\"k:{k}'s requires_grad is {v2.requires_grad}\");\n",
    "\n",
    "    def forward(self, x):\n",
    "        # print(f\"sfeb:\\n{list(self.sfeb.children())}\");\n",
    "        # print(f\"input x shape:{x.size()}\")\n",
    "        x = self.sfeb(x);\n",
    "        #swapaxes\n",
    "        x = x.permute((0, 2, 1, 3));\n",
    "        x = self.tfeb(x);\n",
    "        y = self.output[0](x);\n",
    "        return y;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "67639cc1-63f2-410b-8fe6-aa6b05045d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ACDNet_TL_Model_Extend_without_pretrained_weights(nn.Module):\n",
    "    def __init__(self, PretrainedWeights='acdnet_20khz_trained_model_fold4_91.00.pt',opt=None):\n",
    "        super(ACDNet_TL_Model_Extend_without_pretrained_weights, self).__init__()\n",
    "        acdnet_model = GetACDNetModel(); # load original acdnet model first, note:n_classes is 50 because original acdnet\n",
    "        # device = opt#torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.opt = opt;\n",
    "        self.ch_config = None;\n",
    "        print(f\"device is {self.opt.device}\")\n",
    "        if self.ch_config is None:\n",
    "            self.ch_config = opt.TLAcdnetConfig;\n",
    "            #[channels, channels*8, channels*4, channels*8, channels*8, channels*16, channels*16, channels*32, channels*32, channels*64, channels*64, n_class];\n",
    "        self.sfeb = nn.Sequential(*list(acdnet_model.children())[0])\n",
    "        tfeb_modules = []\n",
    "        tfeb_modules.extend([*list(acdnet_model.tfeb.children())[:-6]])\n",
    "        tfeb_modules.extend([conv12, bn12, nn.ReLU()]);\n",
    "        tfeb_modules.append(nn.AvgPool2d(kernel_size = (2,4)));\n",
    "        tfeb_modules.extend([nn.Flatten(), fcn]);\n",
    "        # self.retrained_layers = nn.Sequential(*list(acdnet_model.tfeb.children())[:-1])\n",
    "        self.tfeb = nn.Sequential(*tfeb_modules)\n",
    "        self.output = nn.Sequential(\n",
    "        nn.Softmax(dim=1));\n",
    "\n",
    "    def forward(self, x):\n",
    "        # print(f\"sfeb:\\n{list(self.sfeb.children())}\");\n",
    "        # print(f\"input x shape:{x.size()}\")\n",
    "        x = self.sfeb(x);\n",
    "        #swapaxes\n",
    "        x = x.permute((0, 2, 1, 3));\n",
    "        x = self.tfeb(x);\n",
    "        y = self.output[0](x);\n",
    "        return y;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4d89596f-04bf-4222-b23f-31ed75cd1407",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetTLACDNet(opt=None):\n",
    "    # model = ACDNet_TL_Model_Extend_without_pretrained_weights(PretrainedWeights=pretrained_acdnet, opt=opt);#ACDNet_TL_Model()\n",
    "    model = ACDNet_TL_Model_Extend_without_pretrained_weights(PretrainedWeights=None, opt=opt);\n",
    "    return model\n",
    "# def GetTLACDNet(opt=None):\n",
    "#     model = ACDNet_TL_Model_Extend(PretrainedWeights=pretrained_acdnet, opt=opt);#ACDNet_TL_Model()\n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3e62e010-cd9a-42cb-ba31-66bb71ae1ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9c3ca4f4-2d45-488d-ba0f-3466bd397cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def genDataTimeStr():\n",
    "    return datetime.today().strftime('%Y-%m-%d %H:%M:%S').replace('-',\"\").replace(' ',\"\").replace(':',\"\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "45c56d94-f01d-4b0b-8c90-85f6e29421f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n報錯訊息：\\nTypeError: can't convert np.ndarray of type numpy.object_. \\nThe only supported types are: float64, float32, float16, int64, int32, int16, int8, uint8, and bool.\\n1\\n2\\n問題描述：\\n當把np轉換成torch tensor時，\\n\\ntrainx = torch.from_numpy(np.reshape(train_x, newshape=(-1,25)))\\n1\\n解決方法：\\n由於讀入的numpy陣列裡的元素是object類型，無法將此型別轉換成tensor。\\n\\n所以，將numpy數組進行強制型別轉換成float型別（或任何pytorch支援的型別：float64, float32, float16, int64, int32, int16, int8, uint8, and bool）即可。\\n\\ntrainx = trainx.astype(float)  # numpy強制轉型\\n————————————————\\n\\n\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "報錯訊息：\n",
    "TypeError: can't convert np.ndarray of type numpy.object_. \n",
    "The only supported types are: float64, float32, float16, int64, int32, int16, int8, uint8, and bool.\n",
    "1\n",
    "2\n",
    "問題描述：\n",
    "當把np轉換成torch tensor時，\n",
    "\n",
    "trainx = torch.from_numpy(np.reshape(train_x, newshape=(-1,25)))\n",
    "1\n",
    "解決方法：\n",
    "由於讀入的numpy陣列裡的元素是object類型，無法將此型別轉換成tensor。\n",
    "\n",
    "所以，將numpy數組進行強制型別轉換成float型別（或任何pytorch支援的型別：float64, float32, float16, int64, int32, int16, int8, uint8, and bool）即可。\n",
    "\n",
    "trainx = trainx.astype(float)  # numpy強制轉型\n",
    "————————————————\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1d36f12e-f8a5-41de-bc65-95bb84e23a25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n解決RuntimeError: Input type and weight type should be the same\\n\\n\\n根據報錯資訊的意思可以推斷，這個錯誤是由輸入和權重的資料類型不一致引起的。因此解決方法很簡單，就是將輸入的資料和模型參數的資料類型統一即可。在這個例子中，有以下幾個解決方法。\\n\\n1.將輸入資料（torch.tensor 形式）轉換成FloatTensor形式，如下：\\n\\n# net_in是torch.tensor形式的输入数据\\nnet_in = net_in.float();\\n1\\n2\\n2.如果輸入資料在轉變為torch.tensor前是以numpy數組的形式儲存的，我們可以將資料提前轉變為float32形式，具體如下：\\n\\n# train_set是numpy.array形式的输入数据\\nimport numpy as np\\nX = train_set.astype(np.float32);\\n1\\n2\\n3\\n3.將模型參數類型轉換為與輸入張量（tensor）一致的型別。在這個例子裡，模型參數需轉換為DoubleTensor，如下所示：\\n\\nmodel.double()\\n1\\n可選擇以上任一方法解決這個問題。但在實際應用上需要注意，第三種解決方法會增加顯存的需求量。更多關於torch中張量（tensor）資料類型的介紹，可參考這個網頁Link。\\n————————————————\\n版权声明：本文为CSDN博主「Henry积少成多」的原创文章，遵循CC 4.0 BY-SA版权协议，转载请附上原文出处链接及本声明。\\n原文链接：https://blog.csdn.net/qq_34612816/article/details/123372456\\n'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "解決RuntimeError: Input type and weight type should be the same\n",
    "\n",
    "\n",
    "根據報錯資訊的意思可以推斷，這個錯誤是由輸入和權重的資料類型不一致引起的。因此解決方法很簡單，就是將輸入的資料和模型參數的資料類型統一即可。在這個例子中，有以下幾個解決方法。\n",
    "\n",
    "1.將輸入資料（torch.tensor 形式）轉換成FloatTensor形式，如下：\n",
    "\n",
    "# net_in是torch.tensor形式的输入数据\n",
    "net_in = net_in.float();\n",
    "1\n",
    "2\n",
    "2.如果輸入資料在轉變為torch.tensor前是以numpy數組的形式儲存的，我們可以將資料提前轉變為float32形式，具體如下：\n",
    "\n",
    "# train_set是numpy.array形式的输入数据\n",
    "import numpy as np\n",
    "X = train_set.astype(np.float32);\n",
    "1\n",
    "2\n",
    "3\n",
    "3.將模型參數類型轉換為與輸入張量（tensor）一致的型別。在這個例子裡，模型參數需轉換為DoubleTensor，如下所示：\n",
    "\n",
    "model.double()\n",
    "1\n",
    "可選擇以上任一方法解決這個問題。但在實際應用上需要注意，第三種解決方法會增加顯存的需求量。更多關於torch中張量（tensor）資料類型的介紹，可參考這個網頁Link。\n",
    "————————————————\n",
    "版权声明：本文为CSDN博主「Henry积少成多」的原创文章，遵循CC 4.0 BY-SA版权协议，转载请附上原文出处链接及本声明。\n",
    "原文链接：https://blog.csdn.net/qq_34612816/article/details/123372456\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "463a7a09-5a89-4097-b4d2-1f8e50f8b33d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TLTrainer:\n",
    "    global logObj;\n",
    "    def __init__(self, opt=None, classes_dict=None):\n",
    "        self.opt = opt;\n",
    "        self.testX = None;\n",
    "        self.testY = None;\n",
    "        self.bestAcc = 0.0;\n",
    "        self.bestAccEpoch = 0;\n",
    "        self.trainGen = getTrainGen(opt,classes_dict=classes_dict)#train_generator.setup(opt, split);\n",
    "\n",
    "    def Train(self):\n",
    "        train_start_time = time.time();\n",
    "        net = GetTLACDNet(self.opt).to(self.opt.device)#models.GetACDNetModel().to(self.opt.device);\n",
    "        #print networks parameters' require_grade value\n",
    "        for k_, v_ in net.named_parameters():\n",
    "            print(f\"{k_}:{v_.requires_grad}\")\n",
    "        print('ACDNet model has been prepared for training');\n",
    "\n",
    "        calc.summary(net, (1,1,self.opt.inputLength));\n",
    "\n",
    "        # training_text = \"Re-Training\" if self.opt.retrain else \"Training from Scratch\";\n",
    "        # print(\"{} has been started. You will see update after finishing every training epoch and validation\".format(training_text));\n",
    "\n",
    "        lossFunc = torch.nn.KLDivLoss(reduction='batchmean');\n",
    "        optimizer = optim.SGD(net.parameters(), lr=self.opt.LR, weight_decay=self.opt.weightDecay, momentum=self.opt.momentum, nesterov=True);\n",
    "\n",
    "        # self.opt.nEpochs = 1957 if self.opt.split == 4 else 2000;\n",
    "        for epochIdx in range(self.opt.nEpochs):\n",
    "            epoch_start_time = time.time();\n",
    "            optimizer.param_groups[0]['lr'] = self.__get_lr(epochIdx+1);\n",
    "            cur_lr = optimizer.param_groups[0]['lr'];\n",
    "            running_loss = 0.0;\n",
    "            running_acc = 0.0;\n",
    "            n_batches = math.ceil(len(self.trainGen.data)/self.opt.batchSize);\n",
    "            for batchIdx in range(n_batches):\n",
    "                # with torch.no_grad():\n",
    "                x,y = self.trainGen.__getitem__(batchIdx)\n",
    "                x = torch.tensor(np.moveaxis(x, 3, 1)).to(self.opt.device);\n",
    "                y = torch.tensor(y).to(self.opt.device);\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad();\n",
    "\n",
    "                # forward + backward + optimize\n",
    "                outputs = net(x);\n",
    "                running_acc += (((outputs.data.argmax(dim=1) == y.argmax(dim=1))*1).float().mean()).item();\n",
    "                loss = lossFunc(outputs.log(), y);\n",
    "                loss.backward();\n",
    "                optimizer.step();\n",
    "\n",
    "                running_loss += loss.item();\n",
    "\n",
    "            tr_acc = (running_acc / n_batches)*100;\n",
    "            tr_loss = running_loss / n_batches;\n",
    "\n",
    "            #Epoch wise validation Validation\n",
    "            epoch_train_time = time.time() - epoch_start_time;\n",
    "\n",
    "            net.eval();\n",
    "            val_acc, val_loss = self.__validate(net, lossFunc);\n",
    "            #Save best model\n",
    "            # self.__save_model(val_acc, epochIdx, net);\n",
    "            self.__save_model_refined(val_acc, tr_acc, epochIdx, net);\n",
    "            self.__on_epoch_end(epoch_start_time, epoch_train_time, epochIdx, cur_lr, tr_loss, tr_acc, val_loss, val_acc);\n",
    "\n",
    "            running_loss = 0;\n",
    "            running_acc = 0;\n",
    "            net.train();\n",
    "\n",
    "        total_time_taken = time.time() - train_start_time;\n",
    "        print(\"Execution finished in: {}\".format(U.to_hms(total_time_taken)));\n",
    "\n",
    "    def load_test_data(self):\n",
    "        # data = np.load(os.path.join(self.opt.data, self.opt.dataset, 'test_data_{}khz/fold{}_test4000.npz'.format(self.opt.sr//1000, self.opt.split)), allow_pickle=True);\n",
    "        data = np.load(self.opt.testData, allow_pickle=True);\n",
    "        print(f\"device is :{self.opt.device}\")\n",
    "        print(f\"len of Y:{len(data['y'])}\")\n",
    "        # self.testX = torch.tensor(np.moveaxis(data['x'], 3, 1)).to(self.opt.device);\n",
    "        dataX = np.moveaxis(data['x'], 3, 1).astype(np.float32);\n",
    "        self.testX = torch.tensor(dataX).to(self.opt.device);\n",
    "        self.testY = torch.tensor(data['y']).type(torch.float32).to(self.opt.device);\n",
    "\n",
    "    def __get_lr(self, epoch):\n",
    "        divide_epoch = np.array([self.opt.nEpochs * i for i in self.opt.schedule]);\n",
    "        decay = sum(epoch > divide_epoch);\n",
    "        if epoch <= self.opt.warmup:\n",
    "            decay = 1;\n",
    "        return self.opt.LR * np.power(0.1, decay);\n",
    "\n",
    "    def __get_batch(self, index):\n",
    "        x = self.trainX[index*self.opt.batchSize : (index+1)*self.opt.batchSize];\n",
    "        y = self.trainY[index*self.opt.batchSize : (index+1)*self.opt.batchSize];\n",
    "        return x.to(self.opt.device), y.to(self.opt.device);\n",
    "\n",
    "    def __validate(self, net, lossFunc):\n",
    "        if self.testX is None:\n",
    "            self.load_test_data();\n",
    "        net.eval();\n",
    "        with torch.no_grad():\n",
    "            y_pred = None;\n",
    "            batch_size = len(self.testX);#(self.opt.batchSize//self.opt.nCrops)*self.opt.nCrops;\n",
    "#             for idx in range(math.ceil(len(self.testX)/batch_size)):\n",
    "#             for idx in range(len(self.testX)):\n",
    "#             x = self.testX[idx*batch_size : (idx+1)*batch_size];\n",
    "            x = self.testX[:];\n",
    "            scores = net(x);\n",
    "            y_pred = scores.data if y_pred is None else torch.cat((y_pred, scores.data));\n",
    "            acc, loss = self.__compute_accuracy(y_pred, self.testY, lossFunc);\n",
    "#         with torch.no_grad():\n",
    "#             y_pred = None;\n",
    "#             batch_size = (self.opt.batchSize//self.opt.nCrops)*self.opt.nCrops;\n",
    "#             for idx in range(math.ceil(len(self.testX)/batch_size)):\n",
    "#                 x = self.testX[idx*batch_size : (idx+1)*batch_size];\n",
    "#                 scores = net(x);\n",
    "#                 y_pred = scores.data if y_pred is None else torch.cat((y_pred, scores.data));\n",
    "\n",
    "#             acc, loss = self.__compute_accuracy(y_pred, self.testY, lossFunc);\n",
    "        net.train();\n",
    "        return acc, loss;\n",
    "\n",
    "    #Calculating average prediction (10 crops) and final accuracy\n",
    "    def __compute_accuracy(self, y_pred, y_target, lossFunc):\n",
    "        # print(f\"shape of y_pred:{y_pred.shape}\");\n",
    "        # print(f\"shape of y_target:{y_target.shape}\");\n",
    "        with torch.no_grad():\n",
    "            #Reshape to shape theme like each sample comtains 10 samples, calculate mean and find theindices that has highest average value for each sample\n",
    "            if self.opt.nCrops == 1:\n",
    "                y_pred = y_pred.argmax(dim=1);\n",
    "                y_target = y_target.argmax(dim=1);\n",
    "            else:\n",
    "                y_pred = (y_pred.reshape(y_pred.shape[0]//self.opt.nCrops, self.opt.nCrops, y_pred.shape[1])).mean(dim=1).argmax(dim=1);\n",
    "                y_target = (y_target.reshape(y_target.shape[0]//self.opt.nCrops, self.opt.nCrops, y_target.shape[1])).mean(dim=1).argmax(dim=1);\n",
    "                print(f\"after: len of y_pred:{len(y_pred)}, len of y_target:{len(y_target)}\")\n",
    "            acc = (((y_pred==y_target)*1).float().mean()*100).item();\n",
    "            # valLossFunc = torch.nn.KLDivLoss();\n",
    "            loss = lossFunc(y_pred.float().log(), y_target.float()).item();\n",
    "            # loss = 0.0;\n",
    "        return acc, loss;\n",
    "\n",
    "    def __on_epoch_end(self, start_time, train_time, epochIdx, lr, tr_loss, tr_acc, val_loss, val_acc):\n",
    "        epoch_time = time.time() - start_time;\n",
    "        val_time = epoch_time - train_time;\n",
    "        line = 'SP-{} Epoch: {}/{} | Time: {} (Train {}  Val {}) | Train: LR {}  Loss {:.2f}  Acc {:.2f}% | Val: Loss {:.2f}  Acc(top1) {:.2f}% | HA {:.2f}@{}\\n'.format(\n",
    "            self.opt.splits, epochIdx+1, self.opt.nEpochs, U.to_hms(epoch_time), U.to_hms(train_time), U.to_hms(val_time),\n",
    "            lr, tr_loss, tr_acc, val_loss, val_acc, self.bestAcc, self.bestAccEpoch);\n",
    "        sys.stdout.write(line);\n",
    "        sys.stdout.flush();\n",
    "        logObj.write(line);\n",
    "        logObj.write(\"\\n\");\n",
    "        logObj.flush();\n",
    "\n",
    "    # def __save_model(self, acc, epochIdx, net):\n",
    "    #     print(\"__save_model is called\")\n",
    "    #     print(f\"current best Acc is {self.bestAcc}\")\n",
    "    #     print(f\"pass in acc is {acc}\")\n",
    "    #     if acc > self.bestAcc or acc > 95.0:\n",
    "    #         dir = os.getcwd();\n",
    "    #         model_name = self.opt.model_name.format(genDataTimeStr(),acc,epochIdx);\n",
    "    #         save_path = os.path.join(self.opt.modelSaveDir,model_name);\n",
    "    #         self.bestAcc = acc;\n",
    "    #         self.bestAccEpoch = epochIdx +1;\n",
    "    #         torch.save({'weight':net.state_dict(), 'config':net.ch_config}, save_path);\n",
    "    #         print(f\"model saved....., acc: {acc}\")\n",
    "    #         logObj.write(f\"save model:{model_name}, bestAcc:{self.bestAcc}, currentAcc:{acc}@{epochIdx}\");\n",
    "    #         logObj.write(\"\\n\");\n",
    "    #         logObj.flush();\n",
    "    \"\"\"\n",
    "    save_val_acc = 94.0;\n",
    "    opt.save_train_acc=77.0 \n",
    "    \"\"\"\n",
    "\n",
    "    def __save_model_refined(self, acc, train_acc, epochIdx, net):\n",
    "        if acc > self.bestAcc and acc > self.opt.first_save_acc:\n",
    "            self.bestAcc = acc;\n",
    "            self.bestAccEpoch = epochIdx +1;\n",
    "            self.__do_save_model(acc, train_acc, self.bestAccEpoch, net);\n",
    "        else:\n",
    "            if acc > self.opt.save_val_acc and train_acc > self.opt.save_train_acc: \n",
    "                self.__do_save_model(acc, train_acc, epochIdx, net);\n",
    "            else:\n",
    "                pass\n",
    "\n",
    "    def __do_save_model(self, acc, tr_acc, epochIdx, net):\n",
    "        save_model_name = self.opt.model_name.format(self.bestAcc, acc, tr_acc, epochIdx);\n",
    "        save_model_fullpath = self.opt.modelSaveDir + save_model_name;\n",
    "        print(f\"save model to {save_model_fullpath}\")\n",
    "        torch.save({'weight':net.state_dict(), 'config':net.ch_config}, save_model_fullpath);\n",
    "        logObj.write(f\"save model:{self.opt.model_name}, bestAcc:{self.bestAcc}, ValAcc:{acc}-TrAcc{tr_acc}-@{epochIdx}\");\n",
    "        logObj.write(\"\\n\");\n",
    "        logObj.flush();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ebb03c91-9d87-44bf-86d5-793e2df7fcc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTrainGen(opt=None, fold=None, classes_dict=None):\n",
    "    dataset = np.load(opt.trainData, allow_pickle=True);\n",
    "    # train_sounds = [dataset['x'][i][0] for i in range(len(dataset['x']))]\n",
    "    # train_labels = [dataset['y'][i][0] for i in range(len(dataset['y']))]\n",
    "    train_sounds = dataset['fold1'].item()['sounds']\n",
    "    train_labels = dataset['fold1'].item()['labels']\n",
    "    trainGen = TLGenerator(train_sounds, train_labels, opt, classes_dict=classes_dict);\n",
    "    return trainGen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "aaea1e6d-a35e-4f5b-9222-39f87e82069b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training_Settings={\n",
    "#     \"last_checkpoint\":\"../trained_models/\",\n",
    "#     \"last_best_acc\":90,\n",
    "#     \"last_acc_epochs\":100,\n",
    "#     \"last_acc_lr\":0.005,\n",
    "#     \"last_acc_weight_decay\":[0.3,0.6,0.9]\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a483e207-8a70-4cb7-b5dd-4b3d171ee9bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# samples:from only alarm training\\n# final acc:97.72\\n# at epochs:190\\n# opt.batchSize = 32;\\n# opt.LR = 0.1;\\n# opt.weightDecay = 5e-3;\\n# opt.momentum = 0.09;\\n# opt.nEpochs = 1000;\\n# opt.schedule = [0.3, 0.6, 0.9];\\n# opt.warmup = 10;\\n================================================\\n# template\\nfinal acc:\\nat epochs: \\nopt.batchSize = ;\\nopt.LR = 0.1;\\nopt.weightDecay = 5e-3;\\nopt.momentum = 0.05;\\nopt.nEpochs = 1000;\\nopt.schedule = [0.3, 0.6, 0.9];\\nopt.warmup = 10;\\n================================================\\nfinal acc:\\nat epochs: \\nopt.batchSize = 64;\\nopt.LR = 0.1;\\nopt.weightDecay = 5e-4;\\nopt.momentum = 0.09;\\nopt.nEpochs = 1600;\\nopt.schedule = [0.3, 0.6, 0.9];\\nopt.warmup = 10;\\n'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "# samples:from only alarm training\n",
    "# final acc:97.72\n",
    "# at epochs:190\n",
    "# opt.batchSize = 32;\n",
    "# opt.LR = 0.1;\n",
    "# opt.weightDecay = 5e-3;\n",
    "# opt.momentum = 0.09;\n",
    "# opt.nEpochs = 1000;\n",
    "# opt.schedule = [0.3, 0.6, 0.9];\n",
    "# opt.warmup = 10;\n",
    "================================================\n",
    "# template\n",
    "final acc:\n",
    "at epochs: \n",
    "opt.batchSize = ;\n",
    "opt.LR = 0.1;\n",
    "opt.weightDecay = 5e-3;\n",
    "opt.momentum = 0.05;\n",
    "opt.nEpochs = 1000;\n",
    "opt.schedule = [0.3, 0.6, 0.9];\n",
    "opt.warmup = 10;\n",
    "================================================\n",
    "final acc:\n",
    "at epochs: \n",
    "opt.batchSize = 64;\n",
    "opt.LR = 0.1;\n",
    "opt.weightDecay = 5e-4;\n",
    "opt.momentum = 0.09;\n",
    "opt.nEpochs = 1600;\n",
    "opt.schedule = [0.3, 0.6, 0.9];\n",
    "opt.warmup = 10;\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "284cdef4-593f-490d-a98f-79a3eca5f5ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    global logObj;\n",
    "    map_dict_train = {\n",
    "        '52':1, #alarm\n",
    "        '56':2,\n",
    "        '71':3,\n",
    "        '99':4, #other_sounds\n",
    "    };\n",
    "    opt = getOpts();\n",
    "    opt.sr = 20000;\n",
    "    opt.inputLength = 30225;\n",
    "    opt.first_save_acc = 73.0;\n",
    "    opt.save_val_acc = 73.0;\n",
    "    opt.save_train_acc = 85.0;\n",
    "    opt.trainer = None\n",
    "    ###office\n",
    "    # opt.trainData=\"../../../datasets/CurrentUse/generated_datasets/train/version6_office/single_fold_train_20240509143202.npz\";\n",
    "    # opt.testData=\"../../../datasets/CurrentUse/generated_datasets/val/version6_office/final_single_val_20240509144233.npz\";\n",
    "    ###home\n",
    "    opt.trainData=\"../../../../uec_iot_ai_models_datasets/generated_datasets/train/version7_madeinhome/single_fold_train_20240519222746.npz\";\n",
    "    opt.testData=\"../../../../uec_iot_ai_models_datasets/generated_datasets/val/version7_madeinhome/final_single_val_20240519223409.npz\";\n",
    "    trainStartTime = genDataTimeStr();\n",
    "    \n",
    "    opt.modelSaveDir = \"../../../trained_models/step_1_base_train/base_train_lr{}_bs{}_wd{}_{}/\".format(opt.LR, opt.batchSize, opt.weightDecay,trainStartTime);\n",
    "    if not pathlib.Path(opt.modelSaveDir).is_dir():\n",
    "        os.makedirs(opt.modelSaveDir,exist_ok=True);\n",
    "        print(f\"'{opt.modelSaveDir}' is created.\");\n",
    "    tlopts.display_info(opt)\n",
    "    opt.model_name = \"uec_model_4Classes_hacc{}_valacc_{}_tracc_{}_{}th_epoch.pt\"\n",
    "    ###\n",
    "    logSaveDir = \"./base_training_logs/\"\n",
    "    ChkAndCreateSingleDir(logSaveDir);\n",
    "    logName = \"BaseTrainLog_{}.log\".format(trainStartTime);\n",
    "    logObj = open(os.path.join(logSaveDir,logName),'w');\n",
    "    \n",
    "    print(\"Initializing TLTrainer Object.....\")\n",
    "    trainer = TLTrainer(opt,classes_dict=map_dict_train)\n",
    "    print(\"Start to training.....\")\n",
    "    trainer.Train();\n",
    "    logObj.flush();\n",
    "    logObj.close();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c46c1284-76a0-4b94-80f0-b1533d9aa283",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***Use device:mps\n",
      "'../../../trained_models/step_1_base_train/base_train_lr0.1_bs64_wd0.0005_20240520064825/' is created.\n",
      "+------------------------------+\n",
      "| ACDNet_TL_Model_Extend Sound classification\n",
      "+------------------------------+\n",
      "| dataset  : uec_iot\n",
      "| nEpochs  : 1600\n",
      "| LRInit   : 0.1\n",
      "| batchSize: 64\n",
      "| Momentum   : 0.09\n",
      "| weightDecay: 0.0005\n",
      "| schedule : [0.3, 0.6, 0.9]\n",
      "| warmup   : 10\n",
      "| nFolds: 1\n",
      "| Splits: [1]\n",
      "+------------------------------+\n",
      "Initializing TLTrainer Object.....\n",
      "Start to training.....\n",
      "device is mps\n",
      "sfeb.0.weight:True\n",
      "sfeb.1.weight:True\n",
      "sfeb.1.bias:True\n",
      "sfeb.3.weight:True\n",
      "sfeb.4.weight:True\n",
      "sfeb.4.bias:True\n",
      "tfeb.0.weight:True\n",
      "tfeb.1.weight:True\n",
      "tfeb.1.bias:True\n",
      "tfeb.4.weight:True\n",
      "tfeb.5.weight:True\n",
      "tfeb.5.bias:True\n",
      "tfeb.7.weight:True\n",
      "tfeb.8.weight:True\n",
      "tfeb.8.bias:True\n",
      "tfeb.11.weight:True\n",
      "tfeb.12.weight:True\n",
      "tfeb.12.bias:True\n",
      "tfeb.14.weight:True\n",
      "tfeb.15.weight:True\n",
      "tfeb.15.bias:True\n",
      "tfeb.18.weight:True\n",
      "tfeb.19.weight:True\n",
      "tfeb.19.bias:True\n",
      "tfeb.21.weight:True\n",
      "tfeb.22.weight:True\n",
      "tfeb.22.bias:True\n",
      "tfeb.25.weight:True\n",
      "tfeb.26.weight:True\n",
      "tfeb.26.bias:True\n",
      "tfeb.28.weight:True\n",
      "tfeb.29.weight:True\n",
      "tfeb.29.bias:True\n",
      "tfeb.33.weight:True\n",
      "tfeb.34.weight:True\n",
      "tfeb.34.bias:True\n",
      "tfeb.38.weight:True\n",
      "tfeb.38.bias:True\n",
      "ACDNet model has been prepared for training\n",
      "+----------------------------------------------------------------------------+\n",
      "+                           Pytorch Model Summary                            +\n",
      "------------------------------------------------------------------------------\n",
      "   Layer (type)       Input Shape      Output Shape    Param #      FLOPS #\n",
      "==============================================================================\n",
      "       Conv2d-1     (1, 1, 30225)     (8, 1, 15109)         72    1,087,848\n",
      "  BatchNorm2d-2     (8, 1, 15109)     (8, 1, 15109)         16            0\n",
      "         ReLu-3     (8, 1, 15109)     (8, 1, 15109)          0      120,872\n",
      "       Conv2d-4     (8, 1, 15109)     (64, 1, 7553)      2,560   19,335,680\n",
      "  BatchNorm2d-5     (64, 1, 7553)     (64, 1, 7553)        128            0\n",
      "         ReLu-6     (64, 1, 7553)     (64, 1, 7553)          0      483,392\n",
      "    MaxPool2d-7     (64, 1, 7553)      (64, 1, 151)          0      483,200\n",
      "      Permute-8      (64, 1, 151)      (1, 64, 151)          0            0\n",
      "       Conv2d-9      (1, 64, 151)     (32, 64, 151)        288    2,783,232\n",
      " BatchNorm2d-10     (32, 64, 151)     (32, 64, 151)         64            0\n",
      "        ReLu-11     (32, 64, 151)     (32, 64, 151)          0      309,248\n",
      "   MaxPool2d-12     (32, 64, 151)      (32, 32, 75)          0      307,200\n",
      "      Conv2d-13      (32, 32, 75)      (64, 32, 75)     18,432   44,236,800\n",
      " BatchNorm2d-14      (64, 32, 75)      (64, 32, 75)        128            0\n",
      "        ReLu-15      (64, 32, 75)      (64, 32, 75)          0      153,600\n",
      "      Conv2d-16      (64, 32, 75)      (64, 32, 75)     36,864   88,473,600\n",
      " BatchNorm2d-17      (64, 32, 75)      (64, 32, 75)        128            0\n",
      "        ReLu-18      (64, 32, 75)      (64, 32, 75)          0      153,600\n",
      "   MaxPool2d-19      (64, 32, 75)      (64, 16, 37)          0      151,552\n",
      "      Conv2d-20      (64, 16, 37)     (128, 16, 37)     73,728   43,646,976\n",
      " BatchNorm2d-21     (128, 16, 37)     (128, 16, 37)        256            0\n",
      "        ReLu-22     (128, 16, 37)     (128, 16, 37)          0       75,776\n",
      "      Conv2d-23     (128, 16, 37)     (128, 16, 37)    147,456   87,293,952\n",
      " BatchNorm2d-24     (128, 16, 37)     (128, 16, 37)        256            0\n",
      "        ReLu-25     (128, 16, 37)     (128, 16, 37)          0       75,776\n",
      "   MaxPool2d-26     (128, 16, 37)      (128, 8, 18)          0       73,728\n",
      "      Conv2d-27      (128, 8, 18)      (256, 8, 18)    294,912   42,467,328\n",
      " BatchNorm2d-28      (256, 8, 18)      (256, 8, 18)        512            0\n",
      "        ReLu-29      (256, 8, 18)      (256, 8, 18)          0       36,864\n",
      "      Conv2d-30      (256, 8, 18)      (256, 8, 18)    589,824   84,934,656\n",
      " BatchNorm2d-31      (256, 8, 18)      (256, 8, 18)        512            0\n",
      "        ReLu-32      (256, 8, 18)      (256, 8, 18)          0       36,864\n",
      "   MaxPool2d-33      (256, 8, 18)       (256, 4, 9)          0       36,864\n",
      "      Conv2d-34       (256, 4, 9)       (512, 4, 9)  1,179,648   42,467,328\n",
      " BatchNorm2d-35       (512, 4, 9)       (512, 4, 9)      1,024            0\n",
      "        ReLu-36       (512, 4, 9)       (512, 4, 9)          0       18,432\n",
      "      Conv2d-37       (512, 4, 9)       (512, 4, 9)  2,359,296   84,934,656\n",
      " BatchNorm2d-38       (512, 4, 9)       (512, 4, 9)      1,024            0\n",
      "        ReLu-39       (512, 4, 9)       (512, 4, 9)          0       18,432\n",
      "   MaxPool2d-40       (512, 4, 9)       (512, 2, 4)          0       16,384\n",
      "      Conv2d-41       (512, 2, 4)         (4, 2, 4)      2,048       16,384\n",
      " BatchNorm2d-42         (4, 2, 4)         (4, 2, 4)          8            0\n",
      "        ReLu-43         (4, 2, 4)         (4, 2, 4)          0           32\n",
      "   AvgPool2d-44         (4, 2, 4)         (4, 1, 1)          0           32\n",
      "     Flatten-45         (4, 1, 1)            (1, 4)          0            0\n",
      "      Linear-46            (1, 4)            (1, 4)         20           20\n",
      "     Softmax-47            (1, 4)            (1, 4)          0            4\n",
      "==============================================================================\n",
      "Total Params: 4,709,204\n",
      "Total FLOPs : 544,230,312\n",
      "------------------------------------------------------------------------------\n",
      "Input size (MB) : 0.12\n",
      "Params size (MB): 17.96\n",
      "Total size (MB) : 18.08\n",
      "------------------------------------------------------------------------------\n",
      "\n",
      "device is :mps\n",
      "len of Y:654\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 1/1600 | Time: 0m15s (Train 0m11s  Val 0m03s) | Train: LR 0.010000000000000002  Loss 0.96  Acc 46.60% | Val: Loss -0.42  Acc(top1) 43.43% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 2/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.87  Acc 49.36% | Val: Loss -0.42  Acc(top1) 43.43% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 3/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.77  Acc 50.83% | Val: Loss -0.42  Acc(top1) 43.43% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 4/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.72  Acc 51.65% | Val: Loss -0.42  Acc(top1) 43.43% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 5/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.68  Acc 50.18% | Val: Loss -0.42  Acc(top1) 43.43% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 6/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.65  Acc 48.53% | Val: Loss -0.42  Acc(top1) 43.43% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 7/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.62  Acc 50.74% | Val: Loss -0.42  Acc(top1) 43.43% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 8/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.59  Acc 48.99% | Val: Loss -0.42  Acc(top1) 43.43% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 9/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.56  Acc 50.18% | Val: Loss -0.42  Acc(top1) 43.43% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 10/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.54  Acc 48.44% | Val: Loss -0.42  Acc(top1) 43.43% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 11/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.47  Acc 51.29% | Val: Loss -0.01  Acc(top1) 45.87% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 12/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.37  Acc 61.58% | Val: Loss -0.01  Acc(top1) 46.18% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 13/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.33  Acc 64.15% | Val: Loss 0.07  Acc(top1) 40.98% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 14/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.31  Acc 61.76% | Val: Loss -0.05  Acc(top1) 50.15% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 15/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.29  Acc 65.62% | Val: Loss 0.05  Acc(top1) 44.34% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 16/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.27  Acc 68.93% | Val: Loss -0.20  Acc(top1) 46.79% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 17/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.26  Acc 68.38% | Val: Loss -0.07  Acc(top1) 50.15% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 18/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.24  Acc 70.04% | Val: Loss 0.01  Acc(top1) 47.09% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 19/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.24  Acc 68.29% | Val: Loss -0.12  Acc(top1) 53.52% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 20/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.22  Acc 69.94% | Val: Loss -0.19  Acc(top1) 57.80% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 21/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.22  Acc 70.77% | Val: Loss -0.18  Acc(top1) 58.10% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 22/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.22  Acc 71.97% | Val: Loss -0.26  Acc(top1) 58.10% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 23/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.21  Acc 73.62% | Val: Loss -0.18  Acc(top1) 58.72% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 24/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.21  Acc 71.23% | Val: Loss -0.19  Acc(top1) 59.02% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 25/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.19  Acc 75.00% | Val: Loss -0.16  Acc(top1) 57.49% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 26/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.21  Acc 72.89% | Val: Loss -0.12  Acc(top1) 55.05% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 27/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.19  Acc 72.79% | Val: Loss -0.22  Acc(top1) 60.24% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 28/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.21  Acc 71.23% | Val: Loss -0.20  Acc(top1) 59.94% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 29/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.19  Acc 74.63% | Val: Loss -0.22  Acc(top1) 59.63% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 30/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.18  Acc 74.63% | Val: Loss -0.11  Acc(top1) 54.43% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 31/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.18  Acc 74.82% | Val: Loss -0.12  Acc(top1) 54.74% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 32/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.18  Acc 75.46% | Val: Loss -0.17  Acc(top1) 57.19% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 33/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.19  Acc 76.10% | Val: Loss -0.21  Acc(top1) 59.33% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 34/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.20  Acc 75.28% | Val: Loss -0.08  Acc(top1) 51.68% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 35/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.17  Acc 79.23% | Val: Loss nan  Acc(top1) 61.47% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 36/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.18  Acc 75.83% | Val: Loss -0.13  Acc(top1) 54.13% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 37/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.18  Acc 76.84% | Val: Loss nan  Acc(top1) 61.16% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 38/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.17  Acc 78.40% | Val: Loss nan  Acc(top1) 63.91% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 39/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.18  Acc 78.31% | Val: Loss nan  Acc(top1) 64.83% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 40/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.17  Acc 79.69% | Val: Loss nan  Acc(top1) 64.83% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 41/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.17  Acc 78.68% | Val: Loss nan  Acc(top1) 63.00% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 42/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.17  Acc 78.86% | Val: Loss nan  Acc(top1) 59.02% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 43/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.18  Acc 79.04% | Val: Loss nan  Acc(top1) 61.47% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 44/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.17  Acc 77.48% | Val: Loss nan  Acc(top1) 62.08% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 45/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.17  Acc 78.03% | Val: Loss nan  Acc(top1) 63.91% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 46/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.17  Acc 78.58% | Val: Loss nan  Acc(top1) 66.06% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 47/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.16  Acc 78.12% | Val: Loss nan  Acc(top1) 63.91% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 48/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.16  Acc 79.14% | Val: Loss nan  Acc(top1) 64.22% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 49/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.16  Acc 78.58% | Val: Loss nan  Acc(top1) 63.91% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 50/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.16  Acc 79.60% | Val: Loss nan  Acc(top1) 57.49% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 51/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.16  Acc 77.94% | Val: Loss nan  Acc(top1) 61.16% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 52/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.17  Acc 79.32% | Val: Loss -0.23  Acc(top1) 61.16% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 53/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.17  Acc 79.96% | Val: Loss nan  Acc(top1) 65.75% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 54/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.17  Acc 79.60% | Val: Loss nan  Acc(top1) 58.41% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 55/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.17  Acc 79.04% | Val: Loss nan  Acc(top1) 65.75% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 56/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.15  Acc 78.12% | Val: Loss nan  Acc(top1) 64.53% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 57/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.16  Acc 78.77% | Val: Loss nan  Acc(top1) 65.75% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 58/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.14  Acc 81.62% | Val: Loss nan  Acc(top1) 65.75% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 59/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.16  Acc 81.53% | Val: Loss nan  Acc(top1) 66.97% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 60/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.15  Acc 79.32% | Val: Loss nan  Acc(top1) 65.44% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 61/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.15  Acc 81.16% | Val: Loss nan  Acc(top1) 60.55% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 62/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.16  Acc 80.33% | Val: Loss nan  Acc(top1) 63.91% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 63/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.16  Acc 80.24% | Val: Loss nan  Acc(top1) 61.77% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 64/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.16  Acc 80.51% | Val: Loss nan  Acc(top1) 65.44% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 65/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.16  Acc 80.24% | Val: Loss nan  Acc(top1) 66.06% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 66/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.15  Acc 81.16% | Val: Loss nan  Acc(top1) 66.67% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 67/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.17  Acc 78.77% | Val: Loss nan  Acc(top1) 65.44% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 68/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.15  Acc 80.24% | Val: Loss nan  Acc(top1) 63.91% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 69/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.15  Acc 81.89% | Val: Loss nan  Acc(top1) 61.47% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 70/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.17  Acc 78.95% | Val: Loss nan  Acc(top1) 65.14% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 71/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.14  Acc 81.99% | Val: Loss nan  Acc(top1) 68.20% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 72/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.15  Acc 79.96% | Val: Loss nan  Acc(top1) 63.61% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 73/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.14  Acc 83.36% | Val: Loss nan  Acc(top1) 66.36% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 74/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.14  Acc 81.62% | Val: Loss nan  Acc(top1) 67.58% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 75/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.15  Acc 79.87% | Val: Loss nan  Acc(top1) 64.53% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 76/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.15  Acc 80.70% | Val: Loss nan  Acc(top1) 68.81% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 77/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.14  Acc 81.62% | Val: Loss nan  Acc(top1) 66.67% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 78/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.14  Acc 82.35% | Val: Loss nan  Acc(top1) 63.91% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 79/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.16  Acc 80.97% | Val: Loss nan  Acc(top1) 65.14% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 80/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.14  Acc 83.64% | Val: Loss nan  Acc(top1) 68.50% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 81/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.15  Acc 82.44% | Val: Loss nan  Acc(top1) 65.44% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 82/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.14  Acc 80.97% | Val: Loss nan  Acc(top1) 67.28% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 83/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.13  Acc 84.93% | Val: Loss nan  Acc(top1) 66.36% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 84/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.13  Acc 83.00% | Val: Loss nan  Acc(top1) 65.75% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 85/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.13  Acc 82.08% | Val: Loss nan  Acc(top1) 62.08% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 86/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.14  Acc 83.09% | Val: Loss nan  Acc(top1) 68.81% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 87/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.14  Acc 81.99% | Val: Loss nan  Acc(top1) 65.75% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 88/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.15  Acc 80.88% | Val: Loss nan  Acc(top1) 70.95% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 89/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.13  Acc 83.46% | Val: Loss nan  Acc(top1) 64.22% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 90/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.15  Acc 81.43% | Val: Loss nan  Acc(top1) 67.28% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 91/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.14  Acc 84.38% | Val: Loss nan  Acc(top1) 63.61% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 92/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.13  Acc 83.09% | Val: Loss nan  Acc(top1) 65.75% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 93/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.14  Acc 81.25% | Val: Loss nan  Acc(top1) 64.83% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 94/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.12  Acc 83.27% | Val: Loss nan  Acc(top1) 63.61% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 95/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.14  Acc 82.26% | Val: Loss nan  Acc(top1) 70.03% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 96/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.12  Acc 84.19% | Val: Loss nan  Acc(top1) 67.58% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 97/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.14  Acc 82.26% | Val: Loss nan  Acc(top1) 67.58% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 98/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.14  Acc 82.63% | Val: Loss nan  Acc(top1) 66.06% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 99/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.13  Acc 82.90% | Val: Loss nan  Acc(top1) 67.28% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 100/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.14  Acc 82.63% | Val: Loss nan  Acc(top1) 69.11% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 101/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.14  Acc 81.71% | Val: Loss nan  Acc(top1) 67.28% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 102/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.14  Acc 83.36% | Val: Loss -0.22  Acc(top1) 62.08% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 103/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.14  Acc 83.36% | Val: Loss nan  Acc(top1) 64.22% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 104/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.13  Acc 82.63% | Val: Loss nan  Acc(top1) 66.67% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 105/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.11  Acc 84.38% | Val: Loss nan  Acc(top1) 66.36% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 106/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.11  Acc 85.75% | Val: Loss nan  Acc(top1) 66.36% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 107/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.14  Acc 85.48% | Val: Loss nan  Acc(top1) 64.83% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 108/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.12  Acc 84.10% | Val: Loss nan  Acc(top1) 63.91% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 109/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.11  Acc 84.83% | Val: Loss nan  Acc(top1) 68.81% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 110/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.13  Acc 83.00% | Val: Loss nan  Acc(top1) 67.28% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 111/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.13  Acc 83.64% | Val: Loss nan  Acc(top1) 67.28% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 112/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.15  Acc 81.89% | Val: Loss nan  Acc(top1) 67.58% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 113/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.12  Acc 84.01% | Val: Loss nan  Acc(top1) 66.97% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 114/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.13  Acc 82.72% | Val: Loss nan  Acc(top1) 69.42% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 115/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.13  Acc 82.90% | Val: Loss nan  Acc(top1) 64.22% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 116/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.14  Acc 83.55% | Val: Loss nan  Acc(top1) 67.58% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 117/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.13  Acc 83.09% | Val: Loss nan  Acc(top1) 65.75% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 118/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.12  Acc 84.10% | Val: Loss nan  Acc(top1) 63.61% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 119/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.14  Acc 84.19% | Val: Loss nan  Acc(top1) 65.14% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 120/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.13  Acc 84.56% | Val: Loss nan  Acc(top1) 67.28% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 121/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.13  Acc 83.92% | Val: Loss nan  Acc(top1) 64.53% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 122/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.11  Acc 85.57% | Val: Loss nan  Acc(top1) 65.14% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 123/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.13  Acc 84.56% | Val: Loss nan  Acc(top1) 65.14% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 124/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.12  Acc 85.57% | Val: Loss nan  Acc(top1) 67.28% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 125/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.12  Acc 85.66% | Val: Loss nan  Acc(top1) 65.75% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 126/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.12  Acc 85.29% | Val: Loss nan  Acc(top1) 66.97% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 127/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.12  Acc 85.48% | Val: Loss nan  Acc(top1) 65.75% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 128/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.11  Acc 86.95% | Val: Loss nan  Acc(top1) 63.61% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 129/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.12  Acc 84.28% | Val: Loss nan  Acc(top1) 66.36% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 130/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.14  Acc 84.01% | Val: Loss nan  Acc(top1) 67.89% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 131/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.13  Acc 82.90% | Val: Loss nan  Acc(top1) 67.89% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 132/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.13  Acc 84.38% | Val: Loss nan  Acc(top1) 62.39% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 133/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.12  Acc 85.11% | Val: Loss nan  Acc(top1) 67.28% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 134/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.12  Acc 81.43% | Val: Loss nan  Acc(top1) 66.97% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 135/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.13  Acc 85.48% | Val: Loss nan  Acc(top1) 63.00% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 136/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.13  Acc 83.36% | Val: Loss nan  Acc(top1) 64.53% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 137/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.12  Acc 84.65% | Val: Loss nan  Acc(top1) 66.97% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 138/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.11  Acc 85.75% | Val: Loss nan  Acc(top1) 66.97% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 139/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.12  Acc 85.02% | Val: Loss nan  Acc(top1) 65.44% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 140/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.13  Acc 83.73% | Val: Loss nan  Acc(top1) 63.91% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 141/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.13  Acc 84.01% | Val: Loss nan  Acc(top1) 64.83% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 142/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.13  Acc 84.74% | Val: Loss nan  Acc(top1) 65.75% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 143/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.13  Acc 82.90% | Val: Loss nan  Acc(top1) 63.30% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 144/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.11  Acc 86.03% | Val: Loss nan  Acc(top1) 60.55% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 145/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.13  Acc 83.00% | Val: Loss nan  Acc(top1) 66.67% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 146/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.11  Acc 85.48% | Val: Loss -0.23  Acc(top1) 62.39% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 147/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.12  Acc 85.29% | Val: Loss nan  Acc(top1) 66.06% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 148/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.12  Acc 86.03% | Val: Loss nan  Acc(top1) 66.06% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 149/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.11  Acc 86.49% | Val: Loss nan  Acc(top1) 67.89% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 150/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.12  Acc 84.10% | Val: Loss nan  Acc(top1) 63.30% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 151/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.11  Acc 85.20% | Val: Loss nan  Acc(top1) 68.20% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 152/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.12  Acc 85.20% | Val: Loss nan  Acc(top1) 63.30% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 153/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.12  Acc 83.55% | Val: Loss nan  Acc(top1) 63.61% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 154/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.12  Acc 85.57% | Val: Loss nan  Acc(top1) 65.14% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 155/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.12  Acc 84.93% | Val: Loss nan  Acc(top1) 63.30% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 156/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.12  Acc 86.76% | Val: Loss nan  Acc(top1) 66.06% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 157/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.12  Acc 85.48% | Val: Loss nan  Acc(top1) 68.20% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 158/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.11  Acc 83.82% | Val: Loss nan  Acc(top1) 68.50% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 159/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.11  Acc 86.67% | Val: Loss nan  Acc(top1) 66.67% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 160/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.12  Acc 85.94% | Val: Loss nan  Acc(top1) 66.67% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 161/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.11  Acc 84.83% | Val: Loss nan  Acc(top1) 64.53% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 162/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.13  Acc 83.64% | Val: Loss nan  Acc(top1) 69.72% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 163/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.12  Acc 86.21% | Val: Loss nan  Acc(top1) 67.58% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 164/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.13  Acc 84.93% | Val: Loss nan  Acc(top1) 63.61% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 165/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.11  Acc 86.03% | Val: Loss nan  Acc(top1) 63.91% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 166/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.11  Acc 85.66% | Val: Loss nan  Acc(top1) 67.28% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 167/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.13  Acc 85.29% | Val: Loss nan  Acc(top1) 64.83% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 168/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.12  Acc 84.19% | Val: Loss nan  Acc(top1) 65.75% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 169/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.12  Acc 85.39% | Val: Loss nan  Acc(top1) 63.30% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 170/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.11  Acc 85.85% | Val: Loss nan  Acc(top1) 65.44% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 171/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.12  Acc 84.56% | Val: Loss nan  Acc(top1) 67.58% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 172/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.11  Acc 86.03% | Val: Loss nan  Acc(top1) 63.30% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 173/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.12  Acc 85.75% | Val: Loss nan  Acc(top1) 66.97% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 174/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.13  Acc 84.56% | Val: Loss nan  Acc(top1) 65.14% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 175/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.11  Acc 85.85% | Val: Loss nan  Acc(top1) 64.83% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 176/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.11  Acc 84.83% | Val: Loss nan  Acc(top1) 67.89% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 177/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.12  Acc 83.64% | Val: Loss nan  Acc(top1) 65.44% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 178/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.12  Acc 84.93% | Val: Loss nan  Acc(top1) 64.53% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 179/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.12  Acc 85.29% | Val: Loss nan  Acc(top1) 66.97% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 180/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.12  Acc 85.66% | Val: Loss nan  Acc(top1) 64.83% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 181/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.12  Acc 86.21% | Val: Loss nan  Acc(top1) 65.14% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 182/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.12  Acc 86.58% | Val: Loss nan  Acc(top1) 62.39% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 183/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.11  Acc 84.38% | Val: Loss nan  Acc(top1) 72.48% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 184/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.11  Acc 84.83% | Val: Loss nan  Acc(top1) 63.61% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 185/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.11  Acc 85.66% | Val: Loss nan  Acc(top1) 67.89% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 186/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.11  Acc 86.67% | Val: Loss nan  Acc(top1) 67.89% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 187/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.10  Acc 87.68% | Val: Loss nan  Acc(top1) 66.97% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 188/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.11  Acc 85.48% | Val: Loss nan  Acc(top1) 66.06% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 189/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.12  Acc 86.12% | Val: Loss nan  Acc(top1) 67.28% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 190/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.11  Acc 87.68% | Val: Loss nan  Acc(top1) 67.28% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 191/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.10  Acc 87.50% | Val: Loss nan  Acc(top1) 64.53% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 192/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.11  Acc 84.47% | Val: Loss nan  Acc(top1) 63.30% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 193/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.11  Acc 85.75% | Val: Loss nan  Acc(top1) 66.06% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 194/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.11  Acc 85.85% | Val: Loss nan  Acc(top1) 66.36% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 195/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.13  Acc 85.85% | Val: Loss nan  Acc(top1) 64.53% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 196/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.12  Acc 85.94% | Val: Loss nan  Acc(top1) 67.89% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 197/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.10  Acc 88.79% | Val: Loss nan  Acc(top1) 63.91% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 198/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.12  Acc 85.66% | Val: Loss nan  Acc(top1) 67.58% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 199/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.11  Acc 86.31% | Val: Loss nan  Acc(top1) 67.89% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 200/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.11  Acc 86.12% | Val: Loss nan  Acc(top1) 70.03% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 201/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.11  Acc 85.75% | Val: Loss nan  Acc(top1) 65.14% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 202/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.10  Acc 87.22% | Val: Loss nan  Acc(top1) 65.75% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 203/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.13  Acc 84.83% | Val: Loss nan  Acc(top1) 63.91% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 204/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.13  Acc 86.31% | Val: Loss nan  Acc(top1) 65.14% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 205/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.12  Acc 85.02% | Val: Loss nan  Acc(top1) 63.00% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 206/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.11  Acc 85.94% | Val: Loss nan  Acc(top1) 66.06% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 207/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.13  Acc 84.47% | Val: Loss nan  Acc(top1) 69.11% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 208/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.10  Acc 87.13% | Val: Loss nan  Acc(top1) 70.34% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 209/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.12  Acc 85.20% | Val: Loss nan  Acc(top1) 64.83% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 210/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.11  Acc 85.11% | Val: Loss nan  Acc(top1) 68.20% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 211/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.11  Acc 87.04% | Val: Loss nan  Acc(top1) 66.67% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 212/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.11  Acc 85.94% | Val: Loss nan  Acc(top1) 66.36% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 213/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.11  Acc 86.49% | Val: Loss nan  Acc(top1) 68.50% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 214/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.11  Acc 86.31% | Val: Loss nan  Acc(top1) 66.06% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 215/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.11  Acc 86.58% | Val: Loss nan  Acc(top1) 65.75% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 216/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.12  Acc 85.02% | Val: Loss nan  Acc(top1) 66.06% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 217/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.11  Acc 84.28% | Val: Loss nan  Acc(top1) 67.58% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 218/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.10  Acc 86.95% | Val: Loss nan  Acc(top1) 67.28% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 219/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.11  Acc 87.22% | Val: Loss nan  Acc(top1) 65.44% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 220/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.11  Acc 86.21% | Val: Loss nan  Acc(top1) 67.28% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 221/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.11  Acc 86.03% | Val: Loss nan  Acc(top1) 67.89% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 222/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.11  Acc 85.94% | Val: Loss nan  Acc(top1) 68.50% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 223/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.10  Acc 86.21% | Val: Loss nan  Acc(top1) 66.97% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 224/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.13  Acc 86.95% | Val: Loss nan  Acc(top1) 65.14% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 225/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.11  Acc 86.12% | Val: Loss nan  Acc(top1) 65.14% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 226/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.10  Acc 86.21% | Val: Loss nan  Acc(top1) 63.30% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 227/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.11  Acc 86.40% | Val: Loss nan  Acc(top1) 65.14% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 228/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.12  Acc 82.63% | Val: Loss nan  Acc(top1) 65.44% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 229/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.10  Acc 85.57% | Val: Loss nan  Acc(top1) 65.75% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 230/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.12  Acc 87.78% | Val: Loss nan  Acc(top1) 67.58% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 231/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.10  Acc 86.49% | Val: Loss nan  Acc(top1) 67.89% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 232/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.10  Acc 86.21% | Val: Loss nan  Acc(top1) 67.58% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 233/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.10  Acc 87.87% | Val: Loss nan  Acc(top1) 67.89% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 234/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.11  Acc 86.40% | Val: Loss nan  Acc(top1) 65.44% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 235/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.11  Acc 87.96% | Val: Loss nan  Acc(top1) 70.03% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 236/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.10  Acc 85.75% | Val: Loss nan  Acc(top1) 64.83% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 237/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.10  Acc 89.15% | Val: Loss nan  Acc(top1) 64.53% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 238/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.11  Acc 87.41% | Val: Loss nan  Acc(top1) 72.48% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 239/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.11  Acc 85.75% | Val: Loss nan  Acc(top1) 67.58% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 240/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.11  Acc 86.31% | Val: Loss nan  Acc(top1) 64.83% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 241/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.10  Acc 83.73% | Val: Loss nan  Acc(top1) 66.36% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 242/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.11  Acc 86.95% | Val: Loss nan  Acc(top1) 69.42% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 243/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.11  Acc 87.22% | Val: Loss nan  Acc(top1) 64.22% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 244/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.11  Acc 86.86% | Val: Loss nan  Acc(top1) 62.69% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 245/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.10  Acc 86.12% | Val: Loss nan  Acc(top1) 63.91% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 246/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.11  Acc 85.20% | Val: Loss nan  Acc(top1) 69.42% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 247/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.09  Acc 87.32% | Val: Loss nan  Acc(top1) 69.11% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 248/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.10  Acc 88.42% | Val: Loss nan  Acc(top1) 63.91% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 249/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.11  Acc 87.78% | Val: Loss nan  Acc(top1) 67.28% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 250/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.10  Acc 88.05% | Val: Loss nan  Acc(top1) 67.58% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 251/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.10  Acc 86.40% | Val: Loss nan  Acc(top1) 68.20% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 252/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.12  Acc 87.32% | Val: Loss nan  Acc(top1) 68.81% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 253/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.10  Acc 86.03% | Val: Loss nan  Acc(top1) 69.11% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 254/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.10  Acc 86.76% | Val: Loss nan  Acc(top1) 68.50% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 255/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.09  Acc 88.69% | Val: Loss nan  Acc(top1) 66.36% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 256/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.10  Acc 88.51% | Val: Loss nan  Acc(top1) 67.89% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 257/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.11  Acc 85.66% | Val: Loss nan  Acc(top1) 66.67% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 258/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.09  Acc 87.59% | Val: Loss nan  Acc(top1) 66.97% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 259/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.11  Acc 85.20% | Val: Loss nan  Acc(top1) 68.50% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 260/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.10  Acc 88.51% | Val: Loss nan  Acc(top1) 67.58% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 261/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.10  Acc 86.95% | Val: Loss nan  Acc(top1) 67.28% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 262/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.11  Acc 86.40% | Val: Loss nan  Acc(top1) 69.11% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 263/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.11  Acc 86.40% | Val: Loss nan  Acc(top1) 66.67% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 264/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.11  Acc 86.86% | Val: Loss nan  Acc(top1) 64.22% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 265/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.10  Acc 87.68% | Val: Loss nan  Acc(top1) 66.97% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 266/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.10  Acc 86.21% | Val: Loss nan  Acc(top1) 64.53% | HA 0.00@0\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "save model to ../../../trained_models/step_1_base_train/base_train_lr0.1_bs64_wd0.0005_20240520064825/uec_model_4Classes_hacc73.39449310302734_valacc_73.39449310302734_tracc_87.13235294117648_267th_epoch.pt\n",
      "SP-[1] Epoch: 267/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.11  Acc 87.13% | Val: Loss nan  Acc(top1) 73.39% | HA 73.39@267\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 268/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.10  Acc 87.87% | Val: Loss nan  Acc(top1) 68.81% | HA 73.39@267\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 269/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.11  Acc 87.32% | Val: Loss nan  Acc(top1) 65.44% | HA 73.39@267\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 270/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.10  Acc 85.94% | Val: Loss nan  Acc(top1) 67.58% | HA 73.39@267\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 271/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.11  Acc 86.86% | Val: Loss nan  Acc(top1) 67.89% | HA 73.39@267\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 272/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.10  Acc 85.66% | Val: Loss nan  Acc(top1) 67.89% | HA 73.39@267\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 273/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.10  Acc 87.04% | Val: Loss nan  Acc(top1) 67.89% | HA 73.39@267\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 274/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.10  Acc 88.60% | Val: Loss nan  Acc(top1) 65.44% | HA 73.39@267\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 275/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.10  Acc 88.05% | Val: Loss nan  Acc(top1) 63.00% | HA 73.39@267\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 276/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.09  Acc 89.61% | Val: Loss nan  Acc(top1) 67.28% | HA 73.39@267\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 277/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.10  Acc 87.04% | Val: Loss nan  Acc(top1) 69.11% | HA 73.39@267\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 278/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.10  Acc 86.67% | Val: Loss nan  Acc(top1) 66.97% | HA 73.39@267\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 279/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.10  Acc 87.41% | Val: Loss nan  Acc(top1) 63.61% | HA 73.39@267\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 280/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.10  Acc 87.13% | Val: Loss nan  Acc(top1) 64.83% | HA 73.39@267\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 281/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.10  Acc 87.32% | Val: Loss nan  Acc(top1) 65.14% | HA 73.39@267\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 282/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.09  Acc 88.51% | Val: Loss nan  Acc(top1) 67.89% | HA 73.39@267\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 283/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.10  Acc 87.13% | Val: Loss nan  Acc(top1) 72.17% | HA 73.39@267\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 284/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.10  Acc 86.12% | Val: Loss nan  Acc(top1) 68.50% | HA 73.39@267\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 285/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.11  Acc 87.22% | Val: Loss nan  Acc(top1) 66.97% | HA 73.39@267\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 286/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.11  Acc 86.40% | Val: Loss nan  Acc(top1) 64.83% | HA 73.39@267\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 287/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.09  Acc 87.22% | Val: Loss nan  Acc(top1) 66.97% | HA 73.39@267\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 288/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.09  Acc 88.42% | Val: Loss nan  Acc(top1) 65.14% | HA 73.39@267\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 289/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.11  Acc 85.29% | Val: Loss nan  Acc(top1) 64.53% | HA 73.39@267\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 290/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.11  Acc 87.59% | Val: Loss nan  Acc(top1) 70.64% | HA 73.39@267\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 291/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.10  Acc 86.58% | Val: Loss nan  Acc(top1) 69.72% | HA 73.39@267\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 292/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.09  Acc 88.69% | Val: Loss nan  Acc(top1) 66.06% | HA 73.39@267\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 293/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.10  Acc 88.05% | Val: Loss nan  Acc(top1) 66.97% | HA 73.39@267\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 294/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.11  Acc 85.75% | Val: Loss nan  Acc(top1) 69.11% | HA 73.39@267\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 295/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.10  Acc 87.96% | Val: Loss nan  Acc(top1) 64.53% | HA 73.39@267\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 296/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.10  Acc 86.49% | Val: Loss nan  Acc(top1) 70.64% | HA 73.39@267\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 297/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.10  Acc 85.85% | Val: Loss nan  Acc(top1) 69.11% | HA 73.39@267\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 298/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.10  Acc 87.41% | Val: Loss nan  Acc(top1) 65.44% | HA 73.39@267\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 299/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.10  Acc 87.13% | Val: Loss nan  Acc(top1) 69.11% | HA 73.39@267\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 300/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.11  Acc 87.87% | Val: Loss nan  Acc(top1) 67.28% | HA 73.39@267\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 301/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.10  Acc 85.39% | Val: Loss nan  Acc(top1) 64.83% | HA 73.39@267\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 302/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.09  Acc 87.41% | Val: Loss nan  Acc(top1) 65.44% | HA 73.39@267\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 303/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.09  Acc 87.22% | Val: Loss nan  Acc(top1) 69.72% | HA 73.39@267\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 304/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.08  Acc 87.78% | Val: Loss nan  Acc(top1) 67.28% | HA 73.39@267\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 305/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.10  Acc 87.13% | Val: Loss nan  Acc(top1) 64.53% | HA 73.39@267\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 306/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.11  Acc 85.66% | Val: Loss nan  Acc(top1) 70.95% | HA 73.39@267\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 307/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.10  Acc 87.50% | Val: Loss nan  Acc(top1) 68.50% | HA 73.39@267\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 308/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.12  Acc 85.57% | Val: Loss nan  Acc(top1) 66.06% | HA 73.39@267\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 309/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.09  Acc 88.60% | Val: Loss nan  Acc(top1) 67.58% | HA 73.39@267\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 310/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.10  Acc 86.58% | Val: Loss nan  Acc(top1) 67.28% | HA 73.39@267\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 311/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.10  Acc 85.66% | Val: Loss nan  Acc(top1) 69.11% | HA 73.39@267\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 312/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.11  Acc 87.04% | Val: Loss nan  Acc(top1) 67.58% | HA 73.39@267\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 313/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.10  Acc 86.76% | Val: Loss nan  Acc(top1) 63.00% | HA 73.39@267\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 314/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.10  Acc 88.69% | Val: Loss nan  Acc(top1) 69.11% | HA 73.39@267\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 315/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.09  Acc 86.12% | Val: Loss nan  Acc(top1) 67.89% | HA 73.39@267\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 316/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.10  Acc 87.50% | Val: Loss nan  Acc(top1) 66.06% | HA 73.39@267\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 317/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.10  Acc 85.85% | Val: Loss nan  Acc(top1) 66.06% | HA 73.39@267\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 318/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.09  Acc 88.24% | Val: Loss nan  Acc(top1) 65.44% | HA 73.39@267\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 319/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.10  Acc 87.87% | Val: Loss nan  Acc(top1) 64.22% | HA 73.39@267\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 320/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.12  Acc 87.22% | Val: Loss nan  Acc(top1) 63.61% | HA 73.39@267\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 321/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.10  Acc 87.50% | Val: Loss nan  Acc(top1) 72.17% | HA 73.39@267\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 322/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.10  Acc 88.05% | Val: Loss nan  Acc(top1) 67.28% | HA 73.39@267\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 323/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.09  Acc 88.33% | Val: Loss nan  Acc(top1) 64.53% | HA 73.39@267\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 324/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.11  Acc 89.15% | Val: Loss nan  Acc(top1) 67.28% | HA 73.39@267\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 325/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.10  Acc 86.40% | Val: Loss nan  Acc(top1) 68.20% | HA 73.39@267\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 326/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.10  Acc 85.20% | Val: Loss nan  Acc(top1) 64.22% | HA 73.39@267\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 327/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.09  Acc 87.96% | Val: Loss nan  Acc(top1) 68.20% | HA 73.39@267\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 328/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.08  Acc 87.78% | Val: Loss nan  Acc(top1) 66.06% | HA 73.39@267\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 329/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.09  Acc 88.60% | Val: Loss nan  Acc(top1) 72.48% | HA 73.39@267\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 330/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.11  Acc 87.59% | Val: Loss nan  Acc(top1) 63.61% | HA 73.39@267\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 331/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.11  Acc 88.05% | Val: Loss nan  Acc(top1) 68.20% | HA 73.39@267\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 332/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.10  Acc 87.13% | Val: Loss nan  Acc(top1) 70.95% | HA 73.39@267\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 333/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.09  Acc 88.24% | Val: Loss nan  Acc(top1) 63.61% | HA 73.39@267\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 334/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.09  Acc 88.51% | Val: Loss nan  Acc(top1) 67.28% | HA 73.39@267\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 335/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.09  Acc 88.60% | Val: Loss nan  Acc(top1) 70.03% | HA 73.39@267\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 336/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.10  Acc 87.04% | Val: Loss nan  Acc(top1) 69.72% | HA 73.39@267\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 337/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.10  Acc 86.40% | Val: Loss nan  Acc(top1) 64.22% | HA 73.39@267\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 338/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.10  Acc 86.58% | Val: Loss nan  Acc(top1) 71.87% | HA 73.39@267\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 339/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.09  Acc 86.76% | Val: Loss nan  Acc(top1) 70.64% | HA 73.39@267\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 340/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.09  Acc 88.60% | Val: Loss nan  Acc(top1) 68.20% | HA 73.39@267\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 341/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.09  Acc 87.41% | Val: Loss nan  Acc(top1) 67.58% | HA 73.39@267\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 342/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.10  Acc 87.22% | Val: Loss nan  Acc(top1) 68.20% | HA 73.39@267\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 343/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.10  Acc 87.13% | Val: Loss nan  Acc(top1) 64.22% | HA 73.39@267\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 344/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.10  Acc 88.33% | Val: Loss nan  Acc(top1) 65.14% | HA 73.39@267\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 345/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.11  Acc 86.95% | Val: Loss nan  Acc(top1) 65.44% | HA 73.39@267\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 346/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.10  Acc 87.50% | Val: Loss nan  Acc(top1) 67.89% | HA 73.39@267\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 347/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.10  Acc 87.22% | Val: Loss nan  Acc(top1) 67.28% | HA 73.39@267\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 348/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.10  Acc 88.14% | Val: Loss nan  Acc(top1) 67.28% | HA 73.39@267\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 349/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.11  Acc 88.05% | Val: Loss nan  Acc(top1) 69.11% | HA 73.39@267\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 350/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.09  Acc 87.41% | Val: Loss nan  Acc(top1) 65.44% | HA 73.39@267\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 351/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.09  Acc 87.04% | Val: Loss nan  Acc(top1) 69.11% | HA 73.39@267\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 352/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.09  Acc 88.14% | Val: Loss nan  Acc(top1) 67.28% | HA 73.39@267\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 353/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.10  Acc 88.69% | Val: Loss nan  Acc(top1) 66.97% | HA 73.39@267\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 354/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.11  Acc 87.22% | Val: Loss nan  Acc(top1) 64.53% | HA 73.39@267\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 355/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.10  Acc 87.41% | Val: Loss nan  Acc(top1) 68.20% | HA 73.39@267\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 356/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.09  Acc 88.79% | Val: Loss nan  Acc(top1) 64.22% | HA 73.39@267\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 357/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.11  Acc 86.67% | Val: Loss nan  Acc(top1) 66.36% | HA 73.39@267\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 358/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.10  Acc 88.24% | Val: Loss nan  Acc(top1) 66.06% | HA 73.39@267\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 359/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.10  Acc 87.13% | Val: Loss nan  Acc(top1) 72.17% | HA 73.39@267\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 360/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.11  Acc 88.69% | Val: Loss nan  Acc(top1) 69.11% | HA 73.39@267\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "save model to ../../../trained_models/step_1_base_train/base_train_lr0.1_bs64_wd0.0005_20240520064825/uec_model_4Classes_hacc73.39449310302734_valacc_73.08868408203125_tracc_85.29411764705883_360th_epoch.pt\n",
      "SP-[1] Epoch: 361/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.10  Acc 85.29% | Val: Loss nan  Acc(top1) 73.09% | HA 73.39@267\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 362/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.10  Acc 86.21% | Val: Loss nan  Acc(top1) 72.48% | HA 73.39@267\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "save model to ../../../trained_models/step_1_base_train/base_train_lr0.1_bs64_wd0.0005_20240520064825/uec_model_4Classes_hacc77.67584228515625_valacc_77.67584228515625_tracc_87.59191176470588_363th_epoch.pt\n",
      "SP-[1] Epoch: 363/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.09  Acc 87.59% | Val: Loss nan  Acc(top1) 77.68% | HA 77.68@363\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "save model to ../../../trained_models/step_1_base_train/base_train_lr0.1_bs64_wd0.0005_20240520064825/uec_model_4Classes_hacc77.67584228515625_valacc_75.22935485839844_tracc_87.86764705882352_363th_epoch.pt\n",
      "SP-[1] Epoch: 364/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.09  Acc 87.87% | Val: Loss nan  Acc(top1) 75.23% | HA 77.68@363\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 365/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.09  Acc 87.96% | Val: Loss nan  Acc(top1) 65.75% | HA 77.68@363\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 366/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.09  Acc 88.14% | Val: Loss nan  Acc(top1) 69.42% | HA 77.68@363\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 367/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.09  Acc 87.78% | Val: Loss nan  Acc(top1) 70.64% | HA 77.68@363\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 368/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.08  Acc 89.34% | Val: Loss nan  Acc(top1) 64.83% | HA 77.68@363\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 369/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.10  Acc 88.79% | Val: Loss nan  Acc(top1) 69.42% | HA 77.68@363\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 370/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.10  Acc 87.59% | Val: Loss nan  Acc(top1) 70.34% | HA 77.68@363\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 371/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.09  Acc 87.41% | Val: Loss nan  Acc(top1) 70.95% | HA 77.68@363\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 372/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.09  Acc 86.21% | Val: Loss nan  Acc(top1) 69.11% | HA 77.68@363\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 373/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.09  Acc 88.97% | Val: Loss nan  Acc(top1) 64.22% | HA 77.68@363\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 374/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.08  Acc 89.80% | Val: Loss nan  Acc(top1) 65.44% | HA 77.68@363\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 375/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.10  Acc 89.06% | Val: Loss nan  Acc(top1) 67.89% | HA 77.68@363\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 376/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.10  Acc 87.87% | Val: Loss nan  Acc(top1) 65.75% | HA 77.68@363\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 377/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.10  Acc 88.51% | Val: Loss nan  Acc(top1) 65.14% | HA 77.68@363\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 378/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.10  Acc 87.22% | Val: Loss nan  Acc(top1) 66.06% | HA 77.68@363\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 379/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.09  Acc 85.57% | Val: Loss nan  Acc(top1) 67.58% | HA 77.68@363\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 380/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.10  Acc 86.86% | Val: Loss nan  Acc(top1) 63.00% | HA 77.68@363\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 381/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.09  Acc 88.88% | Val: Loss nan  Acc(top1) 64.53% | HA 77.68@363\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 382/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.09  Acc 87.96% | Val: Loss nan  Acc(top1) 65.44% | HA 77.68@363\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 383/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.09  Acc 89.25% | Val: Loss nan  Acc(top1) 68.50% | HA 77.68@363\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 384/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.11  Acc 87.32% | Val: Loss nan  Acc(top1) 65.14% | HA 77.68@363\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 385/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.09  Acc 87.04% | Val: Loss nan  Acc(top1) 66.06% | HA 77.68@363\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 386/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.09  Acc 88.05% | Val: Loss nan  Acc(top1) 71.56% | HA 77.68@363\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 387/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.09  Acc 87.68% | Val: Loss nan  Acc(top1) 69.11% | HA 77.68@363\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 388/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.08  Acc 88.69% | Val: Loss nan  Acc(top1) 66.97% | HA 77.68@363\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 389/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.09  Acc 88.33% | Val: Loss nan  Acc(top1) 64.53% | HA 77.68@363\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 390/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.10  Acc 88.69% | Val: Loss nan  Acc(top1) 63.00% | HA 77.68@363\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "save model to ../../../trained_models/step_1_base_train/base_train_lr0.1_bs64_wd0.0005_20240520064825/uec_model_4Classes_hacc77.67584228515625_valacc_73.08868408203125_tracc_87.40808823529412_390th_epoch.pt\n",
      "SP-[1] Epoch: 391/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.09  Acc 87.41% | Val: Loss nan  Acc(top1) 73.09% | HA 77.68@363\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 392/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.10  Acc 88.05% | Val: Loss nan  Acc(top1) 66.06% | HA 77.68@363\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 393/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.09  Acc 86.95% | Val: Loss nan  Acc(top1) 69.42% | HA 77.68@363\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 394/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.09  Acc 88.79% | Val: Loss nan  Acc(top1) 68.20% | HA 77.68@363\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "save model to ../../../trained_models/step_1_base_train/base_train_lr0.1_bs64_wd0.0005_20240520064825/uec_model_4Classes_hacc77.67584228515625_valacc_74.61773681640625_tracc_86.94852941176471_394th_epoch.pt\n",
      "SP-[1] Epoch: 395/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.10  Acc 86.95% | Val: Loss nan  Acc(top1) 74.62% | HA 77.68@363\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 396/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.09  Acc 88.51% | Val: Loss nan  Acc(top1) 66.67% | HA 77.68@363\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 397/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.11  Acc 86.76% | Val: Loss nan  Acc(top1) 69.72% | HA 77.68@363\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 398/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.09  Acc 88.51% | Val: Loss nan  Acc(top1) 66.67% | HA 77.68@363\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 399/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.09  Acc 86.58% | Val: Loss nan  Acc(top1) 71.25% | HA 77.68@363\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 400/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.09  Acc 88.42% | Val: Loss nan  Acc(top1) 64.53% | HA 77.68@363\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 401/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.09  Acc 86.49% | Val: Loss nan  Acc(top1) 67.28% | HA 77.68@363\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 402/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.09  Acc 87.50% | Val: Loss nan  Acc(top1) 64.83% | HA 77.68@363\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 403/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.09  Acc 87.22% | Val: Loss nan  Acc(top1) 72.17% | HA 77.68@363\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 404/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.09  Acc 88.97% | Val: Loss nan  Acc(top1) 68.20% | HA 77.68@363\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 405/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.09  Acc 87.87% | Val: Loss nan  Acc(top1) 64.53% | HA 77.68@363\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 406/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.09  Acc 86.58% | Val: Loss nan  Acc(top1) 68.81% | HA 77.68@363\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 407/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.10  Acc 89.25% | Val: Loss nan  Acc(top1) 67.89% | HA 77.68@363\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 408/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.09  Acc 87.41% | Val: Loss nan  Acc(top1) 64.83% | HA 77.68@363\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "save model to ../../../trained_models/step_1_base_train/base_train_lr0.1_bs64_wd0.0005_20240520064825/uec_model_4Classes_hacc77.67584228515625_valacc_73.08868408203125_tracc_87.59191176470588_408th_epoch.pt\n",
      "SP-[1] Epoch: 409/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.09  Acc 87.59% | Val: Loss nan  Acc(top1) 73.09% | HA 77.68@363\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 410/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.09  Acc 88.24% | Val: Loss nan  Acc(top1) 67.28% | HA 77.68@363\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 411/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.09  Acc 86.21% | Val: Loss nan  Acc(top1) 71.87% | HA 77.68@363\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 412/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.10  Acc 87.32% | Val: Loss nan  Acc(top1) 65.75% | HA 77.68@363\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 413/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.09  Acc 87.87% | Val: Loss nan  Acc(top1) 68.20% | HA 77.68@363\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 414/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.10  Acc 88.14% | Val: Loss nan  Acc(top1) 65.75% | HA 77.68@363\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 415/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.09  Acc 89.98% | Val: Loss nan  Acc(top1) 66.36% | HA 77.68@363\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 416/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.09  Acc 87.96% | Val: Loss nan  Acc(top1) 66.67% | HA 77.68@363\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 417/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.09  Acc 88.24% | Val: Loss nan  Acc(top1) 68.20% | HA 77.68@363\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "save model to ../../../trained_models/step_1_base_train/base_train_lr0.1_bs64_wd0.0005_20240520064825/uec_model_4Classes_hacc77.67584228515625_valacc_73.39449310302734_tracc_87.59191176470588_417th_epoch.pt\n",
      "SP-[1] Epoch: 418/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.10  Acc 87.59% | Val: Loss nan  Acc(top1) 73.39% | HA 77.68@363\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 419/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.09  Acc 87.68% | Val: Loss nan  Acc(top1) 67.28% | HA 77.68@363\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 420/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.08  Acc 88.33% | Val: Loss nan  Acc(top1) 65.44% | HA 77.68@363\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 421/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.09  Acc 88.60% | Val: Loss nan  Acc(top1) 69.11% | HA 77.68@363\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 422/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.10  Acc 88.33% | Val: Loss nan  Acc(top1) 70.64% | HA 77.68@363\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 423/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.09  Acc 88.14% | Val: Loss nan  Acc(top1) 71.25% | HA 77.68@363\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "save model to ../../../trained_models/step_1_base_train/base_train_lr0.1_bs64_wd0.0005_20240520064825/uec_model_4Classes_hacc77.67584228515625_valacc_75.53517150878906_tracc_88.69485294117648_423th_epoch.pt\n",
      "SP-[1] Epoch: 424/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.08  Acc 88.69% | Val: Loss nan  Acc(top1) 75.54% | HA 77.68@363\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "save model to ../../../trained_models/step_1_base_train/base_train_lr0.1_bs64_wd0.0005_20240520064825/uec_model_4Classes_hacc81.34557342529297_valacc_81.34557342529297_tracc_90.25735294117648_425th_epoch.pt\n",
      "SP-[1] Epoch: 425/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.08  Acc 90.26% | Val: Loss nan  Acc(top1) 81.35% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 426/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.09  Acc 88.42% | Val: Loss nan  Acc(top1) 69.11% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 427/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.09  Acc 87.32% | Val: Loss nan  Acc(top1) 66.67% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 428/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.09  Acc 87.87% | Val: Loss nan  Acc(top1) 71.56% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 429/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.08  Acc 87.04% | Val: Loss nan  Acc(top1) 69.42% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 430/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.08  Acc 89.15% | Val: Loss nan  Acc(top1) 71.25% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 431/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.09  Acc 87.22% | Val: Loss nan  Acc(top1) 65.44% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "save model to ../../../trained_models/step_1_base_train/base_train_lr0.1_bs64_wd0.0005_20240520064825/uec_model_4Classes_hacc81.34557342529297_valacc_78.89908599853516_tracc_86.39705882352942_431th_epoch.pt\n",
      "SP-[1] Epoch: 432/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.10  Acc 86.40% | Val: Loss nan  Acc(top1) 78.90% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 433/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.08  Acc 88.05% | Val: Loss nan  Acc(top1) 68.81% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 434/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.09  Acc 86.76% | Val: Loss nan  Acc(top1) 71.25% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 435/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.08  Acc 87.04% | Val: Loss nan  Acc(top1) 70.34% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "save model to ../../../trained_models/step_1_base_train/base_train_lr0.1_bs64_wd0.0005_20240520064825/uec_model_4Classes_hacc81.34557342529297_valacc_73.08868408203125_tracc_86.76470588235294_435th_epoch.pt\n",
      "SP-[1] Epoch: 436/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.10  Acc 86.76% | Val: Loss nan  Acc(top1) 73.09% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 437/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.10  Acc 88.69% | Val: Loss nan  Acc(top1) 69.42% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 438/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.08  Acc 88.97% | Val: Loss nan  Acc(top1) 70.34% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "save model to ../../../trained_models/step_1_base_train/base_train_lr0.1_bs64_wd0.0005_20240520064825/uec_model_4Classes_hacc81.34557342529297_valacc_79.20489501953125_tracc_87.95955882352942_438th_epoch.pt\n",
      "SP-[1] Epoch: 439/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.08  Acc 87.96% | Val: Loss nan  Acc(top1) 79.20% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "save model to ../../../trained_models/step_1_base_train/base_train_lr0.1_bs64_wd0.0005_20240520064825/uec_model_4Classes_hacc81.34557342529297_valacc_75.53517150878906_tracc_87.13235294117648_439th_epoch.pt\n",
      "SP-[1] Epoch: 440/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.08  Acc 87.13% | Val: Loss nan  Acc(top1) 75.54% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 441/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.08  Acc 88.79% | Val: Loss nan  Acc(top1) 67.58% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 442/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.09  Acc 88.05% | Val: Loss nan  Acc(top1) 71.56% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 443/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.09  Acc 87.41% | Val: Loss nan  Acc(top1) 70.34% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 444/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.08  Acc 89.06% | Val: Loss nan  Acc(top1) 70.34% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 445/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.08  Acc 89.61% | Val: Loss nan  Acc(top1) 67.89% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 446/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.09  Acc 88.05% | Val: Loss nan  Acc(top1) 67.28% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 447/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.09  Acc 87.13% | Val: Loss nan  Acc(top1) 67.58% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 448/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.08  Acc 88.42% | Val: Loss nan  Acc(top1) 68.81% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 449/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.09  Acc 88.33% | Val: Loss nan  Acc(top1) 66.67% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 450/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.09  Acc 88.60% | Val: Loss nan  Acc(top1) 69.42% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 451/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.10  Acc 87.41% | Val: Loss nan  Acc(top1) 68.81% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 452/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.08  Acc 89.25% | Val: Loss nan  Acc(top1) 66.97% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 453/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.09  Acc 87.59% | Val: Loss nan  Acc(top1) 66.97% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 454/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.08  Acc 89.80% | Val: Loss nan  Acc(top1) 65.75% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "save model to ../../../trained_models/step_1_base_train/base_train_lr0.1_bs64_wd0.0005_20240520064825/uec_model_4Classes_hacc81.34557342529297_valacc_73.39449310302734_tracc_88.60294117647058_454th_epoch.pt\n",
      "SP-[1] Epoch: 455/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.09  Acc 88.60% | Val: Loss nan  Acc(top1) 73.39% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 456/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.09  Acc 88.14% | Val: Loss nan  Acc(top1) 67.58% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 457/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.09  Acc 88.51% | Val: Loss nan  Acc(top1) 69.11% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 458/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.08  Acc 90.17% | Val: Loss nan  Acc(top1) 66.36% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 459/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.10  Acc 88.79% | Val: Loss nan  Acc(top1) 66.67% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 460/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.08  Acc 90.17% | Val: Loss nan  Acc(top1) 66.67% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 461/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.10  Acc 88.33% | Val: Loss nan  Acc(top1) 68.20% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 462/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.10  Acc 86.31% | Val: Loss nan  Acc(top1) 66.36% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 463/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.08  Acc 89.06% | Val: Loss nan  Acc(top1) 68.81% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 464/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.10  Acc 86.31% | Val: Loss nan  Acc(top1) 69.72% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 465/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.09  Acc 87.59% | Val: Loss nan  Acc(top1) 65.75% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 466/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.07  Acc 90.53% | Val: Loss nan  Acc(top1) 67.89% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "save model to ../../../trained_models/step_1_base_train/base_train_lr0.1_bs64_wd0.0005_20240520064825/uec_model_4Classes_hacc81.34557342529297_valacc_77.67584228515625_tracc_87.86764705882352_466th_epoch.pt\n",
      "SP-[1] Epoch: 467/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.08  Acc 87.87% | Val: Loss nan  Acc(top1) 77.68% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "save model to ../../../trained_models/step_1_base_train/base_train_lr0.1_bs64_wd0.0005_20240520064825/uec_model_4Classes_hacc81.34557342529297_valacc_74.00611877441406_tracc_88.87867647058823_467th_epoch.pt\n",
      "SP-[1] Epoch: 468/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.09  Acc 88.88% | Val: Loss nan  Acc(top1) 74.01% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 469/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.08  Acc 88.60% | Val: Loss nan  Acc(top1) 67.58% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 470/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.09  Acc 89.89% | Val: Loss nan  Acc(top1) 64.22% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "save model to ../../../trained_models/step_1_base_train/base_train_lr0.1_bs64_wd0.0005_20240520064825/uec_model_4Classes_hacc81.34557342529297_valacc_74.00611877441406_tracc_88.32720588235294_470th_epoch.pt\n",
      "SP-[1] Epoch: 471/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.10  Acc 88.33% | Val: Loss nan  Acc(top1) 74.01% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 472/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.09  Acc 88.60% | Val: Loss nan  Acc(top1) 67.28% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 473/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.09  Acc 87.87% | Val: Loss nan  Acc(top1) 65.75% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 474/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.09  Acc 87.96% | Val: Loss nan  Acc(top1) 68.20% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 475/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.08  Acc 88.42% | Val: Loss nan  Acc(top1) 72.78% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 476/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.08  Acc 87.78% | Val: Loss nan  Acc(top1) 63.91% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 477/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.09  Acc 88.88% | Val: Loss nan  Acc(top1) 69.72% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 478/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.10  Acc 87.59% | Val: Loss nan  Acc(top1) 66.67% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 479/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.09  Acc 87.96% | Val: Loss nan  Acc(top1) 72.17% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 480/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.1  Loss 0.08  Acc 87.04% | Val: Loss nan  Acc(top1) 67.28% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 481/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.09  Acc 89.89% | Val: Loss nan  Acc(top1) 70.03% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 482/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.07  Acc 90.07% | Val: Loss nan  Acc(top1) 70.64% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 483/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.08  Acc 89.98% | Val: Loss nan  Acc(top1) 71.56% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 484/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.09  Acc 88.42% | Val: Loss nan  Acc(top1) 69.11% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 485/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.07  Acc 89.98% | Val: Loss nan  Acc(top1) 71.25% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 486/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.08  Acc 88.05% | Val: Loss nan  Acc(top1) 71.56% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 487/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.08  Acc 90.07% | Val: Loss nan  Acc(top1) 71.87% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 488/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.09  Acc 89.06% | Val: Loss nan  Acc(top1) 72.78% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 489/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.08  Acc 90.72% | Val: Loss nan  Acc(top1) 70.64% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 490/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.08  Acc 88.51% | Val: Loss nan  Acc(top1) 70.64% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 491/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.08  Acc 89.98% | Val: Loss nan  Acc(top1) 71.25% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 492/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.09  Acc 89.06% | Val: Loss nan  Acc(top1) 71.56% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 493/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.08  Acc 88.51% | Val: Loss nan  Acc(top1) 72.17% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 494/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.08  Acc 89.52% | Val: Loss nan  Acc(top1) 70.95% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "save model to ../../../trained_models/step_1_base_train/base_train_lr0.1_bs64_wd0.0005_20240520064825/uec_model_4Classes_hacc81.34557342529297_valacc_74.61773681640625_tracc_88.32720588235294_494th_epoch.pt\n",
      "SP-[1] Epoch: 495/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.08  Acc 88.33% | Val: Loss nan  Acc(top1) 74.62% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 496/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.07  Acc 88.05% | Val: Loss nan  Acc(top1) 72.17% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 497/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.07  Acc 88.97% | Val: Loss nan  Acc(top1) 70.95% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 498/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.07  Acc 90.44% | Val: Loss nan  Acc(top1) 71.25% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 499/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.08  Acc 90.72% | Val: Loss nan  Acc(top1) 71.25% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "save model to ../../../trained_models/step_1_base_train/base_train_lr0.1_bs64_wd0.0005_20240520064825/uec_model_4Classes_hacc81.34557342529297_valacc_74.00611877441406_tracc_90.25735294117648_499th_epoch.pt\n",
      "SP-[1] Epoch: 500/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.08  Acc 90.26% | Val: Loss nan  Acc(top1) 74.01% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 501/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.07  Acc 90.62% | Val: Loss nan  Acc(top1) 71.56% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "save model to ../../../trained_models/step_1_base_train/base_train_lr0.1_bs64_wd0.0005_20240520064825/uec_model_4Classes_hacc81.34557342529297_valacc_73.70030975341797_tracc_88.14338235294117_501th_epoch.pt\n",
      "SP-[1] Epoch: 502/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.07  Acc 88.14% | Val: Loss nan  Acc(top1) 73.70% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 503/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.08  Acc 89.52% | Val: Loss nan  Acc(top1) 72.48% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 504/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.08  Acc 89.98% | Val: Loss nan  Acc(top1) 69.72% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 505/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.06  Acc 91.36% | Val: Loss nan  Acc(top1) 70.34% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 506/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.08  Acc 90.62% | Val: Loss nan  Acc(top1) 72.78% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "save model to ../../../trained_models/step_1_base_train/base_train_lr0.1_bs64_wd0.0005_20240520064825/uec_model_4Classes_hacc81.34557342529297_valacc_73.08868408203125_tracc_90.71691176470588_506th_epoch.pt\n",
      "SP-[1] Epoch: 507/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.07  Acc 90.72% | Val: Loss nan  Acc(top1) 73.09% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "save model to ../../../trained_models/step_1_base_train/base_train_lr0.1_bs64_wd0.0005_20240520064825/uec_model_4Classes_hacc81.34557342529297_valacc_74.00611877441406_tracc_88.51102941176471_507th_epoch.pt\n",
      "SP-[1] Epoch: 508/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.07  Acc 88.51% | Val: Loss nan  Acc(top1) 74.01% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 509/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.08  Acc 90.62% | Val: Loss nan  Acc(top1) 72.78% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 510/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.08  Acc 89.71% | Val: Loss nan  Acc(top1) 72.17% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 511/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.08  Acc 90.26% | Val: Loss nan  Acc(top1) 72.48% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 512/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.07  Acc 90.72% | Val: Loss nan  Acc(top1) 71.56% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "save model to ../../../trained_models/step_1_base_train/base_train_lr0.1_bs64_wd0.0005_20240520064825/uec_model_4Classes_hacc81.34557342529297_valacc_73.08868408203125_tracc_88.87867647058823_512th_epoch.pt\n",
      "SP-[1] Epoch: 513/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.07  Acc 88.88% | Val: Loss nan  Acc(top1) 73.09% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "save model to ../../../trained_models/step_1_base_train/base_train_lr0.1_bs64_wd0.0005_20240520064825/uec_model_4Classes_hacc81.34557342529297_valacc_74.61773681640625_tracc_89.24632352941177_513th_epoch.pt\n",
      "SP-[1] Epoch: 514/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.07  Acc 89.25% | Val: Loss nan  Acc(top1) 74.62% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 515/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.08  Acc 89.89% | Val: Loss nan  Acc(top1) 72.17% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "save model to ../../../trained_models/step_1_base_train/base_train_lr0.1_bs64_wd0.0005_20240520064825/uec_model_4Classes_hacc81.34557342529297_valacc_74.00611877441406_tracc_89.43014705882352_515th_epoch.pt\n",
      "SP-[1] Epoch: 516/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.08  Acc 89.43% | Val: Loss nan  Acc(top1) 74.01% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 517/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.07  Acc 90.53% | Val: Loss nan  Acc(top1) 72.48% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 518/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.07  Acc 90.07% | Val: Loss nan  Acc(top1) 72.78% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 519/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.08  Acc 88.05% | Val: Loss nan  Acc(top1) 71.56% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "save model to ../../../trained_models/step_1_base_train/base_train_lr0.1_bs64_wd0.0005_20240520064825/uec_model_4Classes_hacc81.34557342529297_valacc_73.08868408203125_tracc_90.07352941176471_519th_epoch.pt\n",
      "SP-[1] Epoch: 520/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.07  Acc 90.07% | Val: Loss nan  Acc(top1) 73.09% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 521/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.07  Acc 89.89% | Val: Loss nan  Acc(top1) 71.87% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "save model to ../../../trained_models/step_1_base_train/base_train_lr0.1_bs64_wd0.0005_20240520064825/uec_model_4Classes_hacc81.34557342529297_valacc_73.08868408203125_tracc_88.23529411764706_521th_epoch.pt\n",
      "SP-[1] Epoch: 522/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.07  Acc 88.24% | Val: Loss nan  Acc(top1) 73.09% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 523/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.07  Acc 89.98% | Val: Loss nan  Acc(top1) 72.17% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 524/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.07  Acc 90.26% | Val: Loss nan  Acc(top1) 72.17% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 525/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.07  Acc 89.80% | Val: Loss nan  Acc(top1) 71.56% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "save model to ../../../trained_models/step_1_base_train/base_train_lr0.1_bs64_wd0.0005_20240520064825/uec_model_4Classes_hacc81.34557342529297_valacc_73.39449310302734_tracc_89.43014705882352_525th_epoch.pt\n",
      "SP-[1] Epoch: 526/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.09  Acc 89.43% | Val: Loss nan  Acc(top1) 73.39% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 527/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.07  Acc 89.43% | Val: Loss nan  Acc(top1) 72.78% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "save model to ../../../trained_models/step_1_base_train/base_train_lr0.1_bs64_wd0.0005_20240520064825/uec_model_4Classes_hacc81.34557342529297_valacc_73.39449310302734_tracc_89.15441176470588_527th_epoch.pt\n",
      "SP-[1] Epoch: 528/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.07  Acc 89.15% | Val: Loss nan  Acc(top1) 73.39% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 529/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.07  Acc 88.51% | Val: Loss nan  Acc(top1) 72.48% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "save model to ../../../trained_models/step_1_base_train/base_train_lr0.1_bs64_wd0.0005_20240520064825/uec_model_4Classes_hacc81.34557342529297_valacc_73.70030975341797_tracc_88.51102941176471_529th_epoch.pt\n",
      "SP-[1] Epoch: 530/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.07  Acc 88.51% | Val: Loss nan  Acc(top1) 73.70% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 531/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.08  Acc 90.72% | Val: Loss nan  Acc(top1) 72.17% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "save model to ../../../trained_models/step_1_base_train/base_train_lr0.1_bs64_wd0.0005_20240520064825/uec_model_4Classes_hacc81.34557342529297_valacc_73.39449310302734_tracc_90.80882352941177_531th_epoch.pt\n",
      "SP-[1] Epoch: 532/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.07  Acc 90.81% | Val: Loss nan  Acc(top1) 73.39% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "save model to ../../../trained_models/step_1_base_train/base_train_lr0.1_bs64_wd0.0005_20240520064825/uec_model_4Classes_hacc81.34557342529297_valacc_73.39449310302734_tracc_89.52205882352942_532th_epoch.pt\n",
      "SP-[1] Epoch: 533/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.07  Acc 89.52% | Val: Loss nan  Acc(top1) 73.39% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "save model to ../../../trained_models/step_1_base_train/base_train_lr0.1_bs64_wd0.0005_20240520064825/uec_model_4Classes_hacc81.34557342529297_valacc_73.70030975341797_tracc_88.23529411764706_533th_epoch.pt\n",
      "SP-[1] Epoch: 534/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.07  Acc 88.24% | Val: Loss nan  Acc(top1) 73.70% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "save model to ../../../trained_models/step_1_base_train/base_train_lr0.1_bs64_wd0.0005_20240520064825/uec_model_4Classes_hacc81.34557342529297_valacc_73.39449310302734_tracc_90.16544117647058_534th_epoch.pt\n",
      "SP-[1] Epoch: 535/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.07  Acc 90.17% | Val: Loss nan  Acc(top1) 73.39% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "save model to ../../../trained_models/step_1_base_train/base_train_lr0.1_bs64_wd0.0005_20240520064825/uec_model_4Classes_hacc81.34557342529297_valacc_74.61773681640625_tracc_88.69485294117648_535th_epoch.pt\n",
      "SP-[1] Epoch: 536/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.08  Acc 88.69% | Val: Loss nan  Acc(top1) 74.62% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 537/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.08  Acc 90.81% | Val: Loss nan  Acc(top1) 72.48% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "save model to ../../../trained_models/step_1_base_train/base_train_lr0.1_bs64_wd0.0005_20240520064825/uec_model_4Classes_hacc81.34557342529297_valacc_73.70030975341797_tracc_88.05147058823529_537th_epoch.pt\n",
      "SP-[1] Epoch: 538/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.08  Acc 88.05% | Val: Loss nan  Acc(top1) 73.70% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "save model to ../../../trained_models/step_1_base_train/base_train_lr0.1_bs64_wd0.0005_20240520064825/uec_model_4Classes_hacc81.34557342529297_valacc_73.39449310302734_tracc_91.36029411764706_538th_epoch.pt\n",
      "SP-[1] Epoch: 539/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.08  Acc 91.36% | Val: Loss nan  Acc(top1) 73.39% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "save model to ../../../trained_models/step_1_base_train/base_train_lr0.1_bs64_wd0.0005_20240520064825/uec_model_4Classes_hacc81.34557342529297_valacc_73.39449310302734_tracc_89.24632352941177_539th_epoch.pt\n",
      "SP-[1] Epoch: 540/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.07  Acc 89.25% | Val: Loss nan  Acc(top1) 73.39% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 541/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.08  Acc 89.98% | Val: Loss nan  Acc(top1) 71.56% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "save model to ../../../trained_models/step_1_base_train/base_train_lr0.1_bs64_wd0.0005_20240520064825/uec_model_4Classes_hacc81.34557342529297_valacc_73.08868408203125_tracc_88.69485294117648_541th_epoch.pt\n",
      "SP-[1] Epoch: 542/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.07  Acc 88.69% | Val: Loss nan  Acc(top1) 73.09% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "save model to ../../../trained_models/step_1_base_train/base_train_lr0.1_bs64_wd0.0005_20240520064825/uec_model_4Classes_hacc81.34557342529297_valacc_74.31192779541016_tracc_89.70588235294117_542th_epoch.pt\n",
      "SP-[1] Epoch: 543/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.09  Acc 89.71% | Val: Loss nan  Acc(top1) 74.31% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 544/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.07  Acc 92.10% | Val: Loss nan  Acc(top1) 72.78% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 545/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.07  Acc 89.71% | Val: Loss nan  Acc(top1) 70.64% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 546/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.08  Acc 89.52% | Val: Loss nan  Acc(top1) 72.78% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "save model to ../../../trained_models/step_1_base_train/base_train_lr0.1_bs64_wd0.0005_20240520064825/uec_model_4Classes_hacc81.34557342529297_valacc_74.31192779541016_tracc_90.44117647058823_546th_epoch.pt\n",
      "SP-[1] Epoch: 547/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.07  Acc 90.44% | Val: Loss nan  Acc(top1) 74.31% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 548/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.08  Acc 90.26% | Val: Loss nan  Acc(top1) 69.72% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 549/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.07  Acc 90.72% | Val: Loss nan  Acc(top1) 70.95% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "save model to ../../../trained_models/step_1_base_train/base_train_lr0.1_bs64_wd0.0005_20240520064825/uec_model_4Classes_hacc81.34557342529297_valacc_73.70030975341797_tracc_87.86764705882352_549th_epoch.pt\n",
      "SP-[1] Epoch: 550/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.07  Acc 87.87% | Val: Loss nan  Acc(top1) 73.70% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 551/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.07  Acc 91.08% | Val: Loss nan  Acc(top1) 71.87% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 552/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.07  Acc 90.81% | Val: Loss nan  Acc(top1) 71.56% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 553/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.07  Acc 88.69% | Val: Loss nan  Acc(top1) 72.48% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 554/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.08  Acc 91.36% | Val: Loss nan  Acc(top1) 71.56% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 555/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.07  Acc 89.52% | Val: Loss nan  Acc(top1) 71.56% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 556/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.06  Acc 90.99% | Val: Loss nan  Acc(top1) 71.25% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 557/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.08  Acc 89.98% | Val: Loss nan  Acc(top1) 71.56% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 558/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.06  Acc 90.99% | Val: Loss nan  Acc(top1) 71.56% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 559/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.08  Acc 89.43% | Val: Loss nan  Acc(top1) 72.78% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 560/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.07  Acc 90.26% | Val: Loss nan  Acc(top1) 70.03% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 561/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.06  Acc 90.62% | Val: Loss nan  Acc(top1) 70.95% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 562/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.07  Acc 90.72% | Val: Loss nan  Acc(top1) 72.78% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "save model to ../../../trained_models/step_1_base_train/base_train_lr0.1_bs64_wd0.0005_20240520064825/uec_model_4Classes_hacc81.34557342529297_valacc_73.08868408203125_tracc_91.81985294117648_562th_epoch.pt\n",
      "SP-[1] Epoch: 563/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.07  Acc 91.82% | Val: Loss nan  Acc(top1) 73.09% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 564/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.07  Acc 90.72% | Val: Loss nan  Acc(top1) 71.25% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 565/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.07  Acc 91.18% | Val: Loss nan  Acc(top1) 72.48% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "save model to ../../../trained_models/step_1_base_train/base_train_lr0.1_bs64_wd0.0005_20240520064825/uec_model_4Classes_hacc81.34557342529297_valacc_73.08868408203125_tracc_89.79779411764706_565th_epoch.pt\n",
      "SP-[1] Epoch: 566/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.07  Acc 89.80% | Val: Loss nan  Acc(top1) 73.09% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 567/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.07  Acc 90.62% | Val: Loss nan  Acc(top1) 72.17% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "save model to ../../../trained_models/step_1_base_train/base_train_lr0.1_bs64_wd0.0005_20240520064825/uec_model_4Classes_hacc81.34557342529297_valacc_73.08868408203125_tracc_89.79779411764706_567th_epoch.pt\n",
      "SP-[1] Epoch: 568/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.07  Acc 89.80% | Val: Loss nan  Acc(top1) 73.09% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 569/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.07  Acc 90.44% | Val: Loss nan  Acc(top1) 72.17% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 570/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.07  Acc 88.69% | Val: Loss nan  Acc(top1) 71.56% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "save model to ../../../trained_models/step_1_base_train/base_train_lr0.1_bs64_wd0.0005_20240520064825/uec_model_4Classes_hacc81.34557342529297_valacc_73.08868408203125_tracc_88.69485294117648_570th_epoch.pt\n",
      "SP-[1] Epoch: 571/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.08  Acc 88.69% | Val: Loss nan  Acc(top1) 73.09% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 572/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.07  Acc 90.53% | Val: Loss nan  Acc(top1) 70.03% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 573/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.07  Acc 90.44% | Val: Loss nan  Acc(top1) 69.72% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 574/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.07  Acc 90.26% | Val: Loss nan  Acc(top1) 71.87% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 575/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.07  Acc 90.26% | Val: Loss nan  Acc(top1) 72.17% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 576/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.07  Acc 89.52% | Val: Loss nan  Acc(top1) 71.25% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 577/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.07  Acc 90.81% | Val: Loss nan  Acc(top1) 72.48% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 578/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.06  Acc 88.97% | Val: Loss nan  Acc(top1) 72.78% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 579/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.07  Acc 90.44% | Val: Loss nan  Acc(top1) 70.95% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 580/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.06  Acc 89.52% | Val: Loss nan  Acc(top1) 70.64% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 581/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.08  Acc 91.27% | Val: Loss nan  Acc(top1) 71.25% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 582/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.07  Acc 89.80% | Val: Loss nan  Acc(top1) 68.81% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 583/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.08  Acc 88.88% | Val: Loss nan  Acc(top1) 72.78% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "save model to ../../../trained_models/step_1_base_train/base_train_lr0.1_bs64_wd0.0005_20240520064825/uec_model_4Classes_hacc81.34557342529297_valacc_73.70030975341797_tracc_90.34926470588235_583th_epoch.pt\n",
      "SP-[1] Epoch: 584/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.07  Acc 90.35% | Val: Loss nan  Acc(top1) 73.70% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "save model to ../../../trained_models/step_1_base_train/base_train_lr0.1_bs64_wd0.0005_20240520064825/uec_model_4Classes_hacc81.34557342529297_valacc_73.39449310302734_tracc_91.08455882352942_584th_epoch.pt\n",
      "SP-[1] Epoch: 585/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.07  Acc 91.08% | Val: Loss nan  Acc(top1) 73.39% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 586/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.08  Acc 89.61% | Val: Loss nan  Acc(top1) 70.03% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 587/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.07  Acc 90.07% | Val: Loss nan  Acc(top1) 71.56% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "save model to ../../../trained_models/step_1_base_train/base_train_lr0.1_bs64_wd0.0005_20240520064825/uec_model_4Classes_hacc81.34557342529297_valacc_73.70030975341797_tracc_89.88970588235294_587th_epoch.pt\n",
      "SP-[1] Epoch: 588/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.07  Acc 89.89% | Val: Loss nan  Acc(top1) 73.70% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "save model to ../../../trained_models/step_1_base_train/base_train_lr0.1_bs64_wd0.0005_20240520064825/uec_model_4Classes_hacc81.34557342529297_valacc_73.08868408203125_tracc_88.78676470588235_588th_epoch.pt\n",
      "SP-[1] Epoch: 589/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.07  Acc 88.79% | Val: Loss nan  Acc(top1) 73.09% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "save model to ../../../trained_models/step_1_base_train/base_train_lr0.1_bs64_wd0.0005_20240520064825/uec_model_4Classes_hacc81.34557342529297_valacc_73.70030975341797_tracc_90.90073529411765_589th_epoch.pt\n",
      "SP-[1] Epoch: 590/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.07  Acc 90.90% | Val: Loss nan  Acc(top1) 73.70% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "save model to ../../../trained_models/step_1_base_train/base_train_lr0.1_bs64_wd0.0005_20240520064825/uec_model_4Classes_hacc81.34557342529297_valacc_73.70030975341797_tracc_89.24632352941177_590th_epoch.pt\n",
      "SP-[1] Epoch: 591/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.08  Acc 89.25% | Val: Loss nan  Acc(top1) 73.70% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "save model to ../../../trained_models/step_1_base_train/base_train_lr0.1_bs64_wd0.0005_20240520064825/uec_model_4Classes_hacc81.34557342529297_valacc_75.22935485839844_tracc_89.70588235294117_591th_epoch.pt\n",
      "SP-[1] Epoch: 592/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.07  Acc 89.71% | Val: Loss nan  Acc(top1) 75.23% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "save model to ../../../trained_models/step_1_base_train/base_train_lr0.1_bs64_wd0.0005_20240520064825/uec_model_4Classes_hacc81.34557342529297_valacc_74.61773681640625_tracc_89.33823529411765_592th_epoch.pt\n",
      "SP-[1] Epoch: 593/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.08  Acc 89.34% | Val: Loss nan  Acc(top1) 74.62% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 594/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.07  Acc 89.34% | Val: Loss nan  Acc(top1) 72.17% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 595/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.07  Acc 90.53% | Val: Loss nan  Acc(top1) 69.72% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 596/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.07  Acc 90.81% | Val: Loss nan  Acc(top1) 71.25% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 597/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.07  Acc 90.62% | Val: Loss nan  Acc(top1) 71.25% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "save model to ../../../trained_models/step_1_base_train/base_train_lr0.1_bs64_wd0.0005_20240520064825/uec_model_4Classes_hacc81.34557342529297_valacc_73.08868408203125_tracc_89.52205882352942_597th_epoch.pt\n",
      "SP-[1] Epoch: 598/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.07  Acc 89.52% | Val: Loss nan  Acc(top1) 73.09% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 599/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.07  Acc 90.81% | Val: Loss nan  Acc(top1) 70.95% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "save model to ../../../trained_models/step_1_base_train/base_train_lr0.1_bs64_wd0.0005_20240520064825/uec_model_4Classes_hacc81.34557342529297_valacc_73.70030975341797_tracc_89.70588235294117_599th_epoch.pt\n",
      "SP-[1] Epoch: 600/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.07  Acc 89.71% | Val: Loss nan  Acc(top1) 73.70% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "save model to ../../../trained_models/step_1_base_train/base_train_lr0.1_bs64_wd0.0005_20240520064825/uec_model_4Classes_hacc81.34557342529297_valacc_73.70030975341797_tracc_90.25735294117648_600th_epoch.pt\n",
      "SP-[1] Epoch: 601/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.08  Acc 90.26% | Val: Loss nan  Acc(top1) 73.70% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 602/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.08  Acc 89.15% | Val: Loss nan  Acc(top1) 71.87% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "save model to ../../../trained_models/step_1_base_train/base_train_lr0.1_bs64_wd0.0005_20240520064825/uec_model_4Classes_hacc81.34557342529297_valacc_74.92355346679688_tracc_89.98161764705883_602th_epoch.pt\n",
      "SP-[1] Epoch: 603/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.07  Acc 89.98% | Val: Loss nan  Acc(top1) 74.92% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 604/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.07  Acc 89.61% | Val: Loss nan  Acc(top1) 72.78% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 605/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.08  Acc 89.43% | Val: Loss nan  Acc(top1) 70.95% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 606/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.07  Acc 88.97% | Val: Loss nan  Acc(top1) 70.34% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "save model to ../../../trained_models/step_1_base_train/base_train_lr0.1_bs64_wd0.0005_20240520064825/uec_model_4Classes_hacc81.34557342529297_valacc_74.00611877441406_tracc_89.33823529411765_606th_epoch.pt\n",
      "SP-[1] Epoch: 607/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.07  Acc 89.34% | Val: Loss nan  Acc(top1) 74.01% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 608/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.08  Acc 91.54% | Val: Loss nan  Acc(top1) 70.64% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "save model to ../../../trained_models/step_1_base_train/base_train_lr0.1_bs64_wd0.0005_20240520064825/uec_model_4Classes_hacc81.34557342529297_valacc_73.08868408203125_tracc_90.44117647058823_608th_epoch.pt\n",
      "SP-[1] Epoch: 609/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.07  Acc 90.44% | Val: Loss nan  Acc(top1) 73.09% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 610/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.07  Acc 90.17% | Val: Loss nan  Acc(top1) 72.78% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "save model to ../../../trained_models/step_1_base_train/base_train_lr0.1_bs64_wd0.0005_20240520064825/uec_model_4Classes_hacc81.34557342529297_valacc_73.08868408203125_tracc_88.69485294117648_610th_epoch.pt\n",
      "SP-[1] Epoch: 611/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.06  Acc 88.69% | Val: Loss nan  Acc(top1) 73.09% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 612/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.08  Acc 87.68% | Val: Loss nan  Acc(top1) 72.48% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 613/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.08  Acc 90.07% | Val: Loss nan  Acc(top1) 72.17% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "save model to ../../../trained_models/step_1_base_train/base_train_lr0.1_bs64_wd0.0005_20240520064825/uec_model_4Classes_hacc81.34557342529297_valacc_73.39449310302734_tracc_90.99264705882352_613th_epoch.pt\n",
      "SP-[1] Epoch: 614/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.07  Acc 90.99% | Val: Loss nan  Acc(top1) 73.39% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "save model to ../../../trained_models/step_1_base_train/base_train_lr0.1_bs64_wd0.0005_20240520064825/uec_model_4Classes_hacc81.34557342529297_valacc_73.39449310302734_tracc_89.98161764705883_614th_epoch.pt\n",
      "SP-[1] Epoch: 615/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.07  Acc 89.98% | Val: Loss nan  Acc(top1) 73.39% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "save model to ../../../trained_models/step_1_base_train/base_train_lr0.1_bs64_wd0.0005_20240520064825/uec_model_4Classes_hacc81.34557342529297_valacc_74.00611877441406_tracc_89.43014705882352_615th_epoch.pt\n",
      "SP-[1] Epoch: 616/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.08  Acc 89.43% | Val: Loss nan  Acc(top1) 74.01% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "save model to ../../../trained_models/step_1_base_train/base_train_lr0.1_bs64_wd0.0005_20240520064825/uec_model_4Classes_hacc81.34557342529297_valacc_73.39449310302734_tracc_90.53308823529412_616th_epoch.pt\n",
      "SP-[1] Epoch: 617/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.07  Acc 90.53% | Val: Loss nan  Acc(top1) 73.39% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "save model to ../../../trained_models/step_1_base_train/base_train_lr0.1_bs64_wd0.0005_20240520064825/uec_model_4Classes_hacc81.34557342529297_valacc_74.00611877441406_tracc_89.43014705882352_617th_epoch.pt\n",
      "SP-[1] Epoch: 618/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.07  Acc 89.43% | Val: Loss nan  Acc(top1) 74.01% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "save model to ../../../trained_models/step_1_base_train/base_train_lr0.1_bs64_wd0.0005_20240520064825/uec_model_4Classes_hacc81.34557342529297_valacc_73.70030975341797_tracc_90.34926470588235_618th_epoch.pt\n",
      "SP-[1] Epoch: 619/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.07  Acc 90.35% | Val: Loss nan  Acc(top1) 73.70% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 620/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.06  Acc 88.51% | Val: Loss nan  Acc(top1) 72.48% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "save model to ../../../trained_models/step_1_base_train/base_train_lr0.1_bs64_wd0.0005_20240520064825/uec_model_4Classes_hacc81.34557342529297_valacc_74.61773681640625_tracc_89.15441176470588_620th_epoch.pt\n",
      "SP-[1] Epoch: 621/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.09  Acc 89.15% | Val: Loss nan  Acc(top1) 74.62% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "save model to ../../../trained_models/step_1_base_train/base_train_lr0.1_bs64_wd0.0005_20240520064825/uec_model_4Classes_hacc81.34557342529297_valacc_74.92355346679688_tracc_90.625_621th_epoch.pt\n",
      "SP-[1] Epoch: 622/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.07  Acc 90.62% | Val: Loss nan  Acc(top1) 74.92% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "save model to ../../../trained_models/step_1_base_train/base_train_lr0.1_bs64_wd0.0005_20240520064825/uec_model_4Classes_hacc81.34557342529297_valacc_73.08868408203125_tracc_89.43014705882352_622th_epoch.pt\n",
      "SP-[1] Epoch: 623/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.07  Acc 89.43% | Val: Loss nan  Acc(top1) 73.09% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "save model to ../../../trained_models/step_1_base_train/base_train_lr0.1_bs64_wd0.0005_20240520064825/uec_model_4Classes_hacc81.34557342529297_valacc_73.08868408203125_tracc_90.16544117647058_623th_epoch.pt\n",
      "SP-[1] Epoch: 624/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.07  Acc 90.17% | Val: Loss nan  Acc(top1) 73.09% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 625/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.07  Acc 89.71% | Val: Loss nan  Acc(top1) 70.64% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 626/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.06  Acc 90.81% | Val: Loss nan  Acc(top1) 72.78% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 627/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.07  Acc 89.06% | Val: Loss nan  Acc(top1) 72.48% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 628/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.07  Acc 89.06% | Val: Loss nan  Acc(top1) 72.17% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "save model to ../../../trained_models/step_1_base_train/base_train_lr0.1_bs64_wd0.0005_20240520064825/uec_model_4Classes_hacc81.34557342529297_valacc_74.00611877441406_tracc_90.16544117647058_628th_epoch.pt\n",
      "SP-[1] Epoch: 629/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.08  Acc 90.17% | Val: Loss nan  Acc(top1) 74.01% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "save model to ../../../trained_models/step_1_base_train/base_train_lr0.1_bs64_wd0.0005_20240520064825/uec_model_4Classes_hacc81.34557342529297_valacc_73.08868408203125_tracc_88.60294117647058_629th_epoch.pt\n",
      "SP-[1] Epoch: 630/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.08  Acc 88.60% | Val: Loss nan  Acc(top1) 73.09% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 631/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.07  Acc 90.07% | Val: Loss nan  Acc(top1) 72.78% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 632/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.07  Acc 90.90% | Val: Loss nan  Acc(top1) 70.03% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "save model to ../../../trained_models/step_1_base_train/base_train_lr0.1_bs64_wd0.0005_20240520064825/uec_model_4Classes_hacc81.34557342529297_valacc_74.00611877441406_tracc_89.33823529411765_632th_epoch.pt\n",
      "SP-[1] Epoch: 633/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.08  Acc 89.34% | Val: Loss nan  Acc(top1) 74.01% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 634/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.07  Acc 91.27% | Val: Loss nan  Acc(top1) 70.95% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "save model to ../../../trained_models/step_1_base_train/base_train_lr0.1_bs64_wd0.0005_20240520064825/uec_model_4Classes_hacc81.34557342529297_valacc_73.70030975341797_tracc_89.15441176470588_634th_epoch.pt\n",
      "SP-[1] Epoch: 635/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.06  Acc 89.15% | Val: Loss nan  Acc(top1) 73.70% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "save model to ../../../trained_models/step_1_base_train/base_train_lr0.1_bs64_wd0.0005_20240520064825/uec_model_4Classes_hacc81.34557342529297_valacc_74.61773681640625_tracc_89.98161764705883_635th_epoch.pt\n",
      "SP-[1] Epoch: 636/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.08  Acc 89.98% | Val: Loss nan  Acc(top1) 74.62% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "save model to ../../../trained_models/step_1_base_train/base_train_lr0.1_bs64_wd0.0005_20240520064825/uec_model_4Classes_hacc81.34557342529297_valacc_74.61773681640625_tracc_89.61397058823529_636th_epoch.pt\n",
      "SP-[1] Epoch: 637/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.07  Acc 89.61% | Val: Loss nan  Acc(top1) 74.62% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "save model to ../../../trained_models/step_1_base_train/base_train_lr0.1_bs64_wd0.0005_20240520064825/uec_model_4Classes_hacc81.34557342529297_valacc_76.14678955078125_tracc_90.53308823529412_637th_epoch.pt\n",
      "SP-[1] Epoch: 638/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.07  Acc 90.53% | Val: Loss nan  Acc(top1) 76.15% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "save model to ../../../trained_models/step_1_base_train/base_train_lr0.1_bs64_wd0.0005_20240520064825/uec_model_4Classes_hacc81.34557342529297_valacc_74.00611877441406_tracc_88.51102941176471_638th_epoch.pt\n",
      "SP-[1] Epoch: 639/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.08  Acc 88.51% | Val: Loss nan  Acc(top1) 74.01% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "save model to ../../../trained_models/step_1_base_train/base_train_lr0.1_bs64_wd0.0005_20240520064825/uec_model_4Classes_hacc81.34557342529297_valacc_74.92355346679688_tracc_89.52205882352942_639th_epoch.pt\n",
      "SP-[1] Epoch: 640/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.08  Acc 89.52% | Val: Loss nan  Acc(top1) 74.92% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "save model to ../../../trained_models/step_1_base_train/base_train_lr0.1_bs64_wd0.0005_20240520064825/uec_model_4Classes_hacc81.34557342529297_valacc_73.70030975341797_tracc_90.16544117647058_640th_epoch.pt\n",
      "SP-[1] Epoch: 641/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.06  Acc 90.17% | Val: Loss nan  Acc(top1) 73.70% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "save model to ../../../trained_models/step_1_base_train/base_train_lr0.1_bs64_wd0.0005_20240520064825/uec_model_4Classes_hacc81.34557342529297_valacc_74.61773681640625_tracc_89.88970588235294_641th_epoch.pt\n",
      "SP-[1] Epoch: 642/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.07  Acc 89.89% | Val: Loss nan  Acc(top1) 74.62% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "save model to ../../../trained_models/step_1_base_train/base_train_lr0.1_bs64_wd0.0005_20240520064825/uec_model_4Classes_hacc81.34557342529297_valacc_74.92355346679688_tracc_90.99264705882352_642th_epoch.pt\n",
      "SP-[1] Epoch: 643/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.07  Acc 90.99% | Val: Loss nan  Acc(top1) 74.92% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 644/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.07  Acc 89.52% | Val: Loss nan  Acc(top1) 70.64% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "save model to ../../../trained_models/step_1_base_train/base_train_lr0.1_bs64_wd0.0005_20240520064825/uec_model_4Classes_hacc81.34557342529297_valacc_73.39449310302734_tracc_90.71691176470588_644th_epoch.pt\n",
      "SP-[1] Epoch: 645/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.07  Acc 90.72% | Val: Loss nan  Acc(top1) 73.39% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "save model to ../../../trained_models/step_1_base_train/base_train_lr0.1_bs64_wd0.0005_20240520064825/uec_model_4Classes_hacc81.34557342529297_valacc_73.70030975341797_tracc_92.55514705882352_645th_epoch.pt\n",
      "SP-[1] Epoch: 646/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.07  Acc 92.56% | Val: Loss nan  Acc(top1) 73.70% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 647/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.07  Acc 90.07% | Val: Loss nan  Acc(top1) 72.48% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "save model to ../../../trained_models/step_1_base_train/base_train_lr0.1_bs64_wd0.0005_20240520064825/uec_model_4Classes_hacc81.34557342529297_valacc_74.92355346679688_tracc_90.34926470588235_647th_epoch.pt\n",
      "SP-[1] Epoch: 648/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.07  Acc 90.35% | Val: Loss nan  Acc(top1) 74.92% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 649/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.07  Acc 88.79% | Val: Loss nan  Acc(top1) 72.78% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 650/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.08  Acc 89.15% | Val: Loss nan  Acc(top1) 72.48% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 651/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.08  Acc 89.06% | Val: Loss nan  Acc(top1) 72.17% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "save model to ../../../trained_models/step_1_base_train/base_train_lr0.1_bs64_wd0.0005_20240520064825/uec_model_4Classes_hacc81.34557342529297_valacc_73.39449310302734_tracc_90.34926470588235_651th_epoch.pt\n",
      "SP-[1] Epoch: 652/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.07  Acc 90.35% | Val: Loss nan  Acc(top1) 73.39% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "save model to ../../../trained_models/step_1_base_train/base_train_lr0.1_bs64_wd0.0005_20240520064825/uec_model_4Classes_hacc81.34557342529297_valacc_73.70030975341797_tracc_90.44117647058823_652th_epoch.pt\n",
      "SP-[1] Epoch: 653/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.07  Acc 90.44% | Val: Loss nan  Acc(top1) 73.70% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 654/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.06  Acc 91.18% | Val: Loss nan  Acc(top1) 72.78% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 655/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.07  Acc 89.71% | Val: Loss nan  Acc(top1) 72.78% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "save model to ../../../trained_models/step_1_base_train/base_train_lr0.1_bs64_wd0.0005_20240520064825/uec_model_4Classes_hacc81.34557342529297_valacc_74.61773681640625_tracc_90.71691176470588_655th_epoch.pt\n",
      "SP-[1] Epoch: 656/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.08  Acc 90.72% | Val: Loss nan  Acc(top1) 74.62% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "save model to ../../../trained_models/step_1_base_train/base_train_lr0.1_bs64_wd0.0005_20240520064825/uec_model_4Classes_hacc81.34557342529297_valacc_74.31192779541016_tracc_89.24632352941177_656th_epoch.pt\n",
      "SP-[1] Epoch: 657/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.07  Acc 89.25% | Val: Loss nan  Acc(top1) 74.31% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "save model to ../../../trained_models/step_1_base_train/base_train_lr0.1_bs64_wd0.0005_20240520064825/uec_model_4Classes_hacc81.34557342529297_valacc_74.61773681640625_tracc_89.98161764705883_657th_epoch.pt\n",
      "SP-[1] Epoch: 658/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.07  Acc 89.98% | Val: Loss nan  Acc(top1) 74.62% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 659/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.06  Acc 89.34% | Val: Loss nan  Acc(top1) 71.25% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "save model to ../../../trained_models/step_1_base_train/base_train_lr0.1_bs64_wd0.0005_20240520064825/uec_model_4Classes_hacc81.34557342529297_valacc_74.00611877441406_tracc_90.34926470588235_659th_epoch.pt\n",
      "SP-[1] Epoch: 660/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.07  Acc 90.35% | Val: Loss nan  Acc(top1) 74.01% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 661/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.07  Acc 89.34% | Val: Loss nan  Acc(top1) 72.78% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "save model to ../../../trained_models/step_1_base_train/base_train_lr0.1_bs64_wd0.0005_20240520064825/uec_model_4Classes_hacc81.34557342529297_valacc_73.08868408203125_tracc_90.625_661th_epoch.pt\n",
      "SP-[1] Epoch: 662/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.06  Acc 90.62% | Val: Loss nan  Acc(top1) 73.09% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "save model to ../../../trained_models/step_1_base_train/base_train_lr0.1_bs64_wd0.0005_20240520064825/uec_model_4Classes_hacc81.34557342529297_valacc_74.61773681640625_tracc_89.24632352941177_662th_epoch.pt\n",
      "SP-[1] Epoch: 663/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.08  Acc 89.25% | Val: Loss nan  Acc(top1) 74.62% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "save model to ../../../trained_models/step_1_base_train/base_train_lr0.1_bs64_wd0.0005_20240520064825/uec_model_4Classes_hacc81.34557342529297_valacc_75.22935485839844_tracc_90.71691176470588_663th_epoch.pt\n",
      "SP-[1] Epoch: 664/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.06  Acc 90.72% | Val: Loss nan  Acc(top1) 75.23% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 665/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.07  Acc 91.36% | Val: Loss nan  Acc(top1) 71.56% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "save model to ../../../trained_models/step_1_base_train/base_train_lr0.1_bs64_wd0.0005_20240520064825/uec_model_4Classes_hacc81.34557342529297_valacc_76.14678955078125_tracc_90.34926470588235_665th_epoch.pt\n",
      "SP-[1] Epoch: 666/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.07  Acc 90.35% | Val: Loss nan  Acc(top1) 76.15% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 667/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.07  Acc 87.68% | Val: Loss nan  Acc(top1) 72.78% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "save model to ../../../trained_models/step_1_base_train/base_train_lr0.1_bs64_wd0.0005_20240520064825/uec_model_4Classes_hacc81.34557342529297_valacc_74.00611877441406_tracc_90.34926470588235_667th_epoch.pt\n",
      "SP-[1] Epoch: 668/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.07  Acc 90.35% | Val: Loss nan  Acc(top1) 74.01% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 669/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.07  Acc 90.44% | Val: Loss nan  Acc(top1) 71.87% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "save model to ../../../trained_models/step_1_base_train/base_train_lr0.1_bs64_wd0.0005_20240520064825/uec_model_4Classes_hacc81.34557342529297_valacc_75.53517150878906_tracc_89.43014705882352_669th_epoch.pt\n",
      "SP-[1] Epoch: 670/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.08  Acc 89.43% | Val: Loss nan  Acc(top1) 75.54% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "save model to ../../../trained_models/step_1_base_train/base_train_lr0.1_bs64_wd0.0005_20240520064825/uec_model_4Classes_hacc81.34557342529297_valacc_73.39449310302734_tracc_90.34926470588235_670th_epoch.pt\n",
      "SP-[1] Epoch: 671/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.07  Acc 90.35% | Val: Loss nan  Acc(top1) 73.39% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "save model to ../../../trained_models/step_1_base_train/base_train_lr0.1_bs64_wd0.0005_20240520064825/uec_model_4Classes_hacc81.34557342529297_valacc_73.08868408203125_tracc_91.72794117647058_671th_epoch.pt\n",
      "SP-[1] Epoch: 672/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.06  Acc 91.73% | Val: Loss nan  Acc(top1) 73.09% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "save model to ../../../trained_models/step_1_base_train/base_train_lr0.1_bs64_wd0.0005_20240520064825/uec_model_4Classes_hacc81.34557342529297_valacc_73.70030975341797_tracc_89.24632352941177_672th_epoch.pt\n",
      "SP-[1] Epoch: 673/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.07  Acc 89.25% | Val: Loss nan  Acc(top1) 73.70% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "save model to ../../../trained_models/step_1_base_train/base_train_lr0.1_bs64_wd0.0005_20240520064825/uec_model_4Classes_hacc81.34557342529297_valacc_73.70030975341797_tracc_89.79779411764706_673th_epoch.pt\n",
      "SP-[1] Epoch: 674/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.07  Acc 89.80% | Val: Loss nan  Acc(top1) 73.70% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "save model to ../../../trained_models/step_1_base_train/base_train_lr0.1_bs64_wd0.0005_20240520064825/uec_model_4Classes_hacc81.34557342529297_valacc_74.31192779541016_tracc_91.72794117647058_674th_epoch.pt\n",
      "SP-[1] Epoch: 675/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.07  Acc 91.73% | Val: Loss nan  Acc(top1) 74.31% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "save model to ../../../trained_models/step_1_base_train/base_train_lr0.1_bs64_wd0.0005_20240520064825/uec_model_4Classes_hacc81.34557342529297_valacc_74.61773681640625_tracc_89.0625_675th_epoch.pt\n",
      "SP-[1] Epoch: 676/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.07  Acc 89.06% | Val: Loss nan  Acc(top1) 74.62% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "save model to ../../../trained_models/step_1_base_train/base_train_lr0.1_bs64_wd0.0005_20240520064825/uec_model_4Classes_hacc81.34557342529297_valacc_73.39449310302734_tracc_89.52205882352942_676th_epoch.pt\n",
      "SP-[1] Epoch: 677/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.06  Acc 89.52% | Val: Loss nan  Acc(top1) 73.39% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "save model to ../../../trained_models/step_1_base_train/base_train_lr0.1_bs64_wd0.0005_20240520064825/uec_model_4Classes_hacc81.34557342529297_valacc_74.92355346679688_tracc_90.25735294117648_677th_epoch.pt\n",
      "SP-[1] Epoch: 678/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.07  Acc 90.26% | Val: Loss nan  Acc(top1) 74.92% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 679/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.08  Acc 89.80% | Val: Loss nan  Acc(top1) 72.48% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "save model to ../../../trained_models/step_1_base_train/base_train_lr0.1_bs64_wd0.0005_20240520064825/uec_model_4Classes_hacc81.34557342529297_valacc_73.39449310302734_tracc_91.17647058823529_679th_epoch.pt\n",
      "SP-[1] Epoch: 680/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.06  Acc 91.18% | Val: Loss nan  Acc(top1) 73.39% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 681/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.07  Acc 91.45% | Val: Loss nan  Acc(top1) 71.87% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "save model to ../../../trained_models/step_1_base_train/base_train_lr0.1_bs64_wd0.0005_20240520064825/uec_model_4Classes_hacc81.34557342529297_valacc_73.39449310302734_tracc_90.44117647058823_681th_epoch.pt\n",
      "SP-[1] Epoch: 682/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.08  Acc 90.44% | Val: Loss nan  Acc(top1) 73.39% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 683/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.07  Acc 89.25% | Val: Loss nan  Acc(top1) 71.87% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "save model to ../../../trained_models/step_1_base_train/base_train_lr0.1_bs64_wd0.0005_20240520064825/uec_model_4Classes_hacc81.34557342529297_valacc_73.08868408203125_tracc_88.14338235294117_683th_epoch.pt\n",
      "SP-[1] Epoch: 684/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.07  Acc 88.14% | Val: Loss nan  Acc(top1) 73.09% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "save model to ../../../trained_models/step_1_base_train/base_train_lr0.1_bs64_wd0.0005_20240520064825/uec_model_4Classes_hacc81.34557342529297_valacc_73.70030975341797_tracc_88.60294117647058_684th_epoch.pt\n",
      "SP-[1] Epoch: 685/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.06  Acc 88.60% | Val: Loss nan  Acc(top1) 73.70% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "save model to ../../../trained_models/step_1_base_train/base_train_lr0.1_bs64_wd0.0005_20240520064825/uec_model_4Classes_hacc81.34557342529297_valacc_74.31192779541016_tracc_89.61397058823529_685th_epoch.pt\n",
      "SP-[1] Epoch: 686/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.06  Acc 89.61% | Val: Loss nan  Acc(top1) 74.31% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "save model to ../../../trained_models/step_1_base_train/base_train_lr0.1_bs64_wd0.0005_20240520064825/uec_model_4Classes_hacc81.34557342529297_valacc_74.00611877441406_tracc_91.36029411764706_686th_epoch.pt\n",
      "SP-[1] Epoch: 687/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.07  Acc 91.36% | Val: Loss nan  Acc(top1) 74.01% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 688/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.06  Acc 90.07% | Val: Loss nan  Acc(top1) 72.17% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "save model to ../../../trained_models/step_1_base_train/base_train_lr0.1_bs64_wd0.0005_20240520064825/uec_model_4Classes_hacc81.34557342529297_valacc_74.92355346679688_tracc_89.43014705882352_688th_epoch.pt\n",
      "SP-[1] Epoch: 689/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.07  Acc 89.43% | Val: Loss nan  Acc(top1) 74.92% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "save model to ../../../trained_models/step_1_base_train/base_train_lr0.1_bs64_wd0.0005_20240520064825/uec_model_4Classes_hacc81.34557342529297_valacc_74.31192779541016_tracc_90.16544117647058_689th_epoch.pt\n",
      "SP-[1] Epoch: 690/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.06  Acc 90.17% | Val: Loss nan  Acc(top1) 74.31% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 691/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.07  Acc 90.26% | Val: Loss nan  Acc(top1) 70.34% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "save model to ../../../trained_models/step_1_base_train/base_train_lr0.1_bs64_wd0.0005_20240520064825/uec_model_4Classes_hacc81.34557342529297_valacc_75.22935485839844_tracc_91.17647058823529_691th_epoch.pt\n",
      "SP-[1] Epoch: 692/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.06  Acc 91.18% | Val: Loss nan  Acc(top1) 75.23% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 693/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.07  Acc 90.35% | Val: Loss nan  Acc(top1) 72.48% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "save model to ../../../trained_models/step_1_base_train/base_train_lr0.1_bs64_wd0.0005_20240520064825/uec_model_4Classes_hacc81.34557342529297_valacc_73.70030975341797_tracc_89.88970588235294_693th_epoch.pt\n",
      "SP-[1] Epoch: 694/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.06  Acc 89.89% | Val: Loss nan  Acc(top1) 73.70% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 695/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.07  Acc 90.81% | Val: Loss nan  Acc(top1) 72.17% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 696/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.07  Acc 89.15% | Val: Loss nan  Acc(top1) 72.78% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "save model to ../../../trained_models/step_1_base_train/base_train_lr0.1_bs64_wd0.0005_20240520064825/uec_model_4Classes_hacc81.34557342529297_valacc_73.70030975341797_tracc_90.625_696th_epoch.pt\n",
      "SP-[1] Epoch: 697/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.07  Acc 90.62% | Val: Loss nan  Acc(top1) 73.70% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 698/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.08  Acc 90.17% | Val: Loss nan  Acc(top1) 71.25% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "save model to ../../../trained_models/step_1_base_train/base_train_lr0.1_bs64_wd0.0005_20240520064825/uec_model_4Classes_hacc81.34557342529297_valacc_73.70030975341797_tracc_90.53308823529412_698th_epoch.pt\n",
      "SP-[1] Epoch: 699/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.08  Acc 90.53% | Val: Loss nan  Acc(top1) 73.70% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "save model to ../../../trained_models/step_1_base_train/base_train_lr0.1_bs64_wd0.0005_20240520064825/uec_model_4Classes_hacc81.34557342529297_valacc_73.70030975341797_tracc_90.99264705882352_699th_epoch.pt\n",
      "SP-[1] Epoch: 700/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.07  Acc 90.99% | Val: Loss nan  Acc(top1) 73.70% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 701/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.07  Acc 89.15% | Val: Loss nan  Acc(top1) 72.48% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 702/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.07  Acc 90.17% | Val: Loss nan  Acc(top1) 71.25% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 703/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.07  Acc 89.80% | Val: Loss nan  Acc(top1) 71.87% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "save model to ../../../trained_models/step_1_base_train/base_train_lr0.1_bs64_wd0.0005_20240520064825/uec_model_4Classes_hacc81.34557342529297_valacc_73.70030975341797_tracc_89.52205882352942_703th_epoch.pt\n",
      "SP-[1] Epoch: 704/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.07  Acc 89.52% | Val: Loss nan  Acc(top1) 73.70% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "SP-[1] Epoch: 705/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.07  Acc 90.81% | Val: Loss nan  Acc(top1) 72.78% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "save model to ../../../trained_models/step_1_base_train/base_train_lr0.1_bs64_wd0.0005_20240520064825/uec_model_4Classes_hacc81.34557342529297_valacc_73.39449310302734_tracc_89.98161764705883_705th_epoch.pt\n",
      "SP-[1] Epoch: 706/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.07  Acc 89.98% | Val: Loss nan  Acc(top1) 73.39% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "save model to ../../../trained_models/step_1_base_train/base_train_lr0.1_bs64_wd0.0005_20240520064825/uec_model_4Classes_hacc81.34557342529297_valacc_73.39449310302734_tracc_91.36029411764706_706th_epoch.pt\n",
      "SP-[1] Epoch: 707/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.07  Acc 91.36% | Val: Loss nan  Acc(top1) 73.39% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "save model to ../../../trained_models/step_1_base_train/base_train_lr0.1_bs64_wd0.0005_20240520064825/uec_model_4Classes_hacc81.34557342529297_valacc_73.39449310302734_tracc_90.53308823529412_707th_epoch.pt\n",
      "SP-[1] Epoch: 708/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.07  Acc 90.53% | Val: Loss nan  Acc(top1) 73.39% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "save model to ../../../trained_models/step_1_base_train/base_train_lr0.1_bs64_wd0.0005_20240520064825/uec_model_4Classes_hacc81.34557342529297_valacc_76.14678955078125_tracc_89.70588235294117_708th_epoch.pt\n",
      "SP-[1] Epoch: 709/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.08  Acc 89.71% | Val: Loss nan  Acc(top1) 76.15% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "save model to ../../../trained_models/step_1_base_train/base_train_lr0.1_bs64_wd0.0005_20240520064825/uec_model_4Classes_hacc81.34557342529297_valacc_76.45259857177734_tracc_90.16544117647058_709th_epoch.pt\n",
      "SP-[1] Epoch: 710/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.07  Acc 90.17% | Val: Loss nan  Acc(top1) 76.45% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "save model to ../../../trained_models/step_1_base_train/base_train_lr0.1_bs64_wd0.0005_20240520064825/uec_model_4Classes_hacc81.34557342529297_valacc_74.61773681640625_tracc_89.24632352941177_710th_epoch.pt\n",
      "SP-[1] Epoch: 711/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.07  Acc 89.25% | Val: Loss nan  Acc(top1) 74.62% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "save model to ../../../trained_models/step_1_base_train/base_train_lr0.1_bs64_wd0.0005_20240520064825/uec_model_4Classes_hacc81.34557342529297_valacc_74.92355346679688_tracc_89.98161764705883_711th_epoch.pt\n",
      "SP-[1] Epoch: 712/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.07  Acc 89.98% | Val: Loss nan  Acc(top1) 74.92% | HA 81.35@425\n",
      "after: len of y_pred:327, len of y_target:327\n",
      "save model to ../../../trained_models/step_1_base_train/base_train_lr0.1_bs64_wd0.0005_20240520064825/uec_model_4Classes_hacc81.34557342529297_valacc_74.00611877441406_tracc_90.71691176470588_712th_epoch.pt\n",
      "SP-[1] Epoch: 713/1600 | Time: 0m06s (Train 0m06s  Val 0m00s) | Train: LR 0.010000000000000002  Loss 0.06  Acc 90.72% | Val: Loss nan  Acc(top1) 74.01% | HA 81.35@425\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[22], line 39\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     37\u001b[0m trainer \u001b[38;5;241m=\u001b[39m TLTrainer(opt,classes_dict\u001b[38;5;241m=\u001b[39mmap_dict_train)\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStart to training.....\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 39\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m;\n\u001b[1;32m     40\u001b[0m logObj\u001b[38;5;241m.\u001b[39mflush();\n\u001b[1;32m     41\u001b[0m logObj\u001b[38;5;241m.\u001b[39mclose()\n",
      "Cell \u001b[0;32mIn[18], line 37\u001b[0m, in \u001b[0;36mTLTrainer.Train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     34\u001b[0m n_batches \u001b[38;5;241m=\u001b[39m math\u001b[38;5;241m.\u001b[39mceil(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainGen\u001b[38;5;241m.\u001b[39mdata)\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mopt\u001b[38;5;241m.\u001b[39mbatchSize);\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batchIdx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_batches):\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;66;03m# with torch.no_grad():\u001b[39;00m\n\u001b[0;32m---> 37\u001b[0m     x,y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainGen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getitem__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mbatchIdx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m     x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(np\u001b[38;5;241m.\u001b[39mmoveaxis(x, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m1\u001b[39m))\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mopt\u001b[38;5;241m.\u001b[39mdevice);\n\u001b[1;32m     39\u001b[0m     y \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(y)\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mopt\u001b[38;5;241m.\u001b[39mdevice);\n",
      "Cell \u001b[0;32mIn[6], line 21\u001b[0m, in \u001b[0;36mTLGenerator.__getitem__\u001b[0;34m(self, batchIndex)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, batchIndex):\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;66;03m#Generate one batch of data\u001b[39;00m\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;66;03m# batchX, batchY = self.generate_batch(batchIndex);\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m     batchX, batchY \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_batch_select_fixed_class\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatchIndex\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m     batchX \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mexpand_dims(batchX, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m);\n\u001b[1;32m     23\u001b[0m     batchX \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mexpand_dims(batchX, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m);\n",
      "Cell \u001b[0;32mIn[6], line 115\u001b[0m, in \u001b[0;36mTLGenerator.generate_batch_select_fixed_class\u001b[0;34m(self, batchIndex)\u001b[0m\n\u001b[1;32m    113\u001b[0m                 \u001b[38;5;28;01mbreak\u001b[39;00m;\n\u001b[1;32m    114\u001b[0m \u001b[38;5;66;03m# print(f\"escape for loop\");\u001b[39;00m\n\u001b[0;32m--> 115\u001b[0m sound1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpreprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43msound1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    116\u001b[0m sound2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreprocess(sound2)\n\u001b[1;32m    118\u001b[0m \u001b[38;5;66;03m# Mix two examples\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[6], line 166\u001b[0m, in \u001b[0;36mTLGenerator.preprocess\u001b[0;34m(self, sound)\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpreprocess\u001b[39m(\u001b[38;5;28mself\u001b[39m, sound):\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreprocess_funcs:\n\u001b[0;32m--> 166\u001b[0m         sound \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43msound\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    168\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m sound\n",
      "File \u001b[0;32m~/WorkSpaces/Work/Projects/uec-iot-ai-models/src/Training/Basic_Training/../../common/utils.py:37\u001b[0m, in \u001b[0;36mrandom_scale.<locals>.f\u001b[0;34m(sound)\u001b[0m\n\u001b[1;32m     35\u001b[0m ref \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marange(output_size) \u001b[38;5;241m/\u001b[39m scale\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m interpolate \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLinear\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m---> 37\u001b[0m     ref1 \u001b[38;5;241m=\u001b[39m ref\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mint32)\n\u001b[1;32m     38\u001b[0m     ref2 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mminimum(ref1 \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mlen\u001b[39m(sound) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;66;03m# print(f\"ref1:{ref1}, type:{type(ref1)},  ref2:{ref2}, type:{type(ref2)}\")\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56dd0a02-5ede-47ab-873a-bae1f69f291c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d275de5-8d96-492b-a26c-d338649ffd75",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
