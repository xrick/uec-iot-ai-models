{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a30fbf09-03f7-4c3c-aff3-d28a77d29d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys;\n",
    "import os;\n",
    "import glob;\n",
    "import math;\n",
    "import numpy as np;\n",
    "import time;\n",
    "from tensorflow import keras;\n",
    "\n",
    "sys.path.append(os.getcwd());\n",
    "sys.path.append(os.path.join(os.getcwd(), 'common'));\n",
    "import common.utils as U;\n",
    "# import common.opts as opts;\n",
    "import common.tlopts as tlopts\n",
    "import resources.TLModels as tlmodels;\n",
    "import resources.train_generator as train_generator;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8642c4ef-c4ea-450b-ba06-e5ba7344c36d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af57213d-67d3-45d4-b64d-c94a3eafae6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "14259285-fc7b-424d-8528-882273098e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomCallback(keras.callbacks.Callback):\n",
    "    def __init__(self, opt):\n",
    "        self.opt = opt;\n",
    "        self.testX = None;\n",
    "        self.testY = None;\n",
    "        self.curEpoch = 0;\n",
    "        self.curLr = opt.LR;\n",
    "        self.cur_epoch_start_time = time.time();\n",
    "        self.bestAcc = 0.0;\n",
    "        self.bestAccEpoch = 0;\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        self.curEpoch = epoch+1;\n",
    "        self.curLr = Trainer(self.opt).GetLR(epoch+1);\n",
    "        self.cur_epoch_start_time = time.time();\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        train_time = time.time() - self.cur_epoch_start_time;\n",
    "        self.load_test_data();\n",
    "        val_acc, val_loss = self.validate(self.model);\n",
    "        logs['val_acc'] = val_acc;\n",
    "        logs['val_loss'] = val_loss;\n",
    "        if val_acc > self.bestAcc:\n",
    "            self.bestAcc = val_acc;\n",
    "            self.bestAccEpoch = epoch + 1;\n",
    "        epoch_time = time.time() - self.cur_epoch_start_time;\n",
    "        val_time = epoch_time - train_time;\n",
    "        # print(logs);\n",
    "        line = 'SP-{}, Epoch: {}/{} | Time: {} (Train {}  Val {}) | Train: LR {}  Loss {:.2f}  Acc {:.2f}% | Val: Loss {:.2f}  Acc(top1) {:.2f}% | HA {:.2f}@{}\\n'.format(\n",
    "            self.opt.split, epoch+1, self.opt.nEpochs, U.to_hms(epoch_time), U.to_hms(train_time), U.to_hms(val_time),\n",
    "            self.curLr, logs['loss'], logs['accuracy'] if 'accuracy' in logs else logs['acc'], val_loss, val_acc, self.bestAcc, self.bestAccEpoch);\n",
    "        # print(line)\n",
    "        sys.stdout.write(line);\n",
    "        sys.stdout.flush();\n",
    "\n",
    "    def load_test_data(self):\n",
    "        if self.testX is None:\n",
    "            data = np.load(os.path.join(self.opt.data, self.opt.dataset, 'test_data_20khz/fold{}_test4000.npz'.format(self.opt.split)), allow_pickle=True);\n",
    "            self.testX = data['x'];\n",
    "            self.testY = data['y'];\n",
    "\n",
    "    def validate(self, model):\n",
    "        y_pred = None;\n",
    "        y_target = None;\n",
    "        batch_size = (self.opt.batchSize//self.opt.nCrops)*self.opt.nCrops;\n",
    "        for batchIndex in range(math.ceil(len(self.testX) / batch_size)):\n",
    "            x = self.testX[batchIndex*batch_size : (batchIndex+1)*batch_size];\n",
    "            y = self.testY[batchIndex*batch_size : (batchIndex+1)*batch_size];\n",
    "            scores = model.predict(x, batch_size=len(y), verbose=0);\n",
    "            y_pred = scores if y_pred is None else np.concatenate((y_pred, scores));\n",
    "            y_target = y if y_target is None else np.concatenate((y_target, y));\n",
    "            #break;\n",
    "\n",
    "        acc, loss = self.compute_accuracy(y_pred, y_target);\n",
    "        return acc, loss;\n",
    "\n",
    "    #Calculating average prediction (10 crops) and final accuracy\n",
    "    def compute_accuracy(self, y_pred, y_target):\n",
    "        #Reshape y_pred to shape it like each sample comtains 10 samples.\n",
    "        if self.opt.nCrops > 1:\n",
    "            y_pred = (y_pred.reshape(y_pred.shape[0]//self.opt.nCrops, self.opt.nCrops, y_pred.shape[1])).mean(axis=1);\n",
    "            y_target = (y_target.reshape(y_target.shape[0]//self.opt.nCrops, self.opt.nCrops, y_target.shape[1])).mean(axis=1);\n",
    "\n",
    "        loss = keras.losses.KLD(y_target, y_pred).numpy().mean();\n",
    "\n",
    "        #Get the indices that has highest average value for each sample\n",
    "        y_pred = y_pred.argmax(axis=1);\n",
    "        y_target = y_target.argmax(axis=1);\n",
    "        accuracy = (y_pred==y_target).mean()*100;\n",
    "\n",
    "        return accuracy, loss;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "805141a9-fa08-4e3c-b469-f165e4392f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TLTrainer:\n",
    "    def __init__(self, opt=None):\n",
    "        self.opt = opt;\n",
    "        self.trainGen = train_generator.setup(self.opt, self.opt.split);\n",
    "\n",
    "    def Train(self):\n",
    "        # model = tlmodels.GetAcdnetModel(self.opt.inputLength, 50, self.opt.sr, ch_config = self.opt.model_config);\n",
    "        model  = tlmodels.GetTLACDNet()\n",
    "        model.summary();\n",
    "\n",
    "        loss = 'kullback_leibler_divergence';\n",
    "        optimizer = keras.optimizers.SGD(learning_rate=self.opt.LR, weight_decay=self.opt.weightDecay, momentum=self.opt.momentum, nesterov=True)\n",
    "\n",
    "        model.compile(loss=loss, optimizer=optimizer , metrics=['accuracy']);\n",
    "\n",
    "        # learning schedule callback\n",
    "        lrate = keras.callbacks.LearningRateScheduler(self.GetLR);\n",
    "        best_model = keras.callbacks.ModelCheckpoint('tf/trained_models/{}.h5'.format(self.opt.model_name), monitor='val_acc', save_best_only=True, verbose=0);\n",
    "        custom_evaluator = CustomCallback(self.opt);\n",
    "        callbacks_list = [lrate, custom_evaluator, best_model];\n",
    "\n",
    "        model.fit(self.trainGen, epochs=self.opt.nEpochs, steps_per_epoch=len(self.trainGen.data)//self.trainGen.batch_size, callbacks=callbacks_list, verbose=0);\n",
    "\n",
    "    def GetLR(self, epoch):\n",
    "        divide_epoch = np.array([self.opt.nEpochs * i for i in self.opt.schedule]);\n",
    "        decay = sum(epoch > divide_epoch);\n",
    "        if epoch <= self.opt.warmup:\n",
    "            decay = 1;\n",
    "        return self.opt.LR * np.power(0.1, decay);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d99f6a01-7989-47f3-bbed-6ce8b19b91b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    opt = tlopts.parse()#opts.parse();\n",
    "    opt.sr = 16000#20000;\n",
    "    opt.inputLength = 30225;\n",
    "    import torch;\n",
    "    opt.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\");\n",
    "    trainer = TLTrainer(opt);\n",
    "    trainer.Train();"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
