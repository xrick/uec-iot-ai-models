{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7a001c5-4393-49ba-96bb-6643ae25d96f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import subprocess\n",
    "import glob\n",
    "import numpy as np\n",
    "import wavio\n",
    "import time;\n",
    "import random;\n",
    "from common import opts;\n",
    "import common.utils as U;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cafdf4f4-84d1-4fc6-be5d-3f6da8c9fd57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e0b63f0-6769-4418-883f-4832e2875677",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_wav_dir = \"./datasets/before_processed_audio/\"\n",
    "train_dest_wav_dir = \".//datasets/processing_tmp_audios/train/\"\n",
    "test_dest_wav_dir = \"./datasets/processing_tmp_audios/test/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2bd74992-32df-4609-a2a6-36e7390db410",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getOpts():\n",
    "    parser = argparse.ArgumentParser(description='Transfer Learning for ACDNet');\n",
    "    parser.add_argument('--netType', default='ACDNet_TL_Model_Extend',  required=False);\n",
    "    parser.add_argument('--data', default='../datasets/processed/',  required=False);\n",
    "    parser.add_argument('--dataset', required=False, default='uec_iot', choices=['10']);\n",
    "    parser.add_argument('--BC', default=True, action='store_true', help='BC learning');\n",
    "    parser.add_argument('--strongAugment', default=True,  action='store_true', help='Add scale and gain augmentation');\n",
    "    #在ipynb中，不能使用parser.parse，要改用parser.parse_known_args()\n",
    "    opt, unknown = parser.parse_known_args()\n",
    "    #Leqarning settings\n",
    "    opt.batchSize = 88;\n",
    "    opt.weightDecay = 5e-4;\n",
    "    opt.momentum = 0.09;\n",
    "    opt.nEpochs = 10;#2000;\n",
    "    opt.LR = 0.1;\n",
    "    opt.schedule = [0.3, 0.6, 0.9];\n",
    "    opt.warmup = 10;\n",
    "    opt.device = 'cpu';#torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\");\n",
    "    #Basic Net Settings\n",
    "    opt.nClasses = 12#50;\n",
    "    opt.nFolds = 5;\n",
    "    opt.splits = [i for i in range(1, opt.nFolds + 1)];\n",
    "    opt.sr = 20000;\n",
    "    opt.inputLength = 30225;\n",
    "    #Test data\n",
    "    opt.nCrops = 4;\n",
    "    return opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fff8b25c-0106-4c0a-aab9-ce631bd89317",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_sr(src_path, dst_path, sr):\n",
    "    # print('* {} -> {}'.format(src_path, dst_path))\n",
    "    if not os.path.exists(dst_path):\n",
    "        os.mkdir(dst_path);\n",
    "    for src_file in sorted(glob.glob(os.path.join(src_path, '*.wav'))):\n",
    "        dst_file = src_file.replace(src_path, dst_path);\n",
    "        subprocess.call('ffmpeg -i {} -ac 1 -ar {} -loglevel error -y {}'.format(\n",
    "            src_file, sr, dst_file), shell=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ff8e3232-90dd-4bd5-a492-a7a99d09a2e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    classes_dict = {\n",
    "        17:\"17_pouring_water\", #pouring_water\n",
    "        18:\"18_toilet_flushing\", #toilet_flushing\n",
    "        21:\"21_sneezing\", #snezzing\n",
    "        24:\"24_coughing\", #coughing\n",
    "        51:\"51_kettle_sound\", #kettle_sound\n",
    "        52:\"52_alarm\", #alarm\n",
    "        #53:\"53_boiling_water_bubble_sound\", #boiling_water_bubble_sound\n",
    "        54:\"54_ringtone\", #rington\n",
    "        55:\"55_shower_water\", #shower_water\n",
    "        56:\"56_pain_sounds\", #pain_sounds\n",
    "        57:\"57_footsteps\", #footsteps\n",
    "        98:\"98_silence\", #silence\n",
    "        99:\"99_other_sounds\", #other_sounds\n",
    "                   };\n",
    "    sr = 20000;\n",
    "    iter_count = 0;\n",
    "    for k in classes_dict:\n",
    "        cur_src_dir = os.path.join(src_wav_dir,classes_dict[k]);\n",
    "        print(f\"current work directory:{cur_src_dir}\\n\");\n",
    "        for w in sorted(glob.glob(os.path.join(cur_src_dir, '*.wav'))):\n",
    "            fname = \"{}.wav\".format(os.path.basename(w).split('.')[0]);\n",
    "            dest_fname = os.path.join(dest_wav_dir,classes_dict[k],fname);\n",
    "            print(f\"Convert Sampling Rate:{w} >> {dest_fname}\");\n",
    "            subprocess.call('ffmpeg -i {} -ac 1 -ar {} -loglevel error -y {}'.format(\n",
    "            w, sr, dest_fname), shell=True);\n",
    "            # print(f\"wav:{w}\");\n",
    "        # print(f\"key:{k}, value:{classes_dict[k]}\");\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "64c744d9-8451-46ed-9083-532f1b70155a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8749354-1d8b-4395-ab88-b52fb856335f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cae010db-e1ca-4245-ad39-82b1007a8ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(src_path, dst_path):\n",
    "    # print('* {} -> {}'.format(src_path, dst_path))\n",
    "    classes_dict = {\n",
    "        17:\"17_pouring_water\", #pouring_water\n",
    "        18:\"18_toilet_flushing\", #toilet_flushing\n",
    "        21:\"21_sneezing\", #snezzing\n",
    "        24:\"24_coughing\", #coughing\n",
    "        51:\"51_kettle_sound\", #kettle_sound\n",
    "        52:\"52_alarm\", #alarm\n",
    "        #53:\"53_boiling_water_bubble_sound\", #boiling_water_bubble_sound\n",
    "        54:\"54_ringtone\", #rington\n",
    "        55:\"55_shower_water\", #shower_water\n",
    "        56:\"56_pain_sounds\", #pain_sounds\n",
    "        57:\"57_footsteps\", #footsteps\n",
    "        98:\"98_silence\", #silence\n",
    "        99:\"99_other_sounds\", #other_sounds\n",
    "    };\n",
    "    # idx_dict = {\n",
    "    #     17:1, #pouring_water\n",
    "    #     18:2, #toilet_flushing\n",
    "    #     21:3, #snezzing\n",
    "    #     24:4, #coughing\n",
    "    #     51:5, #kettle_sound\n",
    "    #     52:6, #alarm\n",
    "    #     #53:\"53_boiling_water_bubble_sound\", #boiling_water_bubble_sound\n",
    "    #     54:7, #rington\n",
    "    #     55:8, #shower_water\n",
    "    #     56:9, #pain_sounds\n",
    "    #     57:10, #footsteps\n",
    "    #     98:11, #silence\n",
    "    #     99:12, #other_sounds\n",
    "    # };\n",
    "    my_dataset = {};\n",
    "    for fold in range(1, 6):\n",
    "        print(f\"--Start to preparing fold{fold} dataset...---------------\");\n",
    "        my_dataset['fold{}'.format(fold)] = {}\n",
    "        my_sounds = []\n",
    "        my_labels = []\n",
    "        for k in classes_dict:\n",
    "            cur_src_dir = os.path.join(src_path,classes_dict[k]);\n",
    "            print(f\"current source directory:{cur_src_dir}\");\n",
    "            for wav_file in sorted(glob.glob(os.path.join(cur_src_dir, '*.wav'))):\n",
    "                sound = wavio.read(wav_file).data.T[0]\n",
    "                start = sound.nonzero()[0].min()\n",
    "                end = sound.nonzero()[0].max()\n",
    "                sound = sound[start: end + 1]  # Remove silent sections\n",
    "                # label = k;#int(os.path.splitext(wav_file)[0].split('-')[-1])\n",
    "                my_sounds.append(sound)\n",
    "                my_labels.append(k)\n",
    "                print(f\"sound:{wav_file}\\nlabel:{k}\") \n",
    "        print(f\"--End of preparing fold{fold} dataset-------------------\");\n",
    "\n",
    "        my_dataset['fold{}'.format(fold)]['sounds'] = my_sounds\n",
    "        my_dataset['fold{}'.format(fold)]['labels'] = my_labels\n",
    "\n",
    "    np.savez(dst_path, **my_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d45db13e-f528-446d-af18-b35bcfeab459",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_npz_folder = \"../../../RLRepo/Works/Projects/TransferLearning_for_ACDNet/datasets/fsd50k_processed_audios/test_fsd50_20K.npz\"\n",
    "# create_dataset(test_dest_wav_dir,save_npz_folder);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "952a17f0-5fc8-4820-9473-59dd4ca6a3b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_train_npz(train_npz):\n",
    "    dataset = np.load(train_npz, allow_pickle=True);\n",
    "    print(f\"len of sound:{len(dataset['fold1'].item()['sounds'][123])}\");\n",
    "    print(f\"label:{dataset['fold1'].item()['labels'][123]}\");\n",
    "    # print(f\"sound:{dataset['fold3'].item()['sounds'][123]}\");\n",
    "    # print(f\"label:{dataset['fold3'].item()['labels'][123]}\");\n",
    "    # train_sounds = []\n",
    "    # train_labels = []\n",
    "    # for i in range(1, opt.nFolds + 1):\n",
    "    #     sounds = dataset['fold{}'.format(i)].item()['sounds']\n",
    "    #     labels = dataset['fold{}'.format(i)].item()['labels']\n",
    "    #     if i != split:\n",
    "    #         train_sounds.extend(sounds)\n",
    "    #         train_labels.extend(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4dc93c7c-986c-4d1f-95a6-5600f404b2a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load_train_npz(\"../../../RLRepo/Works/Projects/TransferLearning_for_ACDNet/datasets/fsd50k_processed_audios/train_fsd50_20K__202401041450.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e9b07898-b33f-4e09-9171-82444472c2a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ValGenerator():\n",
    "    #Generates data for Keras\n",
    "    def __init__(self, samples, labels, options):\n",
    "        random.seed(42);\n",
    "        #Initialization\n",
    "        print(len(samples));\n",
    "        self.data = [(samples[i], labels[i]) for i in range (0, len(samples))];\n",
    "        self.opt = options;\n",
    "        self.batch_size = 88;#options.batchSize // options.nCrops;\n",
    "        self.preprocess_funcs = self.preprocess_setup();\n",
    "        self.map_dict= {\n",
    "            17:1, #pouring_water\n",
    "            18:2, #toilet_flushing\n",
    "            21:3, #snezzing\n",
    "            24:4, #coughing\n",
    "            51:5, #kettle_sound\n",
    "            52:6, #alarm\n",
    "            #53:\"53_boiling_water_bubble_sound\", #boiling_water_bubble_sound\n",
    "            54:7, #rington\n",
    "            55:8, #shower_water\n",
    "            56:9, #pain_sounds\n",
    "            57:10, #footsteps\n",
    "            98:11, #silence\n",
    "            99:12, #other_sounds\n",
    "        };\n",
    "\n",
    "    def get_data(self):\n",
    "        #Generate one batch of data\n",
    "        x, y = self.generate();\n",
    "        x = np.expand_dims(x, axis=1)\n",
    "        x = np.expand_dims(x, axis=3)\n",
    "        print(x.shape);\n",
    "        print(y.shape);\n",
    "        return x, y\n",
    "\n",
    "    def generate(self):\n",
    "        #Generates data containing batch_size samples\n",
    "        sounds = [];\n",
    "        labels = [];\n",
    "        indexes = None;\n",
    "        for i in range(self.batch_size):\n",
    "            sound, target = self.data[i];\n",
    "            target = self.map_dict[target] - 1;\n",
    "            sound = self.preprocess(sound).astype(np.float32)\n",
    "            label = np.zeros((self.opt.nCrops, self.opt.nClasses));\n",
    "            label[:,target] = 1;\n",
    "\n",
    "            sounds.append(sound);\n",
    "            labels.append(label);\n",
    "\n",
    "        sounds = np.asarray(sounds);\n",
    "        labels = np.asarray(labels);\n",
    "        print(f\"sounds shape:{sounds.shape}\")\n",
    "        sounds = sounds.reshape(sounds.shape[0]*sounds.shape[1], sounds.shape[2]);\n",
    "        labels = labels.reshape(labels.shape[0]*labels.shape[1], labels.shape[2]);\n",
    "\n",
    "        return sounds, labels;\n",
    "\n",
    "    def preprocess_setup(self):\n",
    "        funcs = []\n",
    "        funcs += [U.padding(self.opt.inputLength // 2),\n",
    "                  U.normalize(32768.0),\n",
    "                  U.multi_crop(self.opt.inputLength, self.opt.nCrops)]\n",
    "\n",
    "        return funcs\n",
    "\n",
    "    def preprocess(self, sound):\n",
    "        for f in self.preprocess_funcs:\n",
    "            sound = f(sound)\n",
    "\n",
    "        return sound;\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e27aebb6-abc2-494d-9642-6926f71a4168",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_test_data_src_npz(src_path, dst_path):\n",
    "    # print('* {} -> {}'.format(src_path, dst_path))\n",
    "    classes_dict = {\n",
    "        17:\"17_pouring_water\", #pouring_water\n",
    "        18:\"18_toilet_flushing\", #toilet_flushing\n",
    "        21:\"21_sneezing\", #snezzing\n",
    "        24:\"24_coughing\", #coughing\n",
    "        51:\"51_kettle_sound\", #kettle_sound\n",
    "        52:\"52_alarm\", #alarm\n",
    "        #53:\"53_boiling_water_bubble_sound\", #boiling_water_bubble_sound\n",
    "        54:\"54_ringtone\", #rington\n",
    "        55:\"55_shower_water\", #shower_water\n",
    "        56:\"56_pain_sounds\", #pain_sounds\n",
    "        57:\"57_footsteps\", #footsteps\n",
    "        98:\"98_silence\", #silence\n",
    "        99:\"99_other_sounds\", #other_sounds\n",
    "    };\n",
    "    \n",
    "    my_dataset = {};\n",
    "    my_sounds = []\n",
    "    my_labels = []\n",
    "    my_dataset['testdata'] = {}\n",
    "    for k in classes_dict:\n",
    "        cur_src_dir = os.path.join(src_path,classes_dict[k]);\n",
    "        print(f\"current source directory:{cur_src_dir}\");\n",
    "        for wav_file in sorted(glob.glob(os.path.join(cur_src_dir, '*.wav'))):\n",
    "            sound = wavio.read(wav_file).data.T[0]\n",
    "            start = sound.nonzero()[0].min()\n",
    "            end = sound.nonzero()[0].max()\n",
    "            sound = sound[start: end + 1]  # Remove silent sections\n",
    "            # label = k;#int(os.path.splitext(wav_file)[0].split('-')[-1])\n",
    "            my_sounds.append(sound)\n",
    "            my_labels.append(k)\n",
    "            print(f\"sound:{wav_file}\\nlabel:{k}\") \n",
    "    print(f\"--End of preparing test dataset-------------------\");\n",
    "\n",
    "    my_dataset['testdata']['sounds'] = my_sounds\n",
    "    my_dataset['testdata']['labels'] = my_labels\n",
    "\n",
    "    np.savez(dst_path, **my_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0ecf09c9-6c8d-46ab-9a8e-e68c80dc8b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_test_npz_folder = \"./datasets/fsd50k_processed_audios/Src_test_fsd50_20K_data.npz\"\n",
    "# create_test_dataset(test_dest_wav_dir,save_test_npz_folder);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3d8f5658-f828-49bb-adcb-3b96a1d57078",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_test_npz(test_npz):\n",
    "    dataset = np.load(test_npz, allow_pickle=True);\n",
    "    # sound_ary = np.asarray();\n",
    "    sound_tmp = dataset['testdata'].item()['labels'];\n",
    "    print(f\"len of test sounds is {len(sound_tmp)}\")\n",
    "        # extend(repeat(x, 100))\n",
    "    # sound_data = []\n",
    "    # sound_data.extend(sound_tmp, len(sound_tmp))\n",
    "    # print(dataset['x'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "45124e96-7c79-4892-a449-828f2d388270",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load_test_npz(\"./datasets/fsd50k_processed_audios/Src_test_fsd50_20K_data.npz\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2c7d8fc8-07a6-486f-8c50-4afd79c82abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_test_npz(test_src_npz=None):\n",
    "    opt = getOpts();#opts.parse();\n",
    "    opts.display_info(opt);\n",
    "    opt.batchSize=88;\n",
    "    for sr in [20000]:\n",
    "        opt.sr = sr;\n",
    "        opt.inputLength = 30225;\n",
    "        # mainDir = os.getcwd();\n",
    "        # test_data_dir = os.path.join(mainDir, './datasets/fsd50k_processed_audios/');\n",
    "        # print(test_data_dir)\n",
    "        # if not os.path.exists(test_data_dir):\n",
    "        #     os.mkdir(test_data_dir);\n",
    "\n",
    "        val_sounds = [];\n",
    "        val_labels = [];\n",
    "        dataset = np.load(test_src_npz, allow_pickle=True);\n",
    "        # for s in opt.splits:\n",
    "        start_time = time.perf_counter();\n",
    "        sounds = dataset['testdata'].item()['sounds'];\n",
    "        labels = dataset['testdata'].item()['labels'];\n",
    "        val_sounds.extend(sounds);\n",
    "        val_labels.extend(labels);\n",
    "\n",
    "        valGen = ValGenerator(sounds, labels, opt);\n",
    "        valX, valY = valGen.get_data();\n",
    "\n",
    "        # print('{}/test_data_20K'.format(test_data_dir, s));\n",
    "        np.savez_compressed('../acdnet_trained_data/test_data_20K', x=valX, y=valY);\n",
    "        print('test with shape x{} and y{} took {:.2f} secs'.format(valX.shape, valY.shape, time.perf_counter()-start_time));\n",
    "        sys.stdout.flush();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b93c7d6a-94b6-46fc-900e-476d71072e55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------+\n",
      "| ACDNet_TL_Model_Extend Sound classification\n",
      "+------------------------------+\n",
      "| dataset  : uec_iot\n",
      "| nEpochs  : 10\n",
      "| LRInit   : 0.1\n",
      "| schedule : [0.3, 0.6, 0.9]\n",
      "| warmup   : 10\n",
      "| batchSize: 88\n",
      "| Splits: [1, 2, 3, 4, 5]\n",
      "+------------------------------+\n",
      "88\n",
      "sounds shape:(88, 4, 30225)\n",
      "(352, 1, 30225, 1)\n",
      "(352, 12)\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../acdnet_trained_data/test_data_20K.npz'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mcreate_test_npz\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m../acdnet_training_data/single_fold/Src_test_fsd50_20K_data.npz\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m;\n",
      "Cell \u001b[0;32mIn[25], line 28\u001b[0m, in \u001b[0;36mcreate_test_npz\u001b[0;34m(test_src_npz)\u001b[0m\n\u001b[1;32m     25\u001b[0m valX, valY \u001b[38;5;241m=\u001b[39m valGen\u001b[38;5;241m.\u001b[39mget_data();\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# print('{}/test_data_20K'.format(test_data_dir, s));\u001b[39;00m\n\u001b[0;32m---> 28\u001b[0m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msavez_compressed\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m../acdnet_trained_data/test_data_20K\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalY\u001b[49m\u001b[43m)\u001b[49m;\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest with shape x\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m and y\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m took \u001b[39m\u001b[38;5;132;01m{:.2f}\u001b[39;00m\u001b[38;5;124m secs\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(valX\u001b[38;5;241m.\u001b[39mshape, valY\u001b[38;5;241m.\u001b[39mshape, time\u001b[38;5;241m.\u001b[39mperf_counter()\u001b[38;5;241m-\u001b[39mstart_time));\n\u001b[1;32m     30\u001b[0m sys\u001b[38;5;241m.\u001b[39mstdout\u001b[38;5;241m.\u001b[39mflush()\n",
      "File \u001b[0;32m~/miniconda3/envs/acdnetenv/lib/python3.10/site-packages/numpy/lib/npyio.py:710\u001b[0m, in \u001b[0;36msavez_compressed\u001b[0;34m(file, *args, **kwds)\u001b[0m\n\u001b[1;32m    647\u001b[0m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_savez_compressed_dispatcher)\n\u001b[1;32m    648\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msavez_compressed\u001b[39m(file, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds):\n\u001b[1;32m    649\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    650\u001b[0m \u001b[38;5;124;03m    Save several arrays into a single file in compressed ``.npz`` format.\u001b[39;00m\n\u001b[1;32m    651\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    708\u001b[0m \n\u001b[1;32m    709\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 710\u001b[0m     \u001b[43m_savez\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/acdnetenv/lib/python3.10/site-packages/numpy/lib/npyio.py:736\u001b[0m, in \u001b[0;36m_savez\u001b[0;34m(file, args, kwds, compress, allow_pickle, pickle_kwargs)\u001b[0m\n\u001b[1;32m    733\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    734\u001b[0m     compression \u001b[38;5;241m=\u001b[39m zipfile\u001b[38;5;241m.\u001b[39mZIP_STORED\n\u001b[0;32m--> 736\u001b[0m zipf \u001b[38;5;241m=\u001b[39m \u001b[43mzipfile_factory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mw\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    738\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, val \u001b[38;5;129;01min\u001b[39;00m namedict\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m    739\u001b[0m     fname \u001b[38;5;241m=\u001b[39m key \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.npy\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/acdnetenv/lib/python3.10/site-packages/numpy/lib/npyio.py:103\u001b[0m, in \u001b[0;36mzipfile_factory\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mzipfile\u001b[39;00m\n\u001b[1;32m    102\u001b[0m kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mallowZip64\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 103\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mzipfile\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mZipFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/acdnetenv/lib/python3.10/zipfile.py:1251\u001b[0m, in \u001b[0;36mZipFile.__init__\u001b[0;34m(self, file, mode, compression, allowZip64, compresslevel, strict_timestamps)\u001b[0m\n\u001b[1;32m   1249\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m   1250\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1251\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfp \u001b[38;5;241m=\u001b[39m \u001b[43mio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilemode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1252\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n\u001b[1;32m   1253\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m filemode \u001b[38;5;129;01min\u001b[39;00m modeDict:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../acdnet_trained_data/test_data_20K.npz'"
     ]
    }
   ],
   "source": [
    "create_test_npz(\"../acdnet_training_data/single_fold/Src_test_fsd50_20K_data.npz\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64353f7e-e4c4-4cf3-9fbd-b27d2d4b5c14",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
